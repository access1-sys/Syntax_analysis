1.txt,The bounded confidence model has been widely used to formally study groups of agents who are  sharing opinions with those in their epistemic neighborhood.,has been widely used to
2.txt,"We revisit the model with an eye  toward studying disinformation campaigns, which have been much in the news of late.",with an eye  toward
3.txt,"To that end, we introduce typed agents into the model, specifically agents who can be irresponsible  in different ways, most notably, by being deceitful, but also by being reluctant to try and obtain  information from the world directly.",To that end
4.txt,"We further add a mechanism of confidence dynamics to the  model, which among other things allows agents to adapt the closeness threshold for counting  others as being their epistemic neighbors.",add to
5.txt,This will be used to study the effectiveness of possible  defense mechanisms against disinformation efforts.,This will be used to
7.txt,There is much recent work on how best to organize communities of interacting agents if such communities  are to achieve some fixed goal.,There is much recent work on
8.txt,"For instance, researchers have looked into whether putting  in place certain types of communication structures enables us to improve the efficacy of our beliefforming  practices.","For instance,researchers have looked into"
9.txt,"Most of this work assumes  communities to consist of strictly benevolent agents, all of whom are willing to contribute to the  common goal.",consist of
11.txt,"Our main focus will be on whether certain kinds of communication structures certain sets of rules for  determining who to talk and listen to, and for how to take their opinions into account offer better  protection against such campaigns than others.",Our main focus will be on
12.txt,We trust that the importance of our research topic needs little stressing.,the importance of
13.txt,"Mis- and disinformation  campaigns, for financial or political gains, and sometimes for reasons we are still grappling to  understand, are the order of the day.",null
14.txt,"At least since the campaigns preceding the vote on Brexit and the 2016 presidential election in the United States, it is generally recognized how dangerous this trend is,jeopardizing the foundations of Western democracies and possibly even the future of our planet as a  habitable place.",it is generally recognized
17.txt,"These publications have come from academic researchers,but also from think tanks, and governmental and nongovernmental bodies.",come from
19.txt,"Much of this research has led to valuable new insights, and many of the suggested fixes are causes  worth fighting for.",led to
21.txt,This paper aims to address these and related questions with the help of agent-based computational  models.,aims to address these and related questions
22.txt,"More specifically, our methodological starting point is the  so-called bounded confidence model ; if not introspectively clear, there is undeniable evidence that  we do form our opinions on the basis of both the opinions of others and the results of our probing  the world directly.",on the basis of
23.txt,"In its extant form, however, the BC model assumes all agents to act responsibly in that they do not  hide their opinions from others in the group, let alone lie about their real opinions to mislead those  others, and that they are open to the information that comes in from the world.",null
25.txt,This paper aims to take some first steps toward mending that situation by proposing two extensions  to the model.,aims to take some first steps toward
26.txt,"Specifically, we extend the model by introducing  taken to be the same for all  agents in a community.",we extend the model by introducing
28.txt,"No one should expect a formal analysis of communication structures, on its own, to suggest an  easy fix of the problems that mis- and disinformation campaigns are causing.",null
29.txt,"What we are aiming at  instead is to achieve a deeper understanding of why these problems have proven so recalcitrant, and to  get at least some sense of the direction or directions in which progress may lie.",aiming at
30.txt,"We start, in Section 2.1, by summarizing the BC model in its original form and by highlighting some important limitations.",in its original form
31.txt,"In Section 3, we present the first extension of the model, featuring different types of agents.",null
32.txt,"Section 4 adds the second extension, introducing the concept of confidence dynamics.",the concept of
33.txt,"In both sections, we also show how the new machinery can be used to address questions concerning  the degrees to which evildoers are able to exploit different settings of the parameters of the model.",can be used to address questions concerning
35.txt,"In this section, we review previous work on the BC model and some of its notable variants, which  collectively serve as a starting point for the present research.",null
36.txt,We also say more about the questions that  motivate our endeavor.,null
37.txt,The broad availability of fast and powerful computers has made agent-based computational modeling  a popular tool for studying complex social phenomena that are difficult or even impossible to investigate  analytically.,are difficult or even impossible to
38.txt,"A relatively recent branch of this program focuses on socio-epistemic phenomena,  specifically aspects of knowledge and belief acquisition to which the interaction among agents is central.",focus on
39.txt,"For example, it is nowadays regarded as a truism that most successes of modern science could not have  been achieved by researchers working in complete isolation of one another .","For example, it is nowadays regarded as"
40.txt,A widely used agent-based computational model is the one first presented in Krause and  Hegselmann and Krause in which agents change their opinions by averaging over the opinions of those epistemically close to them.,the one first presented in
41.txt,"In Hegselmann and Krause , the agents also receive direct evidence from the world.",null
42.txt,"Thereby the model covers in a  highly idealized way the fundamental structure of our epistemic situation: learning from others and,  at the same time, learning from the world.",at the same time
43.txt,Many publications have used the model for investigating  descriptive questions,have used the model for
44.txt,"Due to many open questions still lies, a major focus of studies lay on the time that it  takes to reach a stable final pattern.","Due to many open questions still lies, a major focus of studies lay on"
45.txt,"Other work has recruited the model to shed light on a number of normative issues of  interest mostly to philosophers, for instance, concerning the practice of assertion , the  resolution of disagreement amongst peers , and efficient truth approximation.",for instance
47.txt,Crosscombe and Lawry are interested in the issue of  vagueness and present a further extension of the BC model which is populated by agents whose beliefs  can consist of intervals rather than point estimates.,rather than
48.txt,"Somewhat more complicated extensions are to be  found in Lorenz, Jacobmeier, and Pluchino, Latora, and Rapisarda .",null
49.txt,"In  these extensions, agents hold beliefs about multiple issues at the same time rather than about a single  parameter.",hold beliefs about
50.txt,"While these extensions are still restricted to agents having numerical beliefs on unconnected  issues, Riegler and Douven propose an extension of the BC model populated by agents who can hold many beliefs on issues that are not necessarily numerical and that can be logically interconnected.",hold many beliefs on
51.txt,Douven and Wenmackers  present an extension that deviates even further from the original  BC model .,null
52.txt,"Their extension features agents whose belief states at a given time are characterized by probability functions on a set of self-consistent, mutually exclusive, and  jointly exhaustive hypotheses.",null
53.txt,"They let the agents in the model interact by pooling the probabilities  of those within their BCI, where this notion is redefined in probabilistic terms but entirely in the  spirit of the original model.",in the spirit of
54.txt,"Douven and Wenmackers use this version of the BC model to unpack  the updating on worldly evidence, which in the original BC model is a black box.",null
55.txt,"In particular, they unpack it in two different ways one a version of Bayes  rule, the other a  formalization of so-called Inference to the Best Explanation and compare their behaviors along a  number of epistemically important dimensions.",In particular
56.txt,"The extensions to  be presented in the following could be combined with Douven and Wenmackers  model, but this is a  topic for future research; in the present paper, we stick to treating the updating on worldly evidence as  a black box, as is done in BC.",The extensions to  be presented in the following
57.txt,It is natural to suppose that liars aim to have us believe whatever it is they falsely assert.,It is natural to suppose that
58.txt,"That is not  necessarily the case, however.","That is not  necessarily the case, however."
59.txt,"Their purposes might be served as well if their false assertions make us  retract beliefs we had previously adopted, or keep us from accepting something our evidence would  otherwise have inclined us to believe.",null
60.txt,Depending on what their purpose is converting us to a view  they falsely profess or diverting us from a view we tend to endorse they may want to follow different  strategies of deceit.,Depending on what their purpose is
61.txt,A politician in this kind of situation if cynical enough may reason that a subtle lie on X will not succeed in creating enough doubt about  climate science to have a noticeable effect on the turn-out for their opponent.,have a noticeable effect on
62.txt,"By contrast, a blatant  lie may work, in that it will result in just enough doubt about the opponents view on X  to curb some of the publics erstwhile enthusiasm for the candidate, which in turn  may be just enough to make them stay home on election day.",By contrast
63.txt,"This possibility is far from academic, as  we have all been able to read in reports about the Brexit campaign as well as the Trump campaign for  the 2016 presidential election.",as well as
65.txt,"Assuming an at least minimally rational public, a successful misinformation campaign will automatically  mean a successful disinformation campaign.",null
66.txt,"However, for that same reason, a disinformation  campaign will typically have a greater chance of success than a misinformation campaign.",null
67.txt,Whether a  disinformation campaign is enough will depend on the situation.,depend on
68.txt,"For example, from the perspective of tobacco producers, all that matters may be that people do  not believe that smoking is detrimental to their health .","For example, from the perspective of"
69.txt,The former  may be all that is needed to keep tobacco sales at a profitable level; trying to convince the public that  smoking is actually safe may then come at an additional cost with no corresponding return.,null
70.txt,"Similarly,  to win an election, it may be enough to suppress voter enthusiasm among potential voters for your  opponent.",it may be enough to
71.txt,"These people may never vote for you, but just to dampen voter turnout for your opponent  may be enough for you to win.",null
72.txt,"And to diminish this kind of enthusiasm, it may be enough to divert  the public from the truth, not necessarily to make them believe whatever lies you are spreading.",it may be enough to
73.txt,"On the other hand, most Brexiteers seem to have made a serious effort to convince their countrymen that  Leave was the right choice to make in the referendum .",On the other hand
74.txt,"As mentioned in the introduction, the question whether there is anything we can do to protect  ourselves against these kinds of campaigns has been much in the limelight both in academic and  non-academic publications.",As mentioned in the introduction
75.txt,"Against the background of the mathematical model of communication  we are considering here, we may ask whether it could help to be selective in counting others as our  peers ?",it could help to
76.txt,"More generally, are there combinations of  and values that minimize the likelihood for  a misinformation campaign to succeed?",More generally
77.txt,"If so, do the same combinations offer maximum protection  against disinformation campaigns?",null
78.txt,"There is at least one straightforward answer to these questions, to wit, set either equal to 0 or  equal to 1, or both.",null
79.txt,"If you only go by the evidence you get directly from the world, none of the other  community members will have any influence on how you form your opinions.",have any influence on
81.txt,"Note, however, that this would amount to giving up on social learning entirely, and that we  submit is not a realistic option.",amount to
83.txt,"But even if not, it is certainly correct that,as Schurz  points  out, individual learning tends to be much more costly than social learnin.",it is certainly correct that
84.txt,"Allowing ourselves to be influenced by the views of others is not just  something we happen to do, it is something we ought to do in addition to investigating the world  ourselves, rather than as a replacement for that.",it is something we ought to do
85.txt,"Hence, what we should be looking for is a possibility  to be at the same time somewhat sensitive to the opinions of others and still relatively safe from misand  disinformation campaigns.",at the same time
86.txt,it appears eminently suitable to investigate the above kind of  questions.,it appears eminently suitable to
87.txt,"Unfortunately, however, and as indicated already, in its present form the model makes  no provision for representing untruthful agents, the kind of agents running mis- or disinformation  campaigns.",makes no provision for
88.txt,"The assumption that all agents are truthful may, for many purposes, be a harmless and  perhaps even useful idealization but it makes the model unusable as a tool for answering questions  about mis- and disinformation campaigns.",it makes the model unusable as a tool for
89.txt,"As we mentioned, however, one reason why the BC model has gained popularity is its great  flexibility.",one reason why the BC model has gained popularity is
90.txt,"In the following we aim to show that, because of this flexibility, the above questions do not  motivate a radical rethinking of the computational modeling of epistemically interacting agents.",we aim to show that
91.txt,"To the contrary, it is relatively easy to concretize or deidealize the BC model with an eye toward modeling interactions among agents not all of whom are  truthful or willing to make a serious effort of informing themselves.","To the contrary, it is relatively easy to"
92.txt,"In the next section, we take a first step toward this concretization, by extending the BC model to  one that covers communities with non-truthful agents.",take a first step toward
93.txt,"In Section 4, we address another limitation of  the BC model, to wit, that it treats the level of  open-mindedness, in the sense of willingness to take  others opinions into account, as being fixed, instead of being itself open to change.",address another limitation of
94.txt,"The first extension  allows us to model the kind of mis- and disinformation campaigns that motivated the present project,  the second allows us to model possible countermeasures against such campaigns.",null
95.txt,"In the extension to the BC model to be introduced in this section, agents are typed according to how  epistemically responsible they are.",In the extension to the BC model to be introduced in this section
96.txt,"We look at the effects of irresponsible agents on the truth-seeking  endeavors of the responsible agents, where the latter are the agents that already populated the original  BC model.",the effects of
97.txt,The agents that populated the original BC model will henceforth be called truth-seekers.,null
98.txt,"In a first  step, we introduce only one new type of agents, to be calledcampaigners.",In a first step
99.txt,Agents of this new type  do not update in the normal way.,null
100.txt,"In fact, in a clear sense they do not update at all, but rather stick to a  fixed opinion  [0, 1] about the value of .","In fact, in a clear sense"
101.txt,"In all situations to be considered, it will hold that, though important questions will concern how far removed  is from .",it will hold that
102.txt,"Formally, then, the extension to be studied first is characterized by the following bounded confidence with campaigners are as defined previously.",is characterized by
103.txt,"As a further extension, we also want to introduce a type of agent unwilling to gather, or even listen to, worldly evidence but only updating by averaging the opinions of those within her BCI.",As a further extension
104.txt,We refer to such agents as free riders.,refer to
105.txt,"These agents may not have an agenda, hidden or otherwise, to deflect the  truth-seekers from the truth.",null
106.txt,"But their unwillingness to make a serious effort to inform themselves,  other than by listening to their epistemic neighbors, may nonetheless make them complicit in mis- or  disinformation efforts.",make a serious effort to
107.txt,Whether that is really so is something we hope to determine.,null
108.txt,The formal specification of this bounded confidence with campaigners and free riders .,null
109.txt,"Needless to say, our focus will be only on the truth-seekers and, when present, the free riders; as for the campaigners, there is nothing to know about them that we do not know already from their  definition: they simply stick to their fixed opinion under all circumstances, no matter how many  updates we consider.",there is nothing to know about
110.txt,The first questions now to be looked at are how much damage to a society the presence of campaigners can do.,looked at
111.txt,"To develop an understanding of the impact campaigners can have, we start with the simplest model.",null
112.txt,"Thus, whatever the value of  may be,  does not have any influence on the dynamics.",have any influence on
113.txt,"Here and elsewhere, the communities we look at will always include 50 truth seekers, unless indicated  otherwise.",look at
114.txt,"For the first experiment, we consider a variable number of campaigners, that is, agents who do not attend to any other opinion .",null
115.txt,"It is clearly seen that how many others get converted, on average, depends on  the number of campaigners present in the community and on how liberal the others are in counting  others as their peers.",It is clearly seen that
116.txt,We might already seem to face a puzzling phenomenon here.,null
117.txt,"in the left panel of Figure 2, we see that conversion is more successful with fewer campaigners  present than with more of them present, where one might have expected to find the opposite.",null
118.txt,"On  closer inspection, however, the phenomenon is easily understandable.",null
119.txt,"It is due to the fact that the  more campaigners there are, the greater the pull their opinion  exerts on the truth-seekers in their  vicinity, and the greater the chance there will occur an early split among the truth-seekers.",It is due to the fact that
120.txt,"With fewer  campaigners, truth-seekers in their vicinity are also pulled in their direction, but not as strongly, it is easier for other truth-seekers to catch on.",it is easier for
121.txt,"And by catching on, these others can also come under the influence of the campaigners and thereby eventually end up believing .",null
122.txt,"By contrast, if an early split  occurs, some truth-seekers may forever remain out of the reach of the campaigners.",By contrast
123.txt,"The single runs  shown in Figure 3, one featuring eight campaigners , the other fifty, illustrate  this phenomenon.",null
124.txt,Now let us have a look at the more interesting kind of case in which is not equal to 0 and so  the truth-seekers also base their updates on evidence coming from the world.,base on
126.txt,The foregoing result indicates that this may depend on what that opinion is and also on how many campaigners there are in the community.,depend on
128.txt,Figure 4 indicates an answer to the second question.,null
129.txt,"It shows, averaged over 100 simulations for  each combination of number of campaigners and value, the number of truth-seekers whose opinion  equals  in the fixed point .",null
130.txt,"The results are for three values  of  only, but the trend is manifest.",null
131.txt,"The rate at which truth-seekers have been effectively disinformed  in the fixed point depends on bothand the number of campaigners, but most importantly it depends on how far from the truth the campaigners  opinion is.",most importantly it depends  on
132.txt,"We see that, from the perspective of the  campaigners, supposing their goal is disinformation, it pays to be subtle.",from the perspective of
133.txt,This will be a recurring  theme.,null
134.txt,"We are not showing any figures related to the first question, simply because there is not much  of interest to be shown: for the aforementioned parameter settings, none of the truth-seekers get  converted to the campaigners  opinion.",there is not much  of interest to be shown
135.txt,"It is in fact only when the campaigners get very subtle for  instance, by holding an opinion of 0.11  and when we lower  quite a bit, like  to 0.05, that conversion starts to occur,  this may  still only occur if the number of campaigners present in the community is near its maximum.",It is in fact that
136.txt,"Under  circumstances that are just barely less extreme, truth-seekers, while massively lured away from the  truth, are still enough in touch with the world to not become misinformed.",null
137.txt,"So far, we have only considered communities that consisted of truth-seekers and campaigners.",consist of
138.txt,"But in addition we ran simulations with communities that also featured fixed numbers of free riders, agents who are not dogmatic but who update strictly by averaging the opinions of those within their  BCI.",in addition
139.txt,"More exactly, we reran three times the simulations whose results are visualized in Figure 4, once  with 10 free riders added, once with 25, and once with 50.",null
140.txt,"The question we were interested in was what effect the presence of those numbers of free riders had on the number of truth-seekers that ended up,in the fixed point, believing the truth.",The question we were interested in was
141.txt,"Figure 5 brings out the effects for the nine kinds of situations  by plotting the results,for any combination of number of campaigners present and value.",brings out the effects for
142.txt,"Note that, in principle, this can yield results from C50 to 50.",in principle
143.txt,"meaning that for various combinations of parameter settings, the  presence of free riders has a clear negative epistemic effect on the truth-seekers.",has a clear negative epistemic effect on
144.txt,It is remarkable that  the results are largely insensitive to how many free riders there are: the risk brought about by 50 free  riders seems only slightly greater than that brought about by just 10.,It is remarkable that  the results are largely insensitive to
145.txt,To further clarify the results: the yellow slivers in Figure 5 indicate combinations of parameter settings for which truth-seekers that tend to arrive at the truth in the fixed point when no free riders are  present are diverted from the truth in the fixed point when free riders are present.,null
146.txt,"In other words, in  the yellow areas, the presence of free riders helps to bring about the success of disinformation attempts  that would otherwise have faltered.",In other words
147.txt,"The patterns in the various plots may at first appear mysterious, but in fact they are easy to explain.",in fact
148.txt,"As Figure 6 illustrates, depending on the value of, the campaigners may be able to hold all or some free riders hostage, not necessarily in the sense that those free riders side with the campaigners,but at least in the sense that their opinions remain under the influence of the  campaigners  fixed opinion.",depending on
149.txt,"And we see that free riders starting with an opinion below 0.5 rapidly come to side with the truth-seekers, who all end up believing the truth, not held back by any of the free riders.",null
150.txt,That is very different in the upper right panel.,That is very different in
151.txt,"Unfortunately for the latter, because the free riders remain within their BCI, they are stuck with an  opinion that is not quite the truth.",stuck with an  opinion
154.txt,"This means that, while they may have no interest in furthering the  campaigners  cause, free riders at least take the risk of doing so.",have no interest in
155.txt,"Hence, in view of the results shown in Figure 5, it seems reasonable to conclude that free  riders are to some extent  furthering the campaigners  cause.","in view of the results shown in Figure 5, it seems reasonable to conclude that"
156.txt,"Below, we will be more precise about what damage free riders can do.",be more precise about
157.txt,"Before turning to that question, however, we want to briefly mention a variation of the above simulations that we will not  explore in any depth here, but that interested readers may want to investigate using the code in the  Supplementary Materials.",null
158.txt,"So far, we kept one parameter constant, number of truth-seekers .",So far
159.txt,"Instead, one could consider a setup in which the total numbers of agents truthseekers is kept constant, and in which we go through all combinations  of numbers of the three types of agents yielding that constant.",null
160.txt,The question about conversion  could then be asked for each of those  combinations.,null
162.txt,This figure is a so-called ternary plot.,null
163.txt,"For any point represented in the plot, the proportion of agents of the type associated with a given vertex is the shortest distance from the point to the edge  opposite the vertex, divided by the sum of the lengths of the shortest distances from the point to the  various edges.",the proportion of
164.txt,Each point in the plot shows the outcome of one  simulation for the corresponding combination of agents.,Each point in the plot shows
165.txt,The figure reveals a somewhat intricate pattern.,null
166.txt,"At the same time it is clear, however, that the  relative number of free riders in the population is decisive for whether the truth-seekers reach their  goal.",At the same time it is clear that
167.txt,"Where there are relatively few of the former, the truth-seekers arrive at the truth even when vastly outnumbered by campaigners.",arrive at
168.txt,"By contrast, where free riders constitute a sizable portion of the  population, they keep the truth-seekers away from the truth even if there are only very few campaigners  in the population.",By contrast
169.txt,"While we leave a further analysis of this result, and more generally the pursuit of  this variant of our previous simulations, for future research, it is still worth noting how even these  preliminary results underscore the above conclusion about the negative role of free riders.",it is still worth
170.txt,"The truth-seekers have a clear goal, to wit, finding out the truth.",have a clear goal
171.txt,"If campaigners can make it harder or  even impossible for truth-seekers to reach that goal, that could be said to constitute societal damage.",make it harder or  even impossible for
172.txt,"We propose to measure the amount of damage being done by campaigners in terms of the accuracy of  the opinions of the truth-seekers, more specifically by asking how much less accurate .",propose to
173.txt,"We compare four different situations featuring communities of agents who interact  according to the BC model extended to incorporate campaigners, and who receive input from the  world.",null
174.txt,"In all, there are 50 truth-seekers, who, starting with an opinion drawn randomly per agent, are  going to update 50 times.",In all
175.txt,"The two questions now are whether the presence of campaigners makes a difference to the accuracy  of the truth-seekers, and whether it matters how far from the truth the campaigners  opinion is.",makes a difference to
176.txt,"To answer these questions, we ran 1000 simulations for each of the four communities and measured in  each simulation the total inaccuracy .",null
177.txt,"Thus, the answer to our first question is that the presence of campaigners can come at a significant  societal cost, even if it is not guaranteed to do so.",it is not guaranteed to do
178.txt,"Remarkably, campaigners, at least in the case at hand,  compromise the accuracy of their truth-seeking community members the most if they are subtle.",null
179.txt,"At first blush, one might expect greater extremism on the part of the campaigners to do more damage to  the truth-seekers, in which case the fact that the extremists did not significantly affect the accuracy of  the truth-seekers at all may come as a surprise.",null
180.txt,"On more careful consideration, however, it makes a lot  of sense that blatant lying, or at least spreading blatant falsehoods, is going to be ineffective, simply  because the blatancy of the falsehoods makes those spreading them more easily identifiable as agents  whose opinions are to be discounted.",it makes a lot  of sense that
181.txt,"This is only an example, but the finding that campaigners are damaging only if they are subtle is quite  robust, holding across a range of combinations of parameter settings.",null
183.txt,"That being subtle is, under a broad range of conditions, the  better strategy from the campaigners  perspective is a finding we encountered before, and later on we  shall encounter it again.",null
184.txt,"Above, we looked at the impact that free riders could have on the conversion rate.",looked at the impact that
185.txt,"Let us also look if there is, or may be, any societal cost associated with their presence.",associated with
186.txt,"Example 3.2 We saw that, for the conversion rate, the number of free riders present did not seem to  matter much.",null
187.txt,"For most combinations of number of campaigners and values, if the presence of free  riders had an effect on conversion, it did so whether there were as many free riders as truth-seekers or  only a small minority of free riders.",had an effect on
188.txt,"Thus, consider four communities, all of which contain 50 truth-seekers and 15 campaigners, but the first of which contains only those agents, the second contains also 10 free riders, the third 25 free  riders, and the fourth 50.",null
189.txt,"Moreover, the following parameter settings hold in all of them.",null
190.txt,"We are measuring again the total sum of squared errors over 50 updates,running 1000 simulations per community.",null
191.txt,A visual comparison of the results is given in Figure 9.,comparison of
192.txt,"We discern a slight upward trend in SSEs as the number of free riders increases, although it is not immediately obvious from the figure whether  the impact is significant.",it is not immediately obvious from
193.txt,An ANOVA reveals that it is F  to differ significantly from each other.,it is F to differ significantly from
194.txt,It is equally unsurprising that we find a large effect size.,It is equally unsurprising that
195.txt,"Free riders, even if there were no chance that they impacted the accuracy of the truth-seekers, are morally blameworthy for the very general reason that they reap the benefits of the work done by others  while not making any contribution from which others could benefit in return.",there were no chance that
196.txt,"there is an additional reason, namely, precisely the fact that free  riders can significantly and greatly compromise the accuracy of the opinions of those willing to directly  seek information about the world;",there is an additional reason
197.txt,"it is quite reasonable to assume that people may want to adjust their broad- or narrow-mindedness  in counting others as peers, if perhaps just by imitation.",it is quite reasonable to assume that
198.txt,"Being around broad-minded or trusting  people, who are willing to take into account a great variety of opinions.",take into account
199.txt,"Indeed, we may all be uncertain to some extent about how  liberal we should be in listening to others, and we may well let ourselves be guided in this respect by  whoever we recognize as our current peers.",we may all be uncertain to
200.txt,"Moreover, adjusting our BCI may be a defense mechanism against the efforts of the campaigners  to convert us to their opinion or at least divert us from the truth.",null
201.txt,"After all, campaigners will not let  anyone influence their opinion, so they effectively have an of 0.",null
202.txt,Being in the neighborhood of such  people may make us more selective as regards deeming others worthy of influencing our opinion.,null
203.txt,"But that also offers some protection against the campaigners  influence, simply because they are less likely  to be in our peer group.",they are less likely  to
204.txt,"Naturally, for reasons already pointed out, we must guard against becoming  too selective, as that would also annihilate any positive effects social learning can have.",for reasons already pointed out
205.txt,The goal must  be to find the right level of caution.,null
206.txt,"Thus, an agents current peers determine both her new opinion and her new BCI, where the agents  start with a BCI determined by picking, randomly per agent, a real number in an interval ranging from  0 to some contextually set upper bound .",ranging from to
207.txt,"To develop some initial feeling for this further extension, one can compare simulations with and  without CD in a community of only truth-seekers.",compare with
208.txt,The left plot in Figure 11 shows the results for  running the standard BC model till a fixed point is reached.,null
210.txt,"In the figure, it appears that consensus occurs slightly faster without CD.",it appears that consensus occurs
211.txt,A grid  search we conducted did not yield a single parameter setting for which there was a significant difference in accuracy between updating without and updating with CD.,there was a significant difference in
212.txt,"Clearly, however, what we really want  to know is whether there is any effect of CD in .",what we really want  to know is whether there is any effect of
213.txt,"We consider right away communities made up of all three types of agents: truth-seekers, who also  attend to incoming evidence; campaigners, who stick to one and the same opinion from the start.",null
214.txt,We saw in the previous section that campaigners can keep truth-seekers from believing the truth.,keep from
215.txt,We  look at the difference CD may be able to make with regard to this.,look at
217.txt,"If we imagine that the campaigners are trying to lure away from the truth as many of the others  as possible, then we see that they are entirely successful in the situation depicted in the left panel of  Figure 12, in which CD is absent: literally no one ends up believing the truth.",null
218.txt,"All truth-seekers do end up believing something that could be said to be close to the truth, but none of them exactly hits the  mark which is especially disconcerting given that they attach three times as much weight in their  updating to the worldly part as to the social part.",could be said to be close to the truth
219.txt,"Moreover, the free riders are not even close to  in  this situation.",null
220.txt,"By contrast, in the right panel of the same figure, where CD is assumed, not only do all truth-seekers  end up believing the truth, but so does a majority of the free riders.",By contrast
221.txt,"It is also to be noted, however,  that in this situation there is a group of free riders who end up believing the falsehood spread by the  campaigners.",It is also to be noted that
222.txt,"If the latter are meaning to run a misinformation campaign, then they fail completely in  the first situation but at least partly succeed in the second.",null
223.txt,it is hard to give general recommendations concerning opinion dynamics.,it is hard to
224.txt,"In Section 2, we gave the example of a  politician just trying to divert from the truth voters tending toward her opponent, and not necessarily  to make them believe whatever lies she is propagating.",gave the example of
225.txt,"In view of Example 4.1, such a politician might actually be happy with CD being operative.",In view of
226.txt,"On the other hand, the Brexiteers who seriously tried  to convince the British electorate that Leave was their best option may not have been helped by CD.But let us look more systematically at the effects CD may have.",On the other hand
227.txt,A comparison between Figures 13 and 14 suggests a positive answer.,null
228.txt,"These figures show, for various  combinations of numbers of free riders and campaigners, the proportions of truth-seekers ending  up believing the truth and proportions of free riders ending up believing  the truth.",the proportions of
229.txt,The comparison suggests that  which of lying a lot and lying a little is better may entirely depend on whether CD is operative.,depend on
230.txt,"If it is not, then by being more moderate one will keep more truth-seekers and free riders from believing the truth, while if CD is present, then as far as truth-seekers ending up believing the truth is concerned.",as far as
231.txt,"As far as free riders are concerned, lying a little seems to be more effective, although the difference it  makes is small.",As far as free riders are concerned
232.txt,Now let us look at the situation from the perspective of the truth-seekers.,the perspective of
233.txt,Figures 13 and 14 show  that they need not concern themselves much with how many free riders or campaigners there are in their community; these numbers do not appear to matter a whole lot.,null
234.txt,"By contrast, CD can make all the  difference, depending on how far from the truth the misinformation being spread is.",By contrast
235.txt,"Indeed, Figure 13 shows just how dramatic the difference can be when the misinformation is relatively close to the truth:  then virtually all truth-seekers end up believing the truth  if CD is assumed, while virtually no one ends up believing the truth if there is no CD.",is relatively close to
236.txt,"When there is a relatively wide gap between  and , CD hardly makes a difference, as Figure 14 shows; here, the  community appears to be even slightly better off without CD.",makes a difference to
237.txt,These results bear on disinformation campaigns.,null
238.txt,"As for misinformation campaigns, the situation for truth-seekers is similar to the one described on page 11, where we found that, although campaigners  were, under certain circumstances, able to block the truth-seekers from reaching the truth, they were in  general unable to convince the truth-seekers of their fixed opinion.",is similar to
239.txt,"The same turns out to be true here,  and this irrespective of whether CD is assumed.",turns out to be true
240.txt,"For free riders, the picture can look very different, in that, depending on the parameter setting , CD can have a big impact, but not necessarily a positive one.",null
241.txt,"Figure 15 shows, for three different parameter settings, the effect of CD on the proportion of free riders  that side with the campaigners in the fixed point.",the effect of
242.txt,"As is clear from the figure, for two of the three parameter settings there is a greater chance for free  riders to end up with the campaigners in a community with CD than in one without it.",As is clear from the figure
243.txt,"So, in a situation in which evildoers are helped enough if they can sway some free riders perhaps having no hope of diverting any truth-seekers from the truth they may be more effective if they are operating  in a community with CD.",having no hope of
244.txt,"By comparing the top and bottom row of Figure 15, we also see that, if this is what the campaigners are after, they better lie blatantly rather than subtly.",rather than
245.txt,"It is starting to appear  again that, once we admit non-truthfulness in the BC model, the only consistent message may be that  there is no consistent message.",It is starting to appear  again that
246.txt,What is strategically best from the evildoers perspective and what is  best for us to defend ourselves against them both appear to be highly context-dependent.,what is  best for us to
247.txt,"To show the effect of CD on accuracy, we look at what difference it makes if this kind of dynamics is  assumed in the situations studied in Examples 3.1 and 3.2.",the effect of
248.txt,"In the former, we compared in terms of accuracy a community without campaigners with communities with campaigners.",compared with
249.txt,"In the latter example, we compared, also in terms of accuracy, communities with different numbers of free  riders.",compared with
250.txt,In none of the examples did we implement CD.,null
251.txt,"Figure 16 shows the results from running 1,000 simulations for each community and measuring  the SSEs, so that the average starting BCI size of the truthseekers  is the same as the BCI size of the truth-seekers in Example 3.1.",null
252.txt,"In short, it appears that  whether the campaigners lie blatantly or subtly, they are, in a community in which the truth-seekers  adjust their BCIs by averaging in the way described in this section, very limited in the amount of  damage they can do.","In short, it appears that"
253.txt,"We wish we could give a clear and unequivocal answer to the question of whether, in a community  which includes campaigners , it helps when the other agents are open to becoming narrow-minded themselves.",give a clear and unequivocal answer to the question of
254.txt,"But once again,  our results are a mixed bag, indicating that, under certain circumstances, the answer is positive but  that at the same time it would be unwise to recommend CD generally.",at the same time
255.txt,"Finally, we would like to present an extension of the BC model that takes the idea of making BC  updating more realistic one step further still.",we would like to present an extension of
256.txt,"Just as, in reality, BCIs will not be the same for all agents  and from one time step to the next, the weight agents give to their peers  opinions will also not be the  same for all of them, nor remain unchanged through time.",null
257.txt,There is a vast psychological literature on  the so-called conformity bias.,null
258.txt,"In this model, for truth-seekers, their peers influence their new opinion, their BCI, and also the weight  they are going to give to the social part of updating at the next update.",null
260.txt,"But we want a model with full confidence dynamics to allow for a bit more flexibility, by giving  agents some control over how fast their values for  and change under the influence of their peers.",null
261.txt,"For instance, some of us may be much faster in following a trend than others.",For instance
262.txt,"Being around people  who attach great weight to the opinions of their peers, we may want to follow suit but at our own  pace.",attach to
263.txt,"Formally, we may want to move our value for  in the direction of the average of the  values of  our peers, but in doing so we may not want to rush things and do not want to abandon our current  value in favor of that average entirely.",in favor of
265.txt,"Note that this is in fact fully in the spirit of the original BC model, which also gives one control over how fast ones opinion can  change.",in the spirit of
266.txt,"For instance, choosing very small values for  and will guarantee that ones opinion changes  only very slowly.",For instance
267.txt,"To achieve this, we only need to adapt the above model minimally.",null
268.txt,"In particular, we add the  assumption that, for each agent i, there are two further parameters, we could add only free riders, or only campaigners, or both, and we could experiment  with adding different numbers of both, much in the way we have done in the above.",In particular
269.txt,"We could then also raise again the questions that were raised in the above, notably, questions concerning conversion  and accuracy.",null
270.txt,"it is shown that, in a model that is exactly like the simplest version of the BC model except  that it allows all agents to choose their individual  and values, those values are highly significant  predictors of how accurate an agent is over the totality of updates.",it is shown that
271.txt,"This was the outcome from running  1000 simulations with communities of 50 agents all updating 50 times, where at the beginning of each  simulation the value of  was chosen randomly and the agents chose their values for  andrandomly  as well.",at the beginning of
272.txt,"A linear model with sum of squared errors for the various agents as dependent variable, their and values as independent variables, too surprising: it indicates that the more weight agents give to worldly evidence, the less inaccurate they become which is what one would expect.","the more,the less"
273.txt,"The result foris more interesting,  indicating that one also decreases ones inaccuracy by being more inclusive in counting others ones  peers.",being more inclusive in
274.txt,This result is for a model without campaigners and free riders and so not of immediate interest to  our current project.,interest to
275.txt,We mention it because it served as a template for the more involved simulations we  ran that do bear on the question of what social damage is done by campaigners and free riders.,null
276.txt,Each of these simulations started with randomly choosing values for  and  from the unit interval.,null
277.txt,"Also at the beginning of each simulation, truth-seekers and free riders chose their initialvalues as well as their values for .",at the beginning of
278.txt,"Each of  the aforementioned values was chosen from the unit interval, randomly and independently.",null
279.txt,"In each simulation, the agents updated 50 times, and we registered the sum of squared errors of each of the  truth-seekers.",null
280.txt,"In addition to this, we were interested in the impact the absolute distance  between  and  had on the dependent variable.",In addition to
281.txt,"To find out, we fitted a linear model to the simulation  results per combination of number of campaigners and number of free riders and registered the coefficients for all three independent variables together with the associated p values.",null
282.txt,"While we have made the BC model more suitable to the study of large-scale efforts at deceit, we recognize  that it still has limitations which can only be overcome by extending it in ways that go well beyond, for instance, the addition of confidence dynamics that we undertook.",for instance
283.txt,"For example, the restriction of the  agents  opinions to a single issue appears rather serious to us.",For example
284.txt,"After all, it is easily imaginable how one  and the same interest group might want to run a misinformation campaign with regard to one issue  and a disinformation campaign with regard to another.",it is easily imaginable
286.txt,"With regard to one issue, they may have evidence  suggesting that only a blatant lie will rally their own base, even if blatantly lying is likely to alienate  free riders, let alone epistemically responsible agents .",With regard to
287.txt,But this is a step we mention only as an avenue for future research.,But this is a step we mention only as an avenue for future research.
288.txt,"A second limitation concerns the fact that, in our extensions as in the original BC model, agents adopt information coming from the world in a black box fashion, meaning that this part of the actual  updating mechanism remains unspecified.",null
289.txt,This has the advantage of making the model both simple  and general.,the advantage of
290.txt,"On the other hand, there is at least the possibility that the exact updating mechanism that  people employ makes a difference to the degree to which they are susceptible to mis- or disinformation.",On the other hand
291.txt,"We mentioned Douven and Wenmackers  2017 paper, which built on the BC model to compare  Bayesian updating with a form of explanatory reasoning in a social setting .",compare with
292.txt,One notable finding of that work was that the explanation-based update rule they considered  was better able than Bayes  rule to detect the signal in the noise.,was better able than
294.txt,But to investigate this systematically one would need to unpack the  updating mechanism of the extended BC model with typed agents in the way Douven and Wenmackers  unpacked the updating mechanism of the original BC model.,null
295.txt,The aforementioned limitations already suggest two obvious avenues for future research.,null
296.txt,Further  work on the extended model proposed in this paper should also look at issues of interpretation.,proposed in this paper should also look at issues of
297.txt,"In  particular, we have introduced a typology of agents in terms of epistemically responsible behavior.","In particular, we have introduced"
298.txt,"What were called truth-seekers by us were the epistemically responsible agents, while what we called  campaigners were the epistemically irresponsible ones.",null
299.txt,"Note, however, that a radical gestalt switch is possible here: Equations BC, BCC and BCCF are uninterpreted formulas, which get empirical  content by dint of an interpretation that implicitly or explicitly was given in the explanation of  the formulas.",null
300.txt,But we could interpret the central equations  quite differently.,null
301.txt,"For instance, think of those who stay with  all the time as scientists who have found  the truth and will never be dissuaded from it.",For instance
302.txt,"All others, however, are only influenced by the truth  when it is already in their confidence interval.",are influenced by
303.txt,"The agents previously referred to as truth-seekers  are now epistemic villains, namely, members of a conspiratorial group who want to persuade as many  people as possible to believe .",as many people as possible to
304.txt,The conspirators do not reveal their real opinion.,null
305.txt,"At the start of  the dynamics, they distribute themselves randomly across the opinion space; and they agree to move  toward their favored opinion  with a speed controlled by the value of .",At the start of
306.txt,"In another interpretation, the conspirators could simply be bots that are used in a computational propaganda campaign.",are used in
307.txt,"In the probably darkest interpretation, the equations BC,BCCand BCCF describe an opinion dynamics in which two competing manipulation campaigns that use  two different approaches try to persuade innocent individuals.",try to
308.txt,"One campaign tries to persuade the  innocents to believe , the other tries to persuade them to believe .",tries to
309.txt,And the innocents  simply average over all opinions within their confidence interval.,null
310.txt,The basic equations allow for all these interpretations.,null
311.txt,"Finally, Hegselmann and Krause systematically explored the parameter space for the basic  BC model which they presented in that paper and which we summarized in Section 2.1.",presented in
312.txt,"Our main  interest in the current paper was to extend that original model in order to shed some new light on the  kind of epistemically irresponsible behavior that has lately been attracting a good deal of attention,in particular behavior related to mis- and disinformation campaigns.",Our main  interest in the current paper was to
313.txt,"The extended BC model we  developed to that end involves many more parameters than the original BC model, too many to go through the whole parameter space in a systematic fashion.",more than
315.txt,"In  fact, we did better than that, by sampling parameter space and looking for statistically significant  effects of centrally important parameters on a centrally important outcome variable.","In fact, we did better than that"
316.txt,"Moreover, in the Appendix we explain how interested readers can, without much effort, explore  whichever part of parameter space may be of special relevance to their own projects.",null
317.txt,"Still, we do believe that many of the newly introduced features merit further investigation independently of issues of  mis- and disinformation, given that by adding these features we arrived at a more realistic model of  bounded confidence updating.",arrived at
318.txt,"This, too, is left as a future project.",null
319.txt,Current developments in Artificial Intelligence  led to a resurgence of Explainable  AI .,led to
320.txt,New methods are being researched to obtain information from AI systems in  order to generate explanations for their output.,in order to
321.txt,"However, there is an overall lack of  valid and reliable evaluations of the effects on users  experience of, and behavior in  response to explanations.",there is an overall lack of
322.txt,New XAI methods are often based on an intuitive notion what an  effective explanation should be.,are based on
323.txt,Rule-based and example-based contrastive explanations are two  exemplary explanation styles.,null
324.txt,"In this study we evaluate the effects of these two explanation  styles on system understanding, persuasive power and task performance in the context  of decision support in diabetes self-management.",the effects of
325.txt,"Furthermore, we provide three sets of  recommendations based on our experience designing this evaluation to help improve  future evaluations.",based on
326.txt,"Our results show that rule-based explanations have a small positive  effect on system understanding, whereas both rule-base and example-based explanations  seem to persuade users in following the advice even when incorrect.",have a small positive  effect on
327.txt,Neither explanation  improves task performance compared to no explanation.,improves task performance compared to
328.txt,"This can be explained by the fact  that both explanation styles only provide details relevant for a single decision, not the  underlying rational or causality.",null
329.txt,These results show the importance of user evaluations in  assessing the current assumptions and intuitions on effective explanations.,These results show the importance of
330.txt,Humans expect others to comprehensibly explain decisions that have an impact on them.,have an impact on
331.txt,The same holds for humans  interacting with decision support systems  that allow DSS to generate explanations.,null
332.txt,"Aside from the numerous computational evaluations  of implemented methods, literature reviews show that there is an overall lack of high quality user evaluations that add a  user-centered focus to the field of XAI.",there is an overall lack of
333.txt,"As explanations fulfilla user need, explanations generated by a DSS need to be  evaluated among these users.",null
334.txt,This can provide valuable insights into user requirements and effects.,null
335.txt,"In addition, evaluations  can be used to benchmark XAI methods to measure the research fields progress.",In addition
336.txt,The contribution of this article is twofold.,The contribution of
337.txt,"First, we propose a set of recommendationson designing user evaluations  in the field of XAI.",in the field of
338.txt,"Second, we performed an extensive user evaluation on the effects of rule-basedand example-based contrastive explanations.",the effects of
340.txt,These recommendations are intended as a reference for XAI researchers unfamiliar to user  evaluations.,are intended as
341.txt,These recommendations are based on our experience designing a user evaluation and retread knowledge that  is more common in fields such as cognitive psychology and Human-Computer Interaction.,are based on
342.txt,The present user study focused on two styles of contrastive explanations and their evaluation.,focused on
343.txt,Contrastive explanations  in the context of a DSS are those that answer questions as Why this advice instead of that advice?,null
344.txt,These explanations  help users to understand and pinpoint information that caused the system to give one advice over the other.,null
345.txt,"In two separate experiments, we evaluated two contrastive explanation styles.",null
346.txt,An explanation style defines the way information is structured  and is often defined by the algorithmic approach to generate explanations.,is often defined by
348.txt,Insulin is a hormone that DMT1  patients have to administer to prevent the negative effects of the disturbed blood glucose regulation associated with this  condition.,prevent the negative effects of
349.txt,"The dose is highly personal and context dependent, and an incorrect dose can cause the patient short or long term harm.",null
350.txt,The purpose of the DSSs advice is to minimize these adverse effects.,The purpose of
351.txt,This use case was selected for two  reasons.,null
352.txt,"Firstly, AI is increasingly more often used in DMT1 self-management.",used in
353.txt,"Therefore, the results are relevant for  research on DSS aided DMT1 self-management.",are relevant for
354.txt,"Secondly, this use case was both understandable and motivating for healthy  participants without any experience with DMT1.",null
355.txt,"Because DMT1 patients would have potentially confounding experience  with insulin administration or certain biases, we recruited healthy participants that imagined themselves in the situation  of a DMT1 patient.",null
356.txt,"Empathizing with a patient motivated them to make correct decisions, even if this meant to ignore the  DSSs advice in favor of their own choice, or vice versa.",make correct decisions
357.txt,This required an understanding of when the DSSs advice would be  correct and incorrect and how it would behave in novel situations.,null
358.txt,The paper is structured as follows.,The paper is structured as follows
359.txt,First we discuss the background and shortcomings of current XAI user evaluations.,null
360.txt,"Furthermore, we provide examples on how rule-basedand example-based explanations are currently used in XAI.",null
361.txt,"The subsequent section describes three sets of recommendations for user evaluations in XAI, based on our experience designing  the evaluation as well as on relevant literature.",based on
362.txt,"Next, we illustrate our own recommendations by explaining the use case  in more detail and offering the theory behind our hypotheses.",null
363.txt,"This is followed by a detailed description of our methods,  analysis and results.",This is followed by
364.txt,We conclude with a discussion on the validity and reliability of the results and a brief discussion of  future work.,conclude with a discussion on
365.txt,The following two sections discuss the current state of user evaluations in XAI and rule-basedand example-based contrastive explanations.,null
366.txt,"The former section illustrates the shortcomings of current user evaluations, formed by either a lack of  validity and reliability or the entire omission of an evaluation.",a lack of
367.txt,"The latter discusses the two explanation styles used in our  evaluation in more detail, and illustrates their prevalence in the field of XAI.",in the field of
368.txt,A major goal of Explainable Artificial Intelligence is to have AI-systems construct explanations for their own output.,null
369.txt,"Common purposes of these explanations are to increase system understanding, improve behavior predictability  and calibrate system trust  .",null
370.txt,"Other purposes include support in system debugging , verification and  justification .",null
371.txt,"Currently, the exact purpose of explanation methods is often not defined or formalized, even though these  different purposes may result in profoundly different requirements for explanations.",result in
372.txt,This makes it difficult for the field  of XAI to progress and to evaluate developed methods.,makes it difficult for the field  of
373.txt,"The difficulties in XAI user evaluations are reflected in recent surveys from Anjomshoae , Adadi and  Doshi-Velez and Kim that summarize current efforts of user evaluations in the field.",The difficulties in
374.txt,The systematic literature review  by X shows that 97% of the 62 reviewed articles underline that explanations serve a user need but 41% did not evaluate  their explanations with such users.,null
375.txt,"In addition, of those papers that performed a user evaluation, relatively few provided  a good discussion of the context , results  and limitations of their experiment.",In addition
376.txt,The second survey from X evaluated 381 papers and found that only 5% had an explicit focus on the evaluation of the XAI methods.,had an explicit focus on
377.txt,"These two  surveys show that, although user evaluations are being conducted, many of them provide limited conclusions for other XAI  researchers to build on.",provide limited conclusions for
378.txt,A third survey by X discusses an explicit issue with user evaluations in XAI.,null
379.txt,"The authors argue to systematically start evaluating different explanations styles and forms in various domains, a rigor that is currently lacking in XAI user evaluations.",lacking in
380.txt,"To do so in a valid way, several recommendations are given.",null
381.txt,"First, the application level of the study context should be  made clear; either a real, simplified or generic application.",null
383.txt,"Examples include the average human level of expertise targeted, and whether the explanation should  address the entire system or a single output.",null
384.txt,"Finally, the explanations and their effects should be clearly stated together  with a discussion of the studys limitations.",null
385.txt,"Together, these three surveys illustrate the shortcomings of current XAI user  evaluations.",the shortcomings of
386.txt,"From several studies that do focus on evaluating user effects, we note that the majority focuses on subjective measurement.",focus on
387.txt,"Surveys and interviews are used to measure user satisfaction, the goodness of an explanation, acceptance  of the systems advice and trust in the system .",are used to
388.txt,Such subjective measurements can provide a valuable insight in the users perspective on the explanation.,provide a valuable insight in
389.txt,"However, these results do not necessarily relate to the behavioral effects  an explanation could cause.",relate to
390.txt,"Therefore, these subjective measurements require further investigation to see if they correlate  with a behavioral effect.",require further investigation to
391.txt,"Without such an investigation, these subjective results only provide information on the users  beliefs and opinions, but not on actual gained understanding, trust or task performance.",null
392.txt,"Some studies, however, do perform  objective measurements.",null
393.txt,"This allowed the authors to differentiate between behavioral and self-perceived effects of an explanation, underlining the value of performing objective measurements.",null
394.txt,The above described critical view on XAI user evaluations is related to the concepts of construct validity and reliability.,null
395.txt,These two concepts provide clear standards to scientifically sound user evaluations.,null
396.txt,The construct validity of an  evaluation is its accuracy in measuring the intended constructs .,null
397.txt,"Examples of how validity may  be harmed is a poor design, ill defined constructs or arbitrarily selected measurements.",null
398.txt,"Reliability, on the other hand, refers  to the evaluations internal consistency and reproducibility, and may be harmed by a lack of documentation, an unsuitable  use case or noisy measurements.",on the other hand
399.txt,"In the social sciences, a common condition for results to be generalized to other cases  and to infer causal relations is that a user evaluation is both valid and reliable.",null
400.txt,This can be obtained by  developing different types of measurements for common constructs.,This can be obtained by
401.txt,"For example, self-reported subjective measurements  such as ratings and surveys can be supplemented by behavioral measurements to gather data on the performance in a  specific task.",For example
402.txt,Human explanations tend to be contrastive: they compare a certain phenomenon  with a hypothetical one.,compare with
403.txt,"In the case of a decision support systems , a natural question to ask is Why this advice?",In the case of
404.txt,"This question  implies a contrast, as the person asking this question often has an explicit contrasting foil in mind.",null
405.txt,"In other words, the  implicit question is Why this advice and not that advice?The specific contrast allows the explanation to be limited to the  differences between fact and foil.",In other words
406.txt,Humans use contrastive explanations to explain events in a concise and specific manner .,null
407.txt,This advantage also applies to systems: contrastive explanations narrow down the available information to a concrete  difference between two outputs.,difference between
408.txt,"Contrastive explanations can vary depending on the way the advice is contrasted with a different advice, for example using rules or examples.",for example
409.txt,"Within the context of a DSS advising an insulin dose for DMT1 self-management, a contrastive  rule-based explanation could be: Currently the temperature is below 10 degrees and a lower insulin dose is advised.",null
410.txt,"If the  temperature was above 30 degrees, a normal insulin dose would have been advised.",null
411.txt,This explanation contains two rules  that explicitly state the differentiating decision boundaries between the fact and foil.,between and
412.txt,"An example-based explanation refers to historical situations in which the advice was found to be true or false: The  temperature is currently 8 degrees, and a lower insulin dose is advised.",refers to
413.txt,Yesterday was similar: it was 7 degrees and the  same advice proved to be correct.,proved to
414.txt,"Two months ago, when it was 31 degrees, a normal dose was advised instead, which  proved to be correct for that situation.",null
415.txt,"Such example or instance-based explanations are often used between humans, as they illustrate past behavior and allow for generalizationto new situations .",null
416.txt,"Several XAI methods try to identify  examples to generate such explanations, for example those from X.",for example
417.txt,Research on system explanations using rules and examples is not new.,null
418.txt,"Most of the existing research focused on exploring  how users preferred a system would reason, by rules or through examples.",null
419.txt,"For example, users prefer an example-based  spamfilter over a rule-based , while they prefer spam-filter explanations to be rule-based .",For example
420.txt,Another evaluation  showed that the number of rule factors in an explanation had an effect on task performance by either promoting system  over-reliance or self-reliance .,had an effect on
421.txt,"Work by Lim shows that rule-based  explanations cause users to understand system behavior, especially if those rules explain why the system behaves in a  certain way as opposed to why it does not behave in a different way.",as opposed to
422.txt,"Studies such as these tend to evaluate  either rules or examples, depending on the research field  but few compare rules with examples.",such as
423.txt,"As discussed in Section2.1, user evaluations play an invaluable role in XAI but are often omitted or of insufficient quality.",play an invaluable role in
424.txt,Our main contribution is a thorough evaluation of rule-based and example-based contrastive explanations.,null
425.txt,"In addition, we  believe that the experience and lessons learned in designing this evaluation can be valuable for other researchers.",In addition
426.txt,Especially  researchers in the field of XAI that are less familiar with user evaluations can benefit from guidance in the design of user  studies incorporating knowledge from different disciplines.,in the field of
427.txt,"To that end, we propose three sets of recommendations with  practical methods to help improve user evaluations.",To that end
428.txt,An overview is provided in Fig.1.,is provided in
429.txt,"As stated in Section 2.1, the field of XAI often deals with ambiguously defined concepts such asunderstanding.",As stated in
430.txt,We  believe that this hinders the creation and replication of XAI user evaluations and their results.,null
431.txt,"Through clear definitions and  motivation, the contribution of the evaluation becomes more apparent.",the contribution of
432.txt,This also aids other researchers to extend on the  results.,aids to
433.txt,We provide three practical recommendations to clarify the evaluated constructs and their relations.,null
434.txt,Our first recommendation is to clearly define the intended purposes of an explanation in the form of a construct.,Our first recommendation is to
435.txt,"A  construct is either the intended purpose, an intermediate requirement for the purpose or a potential confound to your  purpose.",for the purpose
436.txt,Constructs form the basis of the scientific theory underlying XAI methods and user evaluations.,null
437.txt,"By defining a  construct, it becomes easier to develop measurements.",it becomes easier to
438.txt,"Second, we recommend to clearly define the relations expected  between the constructs.",recommend to
439.txt,A concrete and visual way to do so is through a Causal Diagram which presents the expected causal  relations between constructs .,null
440.txt,These relations form your hypotheses and make sure they are formulated in terms of  your constructs.,in terms of
441.txt,"Clearly stating hypotheses allows other researchers to critically reflect on the underlying theory assumed,  proved or falsified with the evaluation.",null
442.txt,It offers insight in how constructs are assumed to be related and how the results  support or contradict these relations.,null
443.txt,"Our final recommendation regarding constructs is to adopt existing theories, such as from philosophy,  psychology and from human-computer interaction.",such as
444.txt,The former provides construct definitions whereas  the latter two provide theories of human-human and human-computer explanations.,null
445.txt,These three recommendations to define constructs and their relations and grounding them in other research disciplines can contribute to more valid and reliable  user evaluations.,contribute to
446.txt,"In addition, this practice allows results to be meaningful even if hypotheses are rejected, as they falsify a  scientific theory that may have been accepted as true.",In addition
447.txt,"The second set of recommendations regards the experimental context, including the use case.",null
448.txt,"The use case determines  the task, the participants that can and should be used, the mode of the interaction, the communication that takes place and  the information available to the user .",null
449.txt,"These factors can interfere in an exploratory study such as ours, in which the findings  are not domain specific.",null
450.txt,"Hence, we recommend to invest in both understanding the use case domain and reflecting on the  intended purpose of the evaluation.",recommend to
451.txt,These considerations should be consolidated in inclusion criteria to ensure that the  results are meaningful with respect to the studys aim.,with respect to
452.txt,"Our final recommendation related to the context considers the experimental setting and surroundings, as these may affect the quality and generalizability of the results.",null
453.txt,"An online setting may provide a large quantity of readily available  participants, but the results are often of ambiguous quality.",null
454.txt,"If circumstances allow, we recommend  to use a controlled setting .",recommend to
455.txt,This allows for valuable interaction with participants while reducing potential confounds that threaten the evaluations reliability and validity.,null
456.txt,"Numerous measurements exist for computational experiments on suggested XAI methods , but also recommend a critical perspective on whether the measures indeed address the intended  constructs.",perspective on
457.txt,Behavioral measures have a more observational nature and are used to measure actual behavioral effects.,are used to
458.txt,We recommend their usage for objectively measuring constructs such as understanding and task performance.,null
459.txt,"Importantly however, such measures often only measure one aspect of behavior.",null
460.txt,"Ideally, a combination of both measurement types should be  used to assess effects on both the users perception and behavior.",be  used to
461.txt,"In this way, a complete perspective on a construct can be  obtained.",null
462.txt,"In practice, some constructs lend themselves more for self-reported measurements, for example a users perception on trust or understanding.",for example
463.txt,"Other constructs are more suitable for behavioral measurements, such as task performance,  simulatability, predictability, and persuasive power.",are more suitable for
464.txt,"Furthermore, we recommend to measure explanation effects implicitly, rather than explicitly.",rather than
465.txt,"When participants are not aware of the evaluations purpose, their responses may be more genuine.",null
466.txt,"Also, when measuring understanding or similar constructs, the participants explicit focus on the explanations may cause skewed results not present in a real world  application.",focus on
467.txt,This leads to our third recommendation to measure potential biases.,leads to
468.txt,"Biases can regard the participants overall  perspective on AI, the use case, decision-making or similar.",null
469.txt,"However, biases can also be introduced by the researchers  themselves.",be introduced by
470.txt,"For example, one XAI method can be presented more attractively or reliably than another.",For example
471.txt,It can be difficult  to prevent such biases.,It can be difficult  to
472.txt,"One way to mitigate these biases is to design how the explanation are presented, the explanation  form, in an iterative manner with expert reviews and pilots.",null
473.txt,"In addition, one can measure these biases nonetheless if  possible and reasonable.",In addition
474.txt,"For example, a usability questionnaire can be used to measure potential differences between the  way explanations are presented in the different conditions.",For example
475.txt,For our study we designed the explanations iteratively and  verified that the chosen form for each explanation type did not differ significantly in the perception of the participants.,null
476.txt,"In this study, we focused on personalized healthcare, an area in which machine learning is promising and explanations  are essential for realistic applications .",are essential for
477.txt,Our use case is that of assisting patients with diabetes mellitus type 1   with personalized insulin advice.,null
478.txt,DMT1 is a chronic autoimmune disorder in which glucose homeostasis is disturbed and  intake of the hormone insulin is required to balance glucose levels.,null
479.txt,"Since blood glucose levels are influenced by both  environmental and personal factors, it is often difficult to find the adequate dose of insulin that stabilizes blood glucose  levels.",it is often difficult to
480.txt,"Therefore, personalized advice systems can be a promising tool in DMT1 management to improve quality of life  and mitigate long-term health risks.",null
481.txt,"In our context, a DMT1 patient finds it difficult to find the optimal insulin dose for a meal in a given situation.",it difficult to
482.txt,"On the  patients request, a fictitious intelligent DSS provides assistance with the insulin intake before a meal.",provides with
483.txt,"Based on different  internal and external factors, the system may advise to take a normal  insulin dose, or a higher or lower dose than usual.",Based on
484.txt,"For example, the system could advise a lower insulin dose based on  the current temperature.",For example
485.txt,"The factors that were used in the evaluation are realistic, and were based on Bosch and an  interview with a DMT1 patient.",null
486.txt,"In this use case, both the advice and the explanations are simplified.",both and
487.txt,This study therefore falls under the human grounded  evaluation category of Doshi-Velez and Kim: a simplified task of a real-world application.,null
488.txt,"The advice is binary , whereas in reality one would expect either a specific dose or a range of suggested doses.",null
489.txt,"This simplification allowed  us to evaluate with novice users, as we could limit our explanation to the effects of a too low or too high  dosage without going into detail about effects of specific doses.",null
490.txt,"Furthermore, this prevented the unnecessary complication  of having multiple potential foils for our contrastive explanations.",null
491.txt,"Although the selection of the foil, either by system or  user, is an interesting topic regarding contrastive explanations.",is an interesting topic regarding
492.txt,"The second  simplification was that the explanations were not generated using a specific XAI method, but designed by the researchers  instead.",null
493.txt,Several design iterations were conducted based on feedback from XAI researchers and interaction designers to  remove potential design choices in the explanation form that could cause one explanation to be favored over another.,null
494.txt,"Since the explanations were not generated by a specific XAI method, we were able to explore the effects of more prototypical rule- and example-based explanations inspired by multiple XAI methods that generate similar explanations.",were able to explore the effects of
495.txt,There are several limitations caused by these two simplifications.,There are several limitations caused by
496.txt,"First, we imply that the system can automatically select  the appropriate foil for contrastive explanations.",we imply that
497.txt,"Second, we assume that the XAI method is able to identify only the most  relevant factors to explain a decision.",we assume that
498.txt,"Although this assumes a potentially complex requirement for the XAI method, it is a  reasonable assumption as humans prefer a selective explanation over a complete one.",it is a  reasonable assumption
499.txt,"The user evaluation focused on three constructs: system understanding, persuasive power, and task performance.",null
500.txt,"Athough an important goal of offering explanations is to allow users to arrive at the appropriate level of trust in the system, the construct of trust is difficult to define and measure .",an important goal of
501.txt,"As such, our focus was on constructs influencing trust  that were more suitable to translate into measurable constructs; the intermediate construct of system understanding and  the final construct of task performance of the entire user-system combination.",performance of
502.txt,"The persuasive power of an explanation was  also measured, as an explanation might cause over-trust in a user; believing that the system is correct while it is not,  without having a proper system understanding.",null
503.txt,"As such, the persuasive power of an explanation confounds to the effect of  understanding on task performance.",the effect of
504.txt,Both contrastive rule and example-based explanations were compared to each other with no explanationas a control.,were compared to
505.txt,Our  hypotheses are visualized in a Causal Diagram depicted in Fig.2.,null
506.txt,From rule-based explanations we expected participants  to gain a better understanding of when and how the system arrives at a specific advice.,gain a better understanding of
507.txt,Contrastive rule-basedexplanations  explicate the systems decision boundary between fact and foil and we expected the participants to recall and apply this information.,null
508.txt,"Second, we expected that contrastive example-based explanations persuade participants to follow the advice more  often.",null
509.txt,We believe that examples raise confidence in the correctness of an advice as they illustrate past good performance  of the system.,null
510.txt,"Third, we hypothesized that both system understanding and persuasive power have an effect on task performance.",have an effect on
511.txt,"Whereas this effect was expected to be positive for system understanding, persuasive power was expected to affect  task performance negatively in case a systems advice is not always correct.",null
512.txt,This follows the argumentation that persuasive  explanations can cause harm as they may convince users to over-trust a system.,null
513.txt,Note that we conducted two separate  experiments to measure the effects of an explanation type on understanding and persuasion.,the effects of
514.txt,"This allowed us to measure the  effect of each construct separately on task performance, but not their combined effect .",the  effect of
515.txt,The construct of understanding was measured with two behavioral measurements and one self-reported measurement.,null
516.txt,The first behavioral measurement assessed the participants capacity to correctly identify the decisive factorof the situations  in the systems advice.,null
517.txt,This measured to what extent the participant recalled what factor the system believed to be important for a specific advice and situation.,be important for
518.txt,"Second, we measured the participants ability to accurately predict the advicein  novel situations.",null
519.txt,This tested whether the participant obtained a mental model of the system that was sufficiently accurate  enough to predict its behavior in novel situations.,null
520.txt,The self-reported measurement tested the participants perceived system  understanding.,null
521.txt,This provided insight in whether participants over or underestimated their understanding of the system  compared to what their behavior told us.,compared to
522.txt,"Persuasive power of the systems advice was measured with one behavioral measurement, namely the number of times  participants copied the advice, independent of its correctness.",null
523.txt,"If participants that received an explanation followed the advice  more often than participants without an explanation, we addressed this to the persuasiveness of the explanation.",null
524.txt,"Task performance was measured as the number of correct decisions, a behavioral measurement, and perception of predicting  advice correctness, a self-reported measurement.",null
525.txt,"We assumed a system that did not have a 100% accurate performance,  meaning that it also made incorrect decisions.",null
526.txt,"Therefore, the number of correct decisions made by the participant while  aided by the system could be used to measure task performance.",null
527.txt,The self-reported measure allowed us to measure how  well participants believed they could predict the correctness of the system advice.,null
528.txt,"Finally, two self-reported measurements were added to check for potential confounds.",were added to
530.txt,"This could reveal whether one explanation style was designed and visualized better than the other, which would be a confounding variable.",better than
531.txt,"The second,  perceived system accuracy, measured how accurate the participant thought the system was.",null
532.txt,"This could help identify a potential overor underestimation of the usefulness of the system, that could have affected to what extent participants attended  to the systems advice and explanation.",have affected to
533.txt,The combination of self-reported and behavioral measurements enabled us to draw relations between our observations  and a participants own perception.,null
534.txt,"Finally, by measuring a single construct with different measurements we could identify and potentially overcome biases and other weaknesses in our measurements.",null
535.txt,In this section we describe the operationalization of our user evaluation in two separate experiments in the context  of DSS advice in DMT1 self-management .,null
536.txt,Experiment I focused on the construct of system understanding.,focused on
537.txt,Experiment II focused on the constructs of persuasive power and task performance.,focused on
538.txt,The explanation style was the independent variable in both experiments and was tested  between subjects.,both and
539.txt,See Fig.1 for an example of each explanation style.,for an example of
540.txt,"The experimental procedure was similar in both experiments: Participants were informed about the study, use-case and task, as well as presented with a brief narrative  about a DMT1 patient for immersive purposes.",with a brief narrative  about
541.txt,Age and education level were inquired to identify whether the population sample was  sufficiently broad.,null
542.txt,Participants were questioned on DMT1 knowledge to assess if DMT1 was sufficiently introduced and  to check our assumption that participants had no additional domain knowledge.,null
543.txt,"Multiple stimuli were presented, accompanied with either the example or rule-based explanations, or no explanations.",either or
544.txt,Several trials followed to conduct the behavioral measurements.,null
545.txt,A questionnaire was completed to obtain self-reported measurements .,was completed to
546.txt,Participants filled out a usability questionnaire to identify potential interface related confounds.,null
547.txt,The experimental procedure concluded with several questions to assess whether the purpose of  the study was suspected and to measure perceived system accuracyto identify over or under-trust in the system.,the purpose of
548.txt,The purpose of Experiment Iwas to measure the effects of rule-based and example-based explanations on system understanding compared to each other and to the control group with no explanations.,The purpose of
549.txt,See Fig.4 for an overview of both the  learning and testing blocks.,for an overview of
550.txt,"The learning block consisted of 18 randomly ordered trials, each trial describing a single situation with three factors and values from Table1.",consisted of
551.txt,"The situation description was followed by the systems advice, in turn followed by an explanation .",in turn
552.txt,"Finally, the participant was asked to make a decision on administering a higher or lower insulin dose than usual.",make a decision on
553.txt,This block served only to familiarize the participant with the systems  advice and its explanation and to learn when and why a certain advice was given.,null
554.txt,"Participants were not instructed to focus  on the explanations in the learning block, nor were they informed of the purpose of the two blocks.",focus  on
555.txt,"In the testing block, two behavioral measures were used to test the construct of understanding: advice predictionand  decisive factor identification.",were used to
556.txt,"The testing block consisted of 30 randomized trials, each with a novel situation description.",consisted of
557.txt,Each description was followed by the question what advice the participant thought the system would give.,null
558.txt,"This formed the  A third, self-reported measurement was conducted in the post-questionnaire, which contained an eight item question naire based on a 7 point Likert scale.",based on
559.txt,These items formed the measurement of perceived system understanding.,null
560.txt,The questions  were asked without mentioning the term explanation and simply addressedsystem output.,null
561.txt,"The amount of eight items was  deemed necessary, to obtain a measurement less dependent on the formulation of one item.",null
562.txt,The purpose of Experiment IIwas to measure the effects of rule-basedand example-basedexplanations on persuasive  power and task performance.,The purpose of
563.txt,Fig.5 provides an overview of the learning and testing blocks of this experiment.,null
564.txt,"The learning block was similar to that of the  first experiment: a situation was shown, containing three factors from Table1.",was similar to
565.txt,"In the experimental groups, the situation was  followed by an advice and explanation.",null
566.txt,"Next, the participant was asked to make a decision on the insulin dose.",null
567.txt,"After this  point, the learning block differed from the learning block in the first experiment: the participants decision was followed  with feedback on its correctness.",null
568.txt,"In 12 of the 18 randomly ordered trials of this learning block , this  system followed a second, partially correct set of rules, as shown in Table1.",as shown in
569.txt,"The testing block contained 30 trials, also presented in random order, in which a presented situation was followed by  the systems advice and explanation.",null
570.txt,"Next, participants had to choose which insulin dose was correct based on the systems  advice, explanation and gained knowledge of when the system is incorrect.",null
571.txt,"Persuasive power was operationalized as the  number of times a participant followed the advice, independent of whether it was correct or not.",null
572.txt,Task performance was represented by the number of times a correct decision was made.,null
573.txt,"The former reflected how persuasive the advice and  explanation was, even when participants experienced system errors.",null
574.txt,The latter reflected how well participants were able to  understand when the system makes errors and compensate accordingly in their decision.,null
575.txt,"Also in this experiment, a self-reported measurement with eight 7-point Likert scale questions was performed.",null
576.txt,It measured the participants subjective sense of their ability to estimate when the system was correct.,null
577.txt,Their education levels varied from secondary vocational to university education.,varied from to
578.txt,Participants were recruited from a participant  database at TNO Soesterberg  buildings and on social media.,null
580.txt,"Both samples aimed to represent the entire Dutch population and as such the entire range of potential DMT1 patients, hence the wide age and educational  ranges.",null
581.txt,"The inclusion criteria were as follows: not diabetic, no close relatives or friends with diabetes, and no extensive knowledge of diabetes through work or education.",null
582.txt,"General criteria were Dutch native speaking, good or corrected eyesight, and  basic experience using computers.",null
583.txt,These inclusion criteria were verified in the pre-questionnaire.,null
584.txt,"A total of 16 participants  reported a close relative or friend with diabetes and one participant had experience with diabetes through work, despite  clear inclusion instructions beforehand.",A total of
585.txt,"After careful inspection of their answers, none were excluded because their answers  on diabetes questions in the pre-questionnaire were not more accurate or elaborate than others.",null
586.txt,From this we concluded  that their knowledge of diabetes was unlikely to influence the results.,was unlikely to
587.txt,Statistical tests were conducted using SPSS Statistics 22.,null
588.txt,An alpha level of 0.05 was used for all statistical tests.,was used for
589.txt,The data from the behavioral measures in Experiment Iwere analyzed using a one-way Multivariate Analysis of Variance as independent variable and the number of times the advice was copiedas dependent variable.,null
590.txt,"The second ANOVA also had explanation style as independent variable, but the number of correct decisionsas dependent  variable.",null
591.txt,The internal consistency of the self-reported measurement of perceived prediction of advice correctnessfrom the  post-questionnaire was assessed with Cronbachs Alpha and analyzed with a one-way ANOVA.,was assessed with
592.txt,Explanation style was the  independent and the mean rating on the questionnaire the dependent variable.,null
593.txt,The presence of correlations between the  behavioral and the self-reported measurements was assessed with Pearsons product-moment correlations.,was assessed with
594.txt,Detected outliers  were excluded from the analysis.,were excluded from
595.txt,"The purpose of Experiment Iwas to measure gained system understanding when a system provides a rule or example-based explanation, compared to no explanation.",The purpose of
596.txt,This was measured with two behavioral measures and one self-reported  measure.,null
597.txt,Fig.6 shows the results on the two behavioral measures: correct advice prediction in novel situations and correct identification of the systems decisive factor.,null
598.txt,"Some caution is needed in interpreting these results, as this lack of significant correlations  shows a potential lack of statistical power.",null
599.txt,Further posthoc analysis showed a significant difference in factor identification  in favor of rule-based explanations compared to example-based explanations and no explanations .,showed a significant difference in
600.txt,"The purpose of Experiment II was to measure a participants ability to use a decision support system appropriately when  it provides a rule or example-based explanation, compared with no explanation.",The purpose of
601.txt,This was measured with one behavioral  and one self-reported measurement.,null
602.txt,"In addition, we measured the persuasiveness of the system for each explanation style,  compared to no explanations.",In addition
603.txt,This was assessed with one behavioral measure.,was assessed with
604.txt,"Fig.9 shows the results of the behavioral measure for task performance, as reflected by the users decision accuracy.",the results of
605.txt,A  one way ANOVA showed no significant differences .,null
606.txt,"One outlier from the rule-based explanation group was found, its removal did not  affect the analysis.",null
607.txt,"A correlation analysis was performed between the self-reported prediction of advice correctness and the behavioral  measurement of making the correct decision, two measurements of task performance.",null
608.txt,The accompanying scatter plot is  shown in Fig.11.,is shown in
609.txt,A Pearsons product-moment correlation revealed no significant correlation between the self-reported and  behavioral measure .,between and
610.txt,Both  outliers from each measurement were removed in this analysis and did not affect the significance.,null
611.txt,"A usability questionnaire was used to evaluate whether there were differences in usability between the two explanation  styles, as this could influence the results.",was used to
612.txt,"The questionnaire contained five questions on a 100 point scale about readability,  organizationof information, language, images and color.",null
613.txt,"The consistency between the five questions was relatively high,as revealed by a Cronbachs Alpha test.",as revealed by
614.txt,"Fig.12 shows the mean ratings for each question, broken down by  explanation style .No statistical analysis was performed, as this questionnaire  only functioned as a check for potential usability confounds in the experiment.",null
615.txt,"In addition to the ratings, participants were asked about the positive and negative usability aspects of the system in  two open questions.",In addition to
616.txt,"Common positive descriptions included clear, well-arranged, clear and simple icons and understandable language.",null
617.txt,"Although not many participants had negative remarks, most addressed insufficient visual contrast due  to the colors used.",due  to
618.txt,Unique to the example-based explanations participant group were remarks about a lack of concise and  well-arranged information.,a lack of
619.txt,In the control questionnaire we asked participants to give an estimate of the overall systems accuracy.,give an estimate of
620.txt,This was to validate any potential overly positive or negative trust bias towards the system.,null
621.txt,This meant that all participants believed the system to make errors based  on no information.,based  on
622.txt,In Experiment II the systems accuracy was 66.7%.,null
623.txt,Participants experienced this due to the feedback on  made decisions in the learning block.,due to
624.txt,"After the experiment, brief discussions with participants revealed additional perspectives.",null
625.txt,Several participants from the  no explanation group wished the system could give an explanation for its advice.,give an explanation for
626.txt,One participant expressed a need for  knowing the systems rules governing the systems advice.,null
627.txt,"In the two explanation groups, participants experienced the  explanations as useful.",null
628.txt,"Rules were valued for there explicitness, whereas examples were viewed as inciting trust.",were viewed as
629.txt,"However,  in the two explanation groups several participants found it unclear what the highlight of a factor meant.",null
630.txt,"Several  participants also mentioned that, although useful, the explanations lacked a causal rationale.",null
631.txt,Below we discuss the results from both experiments in detail and relate them to our theory presented in Section5.,relate to
632.txt,Experiment Imeasured the participants capacity to understand how and when the system provided a specific advice.,null
633.txt,"This construct was operationalized in three measurements: decisive factor identification, advice predictionand perceived system  understanding.",null
634.txt,We hypothesized that participants receiving contrastive rule-based explanations would score best on all three  measurements.,null
635.txt,Contrastive example-based explanationswere only expected to improve understanding slightly more than no explanations.,more than 
636.txt,The results from our evaluation support these hypotheses in part.,null
637.txt,"First, rule-based explanations indeed seem to allow participants to more accurately identify the factor from a situation that was decisive in the systems advice.",null
638.txt,"However, rule-basednor example-based explanation allowed participants to learn to predict system behavior.",null
639.txt,"The rule-based explanations however,  did cause to participants to think that they better understood the system compared to example-basedand no explanations.",compared to
640.txt,The example-based explanations only showed a small and insignificant increase in perceived system understanding.,null
641.txt,It is important to note that there was no correlation between the self-reported measurement of understanding and the behavioral  measurements of understanding.,It is important to
642.txt,This shows that participants had a perception of understanding that differed from the  understanding as measured with factor identificationand advice prediction.,had a perception of
643.txt,Close inspection of the results showed two potential causes for the lack of support for our hypotheses.,the lack of
644.txt,The first reason  might be because the described DMT1 situations and accompanying system advice was too intuitive.,null
645.txt,This is supported by the  fact that participants with no explanationwere already quite adapt in identifying decisive factors(nearly 70%compared to 33% chance).,This is supported by the  fact that
646.txt,The second reason we inferred from open discussions with participants after the experiment.,null
647.txt,Most participants who  received either explanation style mentioned difficulty in applying and generalizing the knowledge from the explanations to  novel situations.,null
648.txt,Several participants even expressed the desire to know the rationale of why a certain rule or behavior  occurred.,null
649.txt,"This is in line with the theory that explanations should convey specific causal relations obtained from an overall  causal model describing the behavior of the system, instead of just factual correlations between system input and output.",instead of
651.txt,"However, such explanations are capable of educating a user to identify which factors would play a decisive role in system advice given a specific situation.",play a decisive role in
652.txt,"Also, such explanations seem  to provide the user with the perception that  measures that accurately and reliably measure the intended construct.",null
653.txt,"In Experiment II we investigated the extent to which an explanation increases the persuasiveness of an advice, as well as  the explanations effect on task performance.",as well as
654.txt,The persuasive power of an explanation was operationalized with the number  of times the advice was copied.,null
655.txt,Task performance was represented by the number of correct decisionsand the self-reported prediction of advice correctness.,null
656.txt,"We hypothesized that especially contrastive example-based explanations would increase persuasive  power, while these in turn would lower actual task performance.",in turn
657.txt,"In contrast, the understanding participants gained from  rule-based explanationswas expected to cause an increase in task performance  improvement.",In contrast
658.txt,"Due to a lack of statistical evidence not much can be inferred from this, and further evaluation is required.",Due to
659.txt,"Similar to Experiment Iwe found a lack of correlation between reports of participants  perception of predicting advice  correctness, and the number of correct decisions.",Similar to
660.txt,"In other words, these measures do not seem to measure the same construct.",In other words
661.txt,An explanation could be that participants were unable to estimate their own capacity of predicting the correctness of advice.,were unable to
662.txt,"We have shown that providing an explanation with an advice results in users following that advice more often, even  when incorrect.",results in
663.txt,"In addition, there was a suggestion that explanations also improve task performance, especially contrastive  example-based explanations.","In addition, there was a suggestion that"
664.txt,"However, these effects were marginal and not significant.",null
665.txt,These results underline the need in the field of XAI to take a different stance on which explanations should be generated.,take a different stance on
666.txt,"Two common styles of explanations  answering a contrasting question did not appear to increase task performance, an effect often attributed to such explanations  within the field.",attributed to
667.txt,This study has several limitations that warrant caution in generalizing the results to other use cases or to the field of XAI  in general.,the field of
668.txt,The first set of limitations is related to the selected use case of aided DMT1 self-management.,is related to
669.txt,This use case falls into the category simplified  from Doshi-Velez and Kim as it approximates a realistic use case.,falls into
670.txt,"However, two major aspects differ from the reallife situation.",differ from
671.txt,"First, we recruited healthy participants who had to empathize with a DMT1 patient,  instead of actual DMT1 patients.",instead of
672.txt,"Nevertheless, participants were sampled from the entire Dutch population, resulting in a  wide variety of ages and education levels.",resulting in
673.txt,These choices allowed us to measure the effects of the explanation types without  focusing on a specific demographic or having to compensate for varying domain knowledge in DMT1 participants.,the effects of
674.txt,"Second,  the system itself was fictitious and followed a predetermined set of rules rather than comprising the full complexity of  a realistic system.",rather than
675.txt,These two simplifications prevent us to generalize the results and to apply our conclusions to construct  an actual system for aiding DMT1 patients in self-management.,null
676.txt,"However, this was not the purpose of this study.",the purpose of
677.txt,"Instead,  we aimed to evaluate whether the supposed effects of two often cited explanations styles were warranted.",aimed to
678.txt,"We believe the selected use case allowed us to do so, as it gave both context as well as motivation for the users to understand explanations.",as well as
679.txt,"Also, laymen were chosen opposed to DMT1 patients to mitigate any difference in diabetes knowledge and misconceptions,  which can vary greatly between patients.",opposed to
680.txt,"Of course, future research specifically targeted at the development  of a DSS for DMT1 self-management should include DMT1 patients as participants.",targeted at
681.txt,The second set of limitations is related to suspected confounds in the experiment.,is related to
682.txt,"A brief usability questionnaire showed  that participants held an overall positive bias towards the system, whether an explanation was provided or not.",held an overall positive bias towards
683.txt,In addition  this questionnaire showed that participants  perception of the organization of the information was not always positive.,In addition
684.txt,"Hence, a potential limitation lies in the way the explanations were presented.",lies in
685.txt,"Also,surprisingly, in Experiment Iparticipants  attributed a low performance to the system, while they had no information to do so.",had no information to do
686.txt,"In Experiment II however, participants  tended to slightly overestimate the systems actual performance.",null
687.txt,This occurred independent of the explanation style.,null
688.txt,This  shows that the participants could have had a natural tendency to distrust the systems advice.,had a natural tendency to
689.txt,This may have affected the  self-reported results.,null
690.txt,"Finally, a few limitations arose from the design of both experiments.",arose from
691.txt,"The results for the example-based explanations  could have been different with a longer learning block, as it takes time to infer decision boundaries from examples.",it takes time to
692.txt,"Also,  both testing blocks were relatively long, which could have caused participants to continue learning about the system while  we were measuring their understanding.",null
693.txt,"We did not perform any analyses on this, as it would add another level of complexity to the design.",null
694.txt,"Hence, we cannot say for certain that the learning block was of sufficient length to allow participants  to learn enough from the explanations.",for certain
695.txt,"However, if this was the case, we believe that prolonging the learning block would  have resulted in even stronger effects.",resulted in
696.txt,"Lastly, due to the choice of different participant groups for both experiments.",due to
697.txt,"However, we selected this approach instead of combining the constructs in a single  experiment with a within-subject design, to avoid learning effects not sufficiently compensated through randomizing the  understanding and task performance/persuasion blocks.",instead of
698.txt,A lack of user evaluations characterizes the field of Explainable Artificial Intelligence .,A lack of
699.txt,A contribution of this paper was to provide a set of recommendations for future user evaluations.,A contribution of this paper was to
700.txt,Practical recommendations were given for XAI  researchers unfamiliar with user evaluations.,null
701.txt,"These addressed the evaluations constructs and their relations, the selection  of a use case and the experimental context, and suitable measurements to operationalize the constructs in the evaluation.",null
702.txt,These recommendations originated from our experience designing an extensive user evaluation.,null
703.txt,"Our second contribution was to evaluate the effects of contrastive rule-based and contrastive example-based explanationson the participants understanding of system behavior, persuasive power of the systems advice when combined with an explanation, and task performance.",the effects of
704.txt,The evaluation took place in a decision-support context where users were aided in choosing the appropriate dose of insulin  to mitigate the effects of diabetes mellitus type 1.,were aided in
705.txt,Results showed that contrastive rule-based explanations allowed participants to correctly identify the situational factor that  played a decisive role in a systems advice.,played a decisive role in
706.txt,"Neither example-based or rule-based explanations enabled participants to correctly  predict the systems advice in novel situations, nor did they improve task performance.",enabled to
707.txt,"However, both explanation styles  did cause participants to follow the systems advice more often, even when this advice was incorrect.",null
708.txt,This shows that both  rulesand examplesthat answer a contrastive question are not sufficient on their own to improve users  understanding or  task performance.,are not sufficient on
709.txt,We believe that the main reason for this is that these explanations lack a clarification of the underlying  rationale of system behavior.,We believe that the main reason for this is that
710.txt,"Future work will focus on the evaluation of a combined explanation style provided in interactive form, to assess whether  this interactive form helps users to learn a systems underlying rationale.",focus on
711.txt,"As an extension, potential methods will be researched that can generate causal reasoning traces, rather than decision boundaries, to expose the behavior rationale  directly.",rather than
712.txt,"In addition, future research may focus on similar studies with actual diabetes patients to study explanation effects  in potentially homogeneous groups.",In addition
713.txt,"Finally, during the design and analysis of  this user evaluation we discovered a need for validated and reliable measurements.",null
714.txt,We will continue to use different types  of measurements to measure constructs in a valid and reliable way in future user evaluations.,in future
715.txt,This paper presents a bidirectional search algorithm that dynamically improves the bounds  during its execution.,null
716.txt,It has the property that it always terminates on or before the forward  search meets the backward search.,It has the property that
717.txt,"Computational experiments on the pancake problem,  the sliding tile puzzle, and the topspin problem demonstrate that it is capable of solving  problems using signicantly fewer node expansions than A* or state-of-the-art bidirectional  algorithms such as MM and GBFHS.",it is capable of
719.txt,"While there have been a number of success stories for BHS, overall the computational results have been disappointing in comparison with unidirectional search.",in comparison with
720.txt,"This paper presents a BHS algorithm, Dynamically Improved Bounds Bidirectional Search , that improves upon previous BHS algorithms.",null
721.txt,"Pohl's algorithm, Bidirectional Heuristic Path Algorithm, essentially performs two interleaved A* searches, one in the forward direction, which we denote as FA*, and one in the backward direction.",denote as
722.txt,"One shortcoming of BHPA is that some nodes may be expanded twice, once in each direction.",null
723.txt,"Kaindl and Kainz proved that because of this shortcoming, BHPA may need to expand nearly all of the nodes that are expanded by FA* and by BA*.",because of
724.txt,"In such cases, BHPA is inferior to A*.",is inferior to
725.txt,"They also proved that if all the f-values  are distinct, then BHPA must expand at least as many nodes as either FA* or BA* expands.",as many as
726.txt,"We prove, theoretically and demonstrate computationally, that DIBBS is capable of breaking through this theoretical barrier.",is capable of
727.txt,"Holte  recently introduced a family of ""meet in the middle"" algorithms which also are capable of breaking through this theoretical barrier, but their approach is quite different than the approach taken here.",is quite different than
728.txt,"In 1989, Kwa presented BS*, which improved upon BHPA by eliminating the necessity of expanding any nodes in both directions.",the necessity of
729.txt,"While this was an important theoretical advance, computational results continued to be disappointing.",null
730.txt,"We prove that DIBBS, like BS*, never expands a node in both directions.",null
731.txt,"In fact, DIBBS goes one step better,it terminates before the first node is eligible to be expanded in both directions.",In fact
732.txt,"Loosely speaking, DIBBS terminates on or before the two searches meet .",null
733.txt,"The ""meet in the middle"" algorithms by Holte mentioned above, when using a consistent heuristic, also have this property, but again their approach is quite different than the approach taken here.",is quite different than
734.txt,"In the same paper where Kaindl and Kainz demonstrated some of the shortcomings of BHPA, they also laid the foundation for improving BHS algorithms.",laid the foundation for
735.txt,They developed a BHS algorithm that dynamically improves the bounds provided by the heuristics during the search.,null
736.txt,"In 2004, Auer and Kaindl  built two BHS algorithms based on this foundation.",based on
737.txt,"The first, Max-BS*, uses the improved bounds as the priority function in one of the search directions, but not the other.",null
738.txt,It does not use the improved bounds for pruning.,null
740.txt,Our work further builds on the foundation laid by Kaindl and Kainz.,builds on the foundation laid by
741.txt,"First, we show how to refine and improve the dynamic bounds.",null
742.txt,"Second, we show how to seamlessly build the dynamic bound improvement method into a new priority function that permits DIBBS to fully utilize the improved bounds for pruning in both directions and in the priority function.",both and
743.txt,"More recently, Barker and Korf  investigated the limitations of front-to-end BHS algorithms.",the limitations of
744.txt,They arrived at two main conclusions.,arrived at
745.txt,"First,Adding a weak heuristic to a bidirectional bruteforce search cannot prevent it from expanding additional nodes.",null
747.txt,"In addition, they conjectured that the possible contribution of Kaindl and Kainz's BHS algorithm was to avoid generating nodes with f equal to the cost of an optimal path.",In addition
748.txt,We demonstrate computationally that DIBBS can overcome their second conclusion and their conjecture.,null
749.txt,"One might guess that Barker and Korf's pessimistic pronouncements might have stifled further research on BHS algorithms, but it actually had the opposite effect.",it actually had the opposite effect
750.txt,"In their paper, they postulated the existence of a balanced BHS algorithm that never expands nodes deeper than the solution midpoint, even though such an algorithm did not exist at the time.",at the time
751.txt,Holte filled the void by developing the MM algorithm that is guaranteed to meet in the middle.,null
752.txt,"Sharon modified MM to create MM, which exploits knowledge about the smallest cost of an edge.",null
753.txt,A detailed analysis of both algorithms is presented in Holte.,is presented in
754.txt,Computational results presented in these papers established that it is possible for BHS algorithms to expand fewer nodes than either bidirectional bruteforce search or unidirectional heuristic search.,it is possible for
755.txt,See X for a recent survey of bidirectional heuristic search.,null
756.txt,"MM and MM spawned a flurry of research, resulting in several new BHS algorithms and a deeper understanding of the minimum number of nodes that must be expanded by a BHS algorithm.",resulting in
757.txt,Eckerle began investigating the minimum number of nodes that must be expanded.,null
758.txt,"They extended the assumptions from undirectional heuristic search to define Deterministic, Expansion-based, Black Box  bidirectional algorithms.",null
759.txt,They characterized pairs of nodes that must be expanded by any DXBB BHS algorithm.,be expanded by
760.txt,Chen continued this vein of research by proving that the minimum number of node expansions for a DXBB BHS algorithm can be determined by finding a Minimum Vertex Cover  in an auxiliary bipartite graph called GMX.,null
761.txt,"They also developed a BHS algorithm, named Near-Optimal Bidirectional Search , that makes use of this knowledge.",makes use of
762.txt,They proved that NBS will never expand more than twice the number of nodes as the size of a MVC of GMX and that no DXBB BHS algorithm can provide a stronger guarantee than this.,null
763.txt,Shaham constructed an efficient algorithm for finding an MVC of GMX.,null
764.txt,"They also created Fractional MM , which allows flexibility in choosing the meeting point of the forward and backward searches.",null
765.txt,Shaham extend the theory regarding the minimum number of node expansions to the case where the cost of the smallest edge is known and constructed the Meet at the Threshold  algorithm that controls the meeting point of the forward and backward search via a threshold parameter.,null
766.txt,"Shperberg  created the Dynamic Vertex Cover Bidirectional Search  algorithm, which, similar to NBS, uses information about GMX to guide the search, but unlike NBS, does not have a theoretical guarantee about its worst case performance.",have a theoretical guarantee about
767.txt,"Barley created an algorithm named Generalized Breadth-First Heuristic Search , which has great flexibility in controlling where the forward and backward searches.",has great flexibility in
769.txt,"Furthermore, DIBBS assumes that the heuristics are consistent, whereas DXBB algorithms do not.",null
770.txt,"DIBBS does not satisfy these assumptions, so it is not subject to the theoretical minimum number of node expansions provided by the MVC of GMX.",it is not subject to
771.txt,"In fact, in Sections 5 and 6 it is shown that DIBBS often is capable of solving problems while expanding fewer nodes than in a MVC of GMX.",it is shown that
772.txt,"It should be emphasized that while DIBBS shares information between the forward and backward searches, it is a front-to-end  algorithm, which means that the heuristics are only evaluated from a node to either the  start node or the goal node.",It should be emphasized that
773.txt,"This is in contrast with front-to-front algorithms, where the  heuristcs are evaluated from a node to every other node in the frontier of the opposite search  direction.",in contrast with
774.txt,"Front-to-front evaluations dynamically improve the bounds, but at a very high  computational cost.",null
775.txt,DIBBS dynamically improves the bounds with very little additional  computational cost.,null
776.txt,This paper only addresses front-to-end BHS algorithms.,null
777.txt,"After this paper was accepted for publication, the authors were made aware of a paper  by Sadhukhan, in which a similar algorithm was presented.",made aware of
778.txt,"This paper provides more  mathematically rigorous proofs of the correctness of the algorithm, a proof that no node  is expanded twice, a more careful analysis of which nodes will not be expanded, and more  computational testing, including a computational investigation of the minimum number of  nodes that must be expanded.",null
779.txt,"Given an undirected graph  with nonnegative edge costs, a start node s, and a goal node t, the problem is to find a lowest cost path from s to t, where the cost of a path is the sum of the cost of the edges on the path.",the sum of
780.txt,"In order to simplify the presentation and analysis of the algorithm, we assume that there is at least one path from s to t.",In order to
781.txt,An asterisk is used on functions to distinguish an optimal value of the function from a possible suboptimal value along some arbitrary path.,null
782.txt,"For example, gf  is the extra cost of the path P compared  to the lower bound.",For example
783.txt,"However, when ff is used in conjunction with fb within a BHS algorithm,  they can be used to prune nodes and to terminate the algorithm, as will be shown in the  next two sections.",be shown in
784.txt,The following example will be used throughout the paper to illustrate the  denitions and concepts.,null
785.txt,This section presents the bidirectional algorithm and its properties.,null
786.txt,"Capital letters Gd and  Fd are used in the algorithm instead of gd and fd; respectively, in order to distinguish  between values computed by the algorithm and values computed by the original mathematical  denition.",in order to
787.txt,"The Expand Backward function, which is analogous to the Expand Forward  function, is not shown here.",is analogous to
788.txt,The overall approach of DIBBS is similar to many other BHS algorithms that have  appeared in the literature.,is similar to
789.txt,It conducts two searches: a forward search starting from s and  a backward search starting from t: It maintains a closed and open set of nodes in both  directions.,null
790.txt,Closed nodes are the ones that have already been expanded.,null
791.txt,"At each iteration,  a decision is made whether to expand a node in the forward direction or the backward  direction.",null
792.txt,DIBBS is  exible in how that decision is made.,null
793.txt,One possible criteria will be  presented below.,null
794.txt,"Once a direction has been selected, an open node in that direction that  has the smallest value of the priority function is chosen to be expanded.",null
795.txt,"DIBBS diers from other BHS algorithms in that it uses fd as the priority function, as opposed to fd;  which is used by many other BHS algorithms.",as opposed to
796.txt,"The expansion of a node is done similar to other BHS algorithms, with the exception that fd rather than fd is updated .",similar to
797.txt,"Before the next iteration is performed, a termination  criteria is checked.",null
798.txt,DIBBS' termination criteria diers in two respects from many other  BHS algorithms.,null
799.txt,"First, some other algorithms do not terminate until one of the open sets  is empty.",null
800.txt,DIBBS can be terminated while both open sets are nonempty.,null
801.txt,"Second, DIBBS  uses fd in its termination criterion.",null
802.txt,One further dierence is that DIBBS requires consistent  heuristics.,null
803.txt,"If the heuristics are inconsistent, then DIBBS may return a suboptimal path, as  demonstrated in an example in Section 6.",as  demonstrated in
804.txt,DIBBS requires several data structures to be effciently implemented.,null
805.txt,"In particular, the  data structures must be able to choose the open node with the minimum Fd-value, must  maintain a list of both open and closed nodes, and must be able to recognize if a node is in  either of those sets.",In particular
806.txt,"Our implementation uses two heaps, one for the forward direction and  one for the backward direction, to choose the next node to be expanded.",null
807.txt,It stores all the  nodes generated in an unordered list and uses a hash table to determine if a given node is in that list.,null
808.txt,"Sadhukhan developed an algorithm named BAE* that is similar to DIBBS, although  he used dierent notation.",is similar to
809.txt,One other minor dierence between the two algorithms is that BAE* switches  directions every iteration.,null
810.txt,We now prove the correctness of DIBBS.,null
811.txt,Several of the properties are only stated and  proved for the forward search.,null
812.txt,It is to be understood that an analogous property can be  stated and proved for the backward search.,It is to be understood that
813.txt,We begin with the observation that DIBBS  correctly computes the functions .,begin with
814.txt,"This section presents computational experiments with DIBBS on the pancake problem, the  sliding tile puzzle, and on the topspin problem.",null
815.txt,Note that Sadhukhan  only reported  results for BAE* for the sliding tile puzzle.,null
816.txt,The primary purpose of these experiments is a  proof of concept to demonstrate the following claims in practice.,The primary purpose of
817.txt,DIBBS is capable of solving certain problems while expanding fewer nodes than either  FA* or BA*.,either or
818.txt,"DIBBS can overcome Barker and Korf's second conclusion that with a strong heuristic,  BHS will expand more nodes than a unidirectional heuristic search.",null
819.txt,Kainld and Kainz's algorithm performed better than A* merely because it had a  better tie-breaking rule which permitted it to find the optimal path sooner.,performed better than
820.txt,DIBBS is capable of solving certain problems while expanding fewer nodes than the  theoretical minimum for DXBB BHS algorithms.,null
821.txt,"Hence for certain problems it is  capable of outperforming any DXBB algorithm, such as MM, MM, GBFHS, NBS,  MT, DVCBSF , and DVCBSFA.",it is  capable of
822.txt,"Given a stack of n pancakes of distinct diameters, the goal of the pancake problem is to sort them from the smallest to the largest.",the goal of
824.txt,The objective is to minimize the number of flips needed to sort the pancakes.,The objective is to
826.txt,The prefix reversal sorting problem is to find the minimum number of reversals needed to sort the sequence into increasing order.,null
827.txt,"The pancake problem, which is NP-hard , is directly equivalent to the prefix reversal sorting problem.",is directly equivalent to
828.txt,"Helmert , by ignoring the gaps involving the X smallest pancakes.",null
829.txt,"The resulting  heuristic is called GAP-X, where GAP-0 is the same as the original GAP heuristic.",the same as
830.txt,"We  use GAP-1, GAP-2, and GAP-3 to demonstrate how DIBBS performs when given a weaker  heuristic.",null
831.txt,"If the entry  is a percentage, then this is the percentage of the 1,000 instances that were successively  solved before running out of memory.",this is the percentage of
832.txt,An entry of DNR indicates that we did not run the  algorithm because it was estimated that very few of the instances would complete before  running out of memory.,null
833.txt,"The Min algorithm is the algorithm obtained by running  both FA* and BA* and choosing the better one for each problem, it is the algorithm  obtained if we had an oracle that could choose the better direction in advance.",both and
834.txt,The table is  divided into sections based on which heuristic was used.,is  divided into
835.txt,"For each row, the fewest number of  node expansions is in bold.",null
836.txt,"The sliding tile puzzle has been extensively used as a test problem for heuristic search algorithms,  both unidirectional and bidirectional.",null
837.txt,This section presents computational results  for the 15-puzzle on the 100 instances created by Korf  using the Manhattan heuristic.,null
838.txt,The computational results are presented in Table 3.,are presented in
839.txt,"FA* and BA* required too much  memory to be solved, so results for IDA* are reported instead.",null
840.txt,"The table also includes  NBS, DVCBSF;and DVCBSA; since results for these algorithms on the 15-puzzle have been  published.",null
841.txt,"The results for MM and NBS are as reported in X, the results for GBFHS are as  reported in X, and the results for DVCBSF and DVCBSA are as reported in X.",as  reported in
842.txt,The results presented in Table 3 clearly demonstrate that DIBBS dominates the other  algorithms.,null
843.txt,"For unidirectional search, IDA* expanded 115 times as many as nodes as DIBBS.",as many as
844.txt,"G Only the second operation is counted as a move.For these experiments, a  single pattern database of M consecutive positions was used.",counted as
845.txt,"This single pattern  database was used N times, once for postions , MM; GBFHS, and DIBBS contain the average number  of nodes expanded by each of these algorithms.",null
846.txt,"If the entry is a percentage, then this  is the percentage of the 100 instances that were successively solved before running out of  memory.",this  is the percentage of
847.txt,"For these experiments, the direction for each iteration of DIBBS was chosen using  the cardinality rule with f-leveling.",null
848.txt,The computational results for the pancake problem are presented in Table 5. it is the percentage of nodes needed to verify optimality relative to  the number of nodes needed to find and verify optimality.,it is the percentage of
849.txt,"This indicates that for DXBB  algorithms, the best strategy when GAP-0 or GAP-1 is used is to only expand nodes in one  direction, unidirectional dominates bidirectional search.",null
850.txt,"This is in keeping with Barker and Korf's conclusion, With a strong heuristic, a bidirectional heuristic search expands  more nodes than a unidirectional heuristic search.",null
851.txt,This is discussed in greater detail in  Section 7.,is discussed in
852.txt,"For the weaker heuristics, GAP-2 and GAP-3, Table 5 shows that jMVCj and  jMVCj are significantly smaller than Min(FA*,BA*), indicating that unidirectional search  no longer is the best strategy for DXBB algorithms.",null
853.txt,"This can be seen in the computational  results as both MM and GBFHS expand fewer nodes than Min(FA*,BA*), for both verifying  optimality .",both and
854.txt,"Examining the last column in Table 5 reveals that when GAP-0 is used, only about 26%  of the total eort is needed to verify the optimality, whereas about 74% is needed to find  the optimal path.",null
855.txt,This indicates that the optimal path was found relatively late during the  search.,null
856.txt,"For GAP-1, GAP-2, and GAP-3, the opposite occurs; most of the total eort is  needed to verify optimality.",null
857.txt,"This indicates that the optimal path is found relatively early  during the search, but many more nodes must be expanded to verify the optimality of the  path.",null
858.txt,The computational results for the topspin problem are presented in Table 7.,are presented in
859.txt,This indicates that unidirectional  search dominates DXBB bidirectional search algorithms when the stronger heuristics are  used.,null
860.txt,There are several ways that BHS algorithms can improve upon FA* or BA*.,There are several ways that
861.txt,One larger search replaced by two smaller searches.,replaced by
862.txt,"To illustrate this point,  suppose the graph has a uniform branching factor of b, all edges have unit cost, and  heuristics are not used.",null
863.txt,"Consequently, the bidirectional search  is exponentially faster than the unidirectional search.",null
864.txt,"In fact, this observation was the  initial source of optimism that bidirectional heuristic search could outperform unidirectional  heuristic search  in a similar manner.",In fact
865.txt,"As mentioned at the beginning  of this paper, the anticipated improvement from two smaller searches, by and large,  did not materialize in practice for earlier BHS algorithms.",As mentioned at the beginning  of
866.txt,"By  using a dierent priority function and a dierent termination criteria, MM is capable  of solving problems while expanding fewer nodes than either FA* or BA*.",is capable  of
867.txt,Hence it has  achieved the long sought goal of replacing one larger search by two smaller searches.,replacing by
868.txt,DIBBS also achieves the long sought goal of replacing one larger search by two smaller  searches.,null
869.txt,"The results for the 15-puzzle are even more striking, where Table 3 shows that DIBBS  reduces the number of node expansions by a factor of 115 compared to IDA*.",compared to
870.txt,The results for the topspin problem are somewhat dierent.,null
871.txt,"Overall, the computational results demonstrate  that DIBBS, like MM and GBFHS, is capable of solving problems while expanding  fewer nodes than either FA* or BA*.",is capable of
872.txt,The approach taken by MM and GBFHS is quite  dierent than the approach taken by DIBBS.,null
873.txt,"MM and GBFHS accomplish this goal by  controlling where the two searches meet, whereas DIBBS does not control where the  searches meet but uses dynamically improved bounds to reduce the size of the search.",null
874.txt,It is an area of future research to explore whether or not the two approaches can be  successfully combined into a single algorithm.,It is an area of future research to
875.txt,"The results discussed in the previous paragraph, especially for the extremely strong  GAP-0 heuristic, convincingly demonstrate that DIBBS can overcome Barker and  Korf's second conclusion that with a strong heuristic, BHS will expand more nodes  than a unidirectional heuristic search.",null
876.txt,"DIBBS achieves this by dynamically improving  the bounds, or stated more generally, by using information from one search direction  to aid the other direction.",null
877.txt,Their analysis implicitly assumed that such sharing of  information would not happen.,null
879.txt,"For many combinatorial optimization problems, one search direction may be significantly easier than the other direction.",be significantly easier than
880.txt,"For some such  problems, the easier direction might always be the same.",null
881.txt,"For example, Barker and  Korf  reported that the forward direction is consistently easier than the backward  direction for the peg solitaire problem.",For example
882.txt,"In such a case, one would choose to use FA*  over BA*.",null
883.txt,"But for many other problems, the better direction is dependent on the  particular instance, in which case it is not known apriori whether it will be better to  use FA* or BA*.",it will be better to
884.txt,Bidirectional search has the advantage that it can use information as  the algorithm proceeds to determine which direction is easier and then place greater  emphasis on that direction.,null
885.txt,"For the pancake problem, Table 2 shows that the better direction is dependent on the  instance when GAP-0 or GAP-1 is used.",is dependent on
886.txt,"For example, FA*  expands 92,309 nodes on average, which is about 5% more nodes than BA*, which  expands 88,234 nodes, on average.",For example
887.txt,"But if the better direction was known for each  instance in advance, then the number of node expansions could be reduced to 56702  on average, which represents a 35% reduction.",on average
888.txt,"While we do not know of a way to  directly measure how much DIBBS benefitted from exploiting the easier direction, it  could not have not benefitted more than 35%.",more than
889.txt,"Interestingly enough, when GAP-2 or GAP-3 is used, the backward direction is consistently  better than the forward direction.",better than
890.txt,"This can be seen in Table 2 by observing  that the number of nodes expanded by BA* and Min are nearly identical,  while the number of nodes expanded by FA* is much larger.",This can be seen in
891.txt,"For GAP-2 and GAP-3,  the improvement of DIBBS over FA* may be partially due to exploiting the better  direction, but the improvement over BA* is not.",due to
893.txt,It is well known that for many combinatorial  optimization problems there are a large number of nodes with f .,It is well known that
894.txt,"In this case, finding the  optimal path sooner is a realtively small component of the overall success of DIBBS  over FA* and BA*.",null
895.txt,"For the 15-puzzle, comparing Table 3 to Table 5 reveals that IDA* expands 115 times  as many nodes as DIBBS when C is not known in advance and 90 times as many  nodes when C is supplied as the initial upper bound.",as many as
896.txt,"Hence, finding the optimal path  sooner is a relatively small component of the overall success of DIBBS over IDA*.",null
897.txt,"For the topspin problem, especially for the stronger heuristics, Tables 4 and 7 show that  finding the optimal path sooner is a large component of the overall success of DIBBS  over FA* and BA*.",null
898.txt,"For these problems, DIBBS actually requires slightly more node  expansions to verify optimality than Min, but requires significantly fewer  node expansions to find and verify optimality.",null
900.txt,Bidirectional search has the potential advantage  of using information from one direction to improve the bounds in the backward direction.,has the potential advantage  of
901.txt,DIBBS uses dynamically improved bounds to avoid expanding nodes with  min and to terminate the algorithm sooner.,null
902.txt,"It is difficult to measure how much each of the possible sources of improvement contribute  to the overall success of DIBBS, or any other BHS algorithm, because they are intricately  interwoven.",It is difficult to
903.txt,"For example, not only do dynamically improved bounds prevent the expansion  of nodes with min and permit the search to be terminated earlier.",For example
904.txt,Iris recognition as a reliable method for personal identification has many important applications in both public and personal security areas.,has many important applications in
905.txt,Iris recognition has been well studied with the objective to assign class label of each iris image to a unique subject.,null
906.txt,This paper proposes a general framework for iris image classification based on texture analysis.,based on
907.txt,A novel texture representation method called Hierarchical Visual Codebook is proposed to encode the texture primitives of iris images.,is proposed to
908.txt,"The HVC is an integration of two existing Bag-of-Words models, namely Vocabulary Tree and Locality-constrained Linear Coding .",an integration of
911.txt,A comprehensive fake iris image database simulating four types of iris spoof attacks is developed as the benchmark for research.,is developed as
913.txt,"Iris recognition has become a hot research topic driven by its wide applications in national ID card, border control, banking, etc.",null
914.txt,Iris is a ring-shaped region of human eye with rich texture information under near infrared illumination.,null
915.txt,Iris texture is regarded as a genotypic biometric pattern and stable during life so that iris recognition provides an extremely reliable method for individual authentication .,so that
916.txt,"Iris recognition aims to assign a unique identity label to each iris image based on automatic preprocessing, feature analysis and feature matching.",aims to
918.txt,"In traditional iris recognition applications, iris images taken from a human eye are defined as the same class so that the dissimilarity between iris images of different subjects should be identifind.",so that
920.txt,"For example, in iris liveness detection, one needs to classify all iris images  into two categories, genuine or fake iris images;",For example
925.txt,"Both iris image classification and iris recognition can be globally regarded as the same problem of pattern recognition, i.e.",regarded as
927.txt,The only difference is the definition of class labels at macro or micro scale.,null
928.txt,"For recognition, the class label is the identity of a person .",null
929.txt,So the solution of iris image classification is significantly different to iris recognition.,is significantly different to
930.txt,Iris texture naturally has unique pattern for each subject so we can extract the individually specific features to distinguish different subjects.,null
933.txt,"Therefore, iris image classification is actually a more challenging problem compared with iris recognition.",compared with
934.txt,The main challenges of iris image classification are summarized as follows.,The main challenges of
936.txt,The visual appearance of human iris is a complex texture pattern.,null
942.txt,So it is inevitable to introduce some ambiguity into the definition of iris image categories.,it is inevitable to
943.txt,How to represent iris image features suitable for the classification task?,suitable for
944.txt,Iris images naturally exhibit random texture patterns and we usually use the detailed image features for iris recognition.,null
945.txt,"However, the existing feature representation methods in iris recognition cannot be directly used for iris image classification.",used for
946.txt,"On one hand, the iris features for classification should tolerate the within category difference of detailed texture information.",On one hand
947.txt,"On the other hand, the iris features for classification should be distinctive for intercategory iris images.",On the other hand
948.txt,"Therefore, the iris features for classification should exhibit both similarity and dissimilarity for interclass iris  images.",null
949.txt,"For iris images from a same category, the iris features should be clustered closely even these iris images are captured from different subjects.",null
950.txt,"For iris images from different categories, the iris features should be separated at a distance.",null
951.txt,So it is a grand challenge to develop image feature representation method for iris image classification due to such a contradiction.,it is a grand challenge to
952.txt,Work on iris image classification is driven by specific application of iris biometrics.,null
953.txt,So the related works on  iris  image classification for three kinds of typical applications  are summarized as follows.,are summarized as follows
954.txt,An iris recognition system may suffer from illegal attacks since it is usually used to protect valuable resources.,it is usually used to
955.txt,Attack at iris sensor level with forged iris patterns printed on contact lens or paper is a straightforward risk for iris biometrics.,null
956.txt,So iris liveness detection is necessary to protect an iris recognition system from attacks of fake iris images.,is necessary to
957.txt,There are mainly two approaches to check the liveness of input iris images in the literature.,There are mainly two approaches to
960.txt,This approach needs special design of iris sensors.,null
961.txt,"An alternative approach  is to check the liveness characteristics of iris images based on texture analysis, which has the advantage of independence of iris sensors.",based on
963.txt,Quality based image measures were also used for iris liveness detection.,used for
964.txt,"Genuine and fake iris images have distinctive texture patterns, therefore, well developed texture analysis and pattern classification methods can be used for iris liveness detection.",be used for
965.txt,"The texture features useful for iris liveness detection include gray level co-occurrence matrix , statistical distribution of iris texture primitives , local binary patterns and weighted-LBP.",null
967.txt,Some attempts have been made to perform race classification based on biometric images.,based on
968.txt,"Most of the early work is based on facial images, such as the work in X.",such as
969.txt,It is intuitive that visual appearance of human iris is related to racial information.,It is intuitive that
970.txt,"For example, eyes of Western subjects usually exhibit bright and colorful iris appearance with clear texture patterns.",For example
971.txt,"In contrast, eyes of most Asian subjects show brown or dark appearance and it is impossible to obtain detailed texture information in visible lighting.",it is impossible to
972.txt,"Therefore, we argue that human iris is a biometric  trait  with  both  phenotypic  and genotypic features, which is a fundamental assumption enabling iris texture based race classification.",null
973.txt,The phenotypic features of iris biometrics are mainly illustrated in local details of iris texture patterns which are unique to each subject.,are unique to
975.txt,"Although we can observe the similarity in both color and texture of iris images between generelated human eyes , this paper mainly addresses the problem of automatic race classification based on iris texture features.",addresses the problem of
979.txt,So we developed a specific visual  vocabulary namely Iris-Texton to classify Asian and non-Asian subjects based on iris images.,based on
980.txt,Recently we borrowed the ideas of object recognition such as Bag-of-Words model with well optimized codebook for racial iris image classification.,null
981.txt,And Lyle used Local Binary Patterns of periocular biometrics for gender and race classification.,null
983.txt,"As a unique and stable biometric modality, iris pattern is used to identify large population in many government and commercial applications.",is used to
984.txt,"However, large scale iris identification can be much less accurate and less efficient than is commonly believed.",less than
985.txt,A possible solution to speed up large scale iris identification is to classify the large database into a number of categories based on iris texture.,based on
986.txt,"Then, a query iris image is the most promising to be identifind using the templates from its corresponding category.",null
987.txt,It can improve the accuracy of iris recognition by integrating global texture information in classification stage and local texture features in recognition stage.,It can improve the accuracy of
988.txt,There are a few iris image classification methods proposed for coarse iris image classification.,proposed for
991.txt,Mehrotra used energy based histogram of multi-resolution DCT transformation to group iris images.,null
992.txt,Sunder investigated iris macro-features  for iris retrieval and matching.,null
993.txt,"Compared with iris recognition, iris image classification has not been well defined and addressed in the literature.",Compared with
994.txt,Existing research work related to iris image classification is scattered  in pieces for specific problems.,related to
995.txt,"In this paper, we attempt to provide a systematic study of the iris image classification.",attempt to
996.txt,The main contributions of our work are summarized as follows.,The main contributions of our work are
997.txt,"This paper systematically addresses the problem of iris image classification, including its definition, core problems, challenges and applications.",addresses the problem of
998.txt,We propose a general framework for iris image classification based on statistical texture analysis.,based on
999.txt,Three typical applications of iris image  classification  are unifind into the general framework.,are unifind into
1000.txt,So that research efforts in separated problems can be unifind together and advanced solutions to iris image classification will be motivated with the guidance of such a framework.,null
1001.txt,"In addition, a common module of iris image classification can be developed for iris recognition systems for various applications inspired by the general framework.",In addition
1002.txt,A novel texture pattern representation method called Hierarchical Visual Codebook  is proposed to encode the distinctive and robust texture primitives of iris images.,is proposed to
1003.txt,The HVC combines Vocabulary Tree and Locality-constrained Linear Coding to achieve a hierarchical and sparse representation of visual vocabulary.,null
1004.txt,It performs well in typical applications of iris image classification and the results prove that Bag-of- Words model is well suited for iris image classification.,It performs well in
1005.txt,"In addition, HVC provides a promising approach to learn class-specific visual codebook for general image classification.",In addition
1006.txt,Our study on HVC based race classification demonstrates the genotypic nature of iris texture.,null
1007.txt,The success of race classification based on iris images indicates that an iris image is not only a phenotypic biological signature but also a genotypic biometric pattern.,based on
1009.txt,"However, the success of iris image classification does not contradict the fact of accurate individual authentication.",null
1010.txt,Iris image classification and iris recognition are two different concepts and use texture features at different scales to represent iris pattern.,null
1011.txt,Iris texture at a macro scale can reveal the similarity between iris images but the detailed minute iris features can successfully discriminate individuals.,null
1012.txt,An iris image database with four types of fake iris patterns  namely CASIA-Iris-Fake is developed in this paper.,null
1013.txt,The existing research of iris liveness detection are limited on detection of specific fake iris images printed on paper  due to the lack of a universal benchmark containing a variety of fake iris patterns.,due to
1014.txt,The publication of CASIA-Iris-Fake will definitely advance the development of unifind countermeasures against iris spoof attacks.,null
1015.txt,The remainder of this paper is organized as follows.,is organized as follows
1016.txt,"Section 2 proposes a general framework for iris image classification, and the proposed novel iris pattern representation method  is described in details.",is described in details
1019.txt,"A general framework of iris image classification based on a novel texture pattern representation method called Hierarchical Visual Codebook  is proposed in this section, as shown in Fig.",is proposed in
1021.txt,The framework  mainly  includes  four  modules:  iris image preprocessing; low level visual feature extraction; statistical iris image representation based on HVC model; iris image classification.,based on
1023.txt,segmentation of the valid iris texture regions from the original iris images and normalization of the ring-shape iris regions into a unifind coordinate system.,null
1024.txt,"Since the focus of this paper is iris image classifination, the iris image preprocessing method in X is adopted.",null
1025.txt,Traditionally iris images are normalized into polar coordinate system.,are normalized into
1031.txt,"In  this  paper,  we  propose  to  use  dense  SIFT descriptors as the low level features for iris image classification.",propose  to
1032.txt,"Firstly, the gradient  information  encoded  in  SIFT  provides a generic description of local regions for all iris images.",null
1033.txt,"Secondly, the histogram derived from SIFT is distinctive for iris image classification.",is distinctive for
1034.txt,"Thirdly, SIFT is proven as one of  the most robust descriptors in image analysis.",is proven as
1035.txt,Therefore we argue that SIFT is well-suited for low feature extraction in iris image classification.,null
1036.txt,"In this paper, SIFT descriptors are computed at local regions using a 16 window, and each window is divided into 44 cells.",is divided into
1037.txt,"Image gradients within each cell are quantized into a 8-bin histogram, which results in a 128-D SIFT feature.",results in
1038.txt,The SIFT descriptors are densely extracted from the normalized iris images.,null
1040.txt,"Given the low level visual features, it is suggested to obtain the statistical texture representation for iris image classification.",it is suggested to
1041.txt,So that the individual difference of detailed iris texture can be tolerated and the global texture representation is discriminative enough to distinguish iris images of different categories.,null
1042.txt,Bag of Words model is demonstrated as the most popular statistical feature representation in object recognition.,is demonstrated as
1044.txt,The most important issue in BoW  is visual codebook learning and coding.,The most important issue in
1046.txt,Therefore our focus is to develop a novel visual codebook adaptive to the iris texture characteristics.,null
1047.txt,"Compared with the visual signals in general object recognition or scene classification tasks, iris images do not contain abundant structural information and the main visual features in iris patterns are texture information.",Compared with
1048.txt,"In addition, the global texture features between various iris images are much more similar than the visual features between different objects or natural scene images.",In addition
1049.txt,It indicates that the variations of iris textures are distributed  in a relatively small part of the feature space.,are distributed  in
1054.txt,The  basic  idea of VT is to hierarchically represent a large set of representative visual words through recursive applications of K-means clustering.,null
1055.txt,Therefore a larger vocabulary can be used to better model the visual contents of images with a much more efficient lookup of visual words.,be used to
1056.txt,"Since iris images are rich of various texture primitives, it is a good idea to extend the idea of VT to iris image classification.",it is a good idea to
1057.txt,A success of a Bag-of-Words model is mainly contributed by a good visual codebook and a good visual coding strategy.,is mainly contributed by
1058.txt,"Although VT is a good approach to build visual codebook, the hard voting based Vector Quantization coding in VT is not a good visual coding strategy.",is a good approach to
1059.txt,Some coding errors may be introduced into visual representation because of the similarity of some visual words.,be introduced into
1060.txt,So we prefer to a soft voting based visual coding strategy such as LLC.,such as
1061.txt,LLC is an effective visual coding scheme which utilizes the locality constraints to project each descriptor into its local-coordinate system with low computational complexity.,null
1062.txt,It aims to reconstruct visual features with locality constraint instead  of sparsity constraint based on the following optimization criteria.,aims to
1063.txt,"In our approach, the empty clusters obtained during hierarchical codebook learning are also represented with the same method as the real codes, but these codes have value 0 and are not used for coding.",are not used for
1064.txt,"In this section, we use the three levels hierarchical visual codebook as an example to illustrate the coding algorithm.",as an example to
1065.txt,It is easy to extend the example to the cases with more coding levels.,It is easy to
1066.txt,The HVC is integrated into the coding process rather than following a single path down of the vocabulary tree during the image representation phase.,rather than
1067.txt,Each description vector is propagated down the tree by codes allocation in selected candidate codes at each level.,null
1068.txt,We initialize candidate nodes with all the nodes in the first level of B.,in the first level of
1069.txt,The solution of the coding in the i-th level is derived analytically by.,null
1070.txt,The proposed HVC model has both efficiency and robustness advantages during the code book learning phase.,null
1071.txt,"Firstly,the hierarchical K-means classify all features into a small number of classes, and then classify the subset of features belonging to each class into a small number of classes in the next level clustering.",null
1072.txt,It is clear that learning a small number of codes from a subset of feature pool is more efficient than learning a large number of codes from feature pool.,It is clear that
1073.txt,The hierarchical strategy can learn codes from multi-scales.,null
1074.txt,"Secondly, the hierarchical K-means clustering shows robustness in clustering tasks.",null
1075.txt,It performs better than K-means when the intra-class variations are large and the inter-class differences are small.,better than
1076.txt,"The hierarchical K-means is suitable  for iris texture codebook learning, since iris texture is highly random pattern but with relatively smaller variations than natural scene images.",is suitable  for
1077.txt,"Some texture primitives are seldom shown in the codebook learning, but they play significant roles in the iris image classification task.",play significant roles in
1078.txt,These important visual codes with low probability of occurrence may be ignored by the traditional K-means clustering.,null
1079.txt,"In contrast, the hierarchical clustering strategy used in HVC is possible to reserve these visual codes in local feature space.",In contrast
1080.txt,The proposed HVC method achieves small quantization error owning to the dependency between codes in a down path through the vocabulary tree and sparse coding strategy.,null
1081.txt,The tree structure represents some relationships between the codes and creates  overlapping  partitions  of  feature  spaces.,between and
1082.txt,It can capture salient pattern of local descriptors by local constrained and parents constrained coding in each level.,null
1083.txt,The HVC method avoids accumulating errors  from  root  level and provides possibility to correct the quantization errors at lower levels by adopting the feature reconstruction strategy for coding.,null
1084.txt,Max pooling of HVC coding results for all image patches can achieve a powerful statistical feature representation of an iris image.,null
1085.txt,"However, histogram representation of HVC features is a description  of  orderless  patch-based  visual  features so it loses spatial information.",null
1086.txt,A better solution is to combine  HVC with the spatial pyramid matching model  to achieve much higher recognition accuracy.,combine with
1087.txt,But the combination of HVC and SPM will increase the dimensionality of feature vector.,the combination of
1088.txt,"During the coding phase, HVC uses the feature reconstruction strategy for coding, which results in more accurate image representation compared to the vocabulary tree method .",compared to
1089.txt,"Except the first level coding, the coding process just uses the children nodes of k codes with the largest projections in the upper level as the candidate codebook.",null
1090.txt,"This strategy, on one hand, reduces the computational complexity comparing with using all the codes in the vocabulary tree.",on one hand
1091.txt,"On the other hand, the HVC replaces the hard voting with feature reconstruction strategy for coding, which avoids accumulating errors from root level and provides possibility to correct the quantization errors at lower levels.",On the other hand
1092.txt,"In X, the hard voting is used for coding, which may cause projection error lasting from the root of the vocabulary tree to leaves.",is used for
1093.txt,A small quantization error at the root may accumulate into a large quantization error at the leave nodes.,accumulate into
1094.txt,"HVC coding can solve this problem, because it has more than one path through down the vocabulary tree, which uses codes with different parent nodes to reconstruct a descriptor.",more than
1095.txt,"It reduces the dependence on upper level coding, and quantization errors can be corrected at the later level coding process.",null
1096.txt,"Given the statistical representation of HVC features, iris image classification becomes a standard pattern recognition problem and well established classificr such as SVM can be used to predict the class labels.",such as
1097.txt,"To demonstrate the effectiveness of the proposed iris image classification framework, three typical applications, i.e.",null
1099.txt,There are many ways to make counterfeit iris patterns and Fig.,There are many ways to
1101.txt,It is a challenging task to discriminate all these kinds of fake iris images and genuine iris images.,It is a challenging task to
1102.txt,Here a promising iris liveness detection method   is developed based on the proposed iris image classification method.,based on
1103.txt,"Because of the importance of iris liveness detection, some iris image databases containing iris images with cosmetic contact lenses have been published in public domain in recent years.",in recent years
1104.txt,"To the best of our knowledge, the Notre Dame Cosmetic Contact Lenses 2013 is the largest one.",null
1105.txt,"This dataset contains iris images  of subjects without contact lenses, with soft contact lenses, and with cosmetic contact lenses, acquired using an LG 4000 iris sensor.",null
1106.txt,"In our research, both iris images without contact lenses and with soft contact lenses are regarded as genuine iris images because iris texture patterns are still visible through  soft contact lenses to achieve correct identification.",regarded as
1107.txt,And the iris images with cosmetic contact lenses are treated as fake samples.,are treated as
1108.txt,"Although ND-Contact is a good database for research of iris liveness detection, it only has one type of fake iris images, i.e.",null
1110.txt,"Therefore, we developed a more comprehensive database namely CASIA-Iris-Fake for iris liveness detection  is used to capture a large number of fake iris images.",is used to
1111.txt,The Synth subset contains fake iris images artificially synthesized from fake iris images with cosmetic contact lens pattern.,null
1112.txt,These four kinds of typical fake iris images have seemingly realistic iris texture and are useful for testing the performance of iris liveness detection methods.,are useful for
1113.txt,Approaches to generate these fake iris patterns are described as follows.,are described as follows
1114.txt,The UPOL iris database  contains high-quality iris images with abundant and clear iris texture.,null
1115.txt,So one image of each class is randomly chosen and printed on paper using the Fuji Xerox C1110 printer as the counterfeit input of iris recognition systems.,null
1117.txt,each printed iris pattern to construct the Print dataset.,null
1118.txt,There are totally 640 images in this dataset.,null
1119.txt,Cosmetic contact lens are popular currently so we collected 57 kinds of cosmetic contact lens with different texture patterns.,null
1120.txt,Some volunteers are asked to wear these contact lens and then an iris device is used to capture iris images of these subjects.,is used to
1121.txt,There are totally 74 left and right eyes wearing these contact lens.,null
1122.txt,Five fake iris images are captured from each eye to construct the Contact dataset  shows some examples.,null
1124.txt,Ten fake iris image are captured per sample.,null
1125.txt,Therefore there are totally 400 fake iris images in the Plastic dataset.,null
1126.txt,The idea of iris image synthesis is used to generate fake iris images based  on  the  Contact  dataset.,is used to
1127.txt,"We  adopt  the patch-based sampling method  for  synthesis,  and  both intensity and texture features are considered to select sampling patches with smooth transition boundaries.",both and
1128.txt,Various intra-class variations  shows some examples.,null
1129.txt,"We use the same device to capture 6000 genuine iris images from 1, 000 subjects as the positive samples in the experiments of iris liveness detection.",null
1130.txt,Three experiments are carried  out  to  test  the  performance of iris liveness detection methods under different conditions.,are carried  out  to
1132.txt,"Thirdly, the robustness and generalization capability of machine learning based iris liveness detection methods  are  evaluated  on the CASIA-Iris-Fake when the training and testing datasets contain different types of fake iris images.",null
1133.txt," To evaluate the overall performance of iris liveness detection methods, the four fake iris image datasets of CASIA-Iris-Fake are combined together.",the overall performance of
1135.txt,"We use 600 fake and 600 genuine iris images as positive and negative training samples, and others for testing.",null
1136.txt,The ROC curves and the Correct Classification Rate  with Matlab2011 as the programming software.,null
1137.txt,A number of conclusions can be drawn from the experimental results.,be drawn from
1138.txt,"Firstly, all iris image classification methods based on BoW can achieve high accuracy in detection of various fake iris patterns.",based on
1139.txt,"Secondly, the iris liveness detection methods based on learned BoW model  generally perform better than the BoW model without learning such as LBP.",based on
1140.txt,"Thirdly, the proposed HVC is the best performing BoW model for iris liveness detection.",null
1141.txt,"Fourthly, SPM can slightly improve the accuracy of both LLC and HVC with the cost of much higher dimensionality of feature vector.",improve the accuracy of
1142.txt,HVC with two levels of SPM can already achieve better performance than LLC with three levels of SPM.,better performance than
1143.txt,The experimental results demonstrate the spatial distribution information of iris texture primitives is not critical to iris image classification.,is not critical to
1144.txt,But spatial operators such as SPM can provide complementary information to BoW.,such as
1145.txt,So it is suggested to combine HVC and SPM for detection of fake iris patterns in highly secure applications.,it is suggested to
1148.txt,All  the  methods  are  performed  on  the  whole  normalized  iris  image without dividing it into small blocks.,are performed  on
1149.txt,"For the four datasets of CASIA-Iris-Fake, we use 100 fake and 100 genuine iris images as training samples, and the other images are used as the testing samples.",are used as
1150.txt,"For ND-Contact, we use the setting of training and testing datasets defined by the database provider, i.e.",defined by
1151.txt,"a training set of 3,000 images including 2,000 genuine samples and 1,000 fake samples and a testing set including 800 genuine samples and 400 fake samples.",null
1152.txt,We can learn from the experimental results in this Section what are the most important issues in development of an effective iris liveness detection method.,the most important issues
1153.txt,"The problem of iris liveness detection can be solved in hardware level, software level or a com- bination of hardware and software.",be solved in
1154.txt,This paper demonstrates that iris image classification provides a good strategy to detect possible spoof attacks to an iris recognition system at software level.,This paper demonstrates that
1155.txt,Such a solution to iris liveness detection does not need special design of iris devices and it is applicable to all kinds  of iris sensors.,it is applicable to
1156.txt,There are many possible ways to develop an iris image classification method for iris liveness detection.,There are many possible ways to
1157.txt,Our experimental results demonstrate that learning visual codebook specific to genuine and  fake  iris  patterns  can generate a good feature representation for this purpose.,for this purpose
1158.txt,State-of-the-art BoW models in visual recognition such as Vocabulary tree  are good approaches for training the visual representation of iris liveness  detector.,are good approaches for
1159.txt,"This paper proposes a novel visual codebook namely HVC, a combination of VT and LLC, which performs the best in terms of accuracy and generalization for iris liveness detection.",in terms of
1160.txt,The advantage of HVC over VT and LLC is much more significant in real world applications when fake iris pattern types in the training dataset are limited.,The advantage of
1161.txt,The  experimental  results  on cross datasets show that the performance of iris liveness  detection methods may degrade greatly when the special types of fake iris patterns in testing has not been used for training.,has not been used for
1162.txt,This observation reminds us include all kinds of fake iris patterns for training.,null
1163.txt,But it is impossible to know all possible fake iris patterns used by the attackers since iris recognition systems are usually installed in a open environment.,it is impossible to
1164.txt,There are two possible solutions to this problem.,There are two possible solutions to this problem
1165.txt,One is to develop  a robust iris image classification method such as HVC.,such as
1166.txt,"The other is to update the training data of fake iris patterns online, just like the update of virus database in anti-virus software.",null
1167.txt,Race is a classification system used to  categorize  humans into genetically differentiated populations or groups defined by phenotype .,used to
1168.txt,There are a large number of different races in the world.,a large number of
1169.txt,"And the parents of some subjects may come from different races so it is difficult to precisely determine the race category of these subjects, which may generate ambiguity in research of racial classification.",it is difficult to
1170.txt,"Nevertheless, it is meaningful to develop an automatic race classification based on biometric patterns for promising commercial and forensic applications.",it is meaningful to
1171.txt,"And a good start point is the research of classifying subjects with significant racial distinction, which is a well defined pattern classification problem.",null
1172.txt,"For example, this paper mainly discusses iris biometrics based race classification of typical Asian and non-Asian subjects.",For example
1173.txt,"In our experiments, almost all Asian subjects are Chinese and all non-Asian subjects are white people living in Europe or USA.",null
1174.txt,So the ground truth of class label is clearly defined in our research.,null
1175.txt,Three multi-race iris image databases are used in this paper to evaluate the effectiveness of racial iris image classification methods .,the effectiveness of
1176.txt,The CASIA multi-race iris image database .,null
1177.txt,Randomly selected 500 Asian iris images and 500 non-Asian iris images are used as the training set and all the remained iris images are used as the testing set.,are used as
1178.txt,ND-CrossSensor-Iris-2013 Dataset is a large iris image database in the literature and it has race label information for each image.,null
1179.txt,So it is a good database for research of racial iris image classification.,it is a good database for research of
1180.txt,"However, most subjects in this database are white people and each subject has a large number of iris images across multiple sessions.",a large number of
1181.txt,So we need to select a subset from it namely ND multi-race iris image database for our research of racial iris image classification.,null
1182.txt,There are two iris devices used to collect ND-CrossSensor-Iris-2013 Dataset.,used to
1183.txt,"In the dataset of LG2200, 1,194 iris images of 60 Asian subjects and 10,660 iris images of 534 white people are used for race classification experiments.",are used for
1184.txt,"In the dataset of LG4000, 1,124 iris images of 60 Asian subjects and 9,641 iris images of 534 white people are used for race classification experiments.",are used for
1185.txt,"To keep the balance between the iris images of Asian and non-Asian subjects, 8188 iris images of 411 Asian subjects from CASIA-Iris- Lamp are added into the LG2200 and LG4000 dataset.",keep the balance between and
1186.txt,"In each dataset, randomly selected 2,000 Asian iris images and 2,000 non-Asian iris images are used as the training set and  all the remained iris images are used as the testing set.",are used as
1187.txt,"To establish a benchmark for research and comparison of new race classification methods, the IDs of all ND, Clarkson and CASIA iris images selected for the experiment are listed in the document .",null
1188.txt,We have mentioned in Section 2.2 that SIFT is a suitable low level feature descriptor for iris image classification.,null
1189.txt,"So CASIA multi-race iris image database is used to compare the effectiveness of various low level visual features including Gabor, LBP and SIFT for racial iris image classification.",is used to
1190.txt,The experimental results are shown in Table 3 and a number of conclusions can be drawn as follows.,are shown in
1191.txt,"Firstly, SIFT can achieve much higher accuracy than Gabor and LBP when these low level feature descriptors are combined with HVC for racial iris image classification.",achieve much higher accuracy than
1193.txt,This observation demonstrates the difference  between the feature representation in iris recognition and iris image classification.,between and
1194.txt,"Secondly, HVC is a significantly better feature representation method than LLC in the task of racial iris image classification.",better than
1195.txt,"Thirdly, the proposed racial iris image classification method  can successfully discriminate iris images of Asian and non-Asian subjects with an extremely  high accuracy.",with an extremely  high accuracy
1196.txt,The experimental results demonstrate that iris texture pattern is an useful indicator of racial category of a subject.,is an useful indicator of
1197.txt,Therefore the iris biometrics must be a genotypic biometric trait.,null
1198.txt,The racial iris image classification results on the ND multi-race iris image database consistently demonstrate the advantages of the proposed HVC model.,the advantages of
1199.txt,The results also show that racial iris image classification methods can achieve higher accuracy in LG4000 dataset because LG4000  is a more advanced iris device than LG2200 and it can capture higher quality iris images.,achieve higher accuracy in
1200.txt,This conclusion remind us to use high-quality iris devices to capture clear and detailed iris texture for race classification.,null
1201.txt,The high accuracy of racial iris image classification achieved in long-range iris recognition applications  demonstrates the possibility to predict the racial category of a subject at a distance.,null
1202.txt,So that the propose racial iris image classification method has wider applications in commercial or forensic areas.,has wider applications in
1203.txt,"For example, if a  long-range iris device can recognize that the coming customer is an Asian subject from 3 meters away in a less cooperative manner, the automatic vending machine can recommend the most favorite products of Asian users to him.",For example
1204.txt,The results on this database again prove that HVC is the best performing visual representation method for iris image classification.,null
1206.txt,It is a good idea using the proposed HVC method to classify iris images into multiple  categories.,It is a good idea
1207.txt,Some typical iris images from different categories are shown in Fig.,are shown in
1210.txt,"Firstly, iris indexing is performed based on iris image classification.",based on
1211.txt,"Secondly, the query iris image is matched with templates in the retrieved candidate dataset one by one.",is matched with
1212.txt,"As we know, iris indexing is a classification task without ground truth category labels.",null
1213.txt,Categorization is performed by manual labeling or automatic clustering.,is performed by
1214.txt,We adopt an automatic clustering strategy which uses K-means clustering to partition iris images into several categories.,null
1215.txt,Each category is represented by the cluster center vector.,is represented by
1216.txt,A training iris image is labeled according to its nearest clustering center.,according to
1217.txt,The process of iris indexing includes training and testing phases.,null
1218.txt,"The training phase learns the hierarchical visual code-book, clusters iris images and trains classificrs.",null
1219.txt,The testing phase uses the learned classifier to classify a query iris into one category.,null
1220.txt,The linear SVM classifier  is adopted.,null
1221.txt,"Since SVM cannot  be  directly  used  for multi-class classification, a  strategy  of  one  against  the  rest  is  used.",used  for
1222.txt,"The  iris  image classification result cannot guarantee 100% accuracy, so that in practice we can search the high confidence matching template in the most similar category.",so that
1223.txt,The coarse iris image classification experiments are conducted on the large iris image database CASIA-Iris-Thousand   and SVM classification methods are implemented for comparison.,conducted on
1225.txt,Euclid- ian and Chi-square distance are adopted as the dissimilarity functions.,adopted as
1226.txt,A query image is compared to all the images used for training and classified into the category of its nearest neighbor.,compared to
1227.txt,It is more challenging to achieve high classification accuracy with the increasing number of categories.,It is more challenging to
1228.txt,The "HVC SIFT" method achieves the best and the "HVC Gabor" method is better than "Qiu" .,better than
1230.txt,The difference between Euclidian distance and Chi-square distance is not significant for "HVC SIFT" method in this experiment.,is not significant for
1231.txt,But it is much better to use the Chi-square distance as the dissimilarity function for "HVC Gabor" method.,it is much better to
1232.txt,"In the second experiment, SVM is used as the classifier.",is used as
1233.txt,"Experimental results demonstrate that SVM is worse than the NN classifier in iris image classification, but much faster than the later one.",faster than
1234.txt,The main reason is that it is difficult to establish the absolute separation plane between iris image categories using SVM.,it is difficult to
1235.txt,"Compared with the iris texton method  and ""HVC Gabor"" method, ""HVC SIFT"" method also achieves the best performance in this experiment.",Compared with
1237.txt,"Nearly 90% CCR can be achieved for tencategory iris image classification, which means it is a high probability event to authenticate the identity of query iris image by searching less than 10% templates in the central database.",it is a high probability event to
1238.txt,"Moreover, the proposed method can be used in iris recognition systems with proper designed classification confidence threshold.",be used in
1239.txt,Section 5.2 gives an example experiment.,null
1240.txt,Iris recognition has  been  well  studied  in the  literature  and  a number of iris feature descriptors have been proposed for characterizing the most discriminative and robust features in iris texture.,have been proposed for
1241.txt,It has been demonstrated that the feature representation models in state-of-the-art iris recognition methods can be unifind into a general framework of ordinal measures.,It has been demonstrated that
1242.txt,"The CASIA-Iris- Thousand, one of the largest iris image database in the public domain, is used as the testing database since it contains iris images of 1000 subjects.",is used as
1245.txt,"The  Ordinal  Measures and HVC features are extracted, and iris image grouping and SVM classificr for coarse classification are learned for the registration database.",null
1246.txt,"In our experiment, the reliability of the coarse classification is calculated by comparing the largest and second largest decision values of SVM results,the classification is regarded as a successful one, where the threshold 0.5 is decided according to experiments and it is adjustable for different applications.",is regarded as
1248.txt,Iris images are grouped into 9 and 10 categories respectively to show our strategy.,null
1262.txt,"Moreover, it is possible to develop a generic iris image classification module in an iris recognition system for a number of applications.",it is possible to
1263.txt,So that the computational cost of feature extraction and matching for multiple iris image classification tasks can be greatly reduced.,null
1264.txt,Our previous work demonstrated the effectiveness of statistical texture analysis for iris image classification.,null
1266.txt,This paper aims to learn and encode the most effective texture primitives of iris images for classification.,null
1267.txt,"To integrate the advantages of both vocabulary tree and locality- constrained linear coding, a novel iris feature representation method called Hierarchical Visual Codebook  is proposed to encode the distinctive and robust texture primitives  of iris images.",is proposed to
1268.txt,Each code characterizes a kind of frequently appearing local patches in iris images.,null
1269.txt,The codebook of HVC is organized in a tree structure and the relationship between different visual codes is preserved.,null
1270.txt,The global texture of an iris image is well characterized by the statistical distribution of codes in the feature space with overlapping relationship.,is well characterized by
1271.txt,"Extensive experiments illustrate the effectiveness of this generic HVC method for typical applications of iris image classification, i.e.",the effectiveness of
1273.txt,The success of race classification demonstrates the genotypic relationship between iris images of different subjects.,The success of
1275.txt,Such an evidence may be used for social and forensic applications.,be used for
1276.txt,We have attempted to provide a systematic study on iris image classification.,have attempted to
1277.txt,More efforts are clearly required for this topic.,are clearly required for
1278.txt,It is interesting to establish a large-scale multi-race iris image database in public domain.,It is interesting to
1279.txt,And all researchers around the world are invited to update the iris image samples of different races.,are invited to
1280.txt,So that we can investigate the performance of racial iris image classification with the increasing of the number of races in database.,with the increasing of
1281.txt,And it is interesting to investigate the genotypic relationship between iris images from different races through the proposed hierarchical visual codebook.,it is interesting to
1282.txt,"Iris recognition is being deployed in many important applications such as national ID card, banking, social benefit, border control, etc.",such as
1283.txt,The risk of security attacks to iris recognition systems increases accordingly driven by the great benefit of fraudulent identity authentication.,the great benefit of
1284.txt,It is predictable that attackers will pay more efforts to develop advanced methods to spoof iris biometrics.,It is predictable that
1285.txt,So it will become more challenging  to develop a reliable security solution to iris recognition with the advancement of iris attack approaches.,it will become more challenging  to
1286.txt,"In this sense, the research of iris liveness detection will never stop since the attack approaches are dynamically updated.",null
1287.txt,It is also a good idea to establish a large database of fake iris patterns in public domain just like the computer/Internet virus sample database in antivirus software industry.,It is also a good idea to
1288.txt,"Moreover, HVC is a generic texture analysis method and should be applicable to object recognition, texture classification and other texture like biometric traits.",be applicable to
1290.txt,Systems based on bag-of-words models from image features collected at maxima of sparse interest point operators have been used successfully for both computer visual object and action recognition tasks.,based on
1291.txt,"Here, we make three contributions aiming to bridge this gap.",make three contributions aiming to
1294.txt,"Second, we introduce novel dynamic consistency and alignment measures, which underline the remarkable stability of patterns of visual search among subjects.",null
1295.txt,"Third, we leverage the significant amount of collected data in order to pursue studies and build automatic, end-to-end trainable computer vision systems based on human eye movements.",in order to
1296.txt,"The level of annotation varies, spanning a degree of detail from global image or video labels to bounding boxes or precise segmentations of objects .",null
1298.txt,While such data has made advances in system design and evaluation possible,made advances in
1300.txt,"This is noticeable in  the  accuracy  of  state  of the art systems trained with such annotations, which still lags significantly behind human performance on similar tasks.",the accuracy  of
1303.txt,"The human eye movement level, defined by image fixations and saccades, is potentially the less controversial to measure and analyze.",defined by
1306.txt,"It can potentially foster links with the human vision community, in particular researchers developing biologically plausible models of visual attention, who would be able to test and quantitatively analyze their models on shared large scale datasets.",in particular
1307.txt,"Some of the most successful approaches to action recognition employ bag-of words representations based on descriptors computed at spatial-temporal video locations, obtained at the maxima of an interest point operator biased to fire over nontrivial local structure.",based on
1308.txt,although it appears still difficult to detect a large variety of useful objects reliably in challenging video footage.,it appears still difficult to
1309.txt,"Although human pose estimation could greatly disambiguate the interactions between actors and manipulated objects, it is a difficult problem even in a controlled setting due to the large number of local minima in the search space.",it is a difficult problem
1310.txt,The dominant role of sparse spatialtemporal interest point operators as front end in computer vision systems raises the question whether computational insights from a working system like the human visual system can be used to improve performance.,used to
1311.txt,"The sparse approach to computer visual recognition is not inconsistent to the one of biological systems, but the degree of repeatability and the effect of using human fixations with computer vision algorithms in the context of action recognition have not been yet explored.",the effect of
1312.txt,We undertake a significant effort of recording and analyzing human eye movements in the context of dynamic visual action and  context  recognition  tasks for  two  existing  computer  vision  datasets,undertake a significant effort of
1313.txt,"Our findings , and using advanced computer vision descriptors and fusion  methods,  leads  to  state of the art results in the Hollywood-2 and UCF-Sports action datasets.",leads  to
1314.txt,"This is, we argue, one of the first demonstrations of a successful symbiosis of computer vision and human vision technology, within the context of a very challenging dynamic visual recognition  task.",null
1315.txt,It shows the potential of interest point operators learnt from human fixations for computer vision.,null
1317.txt,This paper extends our prior work in  X.,extends our prior work in
1318.txt,The paper is organized as follows.,is organized as follows
1323.txt,This naturally suggests that human fixations could provide  useful information to support automatic action recognition systems.,null
1324.txt,In section 6 we introduce our action recognition pipeline which we shall use through the remainder of the paper.,null
1325.txt,Section 7 explores the action recognition potential of several interest point operators derived from ground truth  human fixations and visual saliency maps.,derived from
1326.txt,"In 8 we turn our attention to the problem of human visual saliency prediction, and introduce a novel spatio-temporal human fixation detector trained using our human gaze dataset.",turn our attention to
1327.txt,Section 9 illustrates how predicted saliency maps can be integrated into a modern state-of-the- art end-to-end action recognition system.,be integrated into
1328.txt,We  draw our  final conclusions in 10.,draw our  final conclusions in
1329.txt,The study of gaze patterns in humans has long received significant interest by the human vision community.,received significant interest by
1330.txt,Research on inter-subject agreement for static stimuli  has shown remarkable inter-observer consistency in the free-viewing condition.,null
1331.txt,The stability of eye movement patterns has also been confirmed in the context of 3D articulated human pose perception tasks in a first person setup.,been confirmed in
1332.txt,Whether visual attention is driven by purely bottom-up cues  is still open to debate .,is driven by
1333.txt,One of the oldest theories of visual attention has been that bottom-up features guide vision towards locations of high saliency.,null
1334.txt,Early computational models of attention assume that human fixations are driven by maxima inside a topographical map that encodes the saliency of each point in the visual  field.,are driven by
1335.txt,Models of saliency can be either prespecified or learned from eye tracking data.,null
1336.txt,In the former category falls the basic saliency model  provides an alternative criterion for building saliency maps.,null
1337.txt,"These can be learned from low-level features or from a combination of low, mid and high-level ones.",null
1338.txt,"Saliency maps have been used for scene classification , object localization and recognition,and action recognition.",have been used for
1339.txt,Comparatively little attention has been devoted to computational models of saliency maps for the dynamic domain.,null
1340.txt,Bottom-up saliency models for static images have been extended to videos by incorporating motion and flicker channels .,have been extended to
1341.txt,All these models are prespecified.,null
1342.txt,"One exception is the work of Kienzle , who train an interest point detector using fixation data collected from human subjects in a free viewing  task.",null
1343.txt,"Datasets containing human gaze pattern annotations of images have emerged from studies carried out by the human and computer vision communities, some of which are publicly available and some that are not .",null
1344.txt,"Most of these datasets have been designed for small quantitative studies, consisting of at most a few hundred images or videos.",consisting of
1345.txt,"In a parallel line of work, Vig  have  also collected eye movements for the Hollywood-2 dataset in the free-viewing condition and performed computer-based action recognition using ground truth fixations,  assuming  the  availability  of eye movement data at test time.",null
1346.txt,"Here, we introduce data captured under three conditions: free viewing , action recognition and context recognition, for two video datasets, Hollywood-2 and UCF Sports .",null
1347.txt,We introduce spatial and sequential metrics to assess the inter-subject consistency and to quantify the influence of task instructions on eye movements.,introduce to
1348.txt,"Moreover, we propose new trainable models for human visual saliency prediction, and pursue end-to-end automatic action recognition frameworks based on predicted visual saliency maps.",based on
1349.txt,"Therefore, we can work with any video, and we do not rely on the availability of human eye movements  in video, at test  time.",rely on
1350.txt,"While visual saliency models can be evaluated in isolation under a variety of measures against human fixations, for computer vision, their ultimate test remains the demonstration of relevance within an end-to-end automatic visual recognition pipeline.",null
1351.txt,"While such integrated systems are still in their infancy, promising demonstrations have recently emerged for computer vision tasks like scene classification, verifying correlations with object  detection responses .",null
1352.txt,"An interesting early biologically inspired recognition system was presented by Kienzle, who learn a fixation operator from human eye movements collected under video free-viewing, then learn action classification models for the KTH dataset with promising results.",null
1353.txt,"In work following up on ours, Fathi  have shown that, under the constraint of a first person perspective, human fixations can also be predicted and used to enhance action recognition performance.",used to
1354.txt,"In contrast, in computer vision, interest point detectors have been successfully used in the bag-of-visual-words framework for action classification and event detection ,but a variety of other methods exists, including random field models  and structured output SVMs .",In contrast
1355.txt,"Currently the most successful systems remain the ones dominated by complex features extracted at interesting locations, bagged and fused using advanced kernel combination techniques.",null
1356.txt,"This study is driven, primarily, by our computer vision interests, yet leverages data collection and insights from human vision.",is driven by
1357.txt,"While in this paper we focus on bag-of-words spatio-temporal computer action recognition pipelines, the scope for study and the structure in the data are broader.",focus on
1358.txt,"We do not see this investigation as a terminus, but rather as a first step in exploring some of the most advanced data and models that human vision and computer vision can offer at the moment.",see as
1359.txt,An objective of this work is to introduce additional annotations in the form of eye recordings for two large scale video data sets for action recognition.,An objective of this work is to
1360.txt,"Introduced in  X,  it is one of the largest and most challenging available datasets for real world actions.",it is one of the largest and most challenging
1361.txt,"It contains 12 classes: answering phone, driving a car, eating, fighting, getting out of a car, shaking hands, hugging, kissing, running, sitting down, sitting up and standing up.",null
1362.txt,These actions are collected from a set of 69 Hollywood movies.,are collected from
1363.txt,The data set is split into a training set of 823 sequences and a test set of 884 sequences.,null
1364.txt,There is no overlap between the 33 movies in the training set and the 36 movies in the test set.,null
1365.txt,"The data set consists of about 487k frames, totaling about 20 hours of   video.",consists of
1366.txt,The UCF Sports Action Dataset: This high  resolution dataset  was collected mostly from broadcast television channels.,null
1367.txt,"It contains 150 videos covering 9 sports action classes: diving, golf swinging, kicking, lifting, horseback riding, running, skateboarding, swinging and  walking.",null
1368.txt,Human subjects: We have collected data from 19 human volunteers  aged  between 21  and 41.,between and
1369.txt,"We split them into three groups based on the task they were required to solve: action recognition, context recognition and free viewing.",based on
1370.txt,Participants in  the  action  recognition  group  were not required to solve any specific task while being presented with the video sequences in the two datasets.,null
1371.txt,"None of the subjects was aware of the task constraints placed on the other groups, and none was a cognitive scientist.",aware of
1372.txt,"We chose the three groups such that no pair of subjects from different groups were acquainted with each other, in order to limit   biases.",in order to
1373.txt,"Eye movements were recorded using an SMI iView X HiSpeed 1250 tower-mounted eye tracker, with a sampling frequency of 500Hz.",null
1374.txt,The head of the subject was placed on a chin-rest located at 60 cm from the display.,null
1375.txt,Viewing conditions were binocular and gaze data was collected from the right eye of the participant.,null
1377.txt,The  calibration procedure was carried out at the beginning of each block.,was carried out
1378.txt,The subject had  to  follow  a  target  that  was  placed  sequentially  at   13 locations evenly distributed across the  screen.,null
1379.txt,Accuracy of the calibration was then validated at 4 of these calibrated locations.,null
1380.txt,"If the error in the estimated position was greater than 0.75  of visual angle, the experiment was stopped and calibration restarted.",greater than
1381.txt,"At the end of each block, validation   was carried out again, to account for fluctuations in the recording environment.",was carried out
1382.txt,"If the validation error exceeded 0.75 of visual angle, the data acquired during the block was deemed noisy and discarded from further analysis.",null
1383.txt,"Because the resolution varies across the  datasets,  each  video  was  rescaled  to  fit the  screen,  preserving  the  original  aspect  ratio.",null
1384.txt,The visual angles subtended by the stimuli were 38.4  in the horizontal plane and ranged from 13.81 to 26.18 in the vertical plane.,ranged from to
1385.txt,"During data acquisition, the eye movement and video  streams were synchronized automatically by the eyetracking system.",null
1386.txt,"To facilitate this process, video files were optimized for the display setup, using the functionality provided by the SMI Experiment Center software.",null
1387.txt,"Before each video sequence was shown, participants were required to fixate the center of the screen.",null
1388.txt,Display would proceed automatically using the trigger area-of-interest feature provided by the iView X software.,provided by
1389.txt,"Participants in the action and context recognition groups had to identify the actions and, respectively, the contextual elements in each video sequence.",null
1390.txt,"Their multiple choice answers were recorded through a set of check-boxes displayed at the end of each video, which the subject manipulated using a mouse.2 Partici- pants in the free viewing group underwent a similar protocol, the only difference being that the questionnaire answering step was skipped.",null
1391.txt,"To avoid fatigue, we split the set of stimuli into 20 sessions , with 5-minute breaks between blocks.",null
1392.txt,"Overall, it took approximately 1 hour for a participant to complete one session.",null
1393.txt,The video sequences were shown to each subject in a different random  order.,null
1394.txt,Our goal is to create a data set that captures the gaze patterns of humans solving a recognition task.,Our goal is to
1395.txt,"Therefore, it is important to ensure that our subjects are successful at this task.",it is important to
1396.txt,Fig.2 shows the confusion matrix between the answers of human subjects and the ground truth.,between and
1397.txt,"For Hollywood-2, there can be multiple labels associated with the same video.",associated with
1398.txt,"We show, apart from the 12 action labels, the 4 most common combinations of labels occurring in the ground truth and omit  less  common ones.",apart from
1399.txt,"The analysis reveals, apart from near-perfect performance, the types of errors humans are prone to make.",null
1400.txt,The most frequent human errors are omissions of one of the actions co-occurring in a video.,null
1401.txt,False positives are much less frequent.,null
1402.txt,"The third type of error of mislabeling a video entirely, almost never happens, and when it does it usually involves semantically related actions, e.g.",null
1404.txt,"In this section, we investigate how  well the  regions  fixated by human subjects agree on a frame by frame basis, by generalizing to video data the procedure used by Ehinger et.",used by
1407.txt,"Therefore, one can address this issue by checking how well the fixation of a subject on one stimulus can be predicted from those of the other subjects on a different, unrelated, stimulus.",address this issue by
1408.txt,"Normally, the average precision when predicting fixations on the same stimulus is much greater than on different    stimuli.",much greater than
1409.txt,"We generalize this protocol for video, by randomly choosing frames from our videos and checking inter-subject correlation on them.",null
1410.txt,We test each subject in turn with respect to the other  score for this classification problem is then computed for the test subject.,with respect to
1411.txt,We average score over all test subjects defines the final consistency metric.,null
1412.txt,This value ranges from 0.5 when no consistency or bias effects are present in the data and when all subjects fixate the same pixel and there is no measurement noise.,null
1413.txt,"For cross-stimulus control, we repeat this process for pairs of frames chosen from different videos and attempt to predict the fixation of each test subject on the first frame from the fixations of the other subjects on the other frame.",attempt to
1414.txt,"Unlike in the procedure followed in X, who considered several fixations per subject for each  exposed  image,  we only consider the single fixation, if any, that a subject made on that frame.",null
1415.txt,The reason is  that  our  stimulus  is dynamic and the spatial positions of future fixations are bound to be altered by changes in the stimulus itself.,are bound to
1416.txt,"In our experiment, we  set  the  width  of  the  Gaussian  blur  kernel  to  match a visual angle span of 1.5.",null
1417.txt,"We have chosen this value, corresponding  to  a  cutoff  frequency  of  approximately  8 cycles/image, for consistency with X.",corresponding  to
1418.txt,"We draw 1,000 samples for both the same-stimulus and different stimulus predictions.",null
1419.txt,We disregard the first 200ms from the beginning of each video to remove bias due to the initial central fixation.,due to
1420.txt,The ROC curves for inter-subject agreement and cross-stimulus control are shown in fig.3.,are shown in
1421.txt,"For the Hollywood-2 dataset, the AUC score is 94.8% for inter-subject agreement and 72.3% for cross-stimulus control.",null
1422.txt,"For UCF Sports, we obtain values of 93.2% and 69.2%.",null
1424.txt,We also analyze inter-subject agreement on subsets of videos corresponding to each action class and for 4 significant labellings considered in fig.2.,corresponding to
1425.txt,"On each of these subsets, inter-subject consistency remains strong, as illustrated in Table 2a,b.",as illustrated in
1426.txt,"Interestingly, there is significant variation in the cross-stimulus control across these classes, especially in the UCF Sports dataset.",there is significant variation in
1427.txt,"The setup being identical, we conjecture that part of this variation is due to the different ways in which various categories of scenes are filmed and the way the director aims to present the actions to the viewer.",due to
1428.txt,"For example, in TV footage for sports events, the actions are typically shot from a frontal pose, the performer is centered almost perfectly and there is limited background clutter.",For example
1429.txt,"These factors lead to a high degree of similarity among the stimuli within the class and makes it easier to extrapolate subject fixations across videos, explaining the unusually high values of this metric for the actions like Dive, Lift and  Swing.",makes it easier to
1430.txt,"In this section, we evaluate the impact of the task on the spatial pattern of eye movements, for this dataset.",the impact of
1431.txt,We first describe our procedure for comparing the visual patterns of two groups of subjects.,null
1432.txt,"We then apply this procedure to compare the action recognition condition against free viewing and context recognition conditions, and discuss our  findings.",null
1433.txt,"Let us consider two tasks, A and B.",null
1434.txt,"Given a set of subjects that are required to solve task A, we can build a saliency map for task A for each video frame.",null
1436.txt,"Let us consider a set SA of nA subjects for task condition A, and a set SB of nB subjects for task condition B.",null
1437.txt,"As for static consistency, we take the average AUC over all stimuli and end up with a set of nA prediction scores .",end up with
1438.txt,"Under the hypothesis that task does influence the spatial layout of overt visual attention, the distributions of scores obtained for subjects in SA and SB should be different, with the latter having a lower average compared to the former.",having a lower average compared to the former
1439.txt,We employ an independent two sample t-test with unequal variances to test this hypothesis .,null
1440.txt,We  place a significance threshold  of 0.05 on the resulting p-values.,null
1441.txt,"In our experiments, we apply the above protocol to compare the action recognition condition against the context recognition and free viewing conditions, for both Hollywood-2 and UCF Sports.",null
1443.txt,"Since in the Hollywood-2 dataset several actions can occur in a video, either simultaneously or sequentially, this rules out initial habituation effects and further neglect  to some degree.",null
1444.txt,"On the other  hand,  for  both  datasets, we find significant differences between subjects performing action recognition and those asked to recognize context, thus showing that task instructions induce significant changes in visual search patterns.",On the other  hand
1445.txt,There is significant debate in the human vision community on whether task influences eye movements.,There is significant debate in
1446.txt,"However, we find significant differences between action and context recognition, in both video and static images, strongly supporting Yarbus' findings.",between and
1448.txt,"A more recent investigation by Borji and Itti also supports the hypothesis that task can be successfully decoded from eye movements, in line with Yarbus' findings.",null
1449.txt,Our static inter-subject agreement analysis shows that the spatial distribution of fixations in video is highly consistent across subjects.,null
1450.txt,There are relatively few commonly agreed metrics that are sensitive to fixation order.,null
1452.txt,"Dynamic consistency measures based on sequence alignment of discrete symbols have been used in the human vision community , but they have been generally limited to static image stimuli and required manual annotations of AOIs to generate semantically meaningful scanpath representations.",based on
1453.txt,"In this section, we introduce methods that automatically discover AOIs in dynamic image sequences .",null
1454.txt,We use these methods to define two metrics that are sensitive to the temporal ordering among fixations and evaluate consistency under these metrics.,null
1455.txt,We first model the scanpath made by each subject as a sequence of discrete symbols and show how this representation can be produced automatically.,null
1456.txt,"We then define two metrics, AOI Markov dynamics and temporal AOI alignment, and show how they can be computed for this representation.",be computed for
1457.txt,After we define  a  baseline  for  our  evaluation  we  conclude  with  a discussion of the  results.,conclude  with  a discussion of the  results
1458.txt,Human fixations tend to be tightly clustered spatially at one or more locations in the image.,null
1459.txt,"Assuming that such regions, called areas of interest , can  be  identified,  the  sequence  of  fixations  belonging   to a subject can be represented discretely by assigning each fixation to the closest AOI.",belonging to
1460.txt,"For example, from the video depicted in fig.4-left, we identify  six  AOIs:  the  bumper of the car, its windshield, the passenger and the handbag he carries, the driver and the side mirror.",For example
1461.txt,We  then  trace  the scan path of each subject through the AOIs based on spatial proximity.,based on
1462.txt,Each fixation gets assigned a label.,null
1463.txt,"For subject 2 shown in the example, this results in the sequence [bumper, windshield, driver, mirror, driver, handbag].",null
1464.txt,Notice that AOIs are semantically meaningful and tend to correspond to physical objects.,tend to
1465.txt,"Interestingly, this supports recent computer vision strategies based on object detectors for action recognition.",based on
1466.txt,"Defining areas of interest manually is labour intensive, especially in the video domain.",null
1467.txt,"Therefore, we introduce an automatic method for determining their locations based on clustering the fixations of all subjects in a frame.",based on
1468.txt,We start by running k-means with 1 cluster and we successively increase their number until the sum of squared errors drops below a threshold.,the sum of
1469.txt,"We then link centroids from successive frames into tracks, as long as they are closely located spatially.",as long as
1470.txt,"For robustness, we allow  for  a  temporal gap  during  the  track  building  process.",null
1471.txt,"Each  resulting track becomes an AOI, and each fixation is assigned to the closest AOI at the time of its   creation.",is assigned to
1472.txt,"In order to provide a reference for our consistency evaluation, we generate 10 random AOI strings per video and compute the consistency on these strings under our metrics.",In order to
1473.txt,We note however that the dynamics of the stimulus places constraints on the sampling process.,null
1474.txt,"First, a random string must obey the time ordering relations among AOIs .",null
1475.txt,"Second, our automatic AOIs are derived from subject fixations and are biased by their gaze preference.",are derived from
1476.txt,"The lifespan of an AOI will not be initiated until at least one subject has fixated it, even if the corresponding object is already visible.",even if
1477.txt,"To remove some of the  resulting  bias  from  our evaluation, we extend each AOI both forward and backwards  in time, until the image patch at its center has undergone significant appearance changes, and use these extended AOIs when generating our random baselines.",null
1478.txt,"For the Hollywood-2 dataset, we find that the average transition probability of each subject's fixations under AOI  Markov  dynamics  is  70%,  compared  to  13%  for  the random baseline .",compared  to
1479.txt,"We also find that, across all  videos, 71% of the AOI symbols are successfully aligned, compared to only 51% for the random baseline.",compared to
1480.txt,We notice similar gaps in the UCF Sports dataset.,null
1481.txt,These results indicate a high degree of consistency in human eye movement dynamics across the two datasets.,null
1482.txt,Alignment scores vary to some extent across  classes.,vary to
1483.txt,"In this section, we investigate this by building vocabularies over image patches collected from the locations fixated by our subjects when viewing videos of the various actions in the Hollywood-2 dataset.",null
1485.txt,We  cluster the resulting descriptors using k-means into 500 clusters.,cluster into
1488.txt,we illustrate image patches  that  have been assigned high probability by the mixture of Gaussians model underlying k-means.,null
1490.txt,"Each row contains the top 5 most probable patches from a cluster , otherwise preferring to center  the  object,  or one of its features, onto their fovea.",null
1491.txt,"Overall, the vocabularies seem to capture semantically relevant aspects of the action classes.",seem to
1492.txt,"This suggests that human fixations provide a degree of object and person repeatability that could be used to boost the performance of computer-based action-recognition methods, a problem we address in the following  sections.",be used to
1493.txt,The visual information found in the fixated regions could potentially aid automated recognition of human actions.,null
1494.txt,"One way to capture this information  is  to  extract  descriptors from these regions, which is equivalent to using them as interest points.",is equivalent to
1495.txt,"Following this line  of  thought,  we evaluate the degree  to  which  human  fixations  are  correlated  with the widely used Harris spatiotemporal cornerness operator .",are correlated  with
1496.txt,"Then, under the assumption that fixations are  available at  testing  time,  we  define  two   interest   point  operators that fire at the centers of fixation, one spatially on  a frame by frame basis  and  one  at  a  spatio-temporal  scale.",null
1497.txt,We compare the performance of these two operators to that of the Harris operator for computer based action classification.,compare to
1499.txt,We start our experiment by running the spatio-temporal Harris corner detector over each video in the dataset.,null
1500.txt,"Assuming an angular radius of 1.5  for the human fovea , we estimate the probability that a corner will be fixated by the fraction of interest points that fall onto the fovea of at least one human observer.",null
1501.txt,We then define two operators based on ground truth human fixations.,based on
1502.txt,"The first operator generates, for each human fixation, one 2D interest point at the foveated position during the lifetime of the fixation.",null
1503.txt,"The  second  operator, generates one 3D interest point for each fixation, with  the  temporal scale proportional to the length of the fixation.",null
1504.txt,We  run the Harris operator and the two fixation operators though our classification pipeline .,null
1505.txt,We find low correlation between the locations at which  classical  interest  point  detectors  fire  and  the human fixations.,between and
1506.txt,"The probability that a spatio-temporal Harris corner will be fixated by a subject is approximately 6%, with little variability across actions .",null
1507.txt,"In addition, our results show that none of our fixation-derived interest point operators improve recognition performance compared to the Harris-based interest point operator.",In addition
1508.txt,"Although our findings suggest that the entire foveated area is not informative, this does not rule out the hypothesis that relevant information for action recognition might lie in a subregion of this area.",null
1509.txt,"Research of human attention suggests that humans can simultaneously attend to one or more subregions of the visual field, as opposed to processing globally all the information available, the so called covert attention.",as opposed to
1510.txt,"Along these  lines,  we  design  an experiment in which we generate finer-scaled interest points in the area fixated by the  subjects.",null
1511.txt,"Given  enough  samples,  we expect to also represent the area to which the covert attention of a human subject was directed at any particular moment through the fixation.",null
1512.txt,"To drive this sampling process, we derive a saliency map from human fixations.",null
1513.txt,The map estimates the probability for each  spatio-temporal  location  in  the  video to be foveated by a human subject.,null
1514.txt,We  then  define  an interest point operator that randomly samples spatio-temporal locations from this probability distribution and compare its performance for action recognition with two baselines.,compare with
1515.txt,"If  subsets of the foveated regions are indeed  informative,  we  expect our saliency-based interest point operator to have superior performance to both baselines.",have superior performance to
1516.txt,"We find that ground truth saliency sampling outperforms both the Harris and the uniform sampling operators significantly, at equal interest point sparsity rates.",null
1517.txt,"Our results indicate that saliency maps encoding only the weak surface structure of fixations , can be used to boost the accuracy of contemporary methods and descriptors used for computer action recognition.",be used to
1518.txt,"Up to this point, we have relied on the availability of ground truth saliency maps at test time.",null
1519.txt,"A natural question is whether it is possible to reliably predict saliency maps, to a degree that still preserves the benefits of action classification accuracy.",it is possible to
1520.txt,This will be the focus of the next section.,the focus of
1521.txt,"Motivated by the findings presented in the previous section, we now show that we can effectively predict saliency maps.",null
1522.txt,We start by introducing two evaluation measures for saliency prediction.,null
1523.txt,"The first is the area-under-the-curve , which is widely used in the human vision community.",is widely used in
1526.txt,"A natural question is whether it is possible to reliably predict saliency maps, to a degree that still preserves the benefits of action classification accuracy.",it is possible to
1527.txt,This will be the focus of the next section.,the focus of
1528.txt,"Motivated by the findings presented in the previous section, we now show that we can effectively predict saliency maps.",null
1529.txt,We start by introducing two evaluation measures for saliency prediction.,null
1530.txt,"The first is the area-under-the-curve , which is widely used in the human vision community.",is widely used in
1532.txt,The second measure is inspired by  our  application  of  saliency  maps  to  action  recognition.,is inspired by
1533.txt,"In the pipeline we proposed in 7.2, ground truth saliency maps  drive  the  random  sampling  process  of  our     interest point operator.",null
1534.txt,"We introduce the spatial  Kullback-Leibler   divergence  measure  to  compare   the   predicted and the ground truth saliencies, because it better reflects the saliency map similarity under a probabilistic interpretation.",null
1535.txt,"We also propose and  study  several  features  for  saliency map prediction, both static and motion based.",both and
1536.txt,"Our analysis includes features derived directly from low, mid and  high level image information.",null
1537.txt,"In addition, we train a HoG-MBH detector that fires preferentially at fixated locations, using the vast amount of eye movement data available in the dataset.",In addition
1538.txt,"We evaluate all these features and their combinations on our dataset, and find that our detector gives the best performance under the KL divergence  measure.",gives the best performance
1539.txt,"The most commonly used measure for evaluating saliency maps in the image domain, the AUC measure, interprets saliency maps as predictors for separating fixated pixels from the rest.",null
1540.txt,The ROC curve is computed for each image and the average area the area under the curve over the whole set of testing images gives the final score.,null
1541.txt,This measure emphasizes the capacity of a saliency map to rank pixels higher when they are fixated then when they are not.,null
1542.txt,"This does not imply, however, that the normalized probability distribution  associated with the saliency map is close to the ground truth saliency map for the image.",is close to
1543.txt,"A better suited way to compare probability distributions is the spatial Kullback-Leibler  divergence, which we propose as our second evaluation measure, defined as.",null
1544.txt,"Having established evaluation criteria, we now run several saliency map predictors on our dataset, which we describe  below.",null
1545.txt,We also provide three baselines for saliency map comparison.,null
1546.txt,"The  first  one  is  the  uniform  saliency  map, that assigns the same fixation  probability  to  each  pixel of the video frame.",null
1547.txt,"Second, we consider the center bias  feature, which assigns each pixel with the distance to the center of the frame, regardless of its visual contents.",null
1548.txt,This feature can capture both the tendency of human subjects to fixate near the center of the screen and the preference of the photographer to center objects into the field of view.,null
1549.txt,"At the other end of the spectrum lies the human saliency baseline, which derives a saliency map from half of our human subjects and is evaluated with respect to fixations of the remaining ones.",with respect to
1550.txt,"When evaluated under the AUC metric, combining predictors always improves performance.",null
1551.txt,"As a general trend, low-level features are better predictors than high level ones.",better than
1552.txt,"The low level motion features , provide similar performance to static low-level features.",provide similar performance to
1553.txt,"Our HoG-MBH detector is comparable to the best static feature, the horizon detector, under the AUC  metric.",is comparable to
1554.txt,"The response of the horizon  detector is a blurred bar which extends horizontally and is often close to vertically centered, making it very  similar  to  a  central bias response.",it very  similar  to
1555.txt,"These observations may explain the high score obtained by this detector, similar to central bias.",similar to
1556.txt,Note however that central bias is not the best feature for saliency prediction under the KL divergence measure and is clearly not a good interest point sampling distribution for visual recognition in an end-to-end   system.,null
1557.txt,"Interestingly, when evaluated according to KL divergence, the ranking of the saliency maps changes: the HoG-MBH detector performs best and the only other predictor that significantly outperforms central bias is the horizon detector.",according to
1558.txt,"Under this metric, combining features does not always improve performance, as the linear combination method of  optimizes pixel-level classification accuracy, and as such is not able to account for the inherent competition that takes place among these predictions due to image-level normalization.",is not able to
1559.txt,We conclude by noticing that fusing our predicted maps as well as our static and dynamic features gives the highest results under AUC metrics.,as well as
1560.txt,"Moreover, the HoG-MBH detector, trained using our eye movement data is the best predictor of visual saliency from our candidate set, under the probabilistic measure of matching the spatial distribution of human  fixations.",null
1561.txt,"We next investigate action recognition performance when interest points are sampled from the saliency maps predicted by our HoG-MBH detector, which we choose because it best approximates the ground truth saliency map spatially, under the KL divergence metric.",null
1562.txt,"Apart from sampling from the uniform and ground truth distributions, as a second baseline, we also sample interest points using the central bias saliency map, which was also shown to approximate to a reasonable extent human fixations under the less intuitive AOI measure .",Apart from
1563.txt,We also investigate whether our end-to-end recognition system can be combined with the state-of-the-art approach of X to obtain better  performance.,combined with
1564.txt,Experimental Protocol: We first run our HoG-MBH detector over the entire Hollywood-2 data set and obtain our automatic saliency maps.,null
1565.txt,We then configure our recognition pipeline with an interest point operator that samples locations using these saliency maps as probability distributions.,null
1566.txt,"We also run the pipeline of  and combine the four kernel matrices produced in the final stage of their classifier with the ones we obtain for our 14 descriptors, sampled from the saliency maps, using MKL.",null
1567.txt,"We also test our recognition pipeline on the UCF Sports dataset, which is substantially different in terms of action classes, scene clutter, shooting conditions and the evaluation procedure.",null
1568.txt,"Unlike Hollywood-2, this database provides no training and test sets, and classifiers are generally evaluated by cross-validation.",null
1569.txt,We follow the standard procedure by first extending the dataset with horizontally flipped versions of each video.,null
1570.txt,"For each cross-validation fold, we leave out one original video and its flipped version and train a multi-class classifier.",null
1571.txt,"We test on the original video, but not its flipped version.",null
1572.txt,We compute the confusion matrix and report the average accuracy over all classes.,null
1573.txt,Our experimental procedure for the UCF Sports dataset closely follows the one we use for Hollywood-2.,null
1574.txt,"We retrain our HoG-MBH detector on a subset of 50 video pairs, while we use the rest of 100 pairs for testing.",null
1575.txt,"The average precision of our detector is 92.5% for the training set and 93.1% on our test set, which confirms that our detector does not overfit the data.",null
1576.txt,We use the retrained detector to  run the same pipelines and baselines as for Hollywood-2.,null
1577.txt,"Although central bias is a relatively close approximation of human visual saliency on our datasets, it does not lead to performance that closely matches the one produced by these maps.",lead to
1578.txt,"Our automatic pipeline based on predicted saliency maps and our ground-truth based pipeline have similar performance, with a slight advantage being observed for predicted saliency in the case of Hollywood-2 and for ground truth saliency for UCF Sports.",with a slight advantage
1579.txt,"Our results confirm that approximations produced by the HoG-MBH detector are qualitatively different from a central bias distribution, focusing on local image structure that frequently co-occurs in its training set of fixations, disregarding on whether it is close to the image center or not .",it is close to
1580.txt,"Therefore, the detector will tend to emphasize these locations as opposed to less relevant ones.",as opposed to
1581.txt,"This also explains why our predicted saliency maps can be as informative for action recognition as ground truth maps, even exceeding their performance on certain action classes: while humans will also fixate on structures not relevant for action recognition, fixated structures that are relevant to this task will occur at a higher frequency in our datasets.",are relevant to
1582.txt,"Hence, they will be well approximated by a detector trained in a bottom-up manner.",null
1583.txt,"This can explain why the performance ballance is even more inclined towards predicted saliency maps on the UCF Sports Actions dataset, where motion and image patterns are more stable and easier to predict compared to the Hollywood-2 dataset.",are more stable and easier to
1584.txt,"Finally, we note that even though our pipeline is sparse, it achieves near state of the art performance when compared to a pipeline that uses dense trajectories.",compared to
1585.txt,we were able to go beyond  the  state-of-the-art  .,were able to
1586.txt,This demonstrates that an end-to-end automatic system incorporating both human and computer vision technology can deliver high performance on a challenging problem such as action recognition in unconstrained  video.,such as
1587.txt,The effect of random sampling on action recognition performance.,The effect of
1588.txt,Our interest point operators are defined by randomly sampling specific spatio-temporal distributions.,null
1589.txt,"This process can stochastically influence the number of relevant and noisy image samples supplied to the classifier both during training and testing, and indirectly affect classification performance.",null
1590.txt,"Here, we quantify this effect to confirm that results repoted in Tables 5 and 6 are stable with respect to random sampling.",with respect to
1591.txt,"We train and evaluate each classification pipeline 10 times, each time using a different random seed for interest point sampling.",null
1592.txt,We then compute the mean and standard deviation of the performance metric .,null
1593.txt,This evaluation procedure is however computationally prohibitive.,null
1594.txt,The vocabulary learning and multiple kernel learning phases are the most computationally expensive.,null
1595.txt,We therefore run this experiment using a lightweight version of our pipeline architecture.,null
1596.txt,"We replace the bag-of-visual-words coding scheme with second order pooling , as described in X.",as described in
1597.txt,"This method explicitly maps the input features into a high dimensional space by computing the matrix logarithm of the covariance matrix of the descriptors in each video, followed by a power scaling step.",null
1598.txt,"We then concatenate the  resulting  descriptors and apply a linear SVM, and hence avoid the expensive multiple kernel learning phase.",null
1599.txt,"The lightweight O2P pipelines are much faster, taking approximately 60 hours when run on the same architecture, yet almost as accurate as our bag-of- words pipelines.",null
1600.txt,"Our results, presented in table 8, show remarkable  stability of the classification performance with respect to the randomness in the sampling process.",with respect to
1601.txt,The relatively smaller number of samples taken for the UCF Sports dataset also explains the higher performance variability on this dataset as compared to Hollywood-2.,compared to
1603.txt,"Apart from stability, we also note that predicted and empirical saliency sampling significantly outperforms the baselines.",Apart from
1604.txt,the  average precision for predicted saliency sampling on Hollywood-2 is 16 standard deviations higher than for central bias  sampling.,higher than
1605.txt,"We have presented experimental and computational modelling work at the incidence of human visual attention and computer vision, with emphasis on action recognition in video.",emphasis on
1606.txt,"Inspired by earlier psychophysics and visual attention findings, not validated quantitatively at large scale until now and not pursued for video, we have collected, and made available to the research community, a set of comprehensive human eye-tracking annotations for Hollywood-2 and UCF Sports.",made available to
1607.txt,"Besides the collection of large datasets, we have performed quantitative analysis and introduced  novel  models  for  evaluating  both  the  static and the dynamic consistency of human fixations across different subjects, videos and actions.",null
1608.txt,We have also performed a large scale analysis of automatic visual saliency models and end-to-end automatic visual action recognition systems.,null
1609.txt,Our studies are performed with particular focus on computer vision techniques and interest point operators and descriptors.,focus on
1610.txt,"In particular, we propose new accurate saliency operators that can be effectively trained based on human fixations.",In particular
1611.txt,"Finally, we show that such automatic saliency predictors can be used within end-to-end computer visual action recognition systems to achieve state of the art results in some of the hardest benchmarks in the field.",null
1612.txt,Fabrication variations can have a detrimental effect on the performance of optical filters based on ring resonators.,have a detrimental effect on
1613.txt,"However, by using robust optimization these effects can be minimized and device yield can be significantly improved.",null
1614.txt,This paper presents an efficient robust optimization technique for designing manufacturable optical filters based on serial ring resonators.,based on
1615.txt,The serial ring resonator is treated as a system which has computationally expensive and cheap components .,is treated as
1616.txt,Cheap mathematical models are constructed of the directional coupler sections in the resonators.,are constructed of
1617.txt,The approximate system response based on the cheap model is then robustly optimized.,based on
1618.txt,The robust bandpass filter performance is compared against designs that do not take uncertainties into account.,take into account
1619.txt,The optimality of the robust solutions is confirmed by simulating it on the expensive physical model as a post-processing step.,null
1620.txt,Results indicatethat the employed approach can provide an efficient means for robust optimization of ring resonator-based optical filters.,provide an efficient means for
1622.txt,Integrated  photonic devices and systems are prone to manufacturing uncertainties which are an unavoidable aspect of fabrication.,are an unavoidable aspect of
1623.txt,"If designers do not account for the geometrical variations that can arise in fabrication, the fabricated structure fails to perform according to the designed specifications.",fails to
1624.txt,Design-for-Manufacturing strategies for integrated photonics therefore have a potential to increase the overall yield and simultaneously reduce the cost of production.,have a potential to increase
1625.txt,"However, in order to perform this, information about the capability of the fabrication process is needed.",in order to
1626.txt,"Ideally, designers should have access to data related to the probability distribution of the uncertainties in fabrication.",have access to
1627.txt,"However, such probability data is usually classified and is not disclosed by foundries to external designers.",null
1628.txt,"In this case, designers often only know the tolerances of the fabrication process.",null
1629.txt,"In other words, the bounds on the fabrication uncertainties are known, but their distribution is unknown.",null
1630.txt,"In the scenario that the uncertainties are bounded but unknown, robust optimization is an established approach to find a fault-tolerant design.",is an established approach to
1631.txt,Robust optimization involves finding the best worst-case performance.,null
1632.txt,The design is optimized so that the best performance is achieved given that the worst-case uncertainty with respect to the performance metric is realized.,with respect to
1633.txt,"The design found using this method is therefore not insensitive, but has a certain guaranteed minimum performance.",null
1634.txt,"To determine the robust optimum, an iterative optimization process is required.",null
1635.txt,An additional challenge in integrated photonic optimization is that the underlying electromagnetic simulation may be computationally expensive.,null
1636.txt,Repeatedly changing the design parameters and rerunning the simulation to find the optimal design can therefore be prohibitively costly.,null
1637.txt,"In order to circumvent this problem, an inexpensive approximate model of the simulation can be constructed and the optimization can be performed on the cheap model.",In order to
1638.txt,"Amongst the available methods for mathematical modeling, Kriging is a strong candidate since it provides an estimator for the approximation error.",null
1639.txt,"Using these estimates, the cheap model, otherwise known as a metamodel, can adaptively be improved by simulating the integrated photonic device response in regions of the design domain that are relevant to robust optimization.",are relevant to
1640.txt,The described approximation approach can efficiently find the robust optimum of an integrated photonic device such as an multi-mode interference   coupler or a single ring resonator .,such as
1641.txt,But in order for the approach to be scalable it should also be able to produce a robust solution for large integrated photonic systems consisting of different components.,it should also be able to
1642.txt,Research has been performed on finding tolerant designs for different integrated photonic devices.,null
1643.txt,"Similarly, the adverse effects of fabrication variations on the performance of microrings has been exhibited in X.",been exhibited in
1644.txt,"However, most of these fault tolerant approaches have been focused on nongeneric methods that only address a particular integrated photonic device.",focused on
1645.txt,An efficient and scalable approach for robust optimization of integrated photonic systems is still lacking.,null
1646.txt,"For device level problems, space-mapping is a generic approach for deterministic and nondeterministic optimization of electromagnetic problems.",null
1647.txt,Applications of this approach for optimization of integrated photonic components have also been presented X.,null
1648.txt,"However, to the best of our knowledge, space-mapping has not been employed for robust optimization of hierarchical systems.",been employed for
1649.txt,"In this work, we propose a system level robust optimization technique for efficiently identifying robust designs for serial ring resonator-based optical filters.",null
1650.txt,A cheap system model is constructed for this purpose based on mathematical models of the components.,based on
1651.txt,The approach is not based on a specific physical model.,based on
1652.txt,Therefore the method could potentially be employed for robust optimization of other integrated photonic systems.,be employed for
1653.txt,"The major restriction is that the structure of the system should be such, that the behavior of the components is independent from one another.",null
1656.txt,"Additionally, it should be recognized that a change in component geometry can cause a local variation in material properties due to stress or shear forces.",it should be recognized that
1657.txt,This change can affect the response of components in the direct vicinity of this local variation in index.,null
1658.txt,"In the strict sense, a neighboring component no longer remains independent in this scenario.",null
1659.txt,"Fortunately, despite the aforementioned concerns, a number of integrated photonic systems consist of components that are independent,e.g.",consist of
1660.txt,interferometers based on MMI couplers.,based on
1661.txt,The robust optimum found on the cheap system model should match the result on the reference simulation.,the result on
1662.txt,"To ensure this, the system response is iteratively improved by simulating the underlying components, using a combination of the system level error estimate and the predicted response, in areas that could potentially contain the system robust optimum.",is improved by
1663.txt,"We employ a sound mathematical criterion to select the best locations in the design space for refinement, in order to minimize the computational effort of the process.",in order to
1664.txt,Serial ring resonator-based optical filters can be seen as examples of integrated photonic systems consisting of several components.,as examples of
1665.txt,Second order and third order serial ring resonators based on single stripe TripleX technology are used for this purpose  .,are used for
1666.txt,Kriging metamodels of the directional coupler sections of the resonators are constructed since simulating the directional coupler is computationally expensive.,null
1667.txt,"The suitability of the approach is demonstrated by comparing the robust solution found with the deterministic optimum, the optimum achieved when optimizing without taking fabrication uncertainties into account.",taking into account
1668.txt,There has been previous work on optimization of ring resonators based optical filters.,There has been previous work on
1669.txt,Different approaches have been used for optimization.,used for
1670.txt,"In X, the placement of poles and zeros of the transfer function is optimized via trial and error.",is optimized via
1671.txt,"In X, a perturbation based approach is employed to vary known mean coupling ratios in order to find the optimal design.",is employed to
1672.txt,"However, these methods optimize the filter performance as a function of the coupling ratio of each directional coupler in the system.",as a function of
1673.txt,Optimization is not performed with respect to the geometrical parameters.,with respect to
1674.txt,Uncertainties in the geometry due to fabrication variations are therefore also not taken into account.,taken into account
1675.txt,"In the present work, the filter is optimized directly as a function of the geometry, meanwhile the robustness with respect to the variations in geometry is also ensured.",with respect to
1676.txt,The proposed approach is suited to problems for which the system simulation is cheap and the component behavior is simpler to approximate than the system response.,The proposed approach is suited to problems for
1677.txt,Systems with multiple identical components are especially strong candidates since a single metamodel can then replace the components.,null
1678.txt,"Once metamodels have been built for the components, the system is arbitrarily scalable at low computational cost.",been built for
1679.txt,"A library of pre-built component models   could be provided in a software package, or built by the user.",be provided in
1680.txt,These pre-built models only need to be refined for each specific case.,null
1681.txt,"For instance, once component metamodels are available for expensive to evaluate devices such as directional couplers.",For instance
1682.txt,"However, the application of the proposed algorithm for robust optimization of other such integrated photonic systems requires further investigation.",null
1683.txt,"In this work, we are interested in performing robust optimization of optical filters based on serial ring resonators.",are interested in
1685.txt,1 shows an illustration of a second-order serial ring resonator.,null
1686.txt,The serial ring resonators are simulated using a single stripe TripleX waveguide   with designed thickness of 32 nm.,null
1687.txt,The wave-guide basically consists of a stripe of Silicon Nitride buried in Silicon Dioxide.,consists of
1688.txt,A very small thickness of 32 nm has been chosen for the waveguide since the directional couplers are extremely sensitive to variation at this thickness.,null
1689.txt,This means that if the nominal performance is optimized then even slight variations in the geometry can cause the designed device to not operate as expected.,null
1690.txt,This setting enables better demonstration of both the value as well as the difficulty of performing robust optimization on sensitive systems.,as well as
1692.txt,"The design variables of the problem are the gaps, g1 to gn between the n directional couplers, the width of the waveguides and the length L of the directional couplers.",null
1693.txt,The width range is chosen such that the waveguide always remains single mode.,null
1694.txt,"The length L for each ring is kept the same so that the round trip length, given the fixed radius, is the same for all rings.",so that
1695.txt,This is needed in order to ensure that the rings in the filter have the same free spectral range.,in order to
1696.txt,"The filter performance should be robust with respect to the parametric uncertainties which impact the cross-sectional geometry, i.e.",with respect to
1698.txt,This involves finding the right combination of the design variables that leads to the most robust design.,leads to
1699.txt,Computing the response at the Through or Drop port basically involves simple linear algebra and matrix manipulation once the power coupling ratio is known for each coupler section.,is known for
1700.txt,"A commercial electromagnetic solver, PhoeniX Software, is used to simulate both quantities.",used to
1701.txt,A coupled mode theory model is employed to simulate PL0 .,is employed to
1702.txt,"On the other hand, L is found using a mode solver.",On the other hand
1703.txt,Both simulations require approximately 10 minutes.,null
1705.txt,This is because the coupled power as a function of coupling length follows a sinusoidal curve whose period is given by L  .,as a function of
1706.txt,The fidelity of the beat length L simulated via the mode solver was independently verified by simulating a directional coupler with different coupling lengths using the coupled mode theory model.,null
1707.txt,The resulting power coupling ratios were used to fit the sinusoidal curve of power coupling ratio with respect to coupling length.,used to
1708.txt,The period of this curve   was compared to the mode solver simulated beat length.,compared to
1709.txt,The two different simulated beat length values showed strong correspondence.,null
1710.txt,"Therefore, the mode solver is used to simulate the beat length  in this work.",used to
1711.txt,The scattering matrix analysis that follows X the computation of PL0 and L in order to find the serial ring resonator response is not computationally expensive.,in order to
1712.txt,We therefore make a clear distinction between the computationally expensive and cheap parts of the system.,make a clear distinction between
1713.txt,"We construct metamodels of the expensive components, response of PL0 and L , given the design variables and the parametric uncertainties.",null
1714.txt,The power coupling ratio given by the combination of the cheap models is then used as an input to the scattering matrix analysis   in order to get the system response for the serial ring resonator.,used as
1715.txt,The elements of the total transfer matrix can thenbe used to compute the transfer function for the through port.,used to
1716.txt,Details for each individual step in this process can be found in .,be found in
1717.txt,Robust optimization can then be efficiently applied on the approximate system response.,applied on
1719.txt,This convergence requires improvement of the cheap system response by adding more data points from the expensive simulation in strategically important regions until an initially specified budget for total simulations is exhausted.,null
1720.txt,"In what follows, we expand upon the robust optimization method and the proposed approach for adaptively improving the system response.",null
1721.txt,Kriging is an interpolation technique with a statistical basis  .,null
1722.txt,An important property of Kriging is that it provides an estimate for the interpolation error.,it provides an estimate for
1724.txt,3 shows a Kriging metamodel of a one-dimensional function based on three samples of a reference function.,based on
1726.txt,"The  figure  also  shows  the  predicted interpolation error, s2 , given by the solid blue line.",null
1727.txt,The interpolation error is zero at the sample points and increases as the distance between the sample points increases.,null
1729.txt,Jones devised such a method for adaptively improving the metamodel in regions of interest for optimization.,null
1730.txt,The authors extended efficient global optimization   approach suggested by Jones.,null
1732.txt,"We proposed an approach for robust optimization of a system based on component metamodels, and verified it on different problems.",proposed an approach for
1733.txt,A system level robust expected improvement criterion was derived which enabled iterative sampling of the expensive components such that the system robust optimum was found efficiently.,null
1734.txt,"Here we summarize the main steps of the method, for detailed derivation the reader is referred to X.",is referred to
1735.txt,The algorithm is demonstrated by applying it on a second order and third order serial ring resonator.,is demonstrated by
1736.txt,The robust solution is compared against the deterministic optimum.,compared against
1737.txt,The optimal locations found on the cheap system response are also fed into the expensive electromagnetic simulators as a postprocessing step in order to verify the fidelity of the solution.,in order to
1738.txt,"For deterministic optimization, it was assumed that the ring resonator structure is symmetric.",it was assumed that
1739.txt,This means that in the case of second order resonator g3 = g1 .,in the case of
1740.txt,"Similarly, for the third order resonator, g4 = g1 and g3 = g2 .",null
1741.txt,"For robust optimization both the cases, one assuming symmetry and another without symmetry of the gaps, were considered.",null
1742.txt,"It was found that for both cases, the best worst-case objective obtained was relatively the same.",It was found that
1743.txt,"Therefore, the greater flexibility of choosing unsymmetrical gap values does not automatically lead to a greater chance of a better solution.",lead to
1744.txt,"In this scenario, it makes sense to perform robust optimization using symmetric gaps, since this reduces the total number of design variables in the problem.",it makes sense to
1745.txt,"In this work, the robust optimization results shown are based on symmetric resonators.",based on
1746.txt,Robust optimization is applied on the cheap system response of the second order resonator.,is applied on
1747.txt,The approximate response is generated by applying scattering matrix analysis on the power coupling ratio for each directional coupler found via the component metamodels for PL0.,null
1748.txt,The robust optimization algorithm is started by constructing the initial component metamodels for PL0.,is started by
1749.txt,The metamodels are built based on 60 initial expensive simulations of the coupled mode theory model and the mode solver.,based on
1751.txt,"The initial locations are chosen via Latin Hypercube sampling , a type of Design of Experiments.",null
1752.txt,"Since L is a system level design variable, it does not have to be sampled.",null
1754.txt,"This means the method can run for 60 iterations, since three such simulations are run at each iteration for the three different gaps g1 , g2 and g3 .",null
1755.txt,A system level deterministic optimization algorithm is applied on the problem for comparison with the robust solution.,is applied on
1756.txt,The approach is also based on adaptive improvement of component metamodels.,based on
1757.txt,"Since uncertainties are not included in the problem definition in the deterministic case, the total number of variables is only limited to the design variables w, g, and L. ",is limited to
1759.txt,"Note that due to the lower dimensionality of the deterministic problem,fewer samples are needed compared to the robust case.",due to
1760.txt,The approximate system response based on the component metamodels for PL0 and L is plotted in Fig.,based on
1762.txt,The normalized frequency is plotted on the x-axis.,plotted on
1763.txt,The actual center frequency will in fact deviate from the original position because of a change in the waveguide width or thickness.,because of
1764.txt,Therefore the original frequency has not been provided in the x-axis  .,provided in
1765.txt,It should be pointed out here that we are interested in the bandpass performance and not in the absolute value of the frequency/wavelength at which it takes place.,It should be pointed out here that
1766.txt,"The system response at the deterministic optimum based on simulation of PL0 on the actual simulator, PhoeniX Software, is also plotted.",based on
1767.txt,"As expected, the approximate system response is quite close to the reference solution.",is quite close to
1768.txt,The same comparison is plotted for the robust optimum at the nominal location.,plotted for
1769.txt,"Once again, the solution found on the actual simulator is quite similar to the approximate system response.",is quite similar to
1770.txt,This shows that the component metamodels predict PL0 with high fidelity in the neighborhood of the robust optimum.,with high fidelity in
1773.txt,it may appear that the robust solution is a better solution at the nominal location than the deterministic optimum in Fig.,it may appear that
1776.txt,The deterministic and robust optimization algorithms are applied on a third order resonator as well.,applied on
1777.txt,The same computational budget is allocated for both problems as was used for the second order resonator problem.,used for
1778.txt,We do not need to increase the computational budget since the underlying component metamodels are made for a single directional coupler.,made for
1779.txt,That directional coupler response can be reused for all the directional couplers in the system since all the couplers share the same design variables and uncertainties domain.,null
1780.txt,The order of the resonator can therefore be increased arbitrarily without incurring high computational costs.,null
1781.txt,This scalability at low cost is one of the primary attractions of the system based approach described in this work.,null
1784.txt,There is hardly any rejection of frequencies in the stop bands for the deterministic optimum  .,There is hardly any rejection of
1785.txt,The pass band performance is significantly better than the deterministic optimum for the second order resonator.,better than
1787.txt,"On the other hand, the worst-case filter response for the robust optimum shows much better attenuation of the light in the stop band.",On the other hand
1788.txt,"The performance for the robust optimum in the stop bands is also much better than the corresponding result for the robust optimum on the second order ring resonator,Table I shows a numerical comparison of the second order and third order nominal and robust designs.",better than
1791.txt,"The last two columns give the numerical performance at the nominal and the worst-case location for the
second and third order nominal and robust optimal solutions.",null
1792.txt,"Turning our attention to the objective value at the nominal location, second last column in Table I, we note that the nominal optimum provides a better   solution for both the second and the third order resonators than the robust optimum.",provides a better   solution for
1793.txt,"However, if the worst possible fabrication with respect to the objective were to occur, then the robust optimal solution deteriorates much less than the nominal solution for both the second and the third order ring resonators, last column.",with respect to
1794.txt,it performs much better in the worst-case than the nominal solution.,it performs much better in
1795.txt,"As expected, the numerical solution for the robust optimum of the third order filter is better than the robust solution for the second order filter.",better than
1796.txt,"If higher order filters were robustly optimized, the best worst-case filter performance could further improve.",null
1797.txt,Note that the same cannot be said for the deterministic optimum.,null
1799.txt,"Apart from the worst-case location for the robust optimum of the third order ring resonator,all the other worst-case locations occur in the interior of the uncertainty set.",in the interior of
1800.txt,The method is based on an iterative optimization strategy that optimizes an approximate system response based on mathematical modeling of the components built using Kriging.,based on
1801.txt,The approach is scalable since it depends on constructing mathematical models of the directional coupler section and using them to produce the serial ring resonator response instead of building new inexpensive models of every new serial ring resonator that is considered.,instead of
1802.txt,It was shown via examples of second order and third or der TripleX based serial ring resonators that the approach can efficiently and consistently find a robust design that is relatively insensitive to fabrication deviations.,It was shown via examples of
1803.txt,"In this example, the robust design showed a lower nominal performance, but a significantly better worst-case performance.",null
1804.txt,"In practice, this would translate into substantially higher yields on optical filters optimized for robustness.",null
1805.txt,it is envisaged that the technique can potentially be employed for efficient global robust optimization of other integrated photonic systems.,it is envisaged that
1806.txt,"The broader applicability of the proposed technique for system robust optimization should be investigated by applying it on other integrated photonic systems, e.g., Array Waveguide Gratings or interferometers based on MMI couplers.",based on
1807.txt,This paper presents an advanced depth intra-coding approach for 3D video coding based on the High Efficiency  Video Coding   standard and the multiview video plus depth representation.,based on
1808.txt,"This paper is motivated  by  the fact that depth signals have specific characteristics that differ from those of natural signals, camera-view video.",differ from
1810.txt,"For this purpose, we introduce intra-picture prediction modes based on geometric primitives along with a residual coding method in the spatial domain, substituting conventional intra-prediction modes and transform coding, respectively.",For this purpose
1811.txt,The results show that our solution achieves the same quality of rendered or synthesized views  with  about the same bit rate as  MVD coding with  the 3D  video extension  of HEVC for high-quality depth maps and with about 8% less overall bit rate as with  3D-HEVC  without  related  depth  tools.,The results show that
1812.txt,"At  the  same  time,  the  combination  of  3D video with 3D computer graphics content is substantially simplified.",At  the  same  time
1814.txt,"Inrecent years, 3D video technology has matured along with intensified research on all stages of the processing chain from 3D video capture to the display technology.",null
1815.txt,This especially includes new and advanced 3D video coding methods for efficient compression and transmission as well as novel applications that combine 3D video and 3D computer graphics elements.,as well as
1816.txt,"3D video solutions can  be  categorized  by the representation  format,  namely,  those  based  on  stereo and multiview  signals  and  those  that  additionally  use depth maps.",based  on
1817.txt,"Regarding the first category, an important milestone was the multiview video coding extension of the X Video  Coding    standard.",null
1818.txt,"Here, the multiview video  representation format is used, showing the same scene from two or more different perspectives.",null
1819.txt,"By adding the concept of disparity-compensated prediction, interview dependencies are efficiently exploited with MVC, resulting in a significant coding gain compared with that of simulcast coding  .",are exploited with
1820.txt,"Target applications  of  MVC were efficient compression and transmission of stereo video, and consequently, it was adopted for the Blu-ray 3D format.",it was adopted for
1821.txt,"For supporting backward compatibility and a direct implementation on top of existing solutions, the design of MVC is restricted to high-level syntax changes of X.",is restricted to
1822.txt,This concept is now also applied to the High  Efficiency  Video Coding standard for defining a simple stereo and multiview video coding extension that benefits from the significantly better coding efficiency of HEVC compared with X.,benefits from
1823.txt,The second category is based on the multiview video plus depth   representation.,based on
1824.txt,"By enhancing MVV with the associated depth signal, a  new class of 3D video solutions  is enabled: via depth image-based rendering , perspectively correct virtual camera views of the scene can be synthesized for arbitrary view positions.",null
1825.txt,"Typical applications in this category are the support of autostereoscopic displays with a large number of views, baseline adaptation for different screen sizes, and free-viewpoint video.",displays with
1826.txt,One key aspect for the success of such applications is efficient compression and transmission of MVD data.,null
1827.txt,"The depth intra-coding solution we present in this paper is a continued development of our  previous  and  ongoing  work in this field, but with a new direction, targeting convergence of 3D video and 3D computer graphics content.",we present in this paper is
1828.txt,"Our approach is motivated by the fact that the characteristics of depth signals differ from those of natural video signals, featuring sharp edges and larger areas of nearly constant or only slowly varying  sample  values .",is motivated by
1830.txt,"We therefore propose a  coding  approach that  is adapted to the specific characteristics of depth signals, replacing intra-prediction modes as well as transform residual coding of HEVC.",adapted to
1831.txt,Our solution is optimized for both efficient compression of depth signals and efficient support of triangular meshes for representing the scene surface.,optimized for
1832.txt,"This introduces additional constraints on the design of the coding scheme, resulting in the carefully considered combination of adapted existing and newly developed methods we present in this paper.",resulting in
1834.txt,"Related to our solution, approaches for non-rectangular block segmentation and wedgelets, inter-component prediction, and residual coding for depth have been studied.",Related to
1835.txt,Morvan proposed platelet-based coding of depth maps.,null
1836.txt,"By modeling the signal of depth blocks using piecewise-linear functions and omitting the residual signal, they reported a bit rate gain of about 25% compared with that of JPEG2000.",compared with
1837.txt,"For the same method, Merkle reported that the bit rate is about 25% higher than that of  H.264/AVC  intra-only coding, while  leading  to a better quality of rendered views using the coded depth  maps.",leading  to
1838.txt,Liu  propose  a  trilateral  filter  together  with a sparse dyadic mode for depth intra coding.,null
1839.txt,The latter combines rectangular and diagonal block partitions with an inter-component predicted contour refinement.,null
1842.txt,Oh and Ho   proposed inter-component prediction for motion vectors using the motion vectors of the corresponding video block also for the depth block.,null
1843.txt,"As an extension of H.264/AVC, they report bit rate gains of about 10% for low rates, while a worse performance is achieved for high rates.",achieved for
1844.txt,Winken propose inter-component prediction for motion vectors by inheriting motion and block partitioning from video to depth.,null
1845.txt,"As an extension of multiview HEVC, they report about 10% reduction in the depth bit rate.",null
1846.txt,"Mora propose inter-component prediction of quadtree partitions using the video quadtree as a reference for  limitation  and  prediction  of the depth quadtree, reporting significant encoder complexity reduction and small depth bit rate gains for 3D video extension of HEVC .",as a reference for
1848.txt,"Our previous work on depth intra coding introduced wedgelet block segmentation with residual adaptation in X and inter-component prediction of wedgelet and contour segmentations in X, reporting about 11% and 6% reduction for the depth bit rate, respectively.",null
1849.txt,"In contrast to the approaches proposed in this paper, these extend MV-HEVC by additional modes and methods, without integrating and evaluating the effect of the view synthesis optimization distortion metric.",In contrast to
1851.txt,"The important new contributions are the mesh extraction algorithm that smoothly integrates in the decoder, the specially adapted set of modeling functions and corresponding prediction modes, and the enhancement of the constant offset residual concept for fully replacing transform residual coding in all stages of the depthrelated intra encoder and decoder.",The important new contributions are
1852.txt,The main principle of our approach is approximation of the signal of a depth block by modeling functions based on geometric primitives that allow representing the scene surface with a minimum number of triangles.,The main principle of our approach is
1853.txt,"In Section II, the two basic types of geometric depth models are introduced, namely, plane fitting for areas with a planar characteristic and wedgelet and contour segmentations for sharp edges.",null
1854.txt,"Following this principle, a full intra-coding solution for depth is developed.",null
1855.txt,"The details are explained in Section III, including intra prediction and inter-component prediction as well as constant offset residual coding in the spatial domain.",as well as
1856.txt,"Section IV is on the application of our solution, including codec integration based on 3D-HEVC and mesh extraction.",based on
1857.txt,"Finally, the results are presented in Section V.",presented in
1858.txt,"Both are adapted to a specific depth signal feature, namely, plane fitting for areas with constant or slowly changing values and non-rectangular block segmentation for sharp edges.",adapted to
1859.txt,"for instance, wedgelet and plane models in X or wedgelet and contour models in X.",for instance
1860.txt,The basic principle of this depth signal modeling approach is  approximation  of  the  signal  of  a  rectangular  block  by  a linear model that describes a plane.,null
1862.txt,"Given a depth block with original sample values d(u,v), deriving the best approximation by a plane model means finding the plane with parameters do, mu , and mv that causes the minimum distortion compared with the original signal.",compared with
1863.txt,The general approach for deriving the minimum distortion linear model for a given set of sample values is known as linear regression  .,The general approach for
1864.txt,"The most commonly used distortion metric for this is the mean squared error (MSE), such that the leastsquares linear regression method derives the linear model with the minimum MSE.",null
1865.txt,"For sample values assigned with more than one coordinate, the method is extended to multiple linear regression.",is extended to
1866.txt,"According  to X,  the  basic  principle  of  this  depth signal modeling approach is  approximation of  the  signal  of a rectangular block by a model that segments the area into  two non-rectangular regions, where each of the segments is represented by a constant value.",According  to
1867.txt,"The  information  required for such a model consists of two elements: the segmentation information, specifying the region each sample belongs to, and the region value information, specifying a constant value for each region.",null
1868.txt,"In the following, we introduce signal modeling with segmentations of type wedgelet and contour in more detail.",null
1870.txt,"In the context of image and video  processing,  the best reconstruction of a signal for a given set of candidate reconstructions is usually  defined  as  the  one  that  causes the minimum distortion compared with the original signal.",defined  as
1871.txt,"Translated to our wedgelet approach, this means finding the model that results in the closest approximation of the original depth values d(u,v) by carrying out a minimum distortion search with a set of candidate segmentation patterns.",carrying out
1872.txt,"Finally, the distortion is calculated from the difference between d(u,v) and dM (u,v).",is calculated from
1873.txt,The algorithm for the minimum distortion search consists of calculating the distortion for each candidate segmentation pattern and selecting the one with the minimum value as the best wedgelet model approximation of the depth signal.,consists of
1874.txt,The set of candidate partitions depends on the particular application and its constraints.,depends on
1875.txt,"For definitely finding the wedgelet model with the overall minimum distortion, the candidate set has to consist of the wedgelet patterns for all possible combinations of the line start and end positions.",consist of
1876.txt,"Like in X, this approach utilizes arbitrary contours as a special type of non-rectangular block segmentation.",null
1879.txt,"In contrast to wedgelet models, any complex shaped object edge can be approximated by a contour model.",In contrast to
1880.txt,"Fig.3 shows the contour segmentation with partitions  P1 and P2 and the contour signal model with segment values d1 and d2, respectively.",null
1881.txt,We employ such contour models for approximating the signal of a given depth block of X.,null
1882.txt,"Here, the partition is not derived based on a set of candidate segmentations, but by direct image segmentation of the depth block.",based on
1883.txt,The most  suitable  method for this  purpose is thresholding.,he most  suitable  method for this  purpose is
1884.txt,"Thresholding is known from digital image processing as a very simple image segmentation approach, extracting two arbitrarily shaped regions from a grayscale image, separating bright from dark areas.",null
1885.txt,Adaptive thresholding means that the image is subdivided into individual subimages and the thresholding is separately applied to each of them.,applied to
1886.txt,We apply adaptive thresholding for deriving the contour segmentation of a depth block.,apply for
1887.txt,"Here, subimages correspond to depth blocks of size N  N  and bright and dark image regions to depth values d(u,v) of foreground and background objects, respectively.",null
1888.txt,The geometry-based depth modeling approach  introduced in Section II can be used for efficient depth compression by taking advantage of its quality to closely approximate the signal of a depth block for predictive coding.,used for
1889.txt,"Accordingly,  the information or parameters describing the model need  to  be available for reconstruction at the  decoder.",null
1890.txt,"At the  encoder, the  decision  on whether and to what extend estimated information is transmitted to the decoder is typically based on a  cost  function that  balances the tradeoff between rate and distortion  , referred to as rate-distortion optimization.",based on
1891.txt,"The following four sections introduce the estimation, prediction, and signaling methods that are required for implementing our depth signal modeling in an MVD coding framework.",required for
1892.txt,"According to X, intra coding of HEVC basically consists of a number of prediction modes together with transform coding of the residual.",According to
1893.txt,The prediction modes can be grouped into those for homogeneous regions  and those for directional structures .,null
1894.txt,"Based on the geometric plane and wedgelet models introduced in Section II, we developed the following novel intra-picture prediction methods for depth coding.",introduced in
1895.txt,"The principle of this intra-coding method is predicting a plane model from the information of previously coded blocks in the same picture, i.e., intra prediction.",The principle of
1896.txt,"Like for Planar and DC intra modes in HEVC , the reference information for prediction consists of the spatially neighboring samples from left and top adjacent blocks.",consists of
1897.txt,"Our plane coding method is purely predictive  , such that no additional information has to be signaled in the bitstream.",null
1898.txt,The plane prediction process is shown in Fig.4.,is shown in
1899.txt,"According to X, the plane model of a depth block is described by the three parameters: offset do, horizontal slope mu and vertical slope mv .",According to
1901.txt,"In contrast to that the Planar mode in HEVC has no simple geometric description, as it linearly interpolates neighboring samples, which results in a smooth surface with a plane-like characteristic.",In contrast to
1902.txt,"In contrast to that the DC mode in HEVC has no simple geometric description, as the predicted signal is subsequently filtered along the left and top edges.",In contrast to
1903.txt,"According to X, the principle of this intra-coding method is estimating the optimum wedgelet segmentation at the encoder by carrying out the minimum distortion search introduced in Section II-B1 and transmitting the segmentation information in the bitstream.",According to
1904.txt,"In general, the coding performance of this approach benefits from a low distortion using the best wedgelet segmentation for reconstruction at the decoder, but suffers from the additional rate required for transmitting the segmentation information.",In general
1905.txt,"To realize an efficient coding mode, two main requirements have to be considered: One is the cost for signaling the segmentation to the decoder and the other the computational complexity of encoder estimation and decoder reconstruction.",null
1906.txt,"A solution that meets both requirements is given as wedgelet pattern lookup table: for a given coding block of size N N , the lookup table is a list of w wedgelet segmentation patterns that result from combining all possible line start and end positions.",result from
1907.txt,"Compared with other solutions, these lookup tables have the following advantages.",Compared with
1908.txt,"The complexity of the  estimation  process  is  reduced,  as segmentation patterns do not have to be generated every time the minimum distortion search is carried out and redundant segmentations are implicitly excluded from being tested.",carried out
1909.txt,The principle of this intra-coding method is predicting the wedgelet segmentation from the information of previously coded blocks in the same picture.,The principle of
1910.txt,"Here, the signal approximation can be improved by additional refinement information, which is estimated at the encoder and signaled in the bitstream.",null
1911.txt,"At the decoder, the signal of the block is reconstructed by combining the predicted segmentation with the transmitted refinement information.",null
1912.txt,The intra prediction of a wedgelet segmentation is shown in Fig.,is shown in
1914.txt,"Following the principle of directional intra prediction in HEVC, the wedgelet segmentation of the current block is predicted from the information of the left and top neighboring blocks that are already decoded and reconstructed.",is predicted from
1915.txt,"In this case, the reference block has to be of type wedgelet, such that the gradient mref can be calculated from the start and end points of the separation line  .",be calculated from
1916.txt,"Given that the line defined by Sref and mref intersects the current block, Sp and Ep are derived as their intersection points with border samples of the current block.",derived as
1917.txt,"The overall process first considers the top block for prediction and if it is not available or applicable, the left block is used.",it is not available
1919.txt,"For depth intra pictures with inter-component prediction, the video slice represents an intra base layer and the depth slice represents an intra enhancement layer.",null
1920.txt,"Thus, the information of the video reference picture has to be transmitted before the depth picture.",null
1921.txt,"Based on X, inter-component prediction for the wedgelet and contour segmentations introduced in Section II-B are considered.",Based on
1922.txt,"For both of them, estimation at the encoder and reconstruction at the decoder are identical and only consist of the inter-component prediction process, such that no additional information has to be signaled in the bitstream.",consist of
1923.txt,The reference for predicting the segmentation is the luminance signal of the co-located block in the decoded video picture.,null
1924.txt,"Regarding coding efficiency, these two modes gain from a very low rate, while the distortion depends on how consistent the object edges in video and depth are.",depends on
1925.txt,"The wedgelet segmentation of the current depth block is predicted from the video reference block by carrying out the minimum distortion search for the best matching wedgelet segmentation, as described in Section II-B1.",as described in
1926.txt,"Given the specific signal and distortion characteristics of depth, we propose an alternative residual  coding  approach for depth intra that accompanies our concept of prediction signals based on geometric models, as introduced in  Sections III-A and III-B.",as introduced in
1927.txt,"Instead of per-sample differences, the transmitted residual of our method only consists of one constant offset value per partition in the spatial domain.",Instead of
1928.txt,This method will be referred to as constant offset residual coding.,be referred to
1929.txt,"Here, the residual signal consists of two COR values for  BSM  and  one  for  Plane.",consists of
1930.txt,"This section is about the application of our depth intracoding approach based on geometric primitives,  with  the  first part addressing codec integration and the second mesh extraction.",based on
1931.txt,"For integrating the proposed depth intra-coding methods, we select 3D-HEVC as a basic framework for MVD compression.",as a basic framework for
1932.txt,"3D-HEVC builds upon MV-HEVC, which supports efficient compression of MVV with inter-view prediction.",builds upon
1933.txt,"Due to the layer design, MV-HEVC can be extended by additional depth layers for supporting MVD in a straightforward way.",Due to
1935.txt,7 shows the layers and dependencies of our basic 3D-HEVC framework with three original camera views.,null
1936.txt,3D-HEVC contains several additional and modified block-level tools for improving the coding performance.,null
1937.txt,These can be categorized by those specific to video or depth and those for intra or inter coding.,be categorized by
1938.txt,The depth coding performance is further improved by disabling deblocking filters and including some special encoder optimizations in 3D-HEVC.,improved by
1939.txt,"The most important one is VSO, a distortion metric for multiview depth coding that relates distortions in the depth directly to the overall synthesized view distortion.",null
1940.txt,"By changing the distortion metric for depth, VSO has an significant effect on RDO and the related decisions at the encoder.",has an significant effect on
1941.txt,"The reference framework for the integration of our depth intra-coding approach is the above-described 3D-HEVC codec, but without the two  depth intra-coding tools referred  to as DMM and SDC , which methodically overlap with parts of our BSM and COR approaches and were originally included in 3D-HEVC as part of our 3D video standardization proposal.",null
1942.txt,"Given this reference, the integration of the methods described in Section III requires the following changes for depth  intra  blocks.",described in
1945.txt,"As  the  second  main  module,  the regular TQR coding is replaced by our COR coding method.",replaced by
1946.txt,"The integration of these main modules includes several minor changes and optimizations for depth intra coding, such as signaling and binarization of related syntax elements or disabling reference sample smoothing .",such as
1947.txt,"Furthermore, we use the fast search strategy for minimum distortion wedgelet derivation according to X which leads to a substantial complexity reduction, especially in combination with VSO.",according to
1948.txt,"Regarding the encoder estimation of COR values, VSO has the effect that values derived according to (9) and (10) not necessarily result in the minimum distortion.",has the effect
1949.txt,"Thus, with VSO the optimal COR values are derived by a minimum distortion search.",are derived by
1950.txt,"Altogether, the resulting codec will be referred to as geometry-based depth intra   extension.",be referred to
1951.txt,Interoperability between 3D video based on the MVD representation and applications in the 3D  computer  graphics domain can be achieved by converting the depth signal     to  a  polygon  mesh  representation.,based on
1952.txt,"Merkle,Farin, and Sarkis resented approaches for extracting the surface mesh from depth or disparity images for different applications.",null
1953.txt,"Such surface meshes typically consist of triangular faces, described by the position of so-called vertices in 3D scene space and their connectivity.",consist of
1954.txt,"Rendering such an extremely large number of triangles for every frame causes complexity problems in 3D computer graphics applications; however, by removing redundant information, the number of vertices can be reduced without introducing additional distortions.",null
1955.txt,"In the case of depth maps, adjacent samples with an identical depth value lead to collinear and coplanar vertices, such that regions of constant depth require a smaller number of vertices.",lead to
1956.txt,"In contrast to this general approach, GDI is explicitly designed for supporting mesh extraction with a very small number of triangles.",In contrast to
1957.txt,Due to the geometry-based models in combination  with  COR  and  disabling smoothing/deblocking filtering  of   reconstructed  samples.,Due to
1958.txt,"Contour blocks require more vertices depending on the shape of the segmentation, however, delimited by the characteristic that all vertices of each segment are coplanar.",null
1960.txt,"8 shows mesh extraction for the different GDI types, with vertices as blue dots and connectivity as blue lines.",null
1961.txt,"For evaluating the impact of our depth coding approach on mesh extraction, we apply the following method: in the case of GDI, the set of vertices is compiled from the geometry model parameters within the decoding process as described above.",null
1962.txt,For contour blocks as well as for all other blocks.,as well as
1963.txt,The initial set consists of the four corner vertices.,consists of
1965.txt,"From the resulting set of vertices for all blocks of a picture, the number of triangles T can be calculated with (1).",null
1966.txt,"Here, the convex hull is formed by the k vertices that correspond to samples on the picture border.",formed by
1967.txt,"The described method is integrated in our 3D-HEVC framework as an alternative decoder output, with aligned new processes on all levels of the decoder from blocks to layers.",integrated in
1968.txt,"In this section, the experimental results are reported and analyzed.",null
1969.txt,"this includes eight test data sets, a camera setup with three original and six synthesized views, layer coding order and inter-layer dependencies according to Fig.",according to
1971.txt,"As usually done for intracoding tools, we additionally test an all-intra coding structure, where neither temporal prediction nor inter-view prediction is enabled.",null
1972.txt,"Regarding the test data sets, two groups of sequences must be distinguished for depth coding, namely, those with high quality depth maps and those with lower quality depth maps.",null
1973.txt,"Due to the large impact on the encoder RDO decisions and  thus  on the depth coding performance, some additional experiments are conducted with VSO disabled.",Due to
1974.txt,"Unless explicitly specified differently, all results in this section refer to the configuration with all-intra coding structure and VSO enabled.",refer to
1975.txt,"For implementing the reference framework and our GDI extension according to Section IV-A, we use version 11 of the 3D-HEVC reference software.",according to
1976.txt,"Moreover, the decoder of our coding framework is extended by the mesh extraction method introduced in Section IV-B.",introduced in
1977.txt,"To identify and analyze all effects of GDI, two reference methods are selected: one is full 3D-HEVC with all tools and the other is the 3D-HEVC implementation reference, namely, 3D-HEVC without two overlapping depth coding tools.",null
1978.txt,This second configuration allows one to clearly evaluate and classify the impact of GDI on top of the reference.,the impact of
1981.txt,"For assessing the magnitude of the gains, it has to be taken  into  account  that  only  a  very  small portion of the total rate can be influenced by GDI , while the video  coding parts of reference methods and GDI are identical.",taken  into  account
1982.txt,"It is noted that enabling VSO  leads  to  an  average  coding  gain of about 19% compared with the VSO off case for all configurations, but also to a huge increase in the encoder complexity.",It is noted that
1983.txt,The results further  indicate  that  the  overall  performance of GDI is slightly  worse  than  that  of  3DH.,slightly  worse  than
1984.txt,"However, as highlighted by the sequence-specific results in Fig.",null
1985.txt,"the coding efficiency differs for individual sequences, depending  on  factors  like  scene   complexity  and   quality of depth signals.",depending  on
1986.txt,"For the group with high-quality depth, noticeable gains are achieved with VSO off and only marginal  losses with VSO on.",null
1987.txt,"For the other group, COR and intercomponent prediction suffer from the worse depth quality, resulting in some losses.",resulting in
1989.txt,10 shows the corresponding rate-distortion   curves for one representative sequence  of each group.,null
1991.txt,11 shows the distortion of synthesized and original views relative to the view position.,null
1992.txt,"It is important to  note  that distortion values of synthesized and original views cannot be directly compared, because they are calculated against a different type of reference.",It is important to  note  that
1993.txt,These results highlight that both VSO and GDI lead to a significant improvement in the quality of synthesized views.,lead to a significant improvement in
1995.txt,"With VSO, the characteristic of the curves changes, resulting in a rather constant synthesized view quality.",resulting in
1996.txt,"For GDI, the diagrams confirm the great positive effect of our approach on the objective quality of synthesized views relative to 3DR.",confirm the great positive effect of
1998.txt,"12 shows examples of the subjective quality, comparing the amount and type of artifacts of 3DR and GDI by highlighting large distortions.",null
1999.txt,These examples clearly illustrate that especially distortions around edges between foreground and background objects are significantly reduced by GDI.,between and
2000.txt,These types of depth distortions have the largest impact on  the synthesized view quality.,have the largest impact on
2001.txt,"corresponding to a reduction of about 88%  and 84% relative to 3DR and 3DH, respectively.",corresponding to
2002.txt,Comparing 3DH and 3DR shows that the additional geometry-based depth coding tools in 3DH only lead to a relatively small reduction.,lead to
2003.txt,"Regarding the random access configuration, the values are overall higher, as the reconstructed signal of inter-coded blocks and pictures has a somewhat different characteristic.",has a somewhat different
2004.txt,"Here, motion and disparity-compensated prediction together with TQR results in rather smoothly changing signals and, consequently, a higher number of triangles for the surface mesh.",null
2005.txt,The sequence-specific results in Fig.,null
2006.txt,"13 highlight that the number of triangles differs for individual sequences, depending on factors like scene complexity and quality of depth signals.",depending on
2008.txt,"Another  advantage  of  GDI  is the considerably smaller relative deviation between individual sequences, with an average  of  24%  compared  with  49%  for 3DR.",compared  with
2009.txt,"For better understanding the impact of our depth intra-coding approach, this section presents additional statistical results.",null
2010.txt,"First, the complexity in terms of encoder  and decoder runtimes is analyzed.",in terms of
2011.txt,Table III shows the relative runtimes of our experiments.,null
2012.txt,"Although these runtime values should be considered as rough estimates, GDI obviously leads to an increased computational complexity relative to 3DR.",leads to
2013.txt,"The main reason for the increase in  decoder complexity is  the minimum distortion search of optimum wedgelet segmentations for inter-component prediction,  even  with  the fast search strategy we apply.",null
2014.txt,Note that the level of optimization regarding implementation complexity is of course much higher for the 3D-HEVC reference codec than for our implementation.,null
2016.txt,"14 shows the depth intra mode distribution: for 3DR about two-thirds of the samples are covered by angular mode blocks, followed by Planar and DC modes.",null
2017.txt,"In contrast to that with  GDI,  about  two-thirds  of  the  samples  are  covered by Plane mode blocks.",In contrast to
2018.txt,"The reason for the relatively small portion of BSM coded blocks is that this kind of bisegmentation primarily comes into consideration for certain areas of a depth picture, along the edges between objects, as highlighted by the example in Fig.",The reason for
2021.txt,"Regarding the residual coding, Table IV shows the portion of samples covered by depth intra blocks with a non-zero residual signal, with TQR and COR values transmitted  in the bitstream, respectively.",null
2022.txt,The amount of blocks with an additional residual neither increases nor decreases significantly for GDI.,neither nor
2023.txt,"A detailed analysis including the additional results for GDI with TQR instead of COR in Table V shows that COR is very efficient for depth coding in terms of RDO, especially in combination with BSM and VSO.",instead of
2024.txt,We presented a depth intra-coding approach for 3D video based on geometric primitives.,based on
2025.txt,Our method is optimized for the specific characteristics of the depth signals in MVD data.,is optimized for
2026.txt,"Based on the 3D-HEVC extension, our approach fully substitutes the intra-prediction modes as well  as  the  residual coding method of HEVC for depth intra  pictures  and intra blocks.",Based on
2027.txt,The main objective for the design of  these  two  functional units was increasing the depth coding efficiency and    at the same time improving the mesh extraction capabilities for bridging the gap between 3D video and 3D computer graphics applications.,between and
2028.txt,"We achieve this by combining prediction modes based on geometric primitives with COR residual coding, ensuring that all reconstructed sample values in a segment or block are either constant or coplanar.",based on
2029.txt,"Regarding the coding efficiency, GDI has the advantage of being optimized for the specific depth  signal  characteristics of sharp object edges and larger areas of nearly constant or slowly varying sample values.",has the advantage of
2031.txt,"Relative to 3D-HEVC without overlapping tools, GDI leads to significant coding gains in synthesized views.",leads to
2032.txt,"Regarding the mesh extraction, GDI has the advantage of being optimized for representing the scene geometry of a block by a very limited number of vertices and triangles.",has the advantage of
2033.txt,This means that the vertices of the surface mesh can be directly derived within the decoding process from the geometry-based signal model parameters and constant offset residual values.,null
2034.txt,The results show that GDI leads to surface meshes with significantly less triangles than generated from an ordinary decoder output of the reference codecs.,leads to
2035.txt,we showed that GDI is superior to HEVC intra coding for depth.,is superior to
2036.txt,One of the remaining issues for further research on this topic is the extension of our approach to inter-picture coding.,the extension of
2037.txt,"Here, additional challenges are foreseen with regard to motion and disparity-compensated prediction as well as the temporal and inter-view consistency of surface meshes.",as well as
2038.txt,Weight imprinting   was  recently  introduced  as  a  way to perform gradient descent-free few-shot  learning.,null
2039.txt,"WI was almost immediately adapted for performing  few-shot learning  on embedded neural network accelerators that do not support back propagation,  edge tensor processing units.",adapted for
2040.txt,"However, WI suffers from many limitations, e.g., it cannot handle novel categories with multimodal distributions and  special  care  should  be  given  to  avoid  overfitting  the learned embeddings on the training classes since this can have a devastating effect on classification accuracy .",have a devastating effect on
2041.txt,"In this article, we propose a novel hypersphere-based WI approach that is capable of training neural networks in a regularized, imprinting aware way effectively overcoming the aforementioned limitations.",is capable of
2042.txt,The effectiveness of the proposed method is demonstrated using extensive experiments on three image data sets.,The effectiveness of the proposed method is
2044.txt,"Deep learning   has achieved remarkable results on a wide range of difficult problems  , from an image and video analysis to natural language processing and visual questioning answering.",null
2045.txt,"This led to the development of embedded neural network accelerators, specifically designed to accelerate only the inference process, e.g., edge TPUs.",null
2046.txt, they cannot  be used  to further train the network using backpropagation.,used  to
2047.txt,"This limits their usefulness under open-world settings, where the models must  be able to continuously adapt to emerging categories  that  were  not seen during the training, which is especially challenging for several robotic perception scenarios and for a wide range of different multimedia applications.",is especially challenging for
2048.txt,"Therefore, the models should be able to draw connections and generalize their knowledge to new novel classes using only a few labeled examples, usually acquired during their interaction with the world.",null
2049.txt,This problem is known as low-shot learning or few-shot learning.,is known as
2050.txt,"Note that zero-shot learning is a related extreme case of the same problem,in which no labeled samples are available for each category.",are available for
2051.txt,"It is worth noting that even though several methods have been recently proposed for few-shot learning, only a few of them are suitable for inference-only neural network accelerators.",It is worth noting that
2052.txt,"Among them, weight imprinting was recently proposed as a way for performing gradient descent-free few-shot learning  .",null
2053.txt,"WI allows for directly expanding the set of categories which a neural network can recognize by directly imprinting a new weight vector in  the  last layer of the network, without requiring backpropagating through the network.",null
2056.txt,"In addition, using the scaling factor c ensures that the cosine similarity will range between c and c, allowing for effectively training the network without imposing a strict lower-bound on the cross entropy loss  .",In addition
2057.txt,"This process found an immediate application on edge accelerators,  edge TPUs, since  it can be readily applied to any neural network simply by extending the last fully connected layer.",it can be readily applied to
2058.txt,"WI, despite its immediate adoption, suffers from many limitations.",null
2059.txt,"First, it assumes that  the  distribution  of  the  new  categories  will be unimodal.",null
2060.txt,This assumption  is  mostly  true  for  the  distribution of classes presented to the network during the training process.,null
2061.txt,"However, this is not always the case for novel categories for which the network has not been optimized  .",null
2062.txt,"Furthermore, the process  of imprinting can negatively affect the accuracy of the network for the existing categories if there is a significant overlap between the class boundaries.",there is a significant overlap between
2063.txt,WI does not provide any efficient mechanism for detecting if adding a new category will negatively impact the existing ones.,null
2064.txt,"Finally, the impact of the scaling factor c was not thoroughly discussed in X.",null
2065.txt,We experimentally found out that the initial value of c can significantly affect the behavior of the model  in  some cases.,null
2066.txt,"For smaller initial values of c, the embeddings tend to gather closely around  the  class prototypes, while for larger initial values  of c, the embedding vectors are spread around each class prototype wi .",null
2067.txt,This behavior is shown in Fig.,is shown in
2069.txt,This does not only affect how the embeddings are distributed through space but it also has a significant impact on the classification accuracy.,it also has a significant impact on
2070.txt,Using  larger  initial  values  of  c  leads to better classification performance.,leads to
2071.txt,"Therefore, we observe that the embeddings that maintained a larger variance around the prototypes allowed for performing better WI later on.",null
2072.txt,These observations hint to a direct connection between maintaining the variance of the embeddings around the prototypes and the generalization abilities of a representation/model on unknown classes.,null
2073.txt,This is not a surprising result since it is well known that overfitted representations almost always lead to worse generalization.,it is well known that
2075.txt,"In addition, note that maintaining the variance will allow more information about the in-class similarities/dissimilarities to be encoded in the resulting representation.",In addition
2076.txt,This allows for learning a more regularized feature space that leads to a better generalization of unknown classes by maintaining the variance around each class prototype and being able to handle multimodal classes by using multiple prototypes per class.,leads to
2077.txt,The rest of this article is structured as follows.,The rest of this article is structured as follows
2078.txt,"First, the proposed method is derived and discussed in Section II.",discussed in
2079.txt,"Then, the proposed method is evaluated and compared with regular WI under different scenarios in Section III.",compared with
2080.txt,"Finally, conclusions are drawn in Section IV.",are drawn in
2081.txt,"To this end, it employs a centroid-based loss, which uniformly distributes the embedding vectors within a radius r around each prototype .",To this end
2083.txt,This process  is shown in Fig.,is shown in
2085.txt,"After learning a representation that fulfills the aforementioned requirements, we can directly classify a new sample, perform gradient descent-free few-shot learning, detect and handle multimodal novel classes, and detect intrusion to the existing classes that can lower the performance of the model.",the performance of
2086.txt,"There are several ways to detect if the distribution of a novel class is indeed multimodal, including, but not limited to, the bandwidth test and the runt test.",There are several ways to
2087.txt,Any of these approaches can be combined with the proposed method to allow for detecting whether the distribution of a class is multimodal.,combined with
2088.txt,"Furthermore, the proposed hypersphere-based formulation also provides a straightforward way to discover multimodal classes: the embedding vectors extracted for  a novel category are clustered, and the distance between the cluster centroids is measured.",null
2089.txt,"If we detect centroids that are at a distance greater than r from each  other,  then  a  hypersphere  with a  radius of r cannot enclose the embeddings of the novel class.",null
2090.txt,"To address this, we can simply add one or more prototypes to model the distribution of the novel class.",null
2091.txt,"In this way, one class can be represented using more than one prototype.",null
2092.txt,"On the other hand, if the centers of the clusters are within a radius of r , then we assume that the proposed classification scheme can directly handle the distribution of the novel class.",On the other hand
2093.txt,The proposed way of handling multimodal classes is straightforward to implement when the proposed hypersphere imprinting approach is used and allows for improving the accuracy  of the proposed method.,improving the accuracy  of the proposed method
2094.txt,"For the MNIST data set, the first five classes were used to train the model.",used to
2095.txt,"For the CUB-200-2011 data set, we followed the evaluation setup proposed in X.",proposed in
2096.txt,"For the AwA2 data set, the first 40  classes were used  for training the model, and the rest of the classes were employed for evaluating the performance of the proposed method.",used  for
2097.txt,"The proposed approach for handling multimodal novel classes, abbreviated as ""HWI-M,"" was also evaluated using an additional multimodal  split of  the MNIST data set.",null
2098.txt,"This split was  compiled  by merging two succeeding classes into one, e.g., ""0"" and ""1"" were merged into a new class, ""2"" and ""3"" into another, and so on.",were merged into
2099.txt,"Then, the three first classes  were used for training and the remaining two of them for evaluating the few-shot learning performance.",used for
2100.txt,The employed  threshold was used to detect whether a class distribution  is multimodal .,used to
2101.txt,"If the distance of the resulting centers was greater than the specified threshold, then two prototypes were used per novel class.",greater than
2102.txt,"Again,  note that the proposed variance-preserving variant of HWI greatly outperforms the HWIvariant.",null
2103.txt,"The proposed method was also evaluated using the CUB-200-2011 data set, which allows for a direct comparison with the original WI approach, as presented in X.",comparison with
2104.txt,The experimental results are reported  in  Table  VI.,are reported  in
2106.txt,Note that the proposed method outperforms the rest of the evaluated approaches.,the rest of
2107.txt,"Note that despite using the same network architecture as the one proposed in X, an InceptionV1 model.",as proposed in
2108.txt,"However, the proposed HWI still outperforms the plain WI, regardless of the used setup.",regardless of
2109.txt,"Similar results are also obtained when the multimodal split of the CUB-200-2011 data set is used, as reported in Table VII.",as reported in
2110.txt,"This split was compiled by merging each set of ten successive classes of the original data set, leading to ten classes that are used for training the models and ten classes for evaluating the imprinting performance.",leading to
2111.txt,"The proposed multimodal-aware imprinting approach again leads to higher accuracy over all the evaluated methods, confirming its ability to handle multimodal novel classes.",leading to
2112.txt,"Finally, we also evaluated the performance of the proposed method using the AwA2 data set.",the performance of
2113.txt,The  results  are  reported  in Table  VIII.,reported  in
2114.txt,"As before, the proposed method leads to significant performance improvements over the plain WI method, while it still outperforms the HWI- methods.",leads to
2115.txt,The smaller differences between HWI- and HWI can be possibly attributed to the smaller learning capacity of the employed network  .,attributed to
2116.txt,"In this article, we proposed a novel HWI approach that maintains all the advantages of regular WI, it is able to readily extend a pretrained neural network to classify samples from novel categories simply by adding new weight vectors in the final classification layer without requiring to perform any form of backpropagation to this end.",it is able to
2117.txt,"At the same time, the proposed method was capable of overcoming significant limitations of WI by being able to learn regularized representations that provide better generalization for classes that were not seen during the training and provides a straightforward way to directly handle novel categories with multimodal distributions.",null
2118.txt,"The proposed method was extensively evaluated on three image data sets, outperforming the regular WI approach.",null
2119.txt,The estimation of multitype cardiac indices from cardiac magnetic resonance imaging  and computed tomography  images attracts great attention because of its  clinical potential for comprehensive function assessment.,attracts great attention
2120.txt,"However, the most exiting model can only work in one imaging modality without transferable capability.",null
2121.txt,"In this article, we propose the multitask learning method with the reverse inferring for estimating multitype cardiac indices in MRI and CT.",null
2122.txt,"Different from the existing forward inferring methods, our method builds a reverse mapping network that maps the multitype cardiac indices to cardiac images.",null
2123.txt,The task dependencies are then learned and shared to multitask learning networks using an adversarial training approach.,null
2124.txt,A series of experiments were conducted in which we first optimized the  performance  of  our  framework via ten-fold cross-validation of over 2900 cardiac MRI images.,A series of experiments were conducted in
2125.txt,"Then, the fine-tuned network was run on an independent data set with 2360 cardiac CT images.",null
2126.txt,The results of all the experiments conducted on the proposed adversarial reverse mapping show excellent performance in estimating multitype cardiac indices.,null
2128.txt,Multittype cardiac indices estimation faces two challenges.,null
2129.txt,"Primarily, the complicated relationships between multitype cardiac indices are the main difficult for  learning  proper task dependencies.",the main difficult for
2130.txt,These indices have considerably different dimensions.,null
2131.txt,"Concerning specific indices, regional wall thicknesses   also vary according  to  the orientation of the myocardium segments in different regions.",according  to
2132.txt,"Furthermore, most of existing multitask methods can only work on one image modality because of the significantly different in appearance between magnetic resonance imaging and computed tomography.",because of
2133.txt,"MRI can accurately define cardiovascular structures and characterize tissue composition, while short- and long-axis CT can be used for cardiac function analysis.",used for
2134.txt,This diagnostic capability has attracted considerable attention because these MRI and CT techniques allow angiography to be performed noninvasively.,null
2135.txt,"However, MRI may not be used for patients with cardiac rhythm management devices for safety reasons.",used for
2136.txt,"In such circumstances, knowledge transfer from CT to MRI is necessary to obtain a better clinical evaluation.",null
2137.txt,Existing multitask learning methods may be unsuitable for estimating multitype cardiac indices in different modalities for two reasons.,be unsuitable for
2138.txt,"For the assumption-based regularization methods, task dependencies are assumed to be known as the prior information, which includes a shared set of features  , and shared cluster structures among tasks.",are assumed to be known as
2139.txt,"However, these assumptions are not always accurate or suited to all tasks.",null
2140.txt,"Second, existing multitask learning methods cannot efficiently transfer the task dependencies learned to other modalities.",null
2141.txt,"This is because most existing multitask learning methods only mine the relationships among tasks but lack a mechanism for sharing the learned knowledge between different image modalities, especially for complex task dependencies.",null
2142.txt,"To address the abovementioned challenges, a multitask learning method based on adversarial reverse mapping is proposed for estimating multitype cardiac indices in different imaging modalities  .",based on
2143.txt,The proposed method investigates multitask learning and the knowledge transfer problem from the perspective of a reverse generation that further learns the mapping from multitype cardiac indices to cardiac images via an adversarial training  approach.,null
2144.txt,"This  is loosely inspired by the recent progress of reverse mapping and adversarial training , which shows the promising ability for modeling the data distribution, especially for assessing joint distributions of complex  semantic  variables .",null
2145.txt,As shown in Fig.,As shown in
2146.txt,"in addition to the multitask learning network that learns the mapping from cardiac image to multitype cardiac indices, we propose a reverse mapping network that further learns the reverse mapping to facilitate  mining and  the representation of task dependencies.",in addition to
2147.txt,"Then, an adversarial training approach is applied to integrate the multitask learning network and the reverse mapping network.",applied to
2148.txt,"Finally, the parameters from the two networks learned from the source modality  are shared with the target modality .",null
2149.txt,We propose an efficient multitask learning framework based on adversarial reverse mapping that can obtain task dependencies .,based on
2150.txt,This network reveals the role of each cardiac index and the dependencies among different cardiac indices from a generational perspective.,null
2151.txt,"Thus, the reverse mapping network can act as a regularization enabling the multitask network to learn task dependencies.",null
2152.txt,We propose a symmetric adversarial training for realizing the regularization of the reverse network to the multitask learning network.,null
2153.txt,"Learning occurs in this adversarial training, and the joint distribution from the reverse mapping network and the multitask network are matched.",null
2154.txt,"The convexity of the matching problem  is then proven, which indicates that the reverse mapping network can effectively constrain the learning of the multitask network.",null
2155.txt,"Furthermore, we propose a bidirectional parameter sharing scheme that shares the parameters learned from both the multitask learning network and the reverse mapping network to facilitate training on different modalities.",null
2156.txt,"Compared with parameters from one-way deep neural networks, our strategy is more powerful for representing complex task dependencies and is, therefore, more effective at sharing them.",Compared with
2157.txt,"Finally, our comprehensive experiments show promising results on estimating multitype cardiac indices from MRI and CT, which validates the feasibility of our adversarial reverse mapping-based multitask learning framework.",null
2158.txt,"Existing segmentation-based method, Max Flow, initially performs cardiac segmentation and then computes other cardiac indices from the cardiac segmentation results.",null
2159.txt,"However,  cardiac segmentation is still  a challenge.",null
2160.txt,"Previously, cardiac segmentation methods were based on traditional techniques.",based on
2161.txt,Other model-based methods include the multivariate mixture model for cardiac segmentation from multisequence MRI and the statistical shape  modelbased methods.,null
2162.txt,"Recently, deep neural networks have demonstrated powerful capability for cardiac image segmentation.",null
2163.txt,FCN  is a basic method for biomedical image segmentation.,is a basic method for
2164.txt,"GAN   improved the FCN based on adversarial training, and V-net improved the FCN based  on 3-D convolutional neural network   that is  often  used in 3-D image.",based on
2165.txt,Patravali used a 2-D CNN to implement slice-by-slice segmentation and a  3-D CNN  for 2D T MRI.,null
2166.txt,"In  contrast  to  most  existing  3-D methods,  Qiao proposed a more advanced approach to obtaining 3-D context information using spatial propagation and have achieved promising results.",In contrast  to
2167.txt,Poudel and Alayba combined a 2-D CNN and recurrent neural network to segment cardiac structures from 3-D MR images.,null
2170.txt,Ahmed also used a CNN to segment cardiac structures from CT images.,null
2171.txt,"However, for segmentation methods, additional computational cost and intermediate operations are required to calculate  1-D cardiac  indices  from   segmentation   results.",required to
2172.txt,"In contrast, our method estimates 1-D cardiac  indices  and 2-D segmentation jointly.",In contrast
2173.txt,"This is because the joint estimation directly models the relationship between image appearance and the cardiac indices, which allows the model to take further advantage of the dependencies between 1-D cardiac indices and 2-D segmentation.",take advantage of
2174.txt,"Therefore, our method provides more information more efficiently.",null
2175.txt,"Regression methods that calculate the cardiac indices directly from cardiac images instead of using cardiac segmentation,have recently attracted a lot of attention.",instead of
2176.txt,"The benefit of regression methods is that they can estimate these indices directly from cardiac images more conveniently, efficiently.",The benefit of
2177.txt,"Therefore, regression methods reduce computational cost and avoid errors induced by intermediate operations that may be applicable in clinical applications.",be applicable in
2178.txt,"Primarily, regression methods can be divided into two categories: two-phase methods and multitask learning methods.",divided into
2179.txt,Most two-phase methods usually extract a feature representation and then employ a regression model to achieve the final estimation.,null
2180.txt,"The feature representation can include statistical features , meshfree representation , CNN-based feature representation, multifeatures composed of pyramidal Gabor features , steerable features and  a histogram of oriented gradients.",composed of
2181.txt,"Regression models include artificial neural networks , random forests ,K-cluster regression forests , and deep regression networks .",null
2182.txt,"Regarding multitask learning methods, recent efforts are primarily based on deep multitask learning.",based on
2183.txt,Xue  proposed a framework of joint representation and regression learning for extracting task-aware features.,null
2184.txt,Several other studies have also modeled the dependencies among different tasks and obtained promising results.,null
2185.txt,"However, most existing methods focus only on MRI  but pay no attention to CT.",pay no attention to
2186.txt,"In contrast, the proposed method can estimate multitype cardiac indices from MRI and can also be transferred to CT.",In contrast
2187.txt,An important research area is dual learning used for translation tasks   .,used for
2188.txt,It has two models: one model that translates English into French and a reverse model that translates French into English.,null
2189.txt,"During the training process, the two models would be complementary via the performance of dual tasks.",the performance of
2190.txt,"Recently, reverse mapping has also been employed for multitask learning.",employed for
2191.txt,"A representative study is X, which first predicts segmentation and tags via a multitask network and then regenerates original images from the predicted results via a reverse mapping network.",null
2192.txt,Generative adversarial networks show impressive results for data synthesis.,show impressive results for
2193.txt,"In  a  standard  GAN,  the generator would try to  generate  fake  samples  to  fool  the discriminator, and the discriminator would try to distinguish between fake and real samples.",between and
2194.txt,"In this game, if the discriminator cannot distinguish between fake and real samples correctly, we suppose that the generator would model the data distribution accurately.",between and
2195.txt,"Recently, some studies also take advantage of both GAN and reverse mapping .",take advantage of
2196.txt,Dual GAN employs two GANs to learn dual tasks.,employs to
2197.txt,"Our proposed method uses a multitask learning  framework with a reverse mapping network that reconstructs the image from learned features and multitype cardiac  indices , an adversarial training approach to solve multitask learning , and a bidirectional parameter sharing mechanism.",null
2198.txt,"Notably, we first inference a shared feature representation to predict multitype cardiac indices.",null
2199.txt,"Then, we also reconstruct the original images from the learned feature representation and predicted multitype cardiac indices, as illustrated in  Fig.",as illustrated in
2201.txt,"Furthermore,  we propose a discriminator network to distinguish  between the two joint distributions from the multitask learning network and the reverse mapping network.",between and
2202.txt,"In this case, we treat the discriminator network as a binary classification subtask in the multitask learning framework.",null
2203.txt,We then explicitly learn the multitask relation.,null
2204.txt,"Finally, we transfer the learned parameters and multitask relation to different imaging modalities, as illustrated in Fig.",as illustrated in
2205.txt,"In previous studies, f  and  g  are  solved  using  an  L1-based reconstruction loss that focuses on image translation but pays no attention to multitask problems .",pays no attention to
2206.txt,The reverse mapping network reveals the role of each index and dependence among different indices from a generational perspective.,the role of
2207.txt,It can act as a regularization enabling the multitask network to learn task dependencies via checking the cardiac image reconstructed from predicted cardiac indices.,It can act as
2208.txt,"Notably, the  reverse mapping network is  trained to  generate corresponding cardiac images from given multitype cardiac indices.",is trained to
2209.txt,"When inaccurate indices are predicted from a cardiac image, the reverse network would also generate an inaccurate cardiac image.",null
2210.txt,"Therefore, the reverse mapping network enables the multitask network to learn the correct task dependence by comparing the regenerated image with the real image.",comparing with
2211.txt,"Although the knowledge leveraged from MRI can reflect the common characteristics, such as cardiac structures and dependencies among multitype cardiac indices, shared in MRI and CT, additional effort is still required to represent and transfer such common characteristics.",such as
2212.txt,"In this section, we propose a new transfer learning scheme, a bidirectional parameter sharing scheme that transfers the learned parameters from deep layers in both the multitask learning network and the reverse mapping network learned from MRI.",null
2213.txt,"We improved a dense convolutional network to fit our multitask learning network, which has one convolution layer and three dense blocks with four,eight,and eight layers.",null
2214.txt,Our model takes 2-D cardiac image slices across one cardiac cycle as input.,null
2215.txt,"Thus, a 3-D CNN is employed for all convolution layers because of its excellent capability in action modeling.",is employed for
2216.txt,"For the first convolution layer, we use three different sizes with convolution kernel to generate hierarchical information for further learning.",null
2217.txt,"For the rest of the 3-D convolution layers in dense blocks, we use a kernel.",null
2218.txt,"Then, we can obtain a feature map (z) output using the third dense block.",null
2219.txt,"Finally, one 3-D deconvolution-based pixel-level classifier is employed to generate 2-D segmentation results from z, and one fully connected network-based regression network Mfc is employed to estimate 1-D cardiac indices from z.",is employed to
2220.txt,"Furthermore, the feature map z is also output by a branch fea.",null
2221.txt,"Notably, the outputs of Mdcnn and Mfc correspond to the 2-D segmentation and 1-D cardiac indices, respectively, in 2-D slices across one cardiac cycle.",null
2222.txt,Structure of the Reverse Mapping Network: Our reverse mapping network has a similar but reverse structure of the multitask learning network.,null
2223.txt,It regenerates corresponding cardiac images from the given multitype cardiac indices.,null
2224.txt,"In particular, for f , we first employ both convolution layers and fully connected layers as a  joint  learning network    to  learn a joint representation from z and the real I .",In particular
2225.txt,"For g, the joint representation is directly generated from the real I .",is directly generated from
2226.txt,"Then, three dense blocks with eight, eight, and four layers are employed for further learning.",are employed for
2227.txt,"Finally, we reconstruct final cardiac images using deconvolution layers.",null
2228.txt,"In contrast to existing methods that only share the parameters from one-way network, our bidirectional parameter sharing scheme shares the parameters of the multitask learning network and the reverse mapping network.",In contrast to
2229.txt,The entire model  is first trained on the MRI data using the adversarial training approach mentioned in Section II-B.,null
2230.txt,Our data include one MRI data set and two CT data sets.,null
2231.txt,The MRI data are collected from a public data set  .,are collected from
2232.txt,There are 2900 2-D short-axis cine MR images of 145 subjects  collected from three hospitals affiliated with two healthcare centers.,collected from
2234.txt,"The pixel spacings of the MR images range from 0.6836  to  2.0833 mm/pixel, with a mode of 1.5625 mm/pixel.",range from 
2235.txt,"The CT data sets are private, which includes one testing set with 360 images and  one  training  set  with  2000  images.",null
2236.txt,All  the images are 2-D  short-axis CT  images of  118 subjects  collected from the Beijing Anzhen Hospital.,collected from
2238.txt,"The pixel spacing of these CT images range from 0.5627 to 2.1232 mm/pixel, with a mode  of 1.6435 mm/pixel.",range from
2239.txt,"All cardiac images undergo several preprocessing steps, including landmark labeling, rotation, ROI cropping, and resizing.",null
2240.txt,The resulted images are approximately aligned with dimensions of 80 80.,null
2242.txt,The interobserver error  ranged  between  0.33%  and  4.11% .,between and
2244.txt,The ground-truth values of the 1-D cardiac indices can be obtained from the two borders.,be obtained from
2245.txt,"The values of WTs and cavity dimensions are normalized by the image dimension, while the areas are normalized by the pixel number  .",null
2246.txt,"During the  evaluation, the  obtained results  are  converted  to physical thickness  and area  by reversing  the resizing procedure and multiplying by the pixel spacing for each subject.",null
2247.txt,"In our experiments, in order to  test  the  performance  of our method on multitype cardiac indices estimation, ten-fold cross-validation is employed for performance evaluation for all comparison and ablation studies in MRI data set.",in order to
2248.txt,"To test the performance on transfer learning from MRI to CT, the model is trained with all MRI data, and the CT data set with 360 images are used for fine-tuning and testing.",are used for
2249.txt,"From  CT to MRI, the other CT  data  set  with  2000  images  are first used to train the model.",used to
2250.txt,"To verify the effectiveness of multitask learning for the proposed method, we use two metrics to measure the multitask relationship.",the effectiveness of
2251.txt,"First, the multitask correlation matrix C for the cardiac indices, which is calculated from the cardiac indices covariate matrix  .",is calculated from
2252.txt,"In C, the positive and negative values indicate positive and negative correlation, respectively.",null
2253.txt,The higher absolute value indicates a strong correlation.,null
2254.txt,"Then,to further consider the segmentation and reverse generation tasks, we measure the performance gain of task correlation between two tasks Ti and Tj .",between and
2255.txt,"First, to evaluate the performance of our method for multitype cardiac indices estimation, we apply our method to cardiac MR images.",the performance of
2256.txt,"Then, we fine-tune the trained model and apply it to a different imaging modality, i.e., CT images.",null
2257.txt,"Second, to validate the ability to explore task dependencies of our adversarial reverse mapping network, we  performed the following comparison and ablation studies.",null
2258.txt,"For comparison, we  test our fully framework on MRI, and then,  we compared it with segmentation-based methods.",compared with
2259.txt,"For ablation studies, we compare the performance from two aspects that include the different network architectures and different cardiac indices that the model predicted.",null
2260.txt,"For the different network architectures, both the multitask learning network and the reverse mapping network are employed.",both and
2261.txt,"Third, to show the effectiveness of our bidirectional parameter sharing scheme, we performed the following studies.",the effectiveness of
2262.txt,"First, we establish several multitask learning frameworks over different baseline deep networks.",null
2263.txt,"These multitask learning frameworks share the same structure of pixel-level classifier, regression network, and joint representation network but have different feature extraction layers.",null
2264.txt,"In particular, we employ 2-D/3-D residual nets and dense nets for feature extraction.",In particular
2265.txt,"Then, for different multitask learning frameworks that we established, we test their performance under different conditions: 1) the framework is trained directly on target data without parameter sharing ; the traditional one-way parameter sharing mechanism is employed ; the bidirectional parameter sharing mechanism is employed.",null
2266.txt,"To further validate the importance of our method, we also transfer the parameters learned from the CT to the MRI.",the importance of
2268.txt,"Figure4 shows the segmentation results estimated by our  method  across  the  entire  cardiac  cycle  for two representative subjects from the MRI and CT data, respectively.",null
2269.txt,Red lines in each frame represent ground-truth contours.,null
2270.txt,Blue lines in each frame represent the automated segmentation results of our method.,null
2271.txt,The complex task dependencies and different imaging modalities pose great challenges for cross-modal multitype cardiac indices estimation.,pose great challenges for
2272.txt,"Even so, our method accurately locate the cardiac structure, as  shown in Fig.",as  shown in
2273.txt,"and also accurately estimate the WT,  Dim,  and Area  indices, as comparison in  Fig.",as comparison in
2275.txt,It means that our method is efficient for the multitype cardiac indices estimation in the MRI and the CT.,It means that our method is efficient for
2276.txt,"Compared with Max Flow, our method achieves average MAE reductions of 56.7%, 5.28%, and 27.1% for WTs,  Dims, and Areas.",Compared with
2277.txt,"MaxFlow method first estimates segmentation, and then, it predicts the cardiac indices from segmentation.",null
2278.txt,it fails to distinguish  between  the  papillary  muscles  and  the myocardium due to extreme deformation and almost the same intensity of papillary muscles and the myocardium at middle frames of cardiac systolic.,it fails to
2280.txt,"Thus, the incorrect papillary muscles segmentation leads to bad results of multitype cardiac indices.",leads to
2281.txt,"In contrast to Max Flow, our method treats segmentation as a subtask, which allows us to simultaneously estimate segmentation with other cardiac indices.",In contrast to
2282.txt,"Compared with the best two-phase regression method MCDBN RF, our method achieves average MAE reductions of 6.9%, 8.28%, and 5.1% for WTs, Dims, and Areas.",Compared with
2283.txt,"These methods estimate cardiac indices in two phases based on handcrafted features, while our method employs an end-to-end framework that can extract task-aware features.",based on
2284.txt,Our method also achieves a better performance compare to deep multitask learning methods.,achieves a better performance
2285.txt,Indices-Net can extract task-aware features based on the jointly learning of representation and regression.,based on
2286.txt,"FullLVNet and DMTRL have the advantages of the combination of CNN and RNN, but they heavily dependent  on a particular constraint for task dependencies learning.",have the advantages of
2287.txt,FullLVNet explores the task dependencies based on predefined assumptions.,based on
2288.txt,DMTRL explores task dependencies based on a carefully designed covariance matrix.,based on
2289.txt,"Unlike these methods, our framework explores the task dependencies via further learning a reverse mapping from multitype cardiac indices to images.",null
2290.txt,"Compared with DMTRL, our method also achieves average MAE reductions of 4.32%, 5.98%, and 6.67% for WTs, Dims, and Areas .",Compared with
2291.txt,"Those sharp images also show that our model stores the information of x into z and can, thus, reconstruct the details of the image.",stores the information of
2292.txt,Combined with the good performance of our model in the multitype cardiac indices estimation,Combined with
2293.txt,"In particular, they achieve average MAE reductions of 15.17%, 6.02%, and 7.34% for WTs, Dims, and Areas and Dice increase of 3.33%, 2.15%, and 2.66% for EpiLV, EndoLV, and Myo.",In particular
2294.txt,This indicates that our bidirectional parameter sharing mechanism can effectively transfer the learned task dependencies from the MRI to the CT.,null
2295.txt,"It is difficult to mine and represent complex task dependencies, which are high-level semantic information.",It is difficult to
2296.txt,"Even so, compared with , the four methods with our bidirectional parameter sharing mechanism can still achieve average MAE reductions of 7.87%, 3.46%, and 3.50% for WTs, Dims, and Areas and Dice increase of 3.45%, 1.70%, and 1.83% for  EpiLV,  EndoLV, and Myo.",compared with
2297.txt,"For methods, even if they employ different networks, they are still trained under a one-way mapping framework from cardiac image to multitype cardiac indices regardless the learning and representation ability  of the networks.",null
2298.txt,"However, our bidirectional parameter sharing mechanism provides a different perspective of the reverse mapping, which explores discriminative information that goes beyond the inherent learning and representation ability of the deep one-way network.",provides a different perspective of
2299.txt,"We also try an extended experiment,which transfers the parameters learned from the CT to the MRI.",null
2300.txt,Both the One-way-para and Bi-para can enhance the performance of the MRI when there is knowledge transfer from the CT to MRI.,the performance of
2301.txt,This indicates that our method effectively meets clinical needs via transferring the  proper task dependencies learned between the two different imaging modalities.,This indicates that
2302.txt,This study has  potential  limitations.,null
2303.txt,The  study  focuses on the 2-D mid-ventricular slices across one cardiac cycle.,focuses on
2304.txt,"However, this might be limited to 3-D cardiac images in clinical application.",be limited to
2305.txt,"Furthermore, the 3-D image-based cardiac functions, i.e., volume and ejection fraction, could not   be obtained directly.",null
2306.txt,"In the future work, it is necessary to generalize the proposed method to 3-D and 3D t cardiac images.",it is necessary to
2307.txt,"In this study, we have developed a multitask learning framework based on adversarial reverse mapping for estimating multitype cardiac indices in different imaging modalities, e.g., MRI and CT.",based on
2308.txt,The proposed framework has an established reverse mapping network that explores task dependencies by learning the mapping from multitype cardiac indices to cardiac images via adversarial training.,null
2309.txt,A bidirectional parameter sharing scheme then transfers the parameters from both the multitask learning network and the proposed reverse mapping network.,both and
2310.txt,Experimental results show that our method not only accurately estimates multitype cardiac indices in MRI but also performs well for knowledge transfer from MRI to CT.,null
2312.txt,"While collecting enough samples from each subject would address this issue, it is often too time consuming and impractical.",it is often too time consuming and impractical
2313.txt,"To tackle this problem, we propose a novel end-to-end deep domain adaptation method to improve the classification performance on a single subject  by taking the useful information from multiple subjects into consideration.",taking into consideration
2314.txt,"Especially, the proposed method jointly optimizes  three  modules,  including a  feature  extractor, a classifier, and a domain discriminator.",null
2315.txt,The feature extractor learns the discriminative latent features by mapping the raw EEG signals into a deep representation space.,null
2316.txt,A center loss is further employed to constrain an invariant feature space and reduce the intrasubject nonstationarity.,employed to
2317.txt,"Furthermore, the domain discriminator matches the feature distribution shift between source and target domains by an adversarial learning strategy.",between and
2318.txt,"Finally, based on the consistent deep features from both domains.",based on
2319.txt,"To evaluate our method, we have conducted extensive experiments on two real public EEG  data sets,  data  set IIa.",conducted extensive experiments on
2320.txt,The experimental results validate the efficacy of our method.,the efficacy of
2321.txt,"Therefore, our method is promising to reduce the calibration time for the use of BCI and promote the development of BCI.",is promising to
2323.txt,Machine learning techniques show  great  efficiency to extract discriminative information from electroen-cephalography   recordings for mental intention recognition .,show  great  efficiency to
2324.txt,"Providing a nonmuscular channel of communication between the human brain and external devices by translating mental intention into control commands, such BCI systems inspire many promising applications, including communication, movement, and rehabilitation for patients, as well as entertainment for healthy people  .",as well as
2325.txt,"The deep neural network , as a subcategory of machine learning, has achieved impressive progress in computer vision  and  natural  language  processing .",achieved impressive progress in
2326.txt,It has been shown that DNN is well suited for end-to-end learning without a priori knowledge of the  target  problem and is able to scale  well  to a large data set.,It has been shown that
2327.txt,"However, due to the special characteristics of EEG signals, DNN is seldom explored in EEG signal analysis.",due to
2328.txt,"On the one hand, EEG signals are generally sample-limited and high-dimensional.",On the one hand
2329.txt,DNN may suffer from a severe overfitting problem with limited EEG samples since it normally requires a larger amount of training data than other machine learning methods.,a larger amount of
2330.txt,"EEG signals have large intersubject variability, where a subject-independent classifier directly trained on EEG data from multiple subjects often has poor generalization capability on a new subject.",has poor generalization capability on
2331.txt,"Therefore, we cannot simply increase the data size by aggregating the training samples from multiple subjects and feed them into the DNN models.",null
2332.txt,Domain adaptation was first explored for domain invariant feature learning in computer vision  and  has  been  used  to overcome this bottleneck of poor performance for every single subject.,explored for
2333.txt,"It is capable to make good use of one specific domain with enough training data, to effectively extract important information or train classifiers adapted to a related but different domain, where only limited labels, even none, can be acquired.",It is capable to
2334.txt,"we refer to the domain with enough annotated data from multiple subjects as the source domain and the one with limited annotations or none at all from the target subject, as the target domain.",refer to
2335.txt,"Until recently, only a few studies have investigated domain adaptation with DNN in the context of EEG classification.",in the context of
2336.txt,Sakhavi  and  Guan fine-tuned a convolutional neural network   pretrained on the source brain signals using target samples with pseudolabels.,null
2337.txt,"However, this would result in overfitting when fewer target data are available.",result in
2338.txt,"To handle limited training data, Li proposed a bihemisphere domain adversarial neural network  model for emotion recognition that tackled the marginal distribution shift between training and test data.",between and
2339.txt,"After that, the classifier trained from labeled source data was applied to target data directly.",was applied to
2340.txt,"However, the BiDANN is strongly dependent on the neuroscience findings on emotion and cannot be applied to the motor imagery task, which is the focus of this article.",be applied to
2341.txt,"To tackle this issue, in this article, we propose a novel end-to-end neural network model, called deep representation-based domain adaptation  , to deal with EEG MI tasks.",deal with
2342.txt,Our data model learns the deep feature representation by considering the marginal and conditional distribution discrepancy between source and target domains.,null
2343.txt,This is achieved by jointly optimizing three modules.,This is achieved by
2344.txt,It predicts the output labels with the extracted deep features from the feature extractor.,null
2345.txt,It is designed to distinguish which domain   the deep features come from so as to constrain the entire deep feature distribution to be similar across domains.,It is designed to
2346.txt,"In addition, to further leverage the label information, the center loss   is employed to constrain the invariant feature mapping in the feature extractor.",In addition
2347.txt,"During training, the parameters of feature extractor and classifier are optimized by minimizing the classification loss and center loss together with the adversarial loss provided by the domain discriminator, while the parameters of  domain  discriminator  are  updated by maximizing the adversarial loss.",are  updated by
2348.txt,The major contributions of this article can be summarized as follows.,The major contributions of this article can be summarized as follows
2349.txt,"To our best of our knowledge, the proposed DRDA model is the first work that explores an end-to-end  DNN model with feature space adaptation for MI tasks.",null
2350.txt,"By reducing the distribution discrepancy between related but different domains, it is able to leverage source samples to improve the single-subject performance in the target domain, even with fewer labels available.",it is able to
2351.txt,We propose an efficient combined loss function that consists of an adversarial loss to reduce the intersubject discrepancy and a center loss to constrain the intrasubject nonstationarity.,consists of
2353.txt,We extensively evaluate the proposed DRDA model on two real EEG data sets.,null
2354.txt,The experimental results show that DRDA achieves state-of-the-art generalization performance in single-trial EEG-based MI tasks.,null
2355.txt,"Therefore, the proposed method has great potential for efficient and robust EEG-based BCIs.",has great potential for
2356.txt,The rest of this article is organized as follows.,The rest of this article is organized as follows
2357.txt,"In Section II, we mainly review the relevant studies on deep learning and domain adaptation used in MI classification.",null
2358.txt,"In  Section III, we describe the proposed model in detail.",null
2359.txt,The experiments and their results are presented and discussed in Section IV.,are presented and discussed in
2360.txt,"Finally, Section V concludes this study.",null
2361.txt,The  conventional  common  spatial   pattern   method  and its various extensions  have achieved promising results.,null
2362.txt,The conventional CSP employs a single fixed frequency band to compute the optimal spatial filter such that the ratio of  the  filtered  variance  between  two categories is maximized .,null
2363.txt,"Similar  to CSP, the filter bank CSP decomposes  the  fixed  frequency  into  multiple   nonoverlapped   subbands and stacks the CSP features in each band.",Similar  to
2365.txt,"However, the extracted matrix-form features are stacked into vectors and fed to a support vector machine  or  a linear discriminant analysis classifier, which would inevitably destroy the latent structural information within the raw EEG data.",null
2366.txt,"To address this issue, modern matrix-form classifiers have been  developed  to  preserve  and  leverage the structural correlation by introducing  certain  constraints on the regression  matrix.",null
2367.txt,Zhou  and  Li   proposed a novel model to regularize the  rank  of  logistic  regression by the nuclear norm.,null
2368.txt,Luo investigated a spectral elastic net regularization and proposed a support matrix machine model.,null
2369.txt,"Based on SMM, Zheng proposed a sparse SMM model   to simultaneously consider low-rank structural information and feature  selection, which further improved the EEG classification performance.",null
2370.txt,"Recently, DNN methods have been investigated in EEG classification tasks .",been investigated in
2371.txt,"For instance, Kumar employed a multilayer perceptron   to replace the commonly used classifiers.",For instance
2372.txt,Yang extracted augmented CSP features from varying frequency bands and then fed into CNN for further feature learning and classification.,null
2374.txt,Bashivan converted the EEG time series into spectral topography images by short-time Fourier transform and then employed CNN to classify the transformed EEG images.,null
2376.txt,"The aforementioned neural network methods still involve preprocessing, such as specialized feature extraction or STFT for image mapping.",such as
2377.txt,"In this regard, several studies explored end-to-end network models for EEG feature extraction and classification.",null
2378.txt,"For example, Tang  employed  a  CNN architecture with several 1-D convolutional layers for raw EEG data.",For example
2379.txt,Schirrmeister proposed a deep CovNet model using separated temporal and spatial  filters and achieved performance as competitive as the widely used FBCSP.,null
2380.txt,Wang discussed different models on MI tasks with the input of signals in the frequency domain.,null
2381.txt,They found that CNN achieved the best performance.,achieved the best performance
2382.txt,"She  proposed a semisupervised version of the extreme learning machine,which could utilize both labeled and unlabeled data to increase the classification accuracy.",null
2383.txt,"To address this issue, domain adaptation has been  applied  to  either  adapt the features/classifier from the source domain to the target domain or extract common features that are robust for different domains.",null
2384.txt,Dose introduced subject-specific adaptation to improve the performance of a single subject.,improve the performance of
2386.txt,Raza presented a covariate shift-detection   method and retrained the classifier once the convariate shifts were detected.,null
2387.txt,Samek constructed an invariant subspace for CSP features by removing the principal nonstationary subspace.,null
2388.txt,"Similarly, Song developed an adaptive CSP method to classify EEG data from multisubjects, which updated the spatial filters for the target domain  during  classification.",null
2389.txt,Jeon proposed an adaptation approach by using samples of the other subjects.,proposed an adaptation approach by
2390.txt,They first selected a source subject whose signal power spectral density was similar to the target one and trained the model with both selected and target subjects.,was similar to
2391.txt,The classifiers for the source and target domains were adaptively trained with  a  gradient reversal  layer  unit.,null
2392.txt,"A weighted transfer method was proposed in X, where a classification model was trained on the target data with the cross-entropy loss.",was proposed in
2393.txt,"Besides, a regularization loss was proposed under the assumption that there was common information across the subjects.",there was common information
2394.txt,The feature distribution similarity between the source and target subjects was employed to weight the regularization of different source subjects in the  loss  term.,was employed to
2395.txt,"He and Wu proposed a data alignment framework in the Euclidean space, where the covariance matrices were aligned between different subjects and could be used as features for classification.",be used as
2396.txt,"Different from those approaches that adapt the spatial filters or the established classifiers from the source domain to the target domain, we seek invariant deep representations between source and target domains with an adversarial learning process.",null
2397.txt,"In this section, we first briefly introduce the notations and definitions that are used later in this work.",null
2398.txt,"Then, we give an overview of the architecture of our method and illustrate the proposed method in detail.",give an overview of
2400.txt,"Intuitively, such features are drawn from different distributions for source and target domains since the marginal distribution discrepancy of the raw data is tremendous between different domains.",are drawn from
2401.txt,"In this way, it is quite difficult to simultaneously leverage the useful information from source features and target features to train the classifier.",it is quite difficult to
2403.txt,"To further learn the discriminative features, we also introduce the center loss to reduce the nonstationarity in the target domain, which pushes away the features from different categories while pulling closer the features belonging to the same class.",null
2404.txt,"Then, the deep features learned from both domains can be used to train the classifier.",be used to
2405.txt,"At the test time, as  shown  in  Fig.",as  shown  in
2406.txt,"the combination of the feature extractor and the classifier forms an end-to-end deep learning model, which directly predicts the MI label from the EEG input.",null
2407.txt,"In what follows, we will introduce the whole process of our approach, including the preprocessing step,the end-to-end network architecture, and the loss functions.",null
2408.txt,"the proposed model consists of three components, including a feature extractor, a classifier, and a domain discriminator.",consists of
2409.txt,We first adopt a Siamese-like structure to take advantage of data from both domains.,take advantage of
2410.txt,"Namely, the feature extractor and classifier share their weights for both s and  t .",null
2411.txt,"However,  the  features learned are different between source and  target domains due to the marginal distribution shift caused by fatigue or distraction of subjects during signal collection.",due to
2412.txt,we split the 2-D convolution into two 1-D convolution operations for EEG classification.,null
2413.txt,"Especially, the  first  two  layers  of  the feature extractor are composed of two 1-D convolutional layers to learn the temporal and spatial feature representations, respectively.",are composed of
2414.txt,"For temporal convolution, a kernel size of 25 is applied to deal with  the  continuous and  extensive series.",is applied to
2415.txt,"It is much larger than the one that is usually used  (3,3)  in image classification task  , allowing for a larger range of temporal transformations in this layer.",It is much larger than
2416.txt,"For spatial convolution, a kernel size  of  the  same  number of  electrode channels  C is engaged to fuse the spatial information from all input electrodes.",is engaged to
2417.txt,This operation fuses the spatial information from different electrodes to the features of a single electrode.,null
2418.txt,"Afterward, an average pooling  layer  of  size  75  is  applied to avoid overfitting and learn the invariant features.",is  applied to
2419.txt,"Finally, a fully connected layer is connected to generate a deep representation.",is connected to
2420.txt,The details of the feature extractor are shown in Table I.,are shown in
2421.txt,"Therefore, the classification performance may be deteriorated if the classifier trained only with the source domain is  applied  to  target  data  directly.",is  applied  to
2422.txt,"To address this issue, we consider the  conditional distribution inconsistency and utilize the labeled features from both domains to train a robust classifier.",null
2424.txt,"This module is essential in our method, which offers the ability to leverage data from other subjects in the target domain.",null
2425.txt,"Inspired by the generative adversarial network , we design the adversarial learning process with the feature extractor and domain discriminator components.",null
2426.txt,"During the learning process, the discriminator distinguishes the features learned  from  which  domain;  at the same time, the feature extractor learns to map the EEG input from both domains into a latent common space.",at the same time
2427.txt,"Finally, the feature extractor is able to  fool the discriminator such  that the domain discriminator fails to distinguish the origin of the extracted features.",is able to
2428.txt,"In this way, the marginal distribution discrepancy of the latent features is alleviated so that the learned features from both domains  can  be  used  to  train  the same classifier.",be  used  to
2429.txt,"For implementation, the discriminator is trained on a binary domain  label set	0, 1 , in which the domain label is 1 for target data and 0 for the source samples.",null
2431.txt,"the domain discriminator consists of four FC layers with size of 64, 32, 16, and 1, respectively.",consists of
2432.txt,The activation function is set to relu for the first three layers and sigmoid for the last layer to output a probability for binary prediction.,null
2433.txt,"The proposed method jointly optimizes the feature extractor, classifier, and domain discriminator.",null
2434.txt,"To be specific, we iteratively train these three modules in two alternative steps and update the parameters according to the chain  rule  in  deep learning methods.",To be specific
2435.txt,"At each  iteration,  we  first  update  the parameters of the domain discriminator, fix the feature extractor and classifier, and then fix the domain discriminator and update the parameters of both the feature extractor and classifier.",null
2436.txt,"During training, several loss functions are adopted to measure the difference between network predictions and the given ground truth.",are adopted to
2437.txt,"For the domain discriminator, it regards the features from source data as fake samples while those from target data as real samples.",null
2438.txt,The domain adaptation operations are carried on the deep representation space generated by the feature extractor.,are carried on
2439.txt,"we adopt a least squared adversarial loss to update the discriminator, whose formulation is given as follows.",is given as follows
2440.txt,"In this section, we extensively validate the proposed method on EEG-based MI classification in the context of BCI.",null
2441.txt,"First, we introduce two public EEG data sets used in the following experiments, Data set IIa and Data set IIb of BCI Competition IV for multiclass and binary classification, respectively.",null
2442.txt,we compare our method with several state-of-the-art methods that demonstrate satisfactory performance on these two data sets.,compare with
2443.txt,"Finally, we perform an ablation study of the proposed method with respect to the model hyperparameters.",with respect to
2444.txt,The data set1 contains 22-channel EEG signals from nine subjects  .,null
2445.txt,The sampling rate of the signals is 250 Hz.,null
2446.txt,"The data were collected on four different MI tasks, including the left hand, right hand, tongue, and both feet.",null
2447.txt,"For each subject, two sessions of data were collected with 288 trials for each session.",were collected with
2448.txt,"Here, the MI data in the first session were used for training, and those in the second session were used for the test.",were used for
2449.txt,"Note that the temporal segment of [2,  6] second is considered in our experiments.",null
2450.txt,"The data set2  records three bipolar-channel EEG signals from nine subjects, namely.",null
2451.txt,The sampling rate is 250 Hz.,null
2452.txt,"For each subject, five sessions were collected.",null
2453.txt,The data in the first three sessions were used for training and the rest were used for tests.,were used for
2454.txt,"There are about 400 trials and 320 trials in the training and test sets, respectively.",null
2455.txt,Our approach is implemented with the TensorFlow library in Python with an Intel Core I7 CPU and a Tesla P40 GPU.,null
2456.txt,"For these two  data sets,  all  the EEG channels are utilized for classification, and the three electrooculography   channels are directly discarded without any artifact removing operation.",null
2457.txt,"We train our DNNs with Adam optimizer  , which has a learning rate of 0.0002.",has a learning rate of
2459.txt,The network parameters are updated by a minibatch with a size of 64 in each training  iteration.,null
2460.txt,We  early terminate the training if no improvement in the training set is observed in ten iterations to avoid overfitting.,is observed in
2461.txt,"Note that the training and test sets are split according to the competition guideline, making the comparison fair for all methods.",according to
2462.txt,We first evaluate different algorithms on data set IIa of BCI Competition IV and present the classification accuracy on each subject and mean  accuracy   values in  Table  II.,null
2463.txt,"For a clear illustration, the highest accuracy or kappa values are highlighted in boldface.",null
2464.txt,the proposed method has superior performance in both mean accuracy and kappa values.,has superior performance in
2465.txt,"The deep learning methods, including ConvNet, C2CM, and ours, outperform the  traditional  methods,  such as FBCSP.",such as
2466.txt,It indicates that the DNNs are able to learn the discriminative features for classification.,It indicates that
2467.txt,"On the contrary, both traditional feature extraction methods with domain adaptation.",On the contrary
2468.txt,This may result from the strong prior assumptions  of  the data.,null
2469.txt,"For example, CCSP assumes that the spatial filter of different subjects should be as close as possible and estimates the covariance matrix by shrinking it toward the mean  of other subjects.",as close as possible
2470.txt,"Similarly, SSCSP investigates the shared global subspace and removes the principal nonstationary subspace common to most subjects before CSP computation.",null
2471.txt,These assumptions are merely held in real applications since EEG data are nonstationary and changed from subject to subject.,null
2472.txt,"In addition, almost all compared methods, including FBCSP, SMM, C2CM, BO, CCSP, and SSCSP, separately optimize  the feature extraction and classification by minimizing different objective functions.",In addition
2473.txt,The  extracted  features  may  not be optimized for the subsequent classification.,be optimized for
2474.txt,"Therefore, our method, which not only learns the discriminative features and classifiers in an end-to-end optimization paradigm but also leverages information from other domains with an adversarial learning scheme, can achieve the best performance.",achieve the best performance
2475.txt,"it finetunes the deep architecture parameters for each subject, such as kernel size and hidden nodes, while ours holds the same model architecture and parameters, making it practical for real online BCI applications.",such as
2476.txt,We further test our method on data set IIb of BCI Competition IV.,null
2477.txt,The results of classification accuracy on each subject with an average score of accuracy are reported in Table III.,are reported in
2478.txt,It indicates that CNN with domain adaptation in an end-to-end paradigm is effective for EEG classification.,It indicates that
2479.txt,The domain adaption realized by adversarial learning is able to pull the data distribution from different subjects close to each other without any strong assumptions.,null
2480.txt,"Therefore, the important information of EEG data from the source domain can be exploited when training a discriminative classifier for the target domain.",null
2481.txt,"We also  notice that, taking FBCSP  as a baseline,  the techniques with handcrafted features, such as SMM and SSMM, outperform FBCSP on data set IIa but are beaten on data set IIb.",such as
2482.txt,It shows that the handcrafted features extracted with expert knowledge may not have enough generalization ability.,It shows that
2483.txt,It again validates the efficacy and robustness of our method.,null
2484.txt,We conduct the following experiments to study the parameter settings and demonstrate the significance of the adversarial loss and the center loss used in the proposed method.,the significance of
2485.txt,"In addition, we also evaluate the pseudolabel strategy when the labels in the target domain are absent.",In addition
2489.txt,We first only feed in the target data from t  to  tailor  the feature extractor and classifier to the target subject.,null
2490.txt,the overall performance is inferior compared with those.,compared with
2491.txt,"it  is  observed that the performance suffers from serious degradation for those subjects whose EEG signals have a poor signal-to-noise ratio , while, for the rest subjects, the  average  accuracy  of our method has a competitive  advantage  against  those  of  the other state-of-the-art methods.",it  is  observed that
2492.txt,"It illustrates that for the subject with  high  SNR EEG signals, our deep model can achieve satisfactory results with little training data, while, for those with EEG data of poor quality.",It illustrates that
2494.txt,"Though it improves the performance of A04 and A05 obviously, the mean accuracy drops to 59.58%.",the performance of
2495.txt,"Thus, it shows that indiscriminately gathering samples from multiple subjects is inefficient due to the distribution shift of different subjects.",it shows that
2496.txt,"Moreover, we also fine-tune the deep model  pretrained on  the source data using the target data for each subject and report the results in Table IV.",null
2497.txt,"Though the fine-tuning method significantly outperforms those in both the abovementioned scenarios, there is still an obvious gap between it and our method with an adversarial loss.",there is still an obvious gap between
2498.txt,"It, in turn, validates that the proposed method with the domain discriminator is able to narrow the distribution discrepancy and leverage the useful information from source data to improve the classification performance.",It validates that
2499.txt,"We also investigate the influence of two adversarial losses, namely, vanilla GAN loss versus LS-GAN loss .",null
2500.txt,"It is observed that for the vanilla loss,the accuracy rates also increase.",It is observed that
2503.txt,Similar trends also occur in the  case  of  the LS-GAN  loss.,in the  case  of
2504.txt,the overall performance of the proposed method with the LS-GAN loss is consistently better than that with the vanilla GAN loss.,the overall performance of the proposed method
2506.txt,We finally investigate the influence of the center loss with different weights on data set IIa of BCI Competition IV and display the performance in Table V.,null
2507.txt,our method does not consider the intrasubject nonstationarity.,null
2508.txt,It is observed that when the classification accuracy increases for both scenarios.,It is observed that
2509.txt,"The improvement is much more significant for the subjects with signals of low quality, e.g., A02 yields a rise of 11% in the accuracy.",much more significant for
2510.txt,"This observation suggests that the center loss is able to handle the intraclass  variations caused by low SNR or nonstationary signals within a single subject, thus making the features learned more discriminative.",null
2511.txt,"For a clear illustration, we further employ the t-SNE method   and visualize the feature distribution of two randomly selected subjects A04 and B05 from these two data sets, respectively, in Fig.",For a clear illustration
2513.txt,"In fact, similar phenomena also occur in other subjects.",In fact
2514.txt,"It also reveals that if without the center loss, the latent features are more scattered and of large entropy.",It also reveals that
2515.txt,"On the contrary,the features are more discriminative, with smaller intraclass distances and larger interclass boundaries.",On the contrary
2516.txt,"Thus, it leads to better classification performance.",it leads to better classification performance
2518.txt,"When the labels of  target  data are absent, we propose a pseudolabel strategy to predict the target labels for domain adaptation.",propose a pseudolabel strategy to
2519.txt,"If without the estimated target labels, the center loss would be deactivated, and our method would degrade to an unsupervised domain adaptation method.",null
2520.txt,"If the target data are also absent, the domain adaptation would be dysfunctional, and our method would further degrade to the one trained with only the annotated source data  .",null
2521.txt,"Thus, to evaluate the pseudolabel strategy in our method, we compare the performance of the pseudolabel strategy, unsupervised domain adaptation, and SourceCNN.",null
2522.txt,Table VI displays the performance of  these  three  models.,the performance of
2523.txt,"The results show that our pseudolabel strategy achieves the highest classification accuracy, while SourceCNN obtains the lowest one.",achieves the highest classification accuracy
2524.txt,It indicates that the classifiers trained directly on the source data have poor generation capability on the target domain.,It indicates that
2525.txt,"On the contrary, our pseudolabel strategy is capable to improve the target domain classification by leveraging additional information from the source data.",On the contrary
2526.txt,"In this article, we proposed a deep end-to-end domain adaptation method to handle the EEG-based MI classification task, which improves the performance of the subject-dependent classifier by leveraging the useful information from the source domain.",improves the performance of
2527.txt,"To alleviate the distribution  discrepancy  between  the source and target domains, a domain discriminator is engaged to narrow the covariate shift with an adversarial learning strategy.",is engaged to
2528.txt,"In this way, the  features  generated  from the source domain have a similar distribution to those  from the target domain.",have a similar distribution to
2529.txt,"In  addition,  a  center  loss  is  introduced to learn invariant features, which reduces the intrasubject nonstationarity by minimizing the feature distance of the same class and maximizing the boundary of different categories.",In  addition
2530.txt,"Therefore, we can make good use of the source data to learn the discriminative features and train a robust classifier with better generalization for the target domain.",make good use of
2531.txt,"We have conducted extensive experiments, and the results show that the proposed approach is effective to identify motor intention from EEG signals and outperforms state-of-the-art methods.",is effective to
2532.txt,"Moreover, it also shows empirically that the proposed adversarial loss and the center loss are able to significantly reduce the intersubject and intrasubject nonstationarity, which can be extended to other BCI applications.",it also shows empirically that
2533.txt,"Feature subset selection, as a special case of the general subset selection problem, has been the topic of a considerable number of studies due to the growing importance of data mining applications.",due to
2534.txt,In the feature subset selection problem there are two main issues that need to be addressed.,there are two main issues that
2535.txt,A search strategy to optimize the measure over the subset space in a reasonable amount of time.,null
2536.txt,In this article mutual information between features and class labels is considered to be the measure function.,is considered to be
2537.txt,"Two series expansions for mutual information are proposed, and it is shown that most heuristic criteria suggested in the literature are truncated approximations of these expansions.",it is shown that
2538.txt,It is well-known that searching the whole subset space is an NP-hard problem.,It is well-known that
2539.txt,"Here, instead of the conventional sequential search algorithms, we suggest a parallel search strategy based on semidefinite programming   that can search through the subset space in polynomial time.",based on
2540.txt,"By exploiting the similarities between the proposed algorithm and an instance of the maximumcut problem in graph theory, the approximation ratio of this algorithm is derived and is compared with the approximation ratio of the backward elimination method.",is compared with
2541.txt,The experiments show that it can be misleading to judge the quality of a measure solely based on the classification accuracy,it can be misleading to
2542.txt,most  machine learning algorithms is  to  approximate  this underlying distribution or estimate some of its characteristics.,null
2543.txt,"Unfortunately, in most practically relevant data mining applications,  the  dimensionality  of  the  feature  vector  is quite high making it prohibitive to learn the underlying distribution.",making it prohibitive to
2544.txt,"For instance, gene expression data or images may easily have more than tens of thousands of features.",For instance
2545.txt,High-dimensional data poses different challenges on induction and prediction algorithms.,poses different challenges on
2546.txt,"Essentially, the amount of data to sustain the spatial density of the underlying distribution increases exponentially with the dimensionality of the feature vector, or alternatively, the sparsity increases exponentially given a constant amount of data.",given a constant amount of data
2547.txt,"Thus, dimensionality reduction techniques, particularly feature extraction and feature selection methods, have to be employed to reconcile idealistic learning algorithms with real-world applications.",be employed to
2548.txt,The first one is to define an appropriate measure function to assign a score to a set of features.,null
2549.txt,"Given an inducer I, wrapper approaches search through thespace of all possible feature subsets and select the one that maximizes the induction accuracy.",null
2550.txt,"Most of  the  methods of this  type require to  check all  the possible  subsets  of features and thus, may rapidly become prohibitive due to the so-called combinatorial explosion.",due to
2551.txt,"Since the measure function is a machine learning algorithm, the selected feature subset is only optimal with respect to that particular algorithm.",with respect to
2552.txt,The second group of feature selection methods are called embedded methods and are based on some internal parameters of the ML algorithm.,are based on
2553.txt,Embedded approaches rank features during the training process and thus simultaneously determine both the optimal  features  and  the  parameters of the ML algorithm.,null
2554.txt,"Since using the internal parameters may not be applicable in all ML algorithms,  this approach cannot be seen as a general solution to the feature selection problem.",be applicable in
2555.txt,"In contrast to wrapper methods, embedded strategies do not require to run the exhaustive search over all subsets since they mostly evaluate each feature individually based on the score calculated from the internal parameters.",In contrast to
2556.txt,"Filter methods, as the third group of selection algorithms, focus on filtering out irrelevant and redundant features in which irrelevancy is defined according to a predetermined measure function.",focus on
2557.txt,"Unlike the first two groups, filter methods do not incorporate the learning part and thus show better generalization power over a wider range of induction algorithms.",a wider range of
2558.txt,They rely on finding an optimal feature subset through the optimization of a suitable measure function.,null
2559.txt,"Since the measure function is  selected  independently of the induction algorithm, this approach decouples the feature selection problem from the following ML algorithm.",null
2560.txt,The first contribution of this work is to analyze the popular mutual information measure in the context of the feature selection problem.,The first contribution of this work is to
2561.txt,We will expand the mutual information function in two different series and show that most of the previously suggested information-theoretic criteria are the first or second order truncation-approximations of these expansions.,null
2562.txt,"The first expansion is based on generalization of mutual information and has already appeared in literature while the second one is new, to the best of our knowledge.",is based on
2563.txt,The well-known minimal Redundancy Maximal Relevance score function can be immediately concluded from the second expansion.,be immediately concluded from
2564.txt,"Alternatively, feature selection methods can be categorized based on the search strategies they employ.",based on
2565.txt,"Popular search approaches can be divided into four categories: Exhaustive search,  greedy  search,  projection  and  heuristic.",be divided into
2566.txt,"A trivial approach is  to  exhaustively search  in  the  subset space as Greedy algorithms iteratively evaluate a candidate subset of features, then modify the subset and evaluate if the new subset is an improvement over the old one.",null
2567.txt,This can be done in a  forward selection setup which starts with an empty set and adds one feature at a time or with a backward elimination process which starts with the full set of features and removes one feature at each step.,null
2568.txt,The third group of the search algorithms are based on targeted projection pursuit which is a linear mapping algorithm to pursue an optimum projection of data onto a low dimensional manifold that scores highly with respect  to  a  measure  function.,with respect  to
2569.txt,"Recently, two convex quadratic programing based methods, QPFS in X and SOSS in X have been suggested to address the search problem.",been suggested to
2570.txt,Developing a new search strategy is another contribution  of this paper.,contribution  of
2571.txt,"Here, we introduce a new class of search algorithms based on Semi-Definite Programming relaxation.",based on
2572.txt,"We reformulate the feature selection problem as a (0-1)-quadratic integer programming and will  show that it can be relaxed to an SDP problem, which is convex and hence can be solved with efficient algorithms.",it can be relaxed to
2573.txt,"Moreover, there is a discussion about the approximation ratio of the proposed algorithm in subsection 3.2.",there is a discussion about
2574.txt,We show that it usually gives better solutions than greedy algorithms in the sense that its approximate solution is more probable to be closer to the optimal point of the criterion.,be closer to
2575.txt,"However, as the number of features increases, it can rapidly become infeasible.",null
2576.txt,"Hence,many popular search approaches use greedy hill climbing, as an approximation to this NP-hard combinatorial problem.",null
2577.txt,It reaches its maximum value when the dependent variable is perfectly described by the feature set.,described by
2578.txt,Most of the suggested non information-theoretic score functions are not formal set measures  .,null
2579.txt,"Therefore, they cannot assign a score to a set of features but rather to individual features.",but rather to
2580.txt,The relevance of the mutual information measure to misclassification error is supported by the existence of bounds relating the probability of misclassification of the Bayes classifier.,is supported by
2581.txt,"By adapting classification error as a criterion, most standard classification algorithms fail to correctly classify the instances from minority classes in imbalanced datasets.",fail to
2583.txt,"Either way, the features should also be  selected  by  an  algorithm  which is insensitive   with respect to class distributions .",with respect to
2584.txt,"Interestingly, by internally applying unequal class dependent costs, mutual information provides some robustness with respect to class distributions.",with respect to
2585.txt,"Thus, even in an imbalanced case, a mutual information based feature selection algorithm is likely to not overlook the features that represent the minority classes.",is likely to
2586.txt,the concept of the mutual information classifier is investigated.,the concept of
2588.txt,The following example shows this robustness.,null
2589.txt,"Unfortunately, despite the theoretical appeal of the mutual information measure, given a limited amount of data, an accurate estimate of the mutual information would be impossible.",null
2590.txt,it is likely that selected features are highly redundant.,it is likely that
2591.txt,"To overcome this problem, several heuristic corrective terms have been introduced to remove the redundant information and select mutually exclusive features.",null
2592.txt,"Here, it is shown that most of these heuristics are derived from the following expansions of mutual information with respect to X.",it is shown that
2593.txt,From the definition in X it is straightforward to infer this expansion.,it is straightforward to
2594.txt,"In the both proposed expansions X, mutual information terms  with  more  than  two  features represent higher-order interaction  properties.",null
2595.txt,The second expansion for mutual information is based on the chain rule of information.,is based on
2596.txt,The chain rule of information leaves the choice of ordering quite flexible.,null
2597.txt,"In general, it can be expanded over N !","In general, it can be expanded over"
2598.txt,"That is, mRMR is a truncated approximation of mutual information and not a heuristic approximation as suggested in .",That is
2599.txt,While  adding  an  informative  but correlated feature may reduce the score value.,null
2600.txt,"Therefore, it is essential to remove constant features by some preprocessing before using the above criteria for feature selection.",it is essential to
2601.txt,"From our experiments, which we omit because of space constraints, ends to underestimate the mutual information while D1 shows a large overestimation for independent features and a large underestimation   in the presence of dependent features.",because of
2602.txt,"In  general, shows more robustness than.",In  general
2603.txt,The same results can be observed for mRMR which is derived from and MIFS derived from Previous work also arrived to the same results and reported that mRMR performs better and more robustly than MIFS especially when  the feature set  is large.,performs better and more robustly than
2604.txt,"Therefore, in the following sections we use as the truncated approximation.",null
2606.txt,"Note that although in X is not a formal set measure any more, it still can be seen as a score function for sets.",it still can be seen as
2607.txt,"However, it is noteworthy that unlike formal measures, the suggested approximations are no longer monotonic where the monotonicity merely means that a subset of features should not be better than any larger set that contains the very same subset.",it is noteworthy that
2608.txt,"Therefore, as explained in the branch and bound based search strategies can not be applied to them.",as explained in
2609.txt,A very similar approach has been applied .,null
2610.txt,"In the above equation, follows the second assumption by substituting the 2nd order Kirkwood approximation inside the logarithm of the entropy integral and X is an immediate consequence of the first assumption.",null
2611.txt,A search strategy is an algorithm trying to find a feature subset in the feature  subset  space that optimizes the measure function.,trying to
2612.txt,"The wide range of proposed search strategies in the literature can be divided into three categories: 1Exponential complexity methods including exhaustive search, branch and bound based algorithms.",be divided into
2614.txt,Stochastic methods like simulated annealing and genetic algorithms .,null
2615.txt,"Here, we introduce a fourth class of search  strategies which is based on the convex relaxation of the 0-1 integer programming and explore its approximation ratio by establishing a link between SSP and an instance of the maximum-cut problem in graph theory.",is based on
2616.txt,"In the following, we briefly discuss the two popular sequential search methods and continue with the proposed solution: a close to optimal polynomial-time complexity search algorithm and its evaluation on different datasets.",null
2617.txt,"From an information theoretical standpoint, the main disadvantage of the forward selection method is that it only can evaluate the utility of a single feature in the limited context of the previously selected features.",the main disadvantage of
2618.txt,The artificial binary classifier in Figure 1 may illustrate this issue.,null
2619.txt,"Since the information content of each feature  is almost zero, it is highly probable that the forward selection method fails to select them in the presence of some other more informative features.",it is highly probable that
2620.txt,"Contrary to forward selection, backward elimination can evaluate the contribution of a given feature in the context of all other features.",Contrary to
2621.txt,Perhaps this is why it has been frequently reported to show superior performance than forward selection.,it has been frequently reported to
2622.txt,"However, its overemphasis on feature interactions is a double-edged sword and may lead to a sub-optimal solution.",lead to
2623.txt,to sacrifice the individually-informative features in favor of the merely cooperatively-informative features.,in favor of
2624.txt,"As a remedy, several hybrid forward-backward sequential search methods have been proposed.",null
2625.txt,"However, they  all  fail  in  one  way or another and more importantly cannot guarantee the goodness of the solution.",null
2626.txt,"Alternatively, a sequential search method can be  seen  as an approximation of the combinatorial subset selection problem.",be  seen  as an approximation of
2627.txt,"To propose a new approximation method, the underlying combinatorial problem has to be studied.",null
2629.txt,It is straightforward to verify that for any binary .,It is straightforward to
2630.txt,"This problem can simply be transformed to a (-1,1)-quadratic programming problem.",null
2631.txt,The   problem can be solved within an additive error Y of  the  optimum  by  for  example  interior point methods.,for  example
2633.txt,The following three steps summarize the approximation algorithm for.,null
2634.txt,"Ignoring the constant factor 1 in X, the equivalent homogeneous form of X can be written as: The randomized rounding step is a standard procedure to produce  a  binary  solution  from  the  real-valued solution.",null
2635.txt,"Given the solution of the problem above, i.e., y, the optimal feature subset is obtained by .",null
2636.txt,The optimization problem in X can be seen as an instance of the maximum-cut problem   with an additional cardinality constraint.,an instance of
2637.txt,"The two main approaches to solve this combinatorial problem are either to use the linear programming relaxation by linearizing the product of two binary variables, or the semidefinite programming relaxation suggested in X The SDP ing approximation algorithms.",solve this combinatorial problem
2638.txt,The third step is to construct a feasible solution that satisfies the cardinality constraint.,null
2639.txt,"Generally, it can be skipped since in feature selection problems the exact satisfaction of the cardinality constraint is not required.",null
2640.txt,Even more efficient algorithms for low-rank SDP have been suggested claiming that they can solve  problems  with  the  size  up  to  N =30000 in areasonable amount of time  .,null
2641.txt,Here we only use the SDP-NAL for our experiments.,null
2642.txt,it is essential to be able to directly examine it.,it is essential to
2643.txt,"However, since estimating the exact mutual information value in real data is not feasible, it is not possible to directly evaluate the measure function.",it is not possible to
2644.txt,Its  quality  can only be indirectly examined through the final classification performance  .,null
2645.txt,"However, the quality of a measure function is not the only contributor to the classification rate.",null
2646.txt,"Since SSP is an NP-hard problem, the search strategy can only find a local optimal solution.",null
2647.txt,"That is, besides the quality of a measure function, the inaccuracy of the search strategy also contributes to the final classification error.",contributes to
2648.txt,"Thus, in order to draw a conclusion concerning the quality of a measure function",in order to draw a conclusion concerning
2649.txt,"In this section, we compare the accuracy of the proposed method with the traditional backward elimination approach.",compare with
2650.txt,A standard approach to investigate the accuracy of an optimization algorithm is by analyzing how close it gets to the optimal solution.,the accuracy of
2651.txt,"Unfortunately, feature selection is an NP-hard problem and thus achieving the optimal solution to use as reference is only feasible for small-sized problems.",is only feasible for
2654.txt,The approximation ratios of BE and COBRA can be found by linking the SSP to the k-heaviest subgraph problem   in graph theory.,null
2655.txt,"k-HSP is an instance  of the  maxcut problem with a cardinality constraint on the selected subset, that is to say, to determine a subset S of k vertices such that the weight of the subgraph induced by S is maximized  .",that is to say
2656.txt,"From the definition of k-HSP, it is clear that SSP with the criterion X is equivalent to the P -heaviest subgraph problem since it selects the heaviest subset of features with the cardinality P.",it is clear that
2657.txt,Their results are directly applicable to COBRA since both algorithms use the same randomization method   and the randomization  is  the  main  ingredient of their approximation analysis.,null
2658.txt,The  approximation ratio of BE for k-HSP has been investigated in X is a deterministic analysis and their results are also valid for  our case.,null
2659.txt,"The approximation ratios of both algorithms for different values of P , as a function of N  , have been listed in Table 1.",been listed in
2660.txt,"As can be seen, as P  becomes smaller,  the approximation ratio approaches zero yielding the trivial lower bound 0 on the approximate solution.",As can be seen
2661.txt,"However, for larger values of P , the approximation ratio is nontrivial since it is bounded away from zero.",it is bounded
2662.txt,"For all cases shown in the table except the last one, COBRA gives better guarantee bound than BE.",null
2663.txt,"Thus, we may conclude that COBRA is more likely to achieve better approximate solution than BE.",we may conclude that
2664.txt,"In the following section, we will focus on comparing our search algorithm with sequential search methods in conjunction with different measure functions and over different classifiers and datasets.",focus on
2665.txt,The evaluation of a feature selection algorithm is an intrinsically difficult task since there is no direct way to evaluate the goodness of a selection process in general.,there is no direct way to
2666.txt,"Thus, usually a selection algorithm is scored based on the performance of its output, i.e., the selected feature subset, in some specific classification   system.",based on
2667.txt,This kind of evaluation can be referred to as the goal-dependent evaluation.,be referred to
2668.txt,"However, this method obviously cannot evaluate the generalization power of the selection process on different induction algorithms.",null
2669.txt,"To evaluate the generalization strength of a feature selection algorithm, we need a goal-independent evaluation.",null
2670.txt,"Thus, for evaluation of the feature selection algorithms, we propose to compare the algorithms over different datasets with multiple classifiers.",compare with
2671.txt,This method leads to a more classifier-independent evaluation process.,leads to
2672.txt,Some properties of the eight datasets used in the experiments are listed in Table 2.,are listed in
2673.txt,All datasets are available on the UCI machine learning archive .,are available on
2674.txt,These datasets have been widely used in previous feature selection studies.,used in
2675.txt,The goodness of each feature set is evaluated with five classifiers including Support Vector Machine  .,is evaluated with
2676.txt,Estimating P by searching over an admissible set that minimizes the classification error-rate.,null
2677.txt,"Regression Tree , Neural Network and Linear Discriminant Analysis .",null
2678.txt,"To derive the classification accuracies, 10-fold cross-validation is performed except for the NCI, DBW and LNG datasets where leave-one-out cross-validation is used.",except for
2679.txt,"As explained before, filter-based methods consist of two components: A measure function and a search  strategy.",consist of
2680.txt,The measure functions we use for our experiments are mRMR and JMI defined in .,use for
2681.txt,"To unambiguously refer to an algorithm, it is denoted by measure function  search method used in that algorithm.",it is denoted
2682.txt,Friedman test with the corresponding WilcoxonNemenyi post-hoc analysis was used to compare the different algorithms.,was used to
2683.txt,"However, looking at the classification rates even before running the Friedman tests on them reveals a few interesting points which are marked in bold font.",are marked in
2684.txt,"First, on the small size datasets  , mRMR+COBRA consistently shows higher performance than other algorithms.",shows higher performance
2685.txt,From its  definition it  is clear that  for BE  and FS this ratio is always equal to 1.,it  is clear that
2686.txt,"However, because of the randomization step this ratio may widely vary for COBRA.",because of
2687.txt,"That is, COBRA generates quite diverse feature sets.",null
2688.txt,Some of these feature sets have relatively low scores as compared with BE or FS sets.,compared with
2689.txt,"However, since for small datasets the estimated mutual information terms are highly inaccurate, features that rank low with our noisy measure  function may in fact be better for classification.",be better for
2690.txt,The second interesting point is with respect to the Madelon dataset.,with respect to
2691.txt,"As can be seen, mRMR with greedy search algorithms perform poorly on this dataset.",As can be seen
2692.txt,"Several authors have already utilized this dataset to compare their proposed criterion with mRMR and arrived at the conclusion that mRMR cannot handle highly correlated features, as in Madelon dataset.",arrived at the conclusion
2693.txt,"However, surprisingly the  performance of the mRMR+COBRA is as good as JMI on this dataset meaning that it is not the criterion but the search method that has difficulty to deal with highly correlated features.",has difficulty to
2694.txt,"Thus, any conclusion with respect to the quality of a measure has to be drawn carefully since.",with respect to
2695.txt,"To discover the statistically meaningful differences between the algorithms, we applied the Friedman test following with Wilcoxon-Nemenyi post-hoc analysis, as suggested in X, on the average accuracies  .",as suggested in
2696.txt,"Note that since we have 8 datasets, there are 8 independent measurements available for each algorithm.",available for
2697.txt,The results of this test for mRMR based algorithms have been depicted in Figure 2.,been depicted in
2698.txt,"In all box plots, CO stands for COBRA algorithm.",stands for
2699.txt,Each box plot compares a pair of the algorithms.,null
2700.txt,The green box plots represent the existence of a significant difference between the corresponding algorithms.,a significant difference between
2701.txt,The adjusted pvalues for each pair of algorithms have also been reported in Figure 2.,been reported in
2702.txt,"The smaller the p-value, the stronger the evidence against the null hypothesis.",null
2703.txt,"As can be seen, COBRA  shows meaningful superiority over both greedy algorithms.",null
2704.txt,The same test was run for each classifier and its  results  can be found in Figure 3.,its  results  can be found in
2705.txt,"While three of the classifiers show some differences between FS and COBRA,  neither of them reveal any meaningful difference between BE and COBRA.",between and
2706.txt,"At this point, the least we can conclude is that independent of the classification algorithm we choose, it is a good chance that FS performs worse than COBRA.",it is a good chance that
2707.txt,"For JMI, however, the performances of all algorithms are comparable and with only 8 datasets it is difficult to draw any conclusion.",it is difficult to
2708.txt,"Thus, the Wilcoxon-Nemenyi test results for JMI is not shown here because of the lack of space.",because of
2709.txt,"As seen, for NCI the averaged similarity ratio is significantly smaller than 1 while for CNA which is a relatively larger dataset,employ quadratic programing techniques to maximize a score function.",smaller than
2710.txt,"SOSS, however, uses an instance of randomized  rounding to  generate  the  set-membership binary .",an instance of
2711.txt,Comparison of COBRA with the greedy search methods over different datasets.,Comparison with
2712.txt,"For each classifier and combination of search method and measure function, the values in parentheses is the number of selected features and the second value is the classification accuracy.",null
2713.txt,The last column reports the average of the classification accuracies for each algorithm .,the average of
2714.txt,Comparison  of COBRA with QPFS and SOSS over  5 datasets.,Comparison with
2715.txt,Average classification rates and their standard deviations  are reported in the top three rows of the table.,are reported in
2716.txt,"In the next three rows, the computational times in second are shown where the first  value for COBRA and SOSS is for calculating the mutual information matrix and the second value is the time needed to solve the optimization problems.",null
2717.txt,Comparing the search strategies for mRMR measure with the Friedman test and its corresponding post-hoc analysis.,Comparing with
2718.txt,The yaxis is the classification accuracy difference and x-axis indicates the names of the compared algorithms.,null
2719.txt,"values while QPFS ranks the features based on their scores   and therefore, sidesteps the difficulties of generating binary values.",based on
2720.txt,Note that both COBRA and SOSS first need to calculate the mutual  information matrix Q.,both and
2721.txt,The first 3 rows of Table 6 report the average classification accuracies of these three algorithms and the standard deviation of these mean accuracies  .,null
2722.txt,"In the next three rows of the table, the  computational times  of each algorithm for a single run are shown, i.e., the amount of time needed to select a feature set with P features.",null
2723.txt,The reported times for COBRA and SOSS  consist  of  two  values.,consist  of
2724.txt,Comparing the search strategies for mRMR.,null
2725.txt,Results of the post-hoc tests for each classifier.,null
2726.txt,"computational superiority, however, seems to come at the expense of lower classification accuracy.",null
2727.txt,"For large datasets such as IAD, CNA and MAD, the Nystrom approximation used in QPFS to cast the problem into a lower dimensional subspace does not yield a precise enough approximation.",such as
2728.txt,"An important remark to interpret these results is that, for NCI dataset   we first filtered out the features with the low mutual information values with the class label and only kept 2000 informative features.",null
2729.txt,"Thus, the dimension is 2000 and not 9703 as mentioned in Table 2.",as mentioned in
2730.txt,The generalization power of the COBRA algorithm over different classifiers is another important issue to test.,null
2731.txt,"As can be observed in Table 4, the number of selected features varies quite markedly from one classifier to another.",As can be observed in
2732.txt,"However, based on our experiments, the optimum feature set of any of the classifiers, usually   achieves a near-optimal accuracy in conjunction with other classifiers as well.",based on
2733.txt,This is shown in Table 7 for 4 classifiers and 3 datasets.,This is shown in
2734.txt,Table 4 is used here to train other classifiers.,null
2735.txt,"Table 7 lists the accuracies obtained by using the LDA features and the optimal features, repeated from Table 4.",null
2736.txt,"Unlike the CNA and IAD datasets, a significant accuracy reduction can be observed in the case of ARR data which has substantially less training data than  CNA  and  IAD.",in the case of
2737.txt,"It  suggests  that for small size datasets, a feature selection scheme should take the induction algorithm into account since the learning algorithm is sensitive to small changes of the feature set.",It  suggests  that
2738.txt,"A convex based parallel search strategy for feature selection, COBRA, was suggested in this work.",null
2739.txt,Its approximation ratio was derived and compared with the approximation ratio of the backward elimination method.,compared with
2740.txt,It was experimentally shown that COBRA outperforms sequential search methods especially in the case of sparse data.,It was experimentally shown that
2741.txt,"Moreover, we presented two series expansions for mutual information, and showed that most mutual information based score functions in the literature including mRMR and MIFS are truncated approximations of these expansions.",null
2742.txt,"Furthermore, the underlying connection between MIFS and the Kirwood approximation was explored, and it was shown that by adopting the class conditional independence assumption and the Kirkwood approximation for, mutual information reduces to the MIFS criterion.",it was shown that
2743.txt,This work has partly been supported by Swiss National Science Foundation  .,been supported by
2744.txt,"To build large-scale query-by-example image retrieval systems, embedding image features into a binary Hamming space provides great benefits.",null
2745.txt,Supervised hashing aims to map the original features to compact binary codes that are able to preserve label based similarity in the binary Hamming space.,are able to
2746.txt,"Most existing approaches apply a single form of hash function, and an optimization process which is typically deeply coupled to this specific form.",null
2747.txt,"This tight coupling restricts the flexibility of those methods, and can result in complex optimization problems that are difficult to solve.",are difficult to solve
2748.txt,In this work we proffer a flexible yet simple framework that is able to accommodate different types of loss functions and hash functions.,is able to
2749.txt,"The proposed framework allows a number of existing approaches to hashing to be placed in context, and simplifies the development of new problem-specific hashing methods.",null
2750.txt,Our framework decomposes the hashing learning problem into two steps: binary codes   learning and hash function learning.,null
2751.txt,"The first step can typically be formulated as binary quadratic problems, and the second step can be accomplished by training standard binary classifiers.",be accomplished by
2752.txt,"For solving large-scale binary code inference, we show how it is possible to ensure the binary quadratic problems to be submodular  such that an efficient graph cuts can be used.",it is possible to
2753.txt,"we propose to use boosted decision trees as the hash functions, which are nonlinear and highly descriptive and are very fast to train and evaluate.",are very fast to
2754.txt,"In the past a few  years,  an  explosion  in  the  size  of the datasets has been witnessed.",null
2755.txt,"It becomes more and more demanding to cope with  image  datasets  with  tens of millions of images, in terms of both efficient storage and computing.",in terms of
2756.txt,Hashing methods construct a  set of hash functions that map  the  original  features  into compact binary codes.,null
2757.txt,Hashing enables fast nearest neighbor search by using look-up tables or Hamming  distance based ranking.,null
2758.txt,"Moreover, compact binary codes are extremely efficient for large-scale data storage or network transfer.",are extremely efficient for
2759.txt,Loss functions for learning-based hashing are typically defined on the basis of the Hamming distance or Hamming affinity of similar and dissimilar data pairs.,on the basis of
2760.txt,"The common forms of hash functions are linear perceptron functions ,kernel functions , eigenfunctions .",null
2761.txt,The optimization procedure is then coupled with the selected family of hash functions.,coupled with
2762.txt,Different  types  of  hash functions offer a trade-off between testing time and ranking accuracy.,null
2764.txt,This coupling often results in   a highly non-convex optimization problem which can  be very challenging to optimize.,be very challenging to
2765.txt,"As an  example,  the loss functions in  MDSH,  KSH  and  BRE     all  take  a similar form that aims to minimize the difference between the Hamming affinity   of data  pairs and the ground truth.",aims to
2766.txt,"Our framework, however, is able to accommodate  any loss functions which are defined on the Hamming distance/affinity of data pairs.",is able to
2767.txt,We decompose the learning into two steps: the  binary  codes  inference  step  and  the hash function learning step.,null
2768.txt,"We can formulate the optimization problem of any Hamming distance/affinity based loss as binary quadratic problems, hence different types of loss functions are unified into the same optimization problem, which significantly simplifies the optimization.",are unified into
2769.txt,"Many supervised hashing approaches usually require complex optimization for directly learning hash functions, hence they are only tractable for small scale training data.",are only tractable for
2770.txt,"In our approach, we propose an efficient graph cuts based block search algorithm for solving large-scale binary code inference problem, thus our method can be easily trained on large-scale dataset.",null
2771.txt,The recent advance of feature learning   shows that high-dimensional features are essential for achieving good performance.,are essential for
2772.txt,"For example, the dimension of codebook based features usually comes to tens of thousands.",For example
2773.txt,Many existing hashing methods becomes impractically slow when training on large scale high-dimensional features.,null
2774.txt,"Non-linear hash functions, e.g., the kernel hash function employed in KSH, have shown much improved performance over the linear hash function.",have shown much improved performance over
2775.txt,"However, kernel functions could be extremely expensive for both training and testing on high-dimensional features.",null
2776.txt,Here we propose to learn decision  trees  as  hash  functions for non-linear mapping.,null
2777.txt,"Compared to kernel method, decision trees only involve simple comparison operations.",Compared to
2778.txt,The main contributions of this work are as follows.,The main contributions of this work are as follows
2779.txt,We decomposes the learning procedure into two steps: binary codes inference step and hash function learning step.,null
2780.txt,This decomposition simplifies the hash function learning problem into a standard binary classification problem.,null
2781.txt,"An arbitrary classifier, such as linear or kernel SVM, boosting, neural networks.",such as
2782.txt,We are able to incorporate various types of loss functions in a unified manner.,are able to
2783.txt,"We show that any type of loss function   defined on Hamming affinity or Hamming distance, can be equivalently converted into    a standard quadratic function, thus we can solve a standard binary quadratic problem for binary code inference.",solve a problem
2784.txt,"For binary code inference, we propose sub-modular formulations and an efficient graph cuts method   based block search method for solving large-scale inference.",null
2785.txt,"We propose to use decision  trees  as hash functions for supervised hashing, which  can easily deal with a very large number of high dimensional training data and has the desirable non-linear mapping.",deal with
2786.txt,Our method significantly outperforms many existing methods in terms of retrieval accuracy.,in terms of
2787.txt,"For high-dimensional data, our method is also orders of magnitude faster for training.",orders of
2788.txt,Hashing methods aim to preserve some notion of similarity   in the Hamming space.,aim to
2789.txt,"For example, Locality-Sensitive Hashing   generates random linear hash functions to approximate cosine similarity;",For example
2790.txt,Supervised hashing is designed to preserve the label-based similarity .,is designed to
2791.txt,"This might take place, for example, in the case where images from the same category are defined as being semantically similar to each other.",for example
2792.txt,Supervised hashing has received increasingly attention recently such as Supervised Hashing with Kernels.,such as
2793.txt,Various optimization techniques are proposed in existing methods.,are proposed in
2794.txt,"For example, random projection is used in LSH and KLSH The optimization techniques in most existing work tightly coupled with their loss functions and hash functions.",For example
2795.txt,"In contrast, our method break this coupling and easily incorporate with various types of loss functions and hash functions.",In contrast
2796.txt,"A number of existing hash methods have explicitly or implicitly employed two-step optimization based strategies for hash function learning, like Self-Taught Hashing.",A number of existing hash methods
2798.txt,STH   has explicitly employed a two-step learning scheme for optimizing the Laplacian affinity loss.,null
2799.txt,"The Laplacian affinity loss in STH only tries to pull together similar data pairs but does not push away dissimilar data pairs, which may lead to inferior performance  .",lead to
2800.txt,"Moreover, STH employs a spectral method for binary code inference, which usually leads to inferior binary solution due to its loose relaxation.",leads to
2801.txt,"Moreover, the spectral method also does not scale well on large training data.",null
2802.txt,"In contrast, we are able to incorporate with any hamming distance or affinity based loss function, and propose an efficient graph cuts based method for large scale binary code inference.",In contrast
2803.txt,MLH   learns hash function by optimizing a convexconcave upper-bound of a hinge loss function  .,null
2804.txt,"They need to solve a binary code inference problem during optimization, for which they propose a so-called loss-adjusted inference algorithm.",null
2805.txt,Similar technique is also applied in X.,is also applied in
2806.txt,The training of ITQ   also involves a two-step optimization strategy.,null
2807.txt,ITQ iteratively generates the binary code and learns a rotation matrix by minimizing the quantization error to the binary code.,null
2808.txt,They generate the binary code simply by thresholding.,null
2809.txt,The problem of similarity search on  high-dimensional data is also addressed in X.,is also addressed in
2810.txt,Their  method  extends the vocabulary tree based search method by replacing the vocabulary tree as boosted trees.,null
2812.txt,"In contrast, hashing methods are largely different from these inverted index based search methods.",In contrast
2813.txt,Our method is in the vein of supervised hashing methods: mapping data points into binary codes so that the hamming distance on binary codes is able to reflect the label based similarity.,is able to
2814.txt,The loss function in hashing learning for preserving pairwise similarity relations is typically defined on Hamming distance or Hamming affinity of data pairs.,is typically defined on
2815.txt,The Hamming  distance  between  two  binary  codes  is  the number of bits taking different values.,null
2816.txt,"Generally, the formulation of hashing learning is to encourage small Hamming distance for similar data pairs and large for dissimilar data pairs.",null
2817.txt,"Closely related to Hamming distance, the Hamming affinity is calculated by the inner product of two binary codes.",is calculated by
2818.txt,Most existing methods try to directly optimize objective   in order to learn the parameters of hash functions.,in order to
2820.txt,"Moreover, this coupling usually results in highly non-convex problems.",results in
2821.txt,We sequentially solve for one bit at a time conditioning on previous bits.,null
2822.txt,"Hence we solve these two steps alternatively, rather than completely separating these two steps.",rather than
2823.txt,"After solving for one bit, the binary codes is updated by applying the learned hash  function.",is updated by
2824.txt,"In this way,  the  learned  hash  functions  is  able  to  make a feedback to the binary code inference  of  next  bit.",is  able  to
2826.txt,We discuss training different  types  of  hash  functions  in  Sec 6.,null
2828.txt,"With the proposed efficient binary code inference, our method is not only flexible, but also capable for large-scale training.",null
2829.txt,"We refer to our method as FastHash, which is shown in Algorithm 1.",is shown in
2830.txt,These loss functions are evaluated in the Experiments section below.,are evaluated in
2831.txt,It is worth noting that the hinge loss   encourage the Hamming distance of dissimilar pairs at least more than half of the bit length.,It is worth noting that
2832.txt,"This is reasonable because the Hamming distance of dissimilar pairs is only required to be large enough, but not necessary be the maximum value.",This is reasonable because
2833.txt,"In contrast, other regression-like loss functions push the distance of dissimilar pairs to the maximum value, which introduces unnecessary penalties.",In contrast
2834.txt,"As empirically verified in our experiments, the Hinge loss usually performs better.",As empirically verified in
2836.txt,We have shown that the simple spectral method can be used to solve the binary code inference problem in X.,be used to
2837.txt,"However solving eigenvalue problems does  not  scale up to large  training  sets,  and  the  spectral  relaxation is rather loose, hence leading to  inferior results.",leading to
2838.txt,"Here we propose sub-modular formulations and an efficient GraphCut based block search method for solving largescale inference, which is much more efficient than the spectral method and is able to achieve better solutions.",much more efficient than
2839.txt,"Specifically, we first group data points into a number of blocks, then iteratively optimize for these blocks until converge.",optimize for
2840.txt,"For each iteration, we randomly pick ne block, then optimize for the corresponding variables of this block, conditioning on the rest of the variables.",null
2841.txt,"In another word, when optimizing for one block, only those variables which correspond to the data points of the target block will be updated; and for the variables which are not involved in the target block, their values remain unchanged.",null
2842.txt,"Obviously, each block update would strictly decrease the objective.",null
2843.txt,The loss of assigning identical binary values of one bit is smaller than assigning distinct binary values.,smaller than
2844.txt,"As loss functions always encourage two similar data points to have similar binary codes, this condition can be trivially satisfied.",null
2845.txt,As a simple example for the KSH loss.,As a simple example for
2846.txt,Blocks can be constructed in many ways as long as they satisfy the condition in Proposition 2.,be constructed in
2847.txt,A simple greedy method is shown in Algorithm 2.,is shown in
2848.txt,Note that the blocks can overlap and the union of them needs to cover all n variables.,null
2849.txt,The second step is to solve a binary classification problem for learning one hash function.,null
2850.txt,The binary codes obtained in the first step is used as the classification labels.,is used as
2851.txt,Any binary classifiers   and any advanced large-scale training techniques can be directly applied for hash function learning.,applied for
2852.txt,Usually the zero-one loss in the above problem is replaced by some convex surrogate loss.,is replaced by
2853.txt,"For example, when training perceptron hash function:we can train a linear SVM classifier by solving:Any binary classifier can be applied here.",For example
2854.txt,"After learning the hash function for one bit, the binary code is updated by applying the learned hash function.",is updated by
2855.txt,Decision trees could be a good choice for hash functions with nonlinear mapping.,be a good choice for
2856.txt,"Compared to kernel method, decision trees only involve simple comparison operations for evaluation.",Compared to
2857.txt,We apply Adaboost to solve above problem,apply to
2858.txt,"In each boosting iteration, a decision tree as well as its weighting coefficient are learned.",as well as
2859.txt,Every node of a binary decision tree is a  decision  stump.,null
2860.txt,Training  a  stump  is  to  find a feature dimension and threshold that minimizes the weighted classification error.,null
2861.txt,"From this point, we are doing feature selection and hash function learning at the same time.",at the same time
2862.txt,We can easily make use of efficient decision tree learning techniques available in the literature.,make use of
2864.txt,We apply the weight-trimming techniqe described in X.,null
2865.txt,"For one node splitting in tree training, only a random subset of feature dimensions are evaluated for splitting.",are evaluated for
2866.txt,"We here describe the results of comprehensive experiments carried out on several large image datasets in order to evaluate the proposed method in terms of training time, binary encoding time and retrieval performance.",in order to
2867.txt,We compare to a number of recent supervised and unsupervised hashing methods.,compare to
2868.txt,"we perform comparison of using different binary code inference algorithms, various kinds of loss functions and hash functions.",perform comparison of
2869.txt,"Given an query image, the retrieved images in the database is returned by hamming distance ranking based on their binary codes.",based on
2870.txt,"The retrieval quality is measured in 3 different aspects: the precision of top-K  retrieved examples  , mean average precision  and the area under the Precision-Recall curve .",null
2871.txt,Results are reported on 6 large image datasets which cover a wide variety of images.,are reported on
2872.txt,"The dataset CIFAR10 1 contains 60, 000 images in small resolution.",null
2873.txt,"The multilabel datasets IAPRTC12 and ESPGAME   contain around 20, 000 images, and MIRFLICKR is a collection of 25000 images.",is a collection of
2874.txt,"SUN397 contains more than 100, 000 scene images form 397 categories.",more than
2875.txt,The large dataset ILSVRC2012 contains roughly 1.2 million images of 1000 categories from ImageNet.,null
2876.txt,"For the multi-class datasets: CIFAR10, SUN397 and ILSVRC2012, the ground truth pairwise similarity is defined as multi-class label agreement.",is defined as
2877.txt,"For multi-label datasets: IAPRTC12, ESPGAME and MIRFLICKR, of which the keyword   annotation are provided in X, two images are treated as semantically similar if they are annotated with at lease 2 identical keywords.",are provided in
2879.txt,"Following the conventional protocol in X for hashing method evaluation, a large portion of the dataset is allocated as an image database for training and retrieval and the rest is put aside for test queries.",null
2880.txt,"Specifically, for CIFAR10, IAPRTC12, ESPGAME and MIRFLICKER, the training data of the the provided split are used as image database and the test data are used   as test queries.",are used as
2881.txt,The splits for SUN397 and ILSVRC2012 are described in their corresponding sections.,are described in
2882.txt,"we  employ  K-SVD for codebook   learning with a codebook size of 800, soft-thresholding for patch encoding and spatial pooling of 3 levels, which results 11200-dimensional features.",null
2883.txt,"For further evaluation, we increase the codebook size to 1600 to generate 22400-dimensional features.",null
2884.txt,We also extract the low-dimensional GIST features for evaluation.,null
2885.txt,"For the dataset ILSVRC2012, we extract the convolution neural network features with 4096 dimensions, which is described in details in the corresponding section.",is described in
2886.txt,"If not specifically specified, we use the following settings for our method: using the KSH loss function, the proposed block GraphCut algorithm in Step-1, and the decision tree hash function in Step-2.",null
2887.txt,"The tree depth is set to 4, and the number of boosting iterations is 200.",null
2888.txt,Different settings  of hash functions or loss functions will be evaluated in the later sections.,be evaluated in
2889.txt,"For comparing methods, we follow the original papers for parameter setting.",null
2890.txt,"If not specified, 64bit binary codes are generated for evaluation.",are generated for
2891.txt,KSH   has been shown to outperform many state-of-the-art comparators.,been shown to
2892.txt,Here we evaluate our method using the KSH loss and compare against the original KSH method on high-dimensional codebook features.,compare against
2893.txt,KSH employs a simple kernel technique by predefining a set of support vectors then learning linear weightings for each hash function.,null
2894.txt,"For our method, we use boosted decision  trees  as  hash  functions.",null
2895.txt,"KSH  is  trained  on   a sampled set of 5000 examples, and the number of support vectors for KSH is varied from 300 to 3000.",null
2896.txt,"The results are summarized in Table 1, which shows that increasing the number of support vectors consistently improves the retrieval precision of KSH.",null
2897.txt,"However, even on this small training set, including more support vectors will dramatically increase the training time and binary encoding time of KSH.",null
2898.txt,We have run our FastHash both on the same sampled training set and the whole training set   in order to show that our method can be efficiently trained on the whole dataset.,in order to
2899.txt,Our FastHash and FastHash-Full outperform KSH by a large margin in terms of both training speed and retrieval precision.,in terms of
2900.txt,It also shows that the decision tree hash  functions  in  FastHash  are  much  more  efficient for testing than the kernel  function  in KSH.,are  much  more  efficient for
2901.txt,"FastHash is orders of magnitude faster than KSH on training, and thus much better suited to large training sets and high-dimensional data.",much better suited to
2902.txt,We also show the precision curves of top-K retrieved examples in Figure 2.,null
2903.txt,The number after "KSH" is the number of support vectors.,null
2904.txt,"Besides high-dimensional features, we also compare with KSH on the low-dimensional GIST feature, and FastHash also significantly performs better; see Table 2 for details.",compare with
2905.txt,Some retrieval examples of our method are shown in Figure 1.,are shown in
2906.txt,We evaluate our method both on the the low-dimensional  GIST features and the high-dimensional  codebook features.,null
2907.txt,"Several state-of-the-art supervised methods are included in this compar-ison: KSH  , Supervised Self-Taught Hashing ,and Semi-supervised Hashing .",null
2908.txt,Boosted decision tree hash functions are used in our method.,null
2909.txt,Comparing methods are trained on a sampled training set .,are trained on
2910.txt,The result is presented in Table 2.,is presented in
2911.txt,The codebook features consistently show better result than GIST features.,null
2912.txt,The results for codebook features is also plotted in Figure 3.,is also plotted in
2913.txt,Results show that comparing methods can be efficiently trained on the GIST features.,null
2914.txt,"However, when applied on high dimensional features, even on a small training set (5000), their training time dramatically increase.",null
2915.txt,It would be very difficult to train these methods on the whole training set.,It would be very difficult to
2916.txt,The training  time of KSH mainly depends on the number of support vectors .,depends on
2917.txt,We  run  our  FastHash  on the same sampled training set and the whole training set.,null
2918.txt,Results show that FastHash can be efficiently trained on the whole dataset.,Results show that
2919.txt,FastHash significantly outperform others both in GIST and codebook features.,both and
2920.txt,A possible way to reduce the training cost on highdimensional data is to apply dimension reduction.,null
2921.txt,"For comparing methods: KSH, SPLH and STHs, here we reduce the original 11200-dimensional codebook features to 500 dimensions by applying PCA.",null
2922.txt,We  also  compare to CCA+ITQ which combines ITQ with the supervised dimensional reduction.,compare to
2923.txt,Our FastHash still use the original high-dimensional features.,null
2924.txt,The result is summarized in Table 3.,is summarized in
2925.txt,"After dimension reduction, most comparing methods can be trained on the whole training set within 24 hours.",null
2926.txt,"For memory usage, many of comparing methods require a large amount of memory for large matrix multiplication.",a large amount of
2927.txt,"In contrast, the decision tree learning in our method only involves simple comparison operations on quantized feature data, thus FastHash only consumes less than 7GB for training.",In contrast
2928.txt,The large dataset ILSVRC2012 contains more than 1.2 million images from ImageNet  .,more than
2929.txt,We use the provided training set as the database  and the validation set as test queries  .,null
2930.txt,Convolution neural networks  have shown the best classification performance on the this dataset.,shown the best classification performance on
2931.txt,"As described in X, the neuron activation values of internal layers of CNNs can be used as features.",As described in
2932.txt,"By using the code of Caffe which implements the CNN architecture in X, we extract 4096-dimensional features from the the seventh layer of the CNN.",null
2933.txt,We compare with a number of supervised and unsupervised methods.,compare with
2934.txt,The  depth for decision trees is set to 16.,null
2935.txt,The smallest 2% data weightings are trimmed for decision tree learning.,null
2936.txt,Most comparing supervised methods become intractable on the full training set.,become intractable on
2937.txt,"In contrast, our method can be efficiently trained using the whole  training set.",In contrast
2938.txt,"For comparison, we also construct a smaller dataset by sampling 50 classes from ILSVRC2012.",null
2939.txt,"It contains 25, 000 training images and 2500 testing images.",null
2940.txt,Results of ImageNet-50 and the full ILSVRC2012 are presented in Table 9.,are presented in
2941.txt,Our FastHash performs significantly better than others.,better than
2942.txt,The retrieval performance of 128 bits on the full ILSVRC2012 is plotted in Figure 8.,is plotted in
2943.txt,"Since binary codes have very small storage cost or network transfer cost, image features can be compressed to binary codes by apply hashing methods.",null
2944.txt,Here we evaluate the image classification performance of using binary codes as features on the dataset ILSVRC2012.,null
2945.txt,Hashing methods are trained on the CNN features.,are trained on
2946.txt,We apply two types of classification methods: the K nearest neighbor   classifier and the one-vs-all linear SVM classifier.,null
2947.txt,KNN classification is performed by majority voting of top-K retrieved neighbors with smallest hamming distances.,is performed by
2948.txt,Results are shown in Table 10.,are shown in
2949.txt,The CNN features used here are extracted on the center crops of images by using Caffe  .,are extracted on
2950.txt,We also report the results of CNN methods which have the state-of-the-art results of this dataset.,null
2951.txt,"As shown in Table  10, there performance gap is around 8% between the error rate of our hashing method and that of Caffe with similar settings.",As shown in
2952.txt,"However, 128- bit binary codes in our methods take up around 1000 times less storage than the CNN features with 4096- dimensional float values.",null
2953.txt,It shows that our method is able to perform effective binary compression without large performance loss.,It shows that our method is able to
2955.txt,Conventional learning-based methods for segmenting prostate in CT images ignore the relations among the low-level features by assuming all these features are independent.,null
2956.txt,"Also, their feature selection steps usually neglect the image appearance changes in different local regions in CT images.",null
2957.txt,"To this end, we present a novel semi-automatic learning-based prostate segmentation method in this article.",null
2958.txt,"For segmenting the prostate in a certain treatment image, the radiation oncologist will be first asked to take a few seconds to manually specify the first and last slices of the prostate.",take a few seconds to
2959.txt,"Then, prostate is segmented with the following two steps: Estimation of 3-D prostate-likelihood map to predict the likelihood of each voxel being prostate by employing the coupled feature representation, and the proposed Spatial-COnstrained Transductive LassO  .",is segmented with
2961.txt,"The experimental result shows that the proposed method outperforms the state-of-the-art methods in a real-world prostate CT dataset, consisting of 24 patients with totally 330 images.",The experimental result shows that
2962.txt,"Moreover, our method is also clinically feasible, since the segmentation performance can be improved by just requiring the radiation oncologist to spend only a few seconds for manual specification of ending slices in the current treatment CT image.",be improved by
2963.txt,"T is estimated that prostate cancer possibly caused 233,000 new cases and 29,480 deaths for U.S. male in 2014, according to the data reported from National Cancer Institute1.",according to
2964.txt,Prostate cancer is thus regarded as one of the most leading reasons for cancer-caused death.,regarded as
2965.txt,"Recently, CT image guided radiotherapy for prostate cancer treatment has raised lots of research interests, due to its ability in better guiding the delivery of radiation to the prostate .",due to
2966.txt,"During the CT image guided radiotherapy, a sequence of CT scans will be acquired from a patient in the planning and treatment days  .",be acquired from
2967.txt,"A CT scan acquired in the planning day is called the planning image, and the scans acquired in the subsequent treatment days are called the treatment images.",null
2968.txt,"the key issue is to accurately determine the boundary of prostate in the images acquired from each treatment day, which is currently often done by the radiation oncologist in a slice-by-slice manner.",the key issue is to
2970.txt,Previous studies show that the major challenging issues to accurately segment prostate in the CT images include: the boundary between prostate region and background   region is usually unclear due to the low contrast in the CT images.,due to
2971.txt,We can observe the large prostate motion even after aligning the two scans based on their bony structures.,based on
2972.txt,This indicates the large prostate motion relative to the bones.,null
2974.txt,"In recent years, several prostate segmentation methods have  been  developed  for  CT  image  guided radiotherapy, with the common goal of segmenting prostate  in the current treatment image by borrowing the knowledge learned from the planning and previous treatment images.",with the common goal of
2975.txt,"In this article, we propose a novel semiautomatic learning-based prostate segmentation method for CT image guided radiotherapy.",null
2976.txt,Previous learning-based methods   often conduct the feature selection and the subsequent prostate-likelihood estimation jointly for all voxels in the image.,null
2977.txt,"However, different local regions may prefer choosing different features to better discriminate between their respective prostate and nonprostate voxels, as indicated by a typical example shown in Fig.2.",as indicated by a typical example shown in
2978.txt,"In this example, we extracted features  for  three  different  local regions, and then apply Lasso   for selection of their respective features.",null
2979.txt,"we can see that the  selected features from three local regions are completely different, demonstrating the necessity of selecting the respective features for each local region.",we can see that
2980.txt,"In this article, we design a novel local learning strategy: partition each 2-D slice into several nonoverlapping local blocks, and then select the respective local features to predict the prostate-likelihood for each local block.",null
2981.txt,"This will be achieved by our proposed Spatial-COnstrained Transductive LassO  and Support Vector Regression , respectively.",This will be achieved by
2982.txt,"Compared with the global learning strategy , the local learning strategy can help preserve the local information, which guides us to predict the more accurate prostate boundary.",Compared with
2983.txt,"Also, previous methods often assume all the extracted features are independent during the prostate segmentation.",null
2984.txt,"However, it is often believed that different features extracted from both prostate and nonprostate regions are actually not isolated, but connected with each others in some way.",it is often believed that
2985.txt,"Therefore, the independency assumption  for the features used  in  the  previous  studies  might  be  too strict.",null
2986.txt,"In this article, we consider to relax independency assumption by introducing the coupled feature representation as inspired by X.",as inspired by
2987.txt,The major difference between the previous learning-based methods and our proposed method can be observed from Fig.3.,The major difference between
2988.txt,"Note that, in our method, before automatic segmentation of prostate from the current treatment CT image, radiation oncologist needs to spend a few seconds to specify the first and last slices of prostate in the CT image.",null
2989.txt,"By spending this little manual time, the segmentation results can be significantly improved, compared with the fully automatic methods  .",compared with
2990.txt,The contributions of our proposed method can be summarized into the following three folds:A novel semi-automatic prostate segmentation method in CT images is proposed.,The contributions of our proposed method
2991.txt,"For segmenting the current treatment image, the patient-specific information is learned from previous planning and treatment images.",null
2993.txt,"It is excepted that the prostate segmen tation performance can be further boosted by incorporating manual specification as reference, thus finally achieving better treatment.",It is excepted that
2994.txt,"With the help of coupled features, the original feature matrix can be complemented by analyzing the intra and inter-coupled interactions.",With the help of
2995.txt,"The experimental results also validate the efficacy of coupled features, compared with original features, for better feature representation by capturing the coupled interaction information.",compared with
2996.txt,SCOTO can successfully select the discriminative features jointly for different local regions   to guide better prostate-likelihood estimation.,null
2997.txt,"Also, a feasible iterative projected gradient descent based strategy is utilized for solving SCOTO.",is utilized for
2998.txt,A preliminary version of this work was presented in  .,was presented in
3001.txt,"In  Section  II, we briefly introduce the related works for prostate segmentation developed in recent years.",null
3002.txt,"The framework and image preprocessing of the proposed method are described in Section III and Section IV, respectively.",are described in
3003.txt,"In Section V, we introduce the usage of coupled feature representation, and propose our new feature selection algorithm, SCOTO, for prostate-likelihood estimation.",null
3004.txt,"In Section VI, the multiatlases based label fusion for final segmentation is discussed.",null
3005.txt,Experimental results and performance comparisons with the competing methods are presented in Section VII.,are presented in
3006.txt,Several  related  issues  are also discussed in Section VIII.,are also discussed in
3007.txt,"The previous methods on prostate segmentation for CT image guided radiotherapy can be roughly  categorized  into  three  classes: deformable-model-based, registration-based, and learning-based methods.",null
3008.txt,"In deformable-model-based methods, the prostate shapes learned from the planning and previous treatment images are first used to initialize the deformable model, and then specific optimization strategies are developed to guide prostate segmentation.",are developed to
3011.txt,"Feng segmented the prostate by using deformable model, which integrates the gradient profile features and the probability distribution function features.",null
3013.txt,"However, good performance largely requires good quality of deformable model initialization.",requires good quality of
3014.txt,"In the case where large prostate motion happens, obtaining a good initialization for deformable model becomes a very challenging task.",becomes a very challenging task
3015.txt,"In registration-based methods  , the planning and previous treatment images are warped onto the current treatment image, and then their respective segmentation images are similarly warped and further combined to obtain the final segmentation of the current treatment image.",null
3016.txt,Chen designed a strategy that aligns the planning image to treatment image by meshless point set modeling and 3D non-rigid registration.,null
3019.txt,"Liao and Shen proposed to use  anatomical  feature selection and an online updating mechanism to integrate both population and patient-specific information, in order to guide the accurate prostate registration.",in order to
3020.txt,"Also, Liao and Shen combined the patch-based feature representation and hierarchical sparse label propagation in order to automatically localize the prostate.",in order to
3021.txt,Several experimental results have demonstrated the robustness and effectiveness of the registration-based methods for prostate segmentation.,null
3022.txt,"However, the segmentation accuracy is limited in the case with inconsistent image appearance changes in CT images.",null
3023.txt,"The last class of methods, learning-based methods  , which attracted lots of interests recently, first use the machine learning techniques to predict the prostate-likelihood map, and then segment the prostate in the estimated prostate-likelihood map.",attracted lots of interests
3025.txt,Shi presented a method by modeling the prostate-likelihood estimation problem as a transductive learning task.,null
3026.txt,Our proposed method belongs to this class of learningbased segmentation methods.,belongs to
3027.txt,"It is worth noting that, besides segmenting prostate from CT images, other segmentation methods are also developed for segmenting prostate from other imaging modalities such as Magnetic Resonance and ultrasound images.",It is worth noting that
3028.txt,"However, these methods cannot be directly borrowed to segment prostate from CT images due to the aforementioned challenges.",due to
3029.txt,"As a learning-based segmentation method, our proposed method mainly consists of two steps:   prostate-likelihood estimation step and  multi-atlases based label fusion step.",consists of
3030.txt,"In the prostate-likelihood estimation step: firstly, all previous and current treatment images are rigidly aligned to the planning image of the same patient based on the pelvic bone structures, for removing the whole-body patient motion that is irrelevant to prostate segmentation.",is irrelevant to
3031.txt,"Then, we extract the ROI regions according to the prostate center in the planning image.",according to
3032.txt,"Secondly, for the current treatment image, radiation oncologist is asked to specify the first and last slices of the prostate.",null
3033.txt,"By combining the voxels in the specified slices of the current treatment image with the voxels sampled from the planning and previous treatment images, we can extract 2-D low-level features for all these voxels separately from their original CT images.",null
3034.txt,"Then, each 2-D slice will be partitioned into several nonoverlapping blocks.",be partitioned into
3036.txt,"Finally, the predicted 2-D prostate-likelihood map of each individual slice will be merged into a 3-D prostate-likelihood map according to the order of their original slices.",according to
3037.txt,"In multi-atlases based label fusion step, to make full use of prostate shape information, those manually segmented prostate images in both planning and previous treatment images of the same patient will be rigidly aligned to the estimated 3-D prostate-likelihood map of the current treatment image.",make full use of
3038.txt,"Then, majority voting will be applied to  fuse the labels from different aligned images, and obtain the final segmentation result.",be applied to
3039.txt,The framework of the proposed method is shown in Fig.4.,The framework of the proposed method is shown in
3040.txt,"Before discussing the details of the prostate-likelihood estimation step and multi-atlases based label fusion step, we will first introduce the notations used in the following parts, and present the implementation details of the alignment, ROI extraction, manual interaction, feature representation, as well as strategy for sampling the training voxels.",as well as
3041.txt,"For each patient, we have one planning image, several previous treatment images with their respective manual prostate segmentations by radiation oncologist offline, and also the treatment image scanned in the current  treatment  day,  which  needs  to  be  segmented  by  the proposed method.",null
3042.txt,"The planning image and its corresponding manual segmentation result are denoted as Ip and Gp, respectively.",are denoted as
3043.txt,"The nth treatment image, which is the current treatment image, is denoted as In.",is denoted as
3046.txt,"Alignment to the Planning Image: During the scanning process of CT image guided radiotherapy at different treatment days, the whole-body rigid motion is often inevitable, which is irrelevant to the prostate motion.",is irrelevant to
3047.txt,"To eliminate the influence, we utilize the pelvic bone structure based alignment, which has been already validated in X.",has been already validated in
3048.txt,"Detailed steps include: pelvic bone segmentation, and rigid alignment.",null
3049.txt,"we adopt a thresholding technique to first segment the pelvic bone structure as reference for the subsequent alignment, which is similar to X.",is similar to
3050.txt,"Specifically, rigid alignment algorithm implemented in FLIRT toolkit is used to perform rigid registration on the segmented pelvic bones.",is used to
3051.txt,"That is, each treatment image will be rigidly aligned to the planning image with respect to their segmented pelvic bone structures.",with respect to
3052.txt,"Instead of asking radiation oncologist for multiple interactions during the segmentation, we only ask for manual specification of the first and last slices of the prostate along the z-axis.",Instead of
3053.txt,It is noteworthy that the radiation oncologist's manual specification is carried after ROI extraction.,It is noteworthy that
3054.txt,"Therefore, it will take only less than 10 seconds for this manual step.",it will take
3055.txt,"In the experiments, we will also show that the segmentation results can be largely improved by asking radiation oncologist to spend such a little interaction time, which is also clinically feasible.",we will also show that
3056.txt,"For the original feature representation, three different kinds of low-level features are extracted from 2-D slice, which include 9-dimensional histogram of oriented gradient.",null
3057.txt,LBP is calculated with the radius value 2 and the neighboring voxel number 8.,is calculated with
3058.txt,Haar is calculated by convolving the 14 multi-resolution wavelet basis functions with the input image similar to X.,similar to
3059.txt,"Since the confusing voxels are frequently lying on the boundary of the prostate region, it is reasonable to sample relatively more voxels around the boundary.",it is reasonable to
3060.txt,"That is, the boundary voxels will have higher probability to be sampled, as illustrated in Fig.5.",as illustrated in
3061.txt,Similar strategy for sampling the training voxels was also used in literature.,used in
3062.txt,"We first discuss the details of our coupled feature representation, and then formulate the spatial-constrained transductive feature selection task as the proposed SCOTO.",null
3063.txt,"Also, we present a feasible optimization strategy for solving SCOTO, whose joint convexity is theoretically guaranteed.",present a feasible optimization strategy for
3064.txt,"Finally, SVR is employed to estimate the prostate-likelihood for each block.",is employed to
3065.txt,"Basically, it is always believed that different voxels of both prostate and non-prostate regions are not isolated, but anatomically connected with each other.",it is always believed that
3066.txt,"Thus, the low-level original features extracted from these voxels are also not independent, but related with each other in a certain way.",null
3067.txt,"However, previous learning-based prostate segmentation methods simply use the low-level original features without considering their relations.",null
3068.txt,"In this article, we first attempt to introduce the coupled feature representation to the prostate segmentation inspired by X.",attempt to
3070.txt,"Thus, the coupled features can represent the voxels in a more meaningful way by capturing both the linear and nonlinear combination of the low-level original features.",in a more meaningful way
3071.txt,It is always excepted that increasing the dimensionality of features can boost the representative ability  .,It is always excepted that
3072.txt,"Here, each feature can be extended to new features, by calculating its power with different orders, to complement the feature matrix, aiming to incorporate both linear and nonlinear information.",aiming to
3073.txt,"we consider adopting the iterative projected gradient descent method  for optimization, which separates the sub-problem into the smoothness term and the non-smoothness term, and solves them iteratively until convergence.",null
3074.txt,"Therefore, the Eq can be separated into the smoothness term and the non-smoothness term.",be separated into
3075.txt,"Here, we introduce the technical details of the multi-atlases based label fusion, which generates the final binary segmentation results according to the prostate-likelihood map   obtained in the previous step.",according to
3077.txt,"To make full use of all the shape information  from the planning and previous treatment images for guiding the segmentation, we adopt the multi-atlases based label fusion with the following steps.",make full use of
3078.txt,The final binary prostate segmentation.,null
3079.txt,"In the experimental evaluation, we will validate the advantages of the multi-atlases based label fusion step in our whole segmentation method.",null
3080.txt,Now we present the qualitative and quantitative evaluation to validate the advantages of the proposed method.,the advantages of
3082.txt,"Then, we evaluate the proposed SCOTO and compare it with several popular feature selection methods.",compare with
3083.txt,"Also, we extensively present the efficacy of the multi-atlases based label fusion as the second step in our whole method.",the efficacy of
3084.txt,"Moreover, we will also discuss the performance under  two  particular  cases, when inaccurate manual specification happens, and when patients are with large irregular prostate motion.",null
3085.txt,"Finally, we compare the proposed method with several state-of-the-art methods, and also report additional quantitative results.",compare with
3086.txt,"Please note that, to better distinguish the previous method using the original features and the current novel method using the coupled features, we denote the previous method as OF+SCOTO, and the current novel method as CF+SCOTO, in the following sections.",null
3087.txt,"All CT images of patients are manually segmented by an experienced radiation oncologist, which we used as ground-truth for quantitative evaluation in the following experiments.",null
3088.txt,"For each patient, the first 3 images are used as training images, from which the training voxels are sampled, along with the available segmentation ground-truths.",along with
3089.txt,so manual segmentation of the first three scans can still be considered as a minor effort for radiation oncologist.,be considered as
3091.txt,The CD means the Euclidean distance between the central locations of the manual segmentation result and the predicted segmentation result.,null
3092.txt,"Since prostate CT-images are 3-D, the CD along 3 directions, including   the lateral, anterior-posterior , and superior-inferior directions, need to be calculated.",null
3093.txt,"Please note that, in the superior-inferior direction, the CD is calculated as 3 times  of the obtained value since the inter-slice voxel size is 3 mm, which is approximately 3 times of that in the x-axis and y-axis.",null
3094.txt,Both choosing too large block size and choosing too small block size are impracticable.,null
3095.txt,"Too large block size will ignore the variations of appearance along the prostate boundary, while too small block size will increase the unnecessary computational burden.",null
3096.txt,"However, it is still an open problem on how  to automatically choose the best block size, which we will study in our future work.",it is still an open problem on
3097.txt,"Also, we illustrate three typical prostate-likelihood maps where OF+SCOTO cannot achieve good performance in our pervious work.",achieve good performance in
3098.txt,"In Table III, HoG indicates the percentage of original HoG features in all the selected  features ,  while HoG-c indicates the percentage of coupled  HoG  features  within  expanded  matrix in  all  the  selected  features.",the percentage of
3099.txt,"We can observe that, by relaxing the feature independency assumption, certain coupled features will be further selected by replacing the original features.",We can observe that
3100.txt,"Also, it is worth noting that, for LBP features, which are seldom selected using the original feature representation.",it is worth noting that
3101.txt,"Specifically, SCOTO belongs to the block-level feature selection methods, which simultaneously selects the features within different local regions.",belongs to
3103.txt,"For all these methods, the parameters are experimentally set using leaveone-out cross-validation.",null
3104.txt,It is noteworthy that the same multi-atlases based label fusion is adopted for all the methods.,It is noteworthy that
3106.txt,We found the proposed SCOTO can achieve superior performance over the related methods.,achieve superior performance over
3107.txt,"Also, compared with these feature selection methods on the Dice ratios, our proposed OF+SCOTO and CF+SCOTO are statistically better than their results through calculating the corresponding pvalues  .",compared with
3108.txt,"Since the automatic approach for selecting the best block size of SCOTO is not available, we investigate the segmentation performance with respect to the change of predefined block size.",with respect to
3111.txt,"We first generate the slice-wise segmentation result for each individual slice using the corresponding slice-wise prostate-likelihood map, and then combine the slice-wise segmentation results for final prostate segmentation  .",null
3112.txt,It is noteworthy that all the three strategies use the same prostate-likelihood map .,It is noteworthy that
3113.txt,"Fig.12 gives mean Dice ratios of all 24 patients among three strategies, which validates that the multi-atlases based label fusion outperforms the two related methods, for both the original  and coupled features.",null
3114.txt,"Fig.12 gives mean Dice ratios of all 24 patients among three strategies, which validates that the multi-atlases based label fusion outperforms the two related methods.",null
3117.txt,Although the prostate part can be roughly determined according to the prostate-likelihood map.,according to
3119.txt,"Our method, multi-atlases based label fusion, takes the advantages of the patientspecific prostate shape information to guide better segmentation.",takes the advantages of
3120.txt,"The manual specification, which needs only a few seconds, can guide better prostate segmentation.",null
3121.txt,"However, inaccurate manual specification sometimes happens due to various reasons  , especially for the inexperienced radiation oncologists.",due to
3122.txt,"In this subsection, we will experimentally investigate the sensitivity of our method with respect to inaccurate manual specification.",with respect to
3124.txt,"In all the 24 patients,it is found that patients 3, 10 and 15 have large prostate motions according to the calculated standard deviation of prostate centers in the planning and treatment images, which can be found by referring to Fig.15.",it is found that
3125.txt,"By applying the proposed method to patients 3, 10 and 15, the obtained mean Dice ratio are 0.909, 0.928, 0.946 by OF+SCOTO, and 0.920, 0.934, 0.946 by CF+SCOTO, respectively, which are better than the corresponding results reported in X.",better than
3126.txt,The comparisons are also listed in Fig.16.,are also listed in
3127.txt,These results show the effectiveness of the proposed method in incorporating the manual specification from radiation oncologist when large irregular motion occurs in the prostate regions.,the effectiveness of
3128.txt,"We now further compare the proposed method with several stateof-the-art methods for prostate segmentation in CT images developed in recent years, which include deformable-model based methods  , registration-based methods , and learning-based method.",compare with
3129.txt,The best results reported in the corresponding literatures are adopted for comparison in this section.,are adopted for
3130.txt,The comparisons among different methods are listed in Table.IV.,are listed in
3131.txt,The results obtained not on the same CT dataset are listed separately.,null
3132.txt,"Evaluated metrics include mean Dice ratio, mean ASD, and median TPF  .",null
3134.txt,"For X, all the 24 patients are evaluated, which is the same with ours, so we call the 24 patients CT dataset as CT dataset 1.",is the same with
3135.txt,"Also, two different subsets of the 24 patients are selected in X, which are called as CT dataset 2 and CT dataset 3, respectively.",are selected in
3138.txt,"These results demonstrated that the proposed methods outperform the related methods in terms of higher mean Dice ratio, median TPF, and mean ASD.",These results demonstrated that
3139.txt,"Also, we can observe that learning-based segmentation methods are generally better than non-learning-based ones, since voxel-level regression/classification might be more useful to discover the local detail information, e.g., the slight boundary change in different treatment days.",be more useful to
3140.txt,We also report the box-and-whisker diagram of Dice ratio in  Fig.17 for each individual patient.,null
3141.txt,"For statistical perspective, quartile- representation is adopted, in which five horizontal lines   mean the min, 25% percentile, median, 75% percentile, and the max value, respectively.",null
3142.txt,"Fig.17 shows the result  of OF+SCOTO, and Fig.17 shows the result of CF+SCOTO.",the result  of
3143.txt,"we use the red curves to denote the manual segmentation results by the radiation oncologist, and the yellow curves to denote the segmentation results by the proposed methods.",null
3144.txt,It can be observed that the predicted prostate boundaries are very close to the boundaries delineated by the radiation oncologist.,It can be observed that
3145.txt,"Also the proposed method can accurately separate the prostate regions and background even in the base and apex slices as shown in Fig.18,which are usually considered very difficult to segment.",as shown in
3146.txt,Our method can be extended to many similar segmentation tasks as detailed below.,be extended to
3147.txt,"For feature representation using coupled features, it can be directly extended to the similar segmentation applications,of which features are usually not i.i.d., but related with others.",it can be directly extended to
3148.txt,"For SCOTO, as a feature selection method, it can be used in many applications, especially for medical image segmentation, of which the local regions are usually spatially connected.",it can be used in
3149.txt,"For multi-atlases based label fusion, it can be also utilized in many  related segmentation tasks, of which the previous scanned data with segmentation results can be borrowed as references for segmentation of future images.",it can be also utilized in
3150.txt,it is known that many TV methods have already been successfully used in many tasks .,it is known that
3151.txt,"However, the major difference between SCOTO and TV methods is that, most of TV methods currently focus on the 1-D task , while our problem focuses on the 2-D task.",focus on
3152.txt,"Also, according to very recent study, it shows that 2-D TV can obtain superior results but always with very high complexity.",according to
3153.txt,"On the other hand, as for the relations between SCOTO and overlapping group sparsity methods.",On the other hand
3154.txt,"The major challenge is that, due to large appearance change and irregular prostate motion, it is very difficult and even infeasible to design specific grouping methods for each individual slice.",it is very difficult
3155.txt,"our method can be treated as an overlapping group sparsity methods, with very simple and general assumption , and can be adopted to other similar tasks.",be treated as
3156.txt,"Finally, it is very challenging to develop automatic methods for localizing the start and ending slices of prostate region according  to our empirical analysis and experimental evaluation, as explained below.",it is very challenging to
3158.txt,"Basically, for the same patient, the start and ending slices of the prostate could change up to 10 voxel  across different treatment days even after rigid registration with pelvic bone structures.",null
3159.txt,Non-prostate and prostate regions   are extremely similar in the start  slices.,are extremely similar in
3160.txt,Many state-of- the-art  methods  cannot  perform  well  in  those  regions.,perform  well  in
3163.txt,"Thus, it is hard to predict the start and ending slices with only 3-5 training images, especially for the case that CT images have poor tissue contrast.",it is hard to
3164.txt,"Therefore, automatic localization of the start and ending slices is commonly considered as the most difficult part in prostate segmentation.",considered as
3165.txt,"In this article, our goal is mainly to incorporate the radiation to determine the most difficult part, and then utilize our method for the subsequent segmentation.",our goal is mainly to
3166.txt,"In this article, we have presented a novel semi-automatic learning method for prostate segmentation in CT images during the image-guided radiotherapy.",null
3167.txt,Previous methods directly employ the low-level features without considering the relations of these features.,null
3168.txt,"Also, previous methods usually ignore the image appearance changing in different local regions of CT images during the feature selection step.",null
3170.txt,"In our method, we first ask the radiation oncologist to spend a   few seconds for the simple specification of ending slices on the current treatment image.",null
3171.txt,The coupled feature representation is then employed by using both the intra- and inter-coupling information from low-level original features.,employed by
3172.txt,"Our proposed SCOTO is further used to simultaneously select the discriminative features for different local regions, for helping estimate the prostate-likelihood  map.",used to
3173.txt,"Finally, the multi-atlases based label fusion method is used to combine the segmentation results of the planning and previous treatment images for final segmentation.",is used to
3174.txt,"We extensively evaluate our method on a CT prostate dataset, which consists of 24 patients with totally 330 images, all along with manual delineation results by the experienced radiation oncologist  .",consists of
3175.txt,Experimental results show that our proposed method not only obtains superior segmentation performance compared with the state-of-the-art methods.,Experimental results show that
3176.txt,"Moreover, several experiments also separately validate the advantages of using coupled feature representation,
SCOTO and the multi-atlases based label fusion.",the advantages of
3177.txt,"In our future work, more advanced features and more intelligent way will be investigated to further improve the current work.",be investigated to
3179.txt,These methods typically map image features to continuous or discrete  values.,null
3180.txt,"A major drawback of existing discriminative methods is that samples are directly projected onto a subspace and hence fail to account for outliers common in realistic training sets due to occlusion, specular reflections or noise.",fail to
3181.txt,It is important to notice that existing discriminative approaches assume the input variables X to be noise free.,It is important to
3182.txt,"Thus, discriminative methods experience significant performance degradation when gross outliers are present.",null
3183.txt,"Despite its obvious importance, the problem of robust discriminative learning has been relatively unexplored in computer vision.",been relatively unexplored in
3184.txt,This paper develops the theory of Robust Regression and presents an effective convex approach that uses recent advances on rank minimization.,presents an effective convex approach
3185.txt,"The framework applies to a variety of problems in computer vision including robust linear discriminant analysis, regression with missing data, and multi-label classification.",applies to
3187.txt,Discriminative methods  have been successfully applied to many computer vision problems.,applied to
3188.txt,"Unlike generative approaches that produce a probability density over all variables, discriminative approaches directly attempt to compute the input to output mappings for classification or regression.",attempt to
3189.txt,"Typically, discriminative models achieve better performance in classification tasks, especially when large amounts of training data are available.",achieve better performance in
3190.txt,"However, discriminative approaches often lack mathematically principled ways to incorporate priors.",null
3191.txt,Linear and non-linear regression have been applied to solve a number of computer vision problems .,been applied to
3192.txt,"Although widely used, a major drawback of existing regression approaches is their lack of robustness to outliers and noise, which are common in realistic training sets due to occlusion, specular reflections or image noise.",are common in
3193.txt,"To better understand the lack of robustness, we consider the problem of learning a linear regressor from image features X to pose angles Y  by minimizing see footnote1 for an explanation of the notation used in this work.",for an explanation of
3195.txt,This is the well known GaussMarkov theorem  .,This is the well known
3197.txt,It is important to notice that in training and testing X is assumed to be noise free.,It is important to
3198.txt,"However, a single outlier in either training or testing can bias the projection because LS projects the data directly onto the subspace of T.",null
3199.txt,"The problem of robustness in regression has been studied thoroughly in statistics, and the last decades have witnessed a fast paced development of the socalled robust methods.",have witnessed a fast paced development of
3200.txt,"For instance, M-estimators assume the error has a heavy tail  and typically re-weight the whole sample inversely.",For instance
3201.txt,"That is, some robust approaches minimize a weighted regression where wi weighs the whole sample.",null
3202.txt,Other robust approaches replace the sum by a more robust measure such as  the  median   or trimmed mean.,such as
3203.txt,"However, all of the aforementioned traditional robust approaches for regression differ from the problem addressed in this paper in two ways.",differ from
3204.txt,This work proposes an intra-sample robust regression method that explicitly accounts for outliers in X.,accounts for
3205.txt,"However, unlike existing EIV models, RR does not require a prior estimate of the noise and all parameters are automatically estimated.",require a prior estimate of
3206.txt,"In addition to reducing the influence of noise and outliers in regression, we extend RR to be  able  to deal with missing data in regression, wherein some elements of X are unknown.",In addition to
3207.txt,"This is a common issue in computer vision applications, since unknown elements typically correspond to unobserved local image features.",This is a common issue in
3208.txt,"Surprisingly, this problem has been relatively unexplored in the computer vision literature.",been relatively unexplored in
3209.txt,"We illustrate the power of RR in several computer vision tasks including head pose estimation from images, facial attribute detection with missing data and robust LDA for multi-label image classification.",null
3210.txt,"Huber introduced M-estimation for regression, providing robustness to sample outliers.",null
3211.txt,"Rousseeuw and Leroy proposed Least Trimmed Squares, which explicitly finds a data subset that minimizes the squared residual sum.",null
3212.txt,"Parallel to developments in the statistics community, the idea of subset selection has also flourished in many computer vision applications.",has also flourished in
3213.txt,Consensus approaches such as RANSAC and M-estimator variants randomly subsample input data to construct a tentative model.,such as
3214.txt,Model parameters are updated when a new configuration produces smaller inlier error than its predecessors.,null
3215.txt,"In spite of accurate parameter estimates, even in the presence of several outliers, these methods heavily rely on the assumption that model generation from a data subset is computationally inexpensive and inlier detection can be done  adequately.",In spite of
3216.txt,"Moreover, the aforementioned methods do not tackle intra-sample outliers, i.e., partial sample corruptions.",null
3217.txt,"To deal with noise in the variables, Error-In-Variable   approaches have been  proposed,  see     for  an overview.",To deal with
3218.txt,"However, existing EIV approaches rely on strong parametric assumptions for the errors.",rely on
3219.txt,"For instance, orthogonal regression assumes that the variance of errors in the input and response variables are identical or their ratio is known .",For instance
3220.txt,"Under these assumptions, orthogonal regression can minimize the Gaussian error orthogonal to the learned regression vectors.",null
3223.txt,"Moment-based methods learn the regression by estimating high-order statistics, i.e., moments, from i.i.d.",null
3225.txt,"Likelihood-based methods  learn a reliable regression when the input and response variables follow a joint, normal and identical distribution.",null
3226.txt,Total Least Square and its nonlinear generalization solve for additive/multiple terms that enforce the correlation between the input and response variables.,null
3227.txt,TLS-based methods relax the assumption in previous methods to allow correlated and non-identically distributed errors.,null
3228.txt,"Nevertheless, they still rely on parametric assumptions on the error.",rely on
3229.txt,"Unfortunately, in typical computer vision applications, errors caused by occlusion, shadow and edges seldom fit such distributions.",null
3230.txt,"Although regression and classification are singlehandled by our framework, several authors have addressed solely the issue of robust classification.",null
3232.txt,"In machine learning, several authors have proposed a worst-case FDA/LDA by minimizing the upper bound of the LDA cost function to increase the separation ability between classes under unbalanced sampling.",null
3233.txt,"As in previous work on robust regression, these methods are only robust to sample-outliers.",null
3234.txt,Our work is more related to recent work in computer vision.,is more related to
3235.txt,Fidler and Leonardis   robustify LDA for intra-sample outliers.,null
3236.txt,"In the training stage, computed PCA on the training data, replaced the minor PCA components by a robustly estimated basis, and combined the two basis into a new one.",null
3237.txt,"Then,the data was projected onto the combined basis and LDA is computed.",was projected onto
3238.txt,"During testing, first estimates the coefficients of a test data on  the  recombined  basis by sub-sampling the data elements using X.",null
3239.txt,"Finally, the class label of the test data is determined by applying learned LDA on the estimated coefficients.",is determined by
3240.txt,"Although outliers outside of the PCA subspace can  be suppressed,does not address the problem of learning LDA with outliers in the PCA subspace of the training data.",address the problem of
3241.txt,Zhu and Martinez  proposed learning a SVM with missing data and robust to outliers.,null
3242.txt,"In X, the possible values for missing elements are modeled by a Gaussian distribution, and such that for each class, the input data with all possible missing elements spans an affine subspace.",null
3243.txt,The decision plane of the robustified SVM jointly maximizes the betweenclass margin while minimizing the angle between the decision plane and the class-wise affine subspaces.,between and
3244.txt,"However,X requires the  location  of  the  outliers to be known.",null
3245.txt,"In contrast to previous works, our RR enjoys several advantage.",In contrast to
3246.txt,Our work is inspired by existing work in robust PCA   and its recent advances due to rank minimization procedures .,is inspired by
3247.txt,These methods model data as the sum of a low-rank clean data component with an arbitrary large and sparse outlier matrix.,null
3251.txt,A major advantage of this approach is the convex formulation.,A major advantage of
3252.txt,"This approach has been extended to other problems such as background modeling and shadow removal, however, were originally devised with tasks such as dimensionality reduction or matrix completion in mind, which are unsupervised in nature.",such as
3253.txt,"In this paper, we will further extend the approach to detect intra-sample outliers in robust regression, and illustrate several applications in computer vision.",we will further extend the approach to
3254.txt,"It is important to notice that RR is different from cleaning the data using RPCA and then computing LS-regression on the clean data, because RR  cleans the input data X = D + E in a supervised manner.",It is important to
3255.txt,"For this reason, the outlier component E computed by RR is able to correct outliers both inside and outside the subspace spanned by D  .",is able to
3256.txt,"The original  form of RR,  is cumbersome to solve because the rank and cardinality operators  are discontinuous and non-convex.",null
3260.txt,The goal is then to learn a mapping from X to labels  indicating  the  class  membership  of the data points.,null
3261.txt,"LDA learns a linear transformation that maximizes inter-class separation while minimizing intra-class variance, and typical solutions are based on solving a generalized eigenvalue problem",are based on
3262.txt,"While there are several approaches to solve the small sample size problem , a more fundamental solution is to relate the LDA problem to a reduced-rank LS problem.",there are several approaches to
3263.txt,LS-LDA directly maps X to the class labels by minimizing.,null
3266.txt,"From now on, we will refer to this problem as""RRMissing"".",refer to
3267.txt,This section compares our RR methods against stateof-the-art approaches on four experiments for regression and classification.,null
3268.txt,The first experiment uses synthetic data to compare with existing approaches and illustrate how existing robust regression methods cannot remove outliers that lie in the subspace of the data.,null
3269.txt,The second experiment applies RR to the problem of head pose estimation from partially corrupted images.,null
3270.txt,"The third experiment reports comparisons of RR against state-of-the-art multi-label classification algorithms on the MSRC, Mediamill and TRECVID2011 databases.",null
3271.txt,"We compared our RR with five state-of-the-art methods: Standard least-squares regression ,GroupLasso ,  RANSAC ,  Total Least Square  that assumes the error in the data is additive and follows a Gaussian distribution.",compared with
3272.txt,The LSR learns directly the regression matrix T using the data X.,null
3273.txt,The other methods  re-weight the data or select a subset of the samples input data X before learning the regression.,null
3274.txt,We randomly  select 100 samples for training and the remaining 100 data points for testing.,null
3275.txt,Both the training and testing sets contain half of the corrupted samples.,null
3276.txt,Fig.2 visualizes the results of the regression for the different methods.,the results of
3278.txt,"Fig.2 shows the results of TX, once T is learned with GLasso.",the results of
3279.txt,"GLasso learns  a sparse regression matrix that re-weights the input data along dimensions, but it is unable to handle within sample outliers.",it is unable to
3280.txt,Observe how the samples are far away from the original clean samples.,are far away from
3283.txt,"Although we selected RANSAC parameters to obtain the best testing error, many of the corrupted data points are still identified as inliers.",are still identified as
3284.txt,"Fig.2 shows results obtained by TLS, where TLS only partially cleaned the corrupted data because the synthesized error cannot be modeled by an isotropic Gaussian distribution.",null
3287.txt,"Because  DRP CA is computed in an unsupervised manner, only the out- of-subspace error  can be discarded, while the in-subspace outliers can not be corrected.",null
3290.txt,Observe that our approach is able to clean both the in-subspace outliers and out-of-subspace.,is able to
3291.txt,This is because our method computes jointly the regression and the subspace estimation.,This is because
3292.txt,we have compared RR with five methods to learn a regression from the image X to the yaw angle Y.,compared with
3293.txt,"For a fair comparison, we randomly divided the 249 subjects into 5 folds and performed 5-fold crossvalidation, at each cross-validation train on 1 fold  and test on the remaining 4.",null
3294.txt,Parameters of interest in methods (2)-(4) were selected by performing grid search over the 5-fold cross-validation.,null
3295.txt,The performance of the compared methods is measured with the averaged angle error.,The performance of
3296.txt,Table  2  summarizes  the  results  of  methods  (1)-(4)and RR.,null
3297.txt,The LSR method produced the largest angle error with the increasing percentage of outliers.,null
3298.txt,"RANSAC produced comparable error as standard LSR,  indicating  that  RANSAC  is  unable  to  select a subset of ""inliers"" to robustly estimate the regression matrix.",is  unable  to
3299.txt,RPCA+LSR produced relatively larger yaw angle error.,null
3300.txt,This is because RPCA is unsupervised and lacks the ability to preserve the discriminative information in X that correlates with the angles Y.,This is because
3302.txt,"There are over 4000 frontal face images of 126 subjects under illumination change, expressions, and facial disguises.",null
3303.txt,Observe that SRC produced little outliers.,null
3304.txt,"This is because both the training and testing images of the same subject contain similar expression, illumination, glasses and scarf.",This is because
3308.txt,"Note different to SRC, our RLDA approach used the cleaned training images D instead of the original training images X.",null
3309.txt,We can see from Fig.5 that RLDA cleaned more intra-sample outliers and reconstruct more facial details than SRC.,null
3310.txt,"In Table 3, we compared face recognition accuracy of linear SVM, SRC and RLDA using the both the downsampled images and the Laplacian face as classification features.",null
3311.txt,"As shown  in  the  first  row  in Table 3 , RLDA produced the higher  accuracy  than SRC and SVM on downsampled images, and comparable accuracy to SRC on Laplacian features.",produced the higher  accuracy
3313.txt,"Furthermore, because the Laplacian features were not computed in the robust manner, under high corruptions , the results with Laplancian features were worse than RLDA with the downsampled images.",null
3314.txt,"Comparing to SVM and SRC, RLDA showed the best robustness for it consistently produced the best results.",Comparing to
3315.txt,"This section evaluates our Robust LDA   method on two multi-label and one multi-class classification tasks: object categorization on the MSRC dataset, action recognition in the MediaMill dataset and event video indexing on the TRECVID 2011 dataset.",null
3316.txt,"Each dataset corpus and features is described below:591 photographs  distributed among 21 classes, with an average of 3 classes per image.",with an average of
3317.txt,We mimic   and divide each image into an grid and calculate the first and second order moments for each color channel on each grid in the RGB space.,null
3318.txt,Mediamill Dataset  consists of 43907 sub-shots divided in 101 classes.,consists of
3319.txt,"We followed   and eliminated classes  containing less than 1000 samples, leaving 27 classes.",null
3320.txt,"Then, we randomly selected 2609 sub-shots such that each class has at least 100 labeled data points.",at least
3321.txt,"Each image was therefore characterized by a 120-dimensional feature vector, as described in X.",as described in
3322.txt,"We used state of the art features obtained from Overfeat, a Convolutional Neural Network trained on ImageNet  .",null
3323.txt,We rescaled every image to pixels and obtained  a single 4096 dimensional feature vector as the output from layer 22 of the network for every image in the dataset.,null
3324.txt,"TRECVID 2011 Dataset  4 consists of video data in MED 2010 and the development data  of MED 2011, totaling 9822 video clips belonging exclusively to one of 18 classes.",null
3325.txt,We  first  detected  100 shots for each video and then used their center frames as keyframes.,null
3326.txt,We described each keyframe using dense SIFT descriptors.,null
3327.txt,"From these, we learned a 4096 dimension Bag-of-Words dictionary.",null
3328.txt,Each video was represented by a normalized histogram of all of its feature points.,was represented by
3329.txt,"We used a 300 core cluster to extract the SIFT features, which took about 1500 CPU hours in total.",null
3330.txt,"In the experiment, we randomly split the dataset into two subsets: 3122 entries for training and 6678 for testing.",null
3331.txt,"We compared RLDA to the state of the art approach for Multi-Label LDA    , and to  Robust  PCA followed by traditional LDA.",compared to
3332.txt,"For control, we also compare to LDA, PCA+LDA .",compare to
3333.txt,"finally, we select the class label from the class labels of k-neighbors by majority voting.",null
3335.txt,"For these reasons, we use Area Under Receiver Operating Characteristic  as our evaluation metric.",null
3336.txt,AUROC summarizes the cost/benifit ratio over all possible classification thresholds.,null
3337.txt,We report the average AUROC for each method under their  best parameters in Table 4.,null
3339.txt,SVM performs better than PCA+LDA and RPCA+LDA.,better than
3340.txt,Our method leads to significant improvements over the others due to its joint classification and data cleaning .,leads to
3341.txt,"For Mediamill, LDA is just slightly worse than PCA+LDA and RPCA+LDA due to the low noise level in the data.",due to
3342.txt,"In this case, RLDA does not ""over-clean"" the data, and performs similar to PCA+LDA and RPCA+LDA.",similar to
3343.txt,"In the PASCAL VOC 2007 dataset results, performance increases become less accentuated, with baseline methods yielding good performance due to the recent advances in representation provided by Overfeat.",due to
3344.txt,"MLDA, on the other hand, results  in a poorer score because it heavily relies on the normalization based on inter-class correlations.",on the other hand
3345.txt,"To test our method in a  large  scale  dataset,  we run experiments on the TRECVID2011 dataset.",null
3346.txt,"We used the Minimum Normalized Detection Cost, the evaluation criteria for MED 2010 and MED 2011 challenges, as suggested by NIST.",as suggested by
3349.txt,"Note because the classes are mutually exclusive, MLDA is identical to LDA.",is identical to
3350.txt,"SVM is heavily affected by  outliers for the ""Wedding Ceremony"", ""Getting a vehicle unstuck"" and ""Making a sandwich"" cases.",is heavily affected by
3351.txt,"For some classes, LDA and RPCA+LDA are similar or better than RLDA.",better than
3352.txt,We  believe  this  is  due  to:  the data features computed by Bag-of-Words model smoothed/regularized some outliers; the nonlinear nature of the classification task.,due  to
3353.txt,Therefore some error patterns modeled by LDA and RPCA enhanced their discriminative ability.,null
3354.txt,"Nevertheless, among all linear algorithms, our method  obtains the best average MinNDC.",null
3355.txt,"In addition, to show how nonlinearity affects the performances, we compared the kernelized version of the LDA , RPCA+LDA and RLDA .",In addition
3357.txt,Other more accurate approximations are possible  .,null
3360.txt,"To train our facial attribute detector, we used training images from the PubFig database that have been labeled with 49 landmarks and images from Multi-PIE database that have been labeled with 68 landmark points.",null
3361.txt,This is a challenging problem because the regressor will have input features of different dimensions.,This is a challenging problem because
3362.txt,In this section we will show how RR is able to merge information from these two databases to get improved results on estimating facial attributes.,is able to
3363.txt,The PubFig database consists of 58797 images of 200 people collected from the internet.,consists of
3364.txt,Classifiers will be trained to recognize these facial attributes from image features.,null
3365.txt,The images in the PubFig database are taken in completely uncontrolled situations with noncooperative subjects.,null
3366.txt,"Thus, there are large variations in pose, lighting, expression, occlusion, scene and camera parameters.",there are large variations in
3367.txt,These imaging conditions pose great difficulties in classifying the facial attributes.,pose great difficulties in
3368.txt,"Besides the PubFig database, we also used 5683 face images from the Multi-PIE database.",null
3370.txt,"First, we used the supervised descent method to detect 49 facial landmarks in the PubFig database.",null
3371.txt,"Second, we compute a 8-dimensional Histogram of Gradient  vector around each facial point.",null
3372.txt,"As a baseline experiment, we applied the RLDA proposed in section 3.1, using only data from the PubFig database.",null
3374.txt,"At each trial of cross-validation we left one fold out for testing, and the rest three folds for training.",null
3375.txt,The averaged AUROCs over 4-fold cross-validation are reported at the optimal parameters.,are reported at
3376.txt,We added data from MultiPIE database to conduct a"PubFig&MultiPIE" experiment.,null
3378.txt,"Finally in testing, we only used the PubFig part of ""D"" to clean the testing data.",null
3379.txt,All quantitative results are shown in Table.,are shown in
3381.txt,"In addition to the ""PubFig only"" baseline, we added one more baseline ""PubFig (49pts)&MPIE (49pts)"" by using features from the 49pts that are common to both datasets.",In addition to
3382.txt,"We also implemented the discriminatively trained LDA for missing data in X, a standard LDA-based approach for missing data.",null
3383.txt,"The approach used the same missing training data as RLDA-missing, and the results were reported in Table.",were reported in
3385.txt,"Comparing to the two baseline methods, our RLDAmissing approach have additional 52-dimensional features learned from the MultiPIE data.",Comparing to
3386.txt,"Comparing to ""LDA-missing"" , our approach does not rely on explicit assumption on the missing values.",Comparing to
3387.txt,"""LDA-missing"" explicitly models the missing values by Gaussian distribution, whereas the missing elements in this experiment are structured.",null
3389.txt,our RLDA-missing produced improved results in both class-wise and average AUROCs.,improved results in
3390.txt,"This paper addressed the problem of robust discriminative learning, and presented a convex formulation for RR.",null
3391.txt,"Our approach jointly learns a regression, while removing the outliers that are not correlated with labels or regression outputs.",correlated with
3392.txt,"The framework of RR is useful to solve problems such as robust LDA, multilabeled image classification and regression with missing data.",is useful to
3393.txt,"We illustrated the benefits of RR in several computer vision problems including facial attribute detection, head pose estimation, and image/video classification.",null
3394.txt,"We show that by removing outliers, our methods consistently learn better representations and outperform state-of-the-art methods in both the linear and kernel spaces  .",both and
3395.txt,"Finally, our approach is general and can be easily applied to robustify other subspace methods such as  partial least square or canonical correlation analysis.",such as
3396.txt,It is often expensive and time consuming to collect labeled training samples in many real-world applications.,It is often expensive and time consuming to
3397.txt,"To reduce human effort on annotating training samples, many machine learning techniques  have been studied to exploit weakly labeled training samples.",null
3398.txt,"Meanwhile, when the training data is represented with multiple types of features, many multi-view learning methods have shown that classifiers trained on different views can help each other to better utilize the unlabeled training samples for the SSL task.",is represented with
3399.txt,"In this paper, we study a new learning problem called multi-view weakly labeled learning, in which we aim to develop a unified approach to learn robust classifiers by effectively utilizing different types of weakly labeled multi-view data from a broad range of tasks including SSL, MIL and relative outlier detection.",aim to
3400.txt,We propose an effective approach called co-labeling to solve the multi-view weakly labeled learning problem.,null
3401.txt,"Specifically, we model the learning problem on each view as a weakly labeled learning problem, which aims to learn an optimal classifier from a set of pseudo-label vectors generated by using the classifiers trained from other views.",aims to
3402.txt,"Unlike traditional co-training approaches using a single pseudo-label vector for training each classifier, our co-labeling approach explores different strategies to utilize the predictions from different views, biases and iterations for generating the pseudo-label vectors, making our approach more robust for real-world applications.",null
3403.txt,"Moreover, to further improve the weakly labeled learning on each view, we also exploit the inherent group structure in the pseudo-label vectors generated from different strategies, which leads to a new multi-layer multiple kernel learning problem.",leads to
3404.txt,"In many real-world applications, it is often expensive and time consuming to collect labeled training samples.",it is often expensive and time consuming to
3405.txt,"In recent decades, researchers have been exploiting various learning scenarios for utilizing weakly labeled samples to reduce human effort on manually labeling the training samples.",reduce effort on
3406.txt,"For example, in semi-supervised learning,  the  training  data  consists of a limited number of labeled training samples and  a  large number of unlabeled training samples.",For example
3407.txt,"Similarly, in multi-instance learning, the training data are provided in the form of bags.",are provided in
3408.txt,"Only the label of each bag is known, while the labels of instances in each bag remain unknown.",null
3409.txt,"In recent work, training data with uncertain labels was referred to as weakly labeled data, and those learning problems were uniformly referred to as the weakly labeled learning problem.",was referred to
3410.txt,"A unified approach was proposed in X for solving various learning problems with weakly labeled data including SSL, MIL and clustering, in which they learnt an optimal classifier from all possible labelings of training data.",was proposed in
3411.txt,"However, their work focused on single-view training data.",focused on
3412.txt,"When training data is represented with multiple feature representations, researchers have developed many multi-view learning approaches to improve performance by utilizing information from different views .",improve performance by
3413.txt,Most of those works in multi-view learning were proposed for the multi-view SSL scenario.,were proposed for
3414.txt,"It has been shown that, with multi-view information, the classifiers trained on different views can effectively help each other to better utilize the unlabeled training data.",It has been shown that
3415.txt,"Nevertheless, those works were designed for SSL.",were designed for
3416.txt,"In this paper,we study the learning problem by using weakly labeled training data with multiple views, which is referred to as the multi-view weakly labeled learning problem.",is referred to
3418.txt,"Specifically, we propose a novel colabeling approach for multi-view weakly labeled learning, in which we consider two major challenges: how to effectively exchange information among different views, and how to effectively learn a robust classifier on each view.",null
3419.txt,"In co-training based methods ,the predictions from a classifier trained on one view are used to label the unlabeled samples for training the classifier on the othe view.",are used to
3421.txt,"Moreover, considering that a single pseudolabel vector in the co-training based approach may be sensitive to the threshold, we further propose different strategies to generate multiple pseudo-label vectors by using different biases to enhance the robustness of our co-labeling approach.",null
3422.txt,"To learn the classifier for each view, traditional cotraining based methods used supervised learning approaches by treating single pseudo-label vector as the ground-truth label vector, which may be  sensitive  to  the noise in the pseudo-label vector.",null
3424.txt,"Specifically, as discussed in Section 4, those pseudo-label vectors can be generated from the classifiers on other views, with different biases and from all previous iterations.",as discussed in
3425.txt,"Inspired by recent works in Section 5 we formulate this learning problem as the MKL problem , in which each base kernel is associated with a pseudo-label vector.",is associated with
3426.txt,"Moreover, by observing that these pseudo-label vectors are generated with different strategies, we further develop  a novel multi-layer MKL method to effectively utilize the intrinsic group structure on those base kernels.",null
3427.txt,An efficient alternating optimization algorithm is proposed to solve the  new  multi-layer  MKL  problem  by  using a recursive updating strategy for updating the kernel combination coefficients.,is proposed to
3428.txt,"In Section 6, we conduct extensive experiments for different weakly labeled learning scenarios including multi-view SSL, multi-view MIL, and multi-view ROD, and also provide a detailed experimental analysis.",null
3430.txt,"Beyond our preliminary work, in this paper, we additionally propose a novel multi-layer MKL method to learn a more  robust  classifier  on  each  view.",null
3431.txt,We  also present a theoretical analysis on our co-labeling approach.,null
3433.txt,"In Section 3, we formulate the learning problem on each view as a weakly labeled learning problem  , in which we learn an optimal classifier from a set of pseudo-label vectors and the combination of these pseudo-label vectors to the final classifier is automatically decided by the multiple kernel learning   method.",null
3434.txt,"Specifically, as discussed in Section 4, those pseudo-label vectors can be generated from the classifiers on other views, with different biases and from all previous iterations.",as discussed in
3435.txt,"Inspired by recent works, in Section 5 we formulate this learning problem as the MKL problem, in which each base kernel is associated with a pseudo-label vector.",is associated with
3436.txt,"Moreover, by observing that these pseudo-label vectors are generated with different strategies, we further develop  a novel multi-layer MKL method to effectively utilize the intrinsic group structure on those base kernels.",null
3437.txt,An efficient alternating optimization algorithm is proposed to solve the  new  multi-layer  MKL  problem  by  using a recursive updating strategy for updating the kernel combination coefficients.,is proposed to
3438.txt,"In Section 6, we conduct extensive experiments for different weakly labeled learning scenarios including multi-view SSL, multi-view MIL, and multi-view ROD, and also provide a detailed experimental analysis.",null
3440.txt,"Beyond our preliminary work, in this paper, we additionally propose a novel multi-layer MKL method to learn a more  robust  classifier  on  each  view.",null
3441.txt,We  also present a theoretical analysis on our co-labeling approach.,null
3442.txt,Our work is related to  traditional  multi-view  learning approaches.,is related to
3443.txt,Most traditional multi-view learning methods were proposed for semi-supervised learning  .,were proposed for
3444.txt,"One of the pioneering works is the co-training method  , which was originally proposed for semisupervised learning problems with two views of training data.",proposed for
3445.txt,"It was further extended to co-EM, in which they label all the unlabeled data at each iteration without considering confidence.",It was further extended to
3446.txt,It was also extended by using SVMs as the base classifiers in X.,It was also extended by
3447.txt,Cotraining was also extended to tri-training and coforest  to handle more than two views.,null
3448.txt,"However, the co-training style algorithms work under strict assumptions that each view is sufficient to train a low-error classifier and both views are conditionally independent, which might not be satisfied on real world datasets.",null
3449.txt,"Many works attempted to relax those assumptions from various perspectives, such as weak dependence .",such as
3450.txt,"Recently, co-training with insufficient views has also been theoretically analyzed in X.",null
3451.txt,"Besides co-training style methods, other methods such as co-regularization based approaches were also proposed to train classifiers on different views based on the so-called co-regularization criterion.",such as
3452.txt,The similar idea has also been employed in multi-view clustering.,employed in
3453.txt,"However, similar to co-training style methods, all these methods are specifically designed for a specific learning scenario.",similar to
3454.txt,Our work is also related to various learning scenarios with different types of weakly labeled training data.,is also related to
3455.txt,"Specifically, besides the above mentioned multi-view SSL works, SSL methods have also been widely studied for single view training data .",null
3456.txt,"MIL is another widely studied learning scenario, in which the weakly labeled training data is provided in the form of bags      of instances.",is provided in
3457.txt,"Only the labels of training bags are given, while the labels of instances inside each training bag are unknown.",null
3458.txt,Many works have been proposed to solve the MIL problems in the literature.,been proposed to
3459.txt,"Another example is maximum margin clustering , in which the goal is to learn a discriminative classifier to partition unlabeled training samples into two disjoint clusters.",null
3460.txt,"Recent work uniformly referred to the above learning scenarios as weakly labeled learning, and proposed a unified scheme called WellSVM to solve it.",null
3461.txt,Another work that can handle different types of weakly labeled data was also proposed in X.,proposed in
3462.txt,Other learning scenarios related to weakly labeled data include relative outlier detection and multi-instance semisupervised learning.,null
3463.txt,"However, all those works were proposed for only single-view training data.",were proposed for
3464.txt,"In contrast, in this work, we study a new learning problem called multi-view weakly labeled learning.",In contrast
3465.txt,"In this section, we first review the existing works on multi-view learning and weakly labeled learning, and then present our co-labeling approach for the multi-view weakly labeled learning problem.",null
3467.txt,The basic idea of co-training is to iteratively add some pseudo-labeled samples into the pool of labeled training samples to re-train the classifiers on both views.,null
3468.txt,"The pseudo-labeled samples are selected from the pool of unlabeled training samples, and are labeled by at least one classifier which has a confident prediction.",null
3469.txt,"While the original co-training algorithm feeds newly labeled training samples to each view, it can also be deemed as a learning process by iteratively updating the pseudo-labels of unlabeled data on each view.",it can also be deemed as
3470.txt,We illustrate the co-training method in Fig.1.,null
3471.txt,"At each iteration, the classifier on one view generates pseudo-label vectors for learning the classifier on the other view  by using the supervised learning approach.",null
3472.txt,"To reduce human effort for labeling training data, various learning scenarios have been proposed in the literature to learn classifiers only based on weakly labeled data.",been proposed in
3473.txt,"For example, in SSL, one is given a limited number of labeled samples and a large amount of unlabeled samples.",null
3474.txt,"In MIL, the training data are given in the form of training bags, with each bag containing a certain number of training instances.",null
3475.txt,"Recently, the work in X studied the weakly labeled learning problem by unifying the above learning scenarios into a general learning problem with weakly labeled data.",null
3477.txt,The label candidate set contains all the possible labelings of the training samples.,null
3478.txt,"Intuitively, the weakly labeled learning problem aims to learn an optimal classifier from all the possible labelings.",aims to
3479.txt,Let us denote the label vector as label for xi and n is the number  of  training  samples.,null
3480.txt,"We give several examples of the definition on the label candidate set corresponding to different traditional learning scenarios including MIL, SSL and ROD.",corresponding to
3481.txt,"In MIL, the constraints are that all instances in the negative bags are negative, and at least one instance   in each positive bag is positive  .",null
3482.txt,Let us denote I as the I-th training bag and YI as the corresponding bag label.,null
3483.txt,"We observe that most traditional multi-view learning approaches are limited to semi-supervised learning, and the recently proposed weakly labeled learning works for semi-supervised learning and multi-instance learning are limited to single-view training data.",are limited to
3484.txt,"In practice, traditional multi-view learning methods can benefit from the recent progress on weakly labeled learning, and weakly labeled learning methods can also be improved with multi-view information.",be improved with
3485.txt,in this paper we propose to study a new learning problem called multi-view weakly labeled learning which aims to solve the weakly labeled learning problem with multi-view training data.,aims to
3486.txt,"Specifically, we focus on the binary classification problem in this work.",focus on
3487.txt,The multi-class classification  problem can be converted into a set of binary classification problems using the one-versus-all strategy.,null
3489.txt,We use the pseudo-label vector set to exchange information from the classifier trained on one view to another.,null
3490.txt,"Specifically, similar to co-training, in our co-labeling approach the pseudo-label vector set v is generated by using the predictions from classifiers trained on the other views.",similar to
3491.txt,"To cope with different weakly labeled data, we first propose a projection operator, which converts the predictions  to pseudolabel vectors by considering the constraints associated with different weakly labeled learning scenarios.",associated with
3492.txt,"Moreover, in the traditional co-training methods, the classifiers exchange information through a single pseudo-label vector.",null
3493.txt,"In contrast, we use a set of pseudo-label vectors in (2), which contain more information for learning a robust classifier.",In contrast
3494.txt,"To learn a classifier on each view, the traditional co-training algorithm adopted the supervised learning method by using single pseudo-label vector as the ground-truth of unlabeled data, which may be sensitive to noise in the pseudo-label vector.",null
3495.txt,"To overcome this problem, in our co-labeling approach, we treat the learning problem on each view as a weakly labeled.",treat as
3496.txt,"Moreover,  to improve weakly labeled learning on each view, we further exploit the group structure within the pseudolabel vectors, which leads to a novel multi-layer MKL problem.",leads to
3497.txt,The details of generating the pseudo-label vector set for each view are introduced in Section 4.,are introduced in
3498.txt,How to generate a set of pseudo-label vectors on one view using the information from the other views is the first key issue of our co-labeling approach.,the first key issue of
3499.txt,"Inspired by co-training  , we generate the pseudo-label vectors on one view by using the predictions   from the classifiers on other views.",Inspired by
3500.txt,"Unlike the co-training method, which uses only a single pseudo-label vector, we need to consider several issues as described below   to better handle the general multi-view weakly labeled learning scenarios and train a more robust classifier.",consider as
3501.txt,"Moreover, the learnt classifiers in the weakly labeled learning problems can be easily biased.",null
3502.txt,"in MIL one common approach is to initialize all the instances in positive bags as positive samples, so it is more likely that the initial classifier will predict the negative samples to be positive.",it is more likely that
3503.txt,A possible solution is to adjust the bias term of the learnt classifier.,null
3504.txt,"However, it is a nontrivial task since we do not have the ground truth labels to decide the adjustment.",it is a nontrivial task since
3505.txt,"Thus far, we only consider the pseudo-label vectors obtained by using the predictions from the latest iteration, which means the pseudo-label vector set on each view can be changed at different iterations.",null
3506.txt,"As a result, one potential problem is that the algorithm may not converge.",As a result
3507.txt,"Inspired by the recent weakly  labeled  learning  works, we construct the pseudo-label vector set by using the pseudo-label vectors obtained from all previous iterations.",null
3508.txt,"In other words, at each iteration we augment the pseudo-label vector set by appending the newly obtained pseudo-label vectors into the previous.",In other words
3509.txt,"After generating a pseudo-label vector set for each view, the remaining problem is to learn a robust classifier using the pseudo-label vector set.",null
3510.txt,"In this section, we formulate the weakly labeled learning problem on each view as an MKL problem by combining each pseudo-label vector with the input kernel.",null
3511.txt,"To train a more robust classifier, we further employ the intrinsic group structure inside the pseudo-label vector set, which leads to a novel multilayer MKL formulation.",leads to
3512.txt,The traditional MKL problem aims  to find an optimal linear combination of input base kernels  with a  single  label  vector.,aims  to
3513.txt,"In  contrast,  we learn the optimal linear combination of input-output kernels in our weakly labeled learning scenario in order to effectively integrate these kernels that are decided by a set of pseudo-label vectors.",In  contrast
3514.txt,The problem in X can be solved by using existing solvers such as X.,such as
3515.txt,"In Section 5.1, we formulate the weakly labeled learning problem on each view as an norm MKL problem, in which we ignore the different ways that the pseudo-label vectors are generated.",null
3516.txt,"By putting the pseudo-label vectors generated in the same way into a group, we can organize the pseudo-label vectors into three dimensions in terms of view, bias, and iteration.",null
3517.txt,"To effectively utilize and capture such a group structure when learning the classifier, we propose to use different regularizers on the combination coefficients at different layers, which leads to a multi-layer MKL problem.",leads to
3518.txt,"In this section, we study a general multi-layer MKL problem and also propose an efficient solution.",null
3519.txt,"Since our multi-view weakly labeled learning problem has a three layer structure, we take the three-layer structure as an example to introduce the objective function and the solution of our multi-layer MKL.",as an example to
3521.txt,We formulate our three-layer Multiple Kernel Learning problem as follows:Different norms may introduce different levels of sparsity on the kernel combination coefficients.,null
3523.txt,"In contrast, our solution is based on the new recursive updating strategy from the introduction of the intermediate variables.",In contrast
3524.txt,"Moreover, the objective function in X for our multi-layer MKL is jointly convex with respect to the kernel combination coefficients and the SVM primal variables, therefore our algorithm enjoys similar convergence properties as p-MKL  .",with respect to
3525.txt,The whole optimization procedure for our co-labeling algorithm is listed in Algorithm 3.,is listed in
3526.txt,A total number of  V classifiers are trained from our co-labeling algorithm.,null
3527.txt,The  initial  pseudo-label  vector  set  v  for  the  vth view is problem dependent.,null
3529.txt,The algorithm is composed of two main loops.,is composed of
3530.txt,"In the outer loop, we iteratively  update  v  for each view by using Algorithm 2, while in the inner loop we learn the classifiers by using our proposed multilayer MKL as discussed in Section 5.3.",as discussed in
3531.txt,"After obtaining the final classifier for each view, the final decision value is calculated by fusing the decision values from all the V views.",is calculated by
3532.txt,"For each view, we solve an MKL problem which minimizes the objective function in X with respect to the SVM primal variables and D .",with respect to
3533.txt,Note we add the new pseudo-label vectors into the set v at each iteration.,null
3534.txt,"So, in the worst case the optimal solution of MKL at the current iteration should be the same one at the previous iteration by setting the entries in the coefficient vector D corresponding to the newly added pseudo-label vectors to zeros.",null
3535.txt,Therefore the objective values of our MKL problem on each view in X should not increase as the number of iterations increases.,null
3536.txt,The  main  cost  in  Algorithm  3   is from the training  process  of  multi-layer  MKL.,null
3538.txt,Note the time complexity for MKL training has not been theoretically analyzed.,null
3539.txt,"Usually, the MKL solver needs to train an SVM for a few iterations.",null
3540.txt,"The empirical analysis shows the time complexity for optimizing the QP problem in SVM is O(n2.3), where n is the number of training samples.",null
3541.txt,We also analyze the generalization bound of our co-labeling algorithm in Appendix B.,null
3542.txt,"Specifically, we first give the generalization bound of our weakly labeled learning method on each view, and then present the generalization bound for the final classifier.",null
3544.txt,"Note Well-SVM   can handle different types of weakly labeled data in the single view setting, we treat it as the most related baseline for comparison.",treat as
3545.txt,We also compare our co-labeling approach with the related state-of-the-art methods for each learning task  .,compare with
3546.txt,"For our co-labeling approach with multi-layer MKL, different norm parameters for different layers can represent different prior information for the corresponding layer.",null
3547.txt,"First, we iteratively update the label candidate sets.",null
3548.txt,The labels from different iterations may be quite  different and only the labels from a limited number of iterations are close to the ground-truth labels.,null
3550.txt,"Second, in our co-labeling algorithm, multiple bias terms are used to  cope  with the prediction biases.",are used to
3551.txt,"Considering that the pseudo-label vectors from different biases within a certain region should be somewhat similar, we use an norm on the biases, which leads to a denser solution.",leads to
3552.txt,So we can better utilize multiple bias terms to enhance the robustness of the learnt classifier.,null
3553.txt,"Third, as the labels from other views may contain complementary information, we thus expect that they are equally important.",null
3554.txt,"Therefore, an norm  is utilized for the view layer in our model.",is utilized for
3555.txt,"While it is possible to tune other values, we finally utilize the norm MKL on each view.",it is possible to
3556.txt,"MIL has been successfully used for Text-Based Image Retrieval , so we evaluate our co-labeling approach for TBIR under the two-view  setting.",used for
3557.txt,"Similar to X, we conduct the experiment on the  large scale NUS-WIDE dataset, which consists of 269,648 images from 81 annotated concepts collected from the website Flickr.com.",Similar to
3558.txt,"The textual feature is extracted from the tags associated with each image, in which the vocabulary is constructed by using the top 1000 words with the highest frequency.",null
3559.txt,"Then, a 1000 dimensional termfrequency feature is extracted for each image.",null
3560.txt,"We treat each type of  feature  as  one  view,  and  use  the Gaussian kernel for each view with the bandwidth parameter as the mean of squared distances between all training samples.",null
3561.txt,"We compare our co-labeling approach with WellSVM and other state-of-the-art MIL methods, MIL-CPB , mi-SVM  and sMIL , which have achieved the best performances on the NUS-WIDE  dataset  as  reported in X.",achieved the best performances on
3562.txt,"Since those works are single-view methods, we use the late fusion strategy to average the decision values from the classifiers on different views.",null
3563.txt,"We also employ the early fusion strategy for these methods by using the average kernel, which are worse than or only comparable to the results using the late fusion strategy.",comparable to
3564.txt,"For all methods, we construct 15, 20, and 25 positive bags using the top-ranked relevant images and the same number of negative bags using randomly selected irrelevant images, in which each bag contains 15 instances.",null
3565.txt,"For performance evaluation, the noninterpolated Average Precision is used as the performance metric.",is used as
3566.txt,Mean Average Precision   is the mean of the APs over all the concepts/classes.,null
3567.txt,The MAPs over 81 concepts  for  different  methods  on the NUS-WIDE dataset are reported in Table 1.,are reported in
3568.txt,"The mi-SVM method outperforms other baseline methods MIL-CPB, sMIL, and WellSVM, which indicates the simple approach works well on this dataset by iteratively training the SVM classifier and inferring the labels of training instances.",null
3569.txt,"We also observe that the results of all methods become higher, when the number of positive/negative training bags increases.",null
3570.txt,"Our co-labeling approaches consistently outperform the existing MIL methods when using different number of positive/negative training bags, which clearly demonstrates the effectiveness of our methods for combining information from two views.",demonstrates the effectiveness of our methods
3572.txt,We apply PMC on the concatenated feature vector from all the views.,null
3573.txt,"For all the methods except  PMC,  the  classifiers  from all views are fused with equal weights to  obtain  the final prediction in the late fusion fashion, unless stated otherwise.",null
3574.txt,We evaluate our co-labeling approach for two-view semi-supervised learning for news classification on the BBC and BBCSport datasets  .,null
3575.txt,The details of these two datasets are summarized in Table 2 and described in the following.,are summarized in
3576.txt,The two datasets contain news articles collected from the BBC.,null
3577.txt,"The BBC dataset contains 2225 documents from five topics and the BBCSport dataset consists of 737 sports news documents from five classes , respectively.",consists of
3579.txt,"For each view, we use the linear kernel for all the methods.",null
3580.txt,"We partition the datasets into the training set and the test set, each of which contains 50% of the documents per class.",null
3581.txt,"Two labeled samples from each class are further selected from the training  set, and all the remaining data in the training set are utilized as unlabeled data for the training process.",are utilized as
3582.txt,"We perform the experiments ten times based on different  data partitions, and report the MAPs in Table 3.",based on
3583.txt,"Our co-labeling methods outperform the existing SSL methods for each single view and for the joint view, which demonstrates the effectiveness of our co-labeling approach for two-view semi-supervised learning.",demonstrates the effectiveness of our co-labeling approach
3584.txt,"We also conduct the experiments for the single-view learning methods SVM, TSVM and WellSVM by using the original features.",null
3585.txt,"The results for SVM, TSVM and WellSVM  are  on the BBC dataset.",null
3586.txt,"It is interesting that SVM and WellSVM achieve better results by using the early fusion strategy with the original features on both datasets, which demonstrates the two methods can benefit from accessing all the features in the learning process for this application.",It is interesting that
3587.txt,"However, those results are still worse than our co-labeling methods.",worse than
3588.txt,"We also evaluate our co-labeling approach for multi-view semi-supervised learning on the Reuters multi lingual dataset , which is from the Reuters RCV1 and RCV2 collections.",null
3589.txt,"The task is to classify the documents written in 5 languages, English, French, German, Italian and Spanish into different categories.",null
3590.txt,"Following X, a total number of 6 classes   are utilized for performance evaluation.",are utilized for
3591.txt,The documents belonging to more than one class are annotated using the label of their smallest class.,null
3592.txt,Each document from the corresponding corpus has been translated to the other 4 languages by using the statistical machine translation system PORTAGE.,null
3593.txt,Detailed information of this dataset is shown in Table 4.,is shown in
3594.txt,"In order to perform the multi-view learning task, we uniformly divide the feature vector of the original language and the four corresponding translated languages into three parts.",In order to
3595.txt,"For each view, we use the linear kernel for all the methods.",null
3596.txt,"In this way, we can obtain a total  number of 15 views for the learning problem.",null
3597.txt,"For each class of each language, a total number of 14 documents are selected as the labeled training data, thus a total number of 84 documents are used as the labeled training data for each language.",are used as
3598.txt,"Moreover, another 2916 samples are utilized as the unlabeled data.",are utilized as
3599.txt,"So a total number of 3,000 documents are used to train the classifiers.",are used to
3600.txt,"For each class of each language, the binary one-vs-others classifiers are trained for performance evaluation, and the experiments are repeated five times with different data partitions.",are trained for
3601.txt,The numbers of training and testing samples are also summarized in Table 4.,are also summarized in
3602.txt,The means and the standard deviations of MAPs over 6 classes and all 5 languages for different methods on the multilingual dataset are reported in Table 5.,are reported in
3603.txt,"Our co-labeling approaches CoL(2-layer) and CoL(3-layer) after considering the group structure outperforms the existing semi-supervised learning methods, which demonstrates the effectiveness of the proposed methods.",demonstrates the effectiveness of the proposed methods
3604.txt,"By fully considering the group structure on all the three layers, CoL(3-layer) achieves the best results.",null
3605.txt,These results again demonstrate that it is beneficial to employ different regularizers at different layers to capture the inherent group structure among the base input-output kernels.,it is beneficial to
3606.txt,"The 20 Newsgroups Data Set6 contains 18,774 news documents from 20 subcategories, in which 11,269 news documents are used as the training set, and the remaining 7,505 news documents are used as the test set.",are used as
3607.txt,"Each news document is represented using the word-frequency feature and its feature dimension is 61, 188.",null
3608.txt,"If we regard the news documents from some groups as the normal patterns, and the news documents from other groups as outliers, the news document classification problem can be treated as an outlier detection task.",be treated as
3609.txt,"In our experiments, we treat the samples from  the first 10 subcategories as the  normal  documents,  and  the samples from the remaining 10 subcategories as the outliers.",null
3610.txt,"We then construct the labeled reference set by using N normal training documents, and use another N normal training documents as unlabeled data.",null
3611.txt,"Also, another N/9 outlier documents in the training set are used as unlabeled training data, such that the outlier ratio for unlabeled training data is 1/10.",are used as
3613.txt,"The test data set is used to evaluate all the algorithms, and the mean of APs over 10 rounds of experiments is reported for performance evaluation.",is used to
3614.txt,"In order to perform the multiview learning task, we also uniformly divide the feature vector of each news document into three parts.",In order to
3615.txt,"In this way, we can obtain a total number of three views for the learning algorithms, and the linear kernel is used for each view in our method.",is used for
3616.txt,"While the ROD task is not discussed in X, we can  still apply WellSVM to this task, which is referred to as WellSVM-ROD here.",is not discussed in
3617.txt,We also compare our work with the state-of-the-art ROD methods MLOD and LSOD for the ROD task.,compare with
3618.txt,The parameters of MLOD and LSOD are set by using their leave-one-out cross validation strategies .,null
3619.txt,"From the results shown in Table 6, we have the following observations.",null
3620.txt,"First, our co-labeling approach CoL(3-layer) again achieves the best performances for multi-view relative outlier detection when using different number of normal news documents.",achieves the best performances for
3622.txt,"To effectively utilize different types of multi-view weakly labeled data, in this paper we have studied a new problem called multi-view weakly labeled learning, which covers various weakly labeled learning problems including SSL, MIL and ROD under the multi-view setting.",null
3623.txt,We firstly propose a co-labeling framework  to  solve  the multi-view weakly labeled learning problem using pseudo-label vectors.,null
3624.txt,"For each view, we propose a novel multi-layer MKL formulation to train a more robust classifier based on a set of input-output kernels associated with the pseudo-label vectors generated from different iterations, biases and views.",based on
3625.txt,"Extensive experimental results for MIL, SSL and ROD on the real-world multi-view datasets demonstrate that our proposed approach achieves state-of-the-art results.",null
3626.txt,Coherency Sensitive Hashing   extends Locality Sensitivity Hashing   and PatchMatch to quickly find matching patches between two images.,null
3627.txt,"LSH relies on hashing, which maps similar patches to the same bin, in order to find matching patches.",in order to
3628.txt,"PatchMatch, on the other hand, relies on the observation that images are coherent, to propagate good matches to their neighbors in the image plane, using random patch assignment to seed the initial matching.",on the other hand
3629.txt,CSH relies on hashing to seed the initial patch matching and on image coherence to propagate good matches.,null
3630.txt,"In addition, hashing lets it propagate information between patches with similar appearance.",In addition
3631.txt,"This way, information is propagated much faster because it can use similarity in appearance space or neighborhood in the image plane.",null
3632.txt,"As a result, CSH is at least three to four times faster than PatchMatch and more accurate, especially in textured regions, where reconstruction artifacts are most noticeable to the human eye.",null
3634.txt,"In the Approximate Nearest Neighbor Fields problem, the goal is to quickly compute a mapping between the set of patches of one image to that of another, with a minimal L2 distance between the vector representations of the matching patches.",null
3635.txt,"Computing ANNFs is an important building block in many computer vision and graphics applications such as texture synthesis, image editing and image denoising.",such as
3636.txt,This is a challenging task because the number of patches in an image is in the millions and one needs to find Approximate Nearest Neighbors for each patch in real or near real time.,This is a challenging task because
3637.txt,"In the past, it was customary to compute ANNF with traditional approximate nearest neighbor tools such as Locality Sensitive Hashing  or KD-trees.",such as
3638.txt,These tools perform well in terms of accuracy but are not as fast as one would hope.,as fast as
3639.txt,"Recently, a novel method, termed PatchMatch, proved to outperform those methods by up to two orders of magnitude, making applications that rely on ANNF run at interactive rate.",null
3640.txt,The key to this speedup is that PatchMatch relies on the fact that images are generally coherent.,null
3641.txt,"That is, if  we  find  a  pair  of  similar  patches, in two images, then their neighbors  in  the  image  plane are also likely to be similar.",null
3642.txt,PatchMatch uses a random search to seed the patch matches and iterates for a small  number of times to propagate good matches.,null
3643.txt,"Unfortunately, PatchMatch is not as accurate as LSH or KD-trees and increasing its accuracy requires more iterations that cost much more time.",null
3644.txt,"In addition, the main assumption it relies on X , with noticeable influence on mapping quality.",In addition
3645.txt,"It is therefore beneficial to develop an algorithm that is as fast, or faster, than PatchMatch, and more accurate.",It is therefore beneficial to
3646.txt,"Coherency Sensitive Hashing   replaces the random search step of PatchMatch with a hashing scheme, similar to the one used in LSH.",similar to
3647.txt,"As a result, the process of seeding good matches is much more targeted and information is propagated much more efficiently.",As a result
3648.txt,"Specifically, information is propagated to  nearby  patches  in  the  image  plane,  as is done in PatchMatch, and to similar patches that were hashed to the same value.",null
3649.txt,"In other words, we propagate information to patches that are close in the image plane    or are similar in appearance.",In other words
3650.txt,"The end result is that our algorithm runs faster and gives more accurate results, in terms of root mean square  error of the retrieved patches, compared to PatchMatch.",compared to
3651.txt,This increased speed and accuracy comes at a modest increase in memory footprint since we need to store the hashing tables.,null
3652.txt,An interesting property of our algorithm is that its reconstruction errors are significantly lower than those obtained by PatchMatch.,lower than
3653.txt,"To measure this, we define incoherency to measure the number of neighboring patches in one image that are mapped to neighboring patches in the other image.",null
3654.txt,We  find that the mappings produced by CSH are much  less coherent than the ones produced by PatchMatch.,less than
3655.txt,This is because CSH does not rely on the image coherency assumption as much as PatchMatch does.,as much as
3656.txt,Experiments suggest a strong correlation between the coherency of the mapping and RMS error.,between and
3657.txt,"The less coherent the mapping, the lower the error.",null
3658.txt,We also characterized the errors by image content and found that CSH works better than PatchMatch in textured regions.,better than
3659.txt,We demonstrate the advantages of CSH over PatchMatch on a new data set of 133 image pairs  with 2 mega pixel resolution1.,null
3661.txt,Efros and Leung introduced a simple non-parametric texture synthesis algorithm.,null
3663.txt,"Common to all these techniques  is  the  need  to  find, for each patch in  image  A,  a  similar    patch in image B, where in some  cases  images  A and  B can  be the same image.",null
3664.txt,Wei and Levoy   proposed a Tree Structure Vector Quantization method to quickly find the necessary matches.,null
3665.txt,"Others relied on existing ANN search techniques such as kd-trees  , perhaps enhancing them with PCA, to reduce dimensionality.",such as
3666.txt,Ashikhmin was the first to introduce the concept of coherency and used it to accelerate non-parametric texture synthesis.,null
3667.txt,This was later extended to k-coherence by Tong that pre-computed a set of k nearest neighbors for each patch and used it to accelerate the search for ANN.,null
3668.txt,They have also demonstrated it for texture synthesis.,null
3672.txt,Two leading methods for ANN search are kd-trees   and Locality Sensitive Hashing.,null
3673.txt,"Both partition the space, either deterministically or randomly in order to allow for quick query time.",in order to
3674.txt,In this work we focus on LSH and show how to extend it to deal with coherent data.,focus on
3675.txt,"The work most closely related to ours, and indeed the one that inspired ours, is that of PatchMatch  .",null
3676.txt,PatchMatch takes image coherence to the extreme and uses it for various image editing applications.,null
3678.txt,Given a pair of images it randomly assigns each patch in image A to a patch in image B.,null
3679.txt,"While most assignments yield poor matches, some are quite good and these are propagated to nearby patches in the image plane.",null
3680.txt,"To avoid being trapped in a local minima, it also performs  a number of random patch assignments for each patch, keeping the best match after each stage.",null
3681.txt,The algorithm usually converges after a small number of iterations.,null
3682.txt,The Generalized PatchMatch   is a recent extension    of Barnes et al.,null
3685.txt,"Also, He and Sun successfully use the statistics of patch matching offsets, obtained by PatchMatch, in a graph-cut based solution for image completion.",null
3686.txt,Patch-based methods have been very successful in a wide variety of computer vision and graphics applications.,been very successful in
3687.txt,Efros and Leung   introduced a simple non-parametric texture synthesis algorithm.,null
3688.txt,Non-parametric texture synthesis was then used for various image editing applications by Simakov and it also inspired the method of nonlocal means for image denoising.,used for
3689.txt,"Common to all these techniques  is  the  need  to  find, for each patch in  image  A,  a  similar    patch in image B, where in some  cases  images  A and  B can  be the same image.",null
3690.txt,Wei and Levoy proposed a Tree Structure Vector Quantization method to quickly find the necessary matches.,null
3691.txt,"Others relied on existing ANN search techniques such as kd-trees  , perhaps enhancing them with PCA, to reduce dimensionality.",such as
3692.txt,Ashikhmin  was the first to introduce the concept of coherency and used it to accelerate non-parametric texture synthesis.,null
3693.txt,This was later extended to k-coherence by Tong that pre-computed a set of k nearest neighbors for each patch and used it to accelerate the search for ANN.,null
3694.txt,They have also demonstrated it for texture synthesis.,null
3698.txt,Two leading methods for ANN search are kd-trees   and Locality Sensitive Hashing.,null
3699.txt,"Both partition the space, either deterministically or randomly  in order to allow for quick query time.",in order to
3700.txt,"In this work we focus on LSH and show how to extend it to deal with coherent data, such as patches in an image.",such as
3701.txt,"The work most closely related to ours, and indeed the one that inspired ours, is that of PatchMatch  .",null
3702.txt,PatchMatch takes image coherence to the extreme and uses it for various image editing applications.,null
3704.txt,Given a pair of images it randomly assigns each patch in image A to a patch in image B.,null
3705.txt,"While most assignments yield poor matches, some are quite good and these are propagated to nearby patches in the image plane.",are propagated to
3706.txt,"To avoid being trapped in a local minima, it also performs  a number of random patch assignments for each patch, keeping the best match after each stage.",null
3707.txt,The algorithm usually converges after a small number of iterations.,null
3708.txt,The Generalized PatchMatch   is a recent extension    of Barnes et al.,null
3711.txt,"Also, He and Sun successfully use the statistics of patch matching offsets, obtained by PatchMatch, in a graph-cut based solution for image completion.",null
3712.txt,The notion of Locality Sensitive Hashing was first introduced by Indyk and Motwani.,introduced by
3713.txt,"Given a set of points in a metric space, LSH function families have the property that points that are close to each other have a higher probability of colliding compared to points that are far apart.",have a higher probability of
3714.txt,The first usage of LSH for nearest neighbor search in high dimensions worked in high dimensional binary Hamming space.,null
3716.txt,In the rest of this section we outline their approach.,In the rest of this section
3718.txt,"In the indexing stage, primitive hash functions from H are used to create an index in which similar points map into  the same hash bins with high probability.",are used to
3719.txt,M such primitive hash functions are concatenated to create a code which amplifies the gap between the collision probability of far away points and the collision probability of nearby points.,null
3720.txt,"Such a code creates a single hash table, by evaluating it on all data-set points.",null
3721.txt,"In the search stage, a query point is hashed into a table bin, from which the nearest of residing data-set points is chosen.",null
3722.txt,"In order to decrease the probability of falling into an empty bin,which are searched sequentially at search stage.",In order to
3723.txt,"Datar show that the above scheme results in significantly improved efficiency compared to previous methods in the case of L2 distances,which are the ones of interest in our case.",compared to
3726.txt,The role of  the random offset b is to neutralize the quantization limits of fixed binning.,null
3727.txt,"Specifically, it ensures that similar patches  will collide  with high probability,which is a concatenation of M random projection-based hash functions hai,bi , independently created as described in the previous paragraph.",as described in
3728.txt,"Figure 2 , illustrates the spatial decomposition induced by such a function g, built of two projection lines.",null
3730.txt,They are used in the two main stages of the hashing scheme.,are used in
3731.txt,"In the indexing stage, they are used in the definition of the underlying hashing functions, while in the search stage  for the efficient approximation of L2 distances between patches.",null
3732.txt,"Even though our hashing scheme is a general framework and these components could have been implemented differently, the use of the WH kernels turns out to be a key ingredient in the good speed/accuracy tradeoff of the algorithm.",turns out to be a key ingredient in
3733.txt,"We therefore elaborate next on the specific properties of the WH projections, which make them suitable for our needs.",make them suitable for
3734.txt,"In Sections 5.1 and 5.2, we give further implementation details.",null
3737.txt,When designing our locality sensitive hash functions we will use a standard procedure of projecting each high dimensional point to some 1dimensional linear subspace.,null
3738.txt,"However, while in the standard computation of the L2 distance the L2 accumulates at a constant pace, in the case of the WH kernels with their increasing frequency ordering, the first projections typically capture most of the energy of the distance.",in the case of
3739.txt,This means that evaluating the distance with fairly few projections gives an efficient way to lower-bound the true distance.,gives an efficient way to
3740.txt,"We therefore compute, a priori, a subset of WH projections of all the patches of the image.",null
3741.txt,"This set of projections is used for L2 distance approximation, as described above.",is used for
3742.txt,"A much smaller subset of these projections, is used for hashing .",is used for
3743.txt,The straight forward way to use the LSH search scheme for image patches would have been to treat each d-by-d patch as a d2 vector in Euclidian space and the rest follows.,null
3745.txt,"Instead, we follow the general lines of the LSH scheme, but replace several of its main ingredients with new ones, which are designed to exploit the image patches setup.",are designed to
3746.txt,"At the Indexing stage, we replace the family of LSH functions with a new set of functions, which make use of the WalshHadamard kernels  .",make use of
3747.txt,"At the search stage, we dramatically extend the set of candidate patches that are considered, compared to the limited set of patches that point to the same index.",compared to
3748.txt,We term the resulting scheme Coherency Sensitive Hashing .,null
3750.txt,Our indexing scheme is based on that of  Datar .,is based on
3751.txt,"In our case, however, each vector is an image patch and we do not project it onto random lines, but rather on a fixed set of   the leading  2D Walsh Hadamard kernels.",null
3752.txt,"The motivation for this choice was given earlier in Section 4 and we now discuss the details, highlighting how this stage differs from the original one.",null
3754.txt,The differences are highlighted in Figure 2 and can be summarized as follows .,be summarized as follows
3755.txt,"Since points are vectors of pixel intensities, this translates to an approximately fixed number of bins per projection.",null
3756.txt,"In CSH, we assign each projection line  a number of bins that is proportional to the dispersion of patch projection values.",is proportional to
3757.txt,"The higher the frequency of the kernel, the less the projections are dispersed, but rather they concentrate around 0.",null
3758.txt,"Also, projections of the luminance(Y) component of patches tends to be more wide spread  compared to the chroma  components.",compared to
3759.txt,"In general, we restrict the number of bins per projection to be a power of 2.",In general
3760.txt,"In CSH, on the other hand, we aim at having an even spreading of samples across the bins.",on the other hand
3761.txt,This will enable making efficient usage of the limited number of bits that make up the code.,making efficient usage of
3762.txt,"For a certain projection its bin boundaries; In terms of X, we did the bit allocations manually , and keep them fixed for all images.",null
3763.txt,Increasing the number of bits is equivalent to a denser subdivision of the space.,is equivalent to
3764.txt,"This will guarantee better similarity of points that have the same code, but it comes  at the risk of having many  points,  whose  relevant NNs are all assigned different hash values.",null
3765.txt,"The fixed values, which were determined to ensure good overall behavior and were used throughout our experiments, are specified in Figure 3.",are specified in
3769.txt,"We therefore expect to have a fixed percentage of samples in each of the bins, except for the first and last ones.",null
3770.txt,Some examples of this automatic bin assignment are shown in Figure 4.,are shown in
3772.txt,"Note also that the random shifting is the only source of variability between the L hash tables, since as opposed to the original LSH we use a fixed set of projection lines.",as opposed to
3773.txt,"In the Indexing stage we built a set of L hash tables, with the desired property of local sensitivity in the appearance plane.",null
3774.txt,"Namely, that similar patches   are likely to be hashed to the same entry.",null
3775.txt,"The straight forward LSH search scheme would have simply implied, for each patch  in  image  A, to consider the set of patches of image B, which are hashed to the same entry in any of the L tables.",null
3776.txt,"The resulting set of potential candidates is rather small, does not exploit the known spatial arrangement of the patches and does not allow propagation of information between patches.",null
3777.txt,"Instead, CSH runs a search over L iterations,   in which it creates a rich set of candidates by combining cues of both appearance and coherence of location in a novel manner.",null
3778.txt,Let   gi   denote   the   hash   code       used   to   create the hash table Ti.,used   to
3781.txt,"On the other hand, Observation 4 follows from the coherency of patches in the image.",On the other hand
3783.txt,LSH uses exactly the candidates of type 1.,null
3784.txt,"These candidates on their own are especially limited, mainly since they do not exploit image coherency, but also since they do not take advantage of appearance similarity between patches in image A.",take advantage of
3785.txt,"On the other hand, PatchMatch exploits only image coherency.",On the other hand
3786.txt,"One clear limitation of PatchMatch, which our algorithm overcomes, is its assumption that mappings that are mostly smooth may achieve pleasing approximations.",null
3788.txt,"This approach works well on large contiguous areas that appear in both images, since a proper random guess will propagate to the whole area.",null
3789.txt,"However, it has difficulties in textured areas, which are not replicated in both images.",it has difficulties in
3790.txt,"In our approach, we intensively relate patches which collide under some hash function.",null
3791.txt,Such collisions occur based entirely on the appearance of the pair of patches without any relation to their spatial arrangement.,null
3792.txt,The spatial layout of our mapping is much less continuous compared to that of PatchMatch.,compared to
3794.txt,Given the candidate set all that remains is to find the nearest one.,null
3795.txt,This step of the algorithm is actually the main overall time consumer.,null
3796.txt,"We therefore resort to an approximation of the process, which has a negligible impact on the overall precision but greatly reduces run time.",has a negligible impact on
3797.txt,This is where we make a second use of the Walsh Hadamard   projections.,make a second use of
3798.txt,We use them here in the way Hel-Or et al.,null
3800.txt,"The idea is that accumulating the squared differences between the projections of a pair of patches on the WH kernels, one at a time, produces an increasingly tighter lower bound on the squared Euclidean distance between the patches, following Equation 3.",null
3802.txt,"This method incorporates an early termination mechanism, rejecting a candidate once  the  sum of projected differences exceeds the current nearest approximation of patch distance.",null
3803.txt,"In Figure 6 we specify  the exact set of kernels, used for the approximation.",used for
3804.txt,"Notice that as the patch dimension grows, we  need  a  smaller  and smaller portion of projections, enabling the ranking of candidates to be increasingly efficient.",null
3806.txt,In this section we propose several extensions to the basic CSH scheme.,null
3808.txt,"One exception is the projection bin edge locations, which are determined by sampling the distributions of the projected patches.",null
3809.txt,"Unlike those, both the selection  of which of the WH kernels to use and the number of bits assigned to each one were determined manually in a way that is proportional to the dispersion of values in each of  the projections, averaged over many image-pair instances.",null
3810.txt,In the indexing stage of the CSH hashing scheme the hash functions used do not depend on the images being matched.,null
3811.txt,"One exception is the projection bin edge locations, which are determined by sampling the distributions of the projected patches.",null
3812.txt,"Unlike those, both the selection  of which of the WH kernels to use and the number of bits assigned to each one were determined manually in a way that is proportional to the dispersion of values in each of  the projections, averaged over many image-pair instances.",null
3815.txt,We first compute the variance of the patch projections on each of the WH kernels.,null
3816.txt,"Each projection is initially allocated one bin and we then iteratively allocate an extra bit to the projection, whose average variance per bin is the largest.",null
3817.txt,"We consider two alternatives to this extension, depending on the way we divide the values  into a certain number of bins.",null
3818.txt,In the first option which we term CSH-AP the bin edges are determined in such a way that an equal number of samples fall into each bin.,null
3819.txt,"In the second option CSH-AKM  the bin edges are computed by a 1-dimensional k-means procedure , which by definition minimizes the average within-bin sample variance.",null
3820.txt,In Section 7.2 we compare these two variants against the regular CSH hash-function as well as to other leading hashing schemes found in the literature.,as well as
3821.txt,Nearest-Neighbor methods typically support the option of retrieving the k   nearest-neighbors of a given query point .,null
3822.txt,"Such a need may arise in many applications and a good example in the scenario of patches of images is in the Non-Local-Means   denoising algorithm, where a patch is denoised using a large set of patches from its vicinity, and the contribution of a patch exponentially drops with the squared L2 distance from the source patch.",null
3823.txt,"Therefore, the general contribution is typically dominated by the several most similar patches while the contribution of the rest of the patches is negligible.",null
3824.txt,A method for retrieving the k nearest patches would have enabled significantly accelerating the process or alternatively enabling searching in a wider vicinity of the patch.,null
3825.txt,The Generalized PatchMatch algorithm enables such a kNN search.,null
3826.txt,"Note that in this  case the goal is to minimize the same error as in the ANN  problem, where and additional average is taken over the k retrieved neighbors.",null
3827.txt,"At the beginning of the run, the best-candidate map is initialized to contain k random locations per patch.",At the beginning of
3828.txt,"Then, at the search stage, we keep the k best candidates seen so far, by evicting the worst candidate from the list when a good new candidate is found.",null
3829.txt,"In addition,we widen our hash table to keep more patch representatives per table entry.",In addition
3830.txt,"It happens that given a pair of images A and B, it is required to compute NNFs in both directions.",it is required to
3832.txt,"As a result, the bi-directional NNF can be computed at a major saving in runtime, with a negligible increase in memory.",As a result
3833.txt,Many patch based methods for video enhancement extensively compute dense matches between 3-dimensional space-time patches.,null
3834.txt,We extend CSH in this direction and experiment on computing space-time NNFs between pairs of videos.,null
3835.txt,CSH extends naturally to incorporate the additional temporal dimension.,null
3836.txt,We repeated the process of manually:  selecting the set  of  3D  WH  kernels  that  are used for L2 distance approximations.,are used for
3839.txt,"The Generalized PatchMatch is an extension of PatchMatch, which enables adding rotation or even rotation and scale to the search space.",null
3840.txt,Their approach was to handle this kind of flexibility by adding new dimensions to the basic 2-dimensional search space.,null
3841.txt,"This clearly makes it harder to find good matches, based on the random search and propagations scheme.",based on
3842.txt,We take a different approach and handle the addition of rotation by normalizing patches with respect to it4.,with respect to
3843.txt,"This was the approach taken by SIFT  and other methods, which make local descriptions invariant to rotation.",null
3844.txt,"Specifically, the normalization is done at each location by taking an interpolated patch in the prominent gradient orientation which is chosen according to a weighted voting scheme.",according to
3845.txt,Taking rotation into consideration required several adaptations in the CSH scheme.,null
3847.txt,The final output of the algorithm is a translation and rotation value per patch.,null
3848.txt,The rotation value is taken to be the difference between the rotations of the two matching normalized patches.,null
3849.txt,In this section we report on different experiments we performed to validate the algorithm and its different extensions.,null
3850.txt,"In Section 7.1, we compare CSH to PatchMatch in terms of the speed-accuracy tradeoff on a large data-set we collected.",compare to
3851.txt,In Section 7.2 we compare the CSH hash function and its variants to other hashing codes.,null
3852.txt,"In Section 7.3 we discuss additional properties of the the CSH mappings, which are shown to be essential for the task of patch-based reconstruction  .",be essential for
3853.txt,"The k-NN, video and rotation extensions are demonstrated in Sections 7.5, 7.6 and 7.7.",are demonstrated in
3854.txt,PatchMatch implementation was taken from the PatchMatch website5.,null
3855.txt,"Both algorithms were run in a single core configuration on a 2.66 GHz machine, with 8 GB of RAM.",null
3857.txt,"However,  instead of constructing the complete index of L hash tables and then searching through them sequentially, our implementation performs L iterations of the index and search steps, using only one table at a time.",instead of
3858.txt,"For further improvement in memory consumption, one could compute the WH projections on the fly, while making a slight change in ordering in the ranking stage.",making a slight change in
3859.txt,"This is possible, since we use them in a sequential order that complies with the Gray Code ordering of these kernels.",null
3861.txt,"In order to compare speed, take a certain error rate and compare how long it would take to reach it by each of the algorithms.",In order to
3862.txt,"For instance, the error rate that PatchMatch reaches after 5 iterations is reached by our algorithm 3 or 4 times faster.",For instance
3863.txt,"In this experiment we directly measure the efficiency of  the CSH hash function, which is compared to several alternative hash functions within the CSH (LSH-based) framework.",is compared to
3864.txt,"To do so, for a given image pair we take a random set of source-image query patches as well as the entire set of target-image patches, all which are hashed  into 16 bit code words, using a variety of possible hash functions.",as well as
3865.txt,"The first alternative hash-function, is the baseline standard LSH hash function, in which 16 random projection lines are used, each allocated a single bit.",null
3866.txt,Note that this hash functions is totally agnostic to the input data.,null
3867.txt,"Next, several state-of-the art quantization methods which all largely exploit the specific distribution of the input vectors.",null
3868.txt,"These are Product Quantization , Iterative Quantization and the more recent Optimized Product Quantization.",null
3869.txt,We also report results  for three variants of the CSH hash function.,null
3871.txt,Notice in the legend the average coding times for encoding the entire set of patches of a  pair of images.,null
3872.txt,The  main observation  is that the CSH hash function finds large amounts of low-error matching patches at a very competitive runtime.,null
3874.txt,"On the other hand, a large fraction of query patches do not have similar patches in the target and minimizing their error is of lower importance.",On the other hand
3875.txt,"In this sense, considering the K-means based variant CSH-AKM ,  its curve is generally above that of the original CSH, however, it is lower in the important low-error range.",it is lower in
3876.txt,"Therefore, it is less efficient in our setup.",it is less efficient in
3877.txt,The other proposed variant CSH-AP  only slightly outperforms the original version and is therefore less attractive due to its runtime overhead.,due to
3879.txt,PatchMatch  and  CSH  differ  in  the  way  the  quality  of  a match depends on the energy level of  the  patch  .,null
3880.txt,"Generally speaking, PatchMatch copes slightly better with flat areas, while CSH does better in the mid range and going towards textured, edgy patches.",Generally speaking
3881.txt,"This is, again, due to the locality of the PatchMatch search and propagation, which will work well in large homogeneous areas, but will fail in high energy areas where usually nearby patches might only be well matched to patches that are very distant in the target image.",due to
3883.txt,"For each such decile of patches we calculated the mean error of the patch matches, produced by each of the algorithms.",null
3884.txt,"In Figure 10, we plot the difference between the PatchMatch error and the CSH error for each of the deciles.",null
3885.txt,The general trend of the plot is clear and consistent across the range of patch energies.,null
3886.txt,"We argue that the distribution of errors produced by CSH is preferable to that of PatchMatch, since it is known that errors along edges and textured areas have a much stronger visual impact compared to inaccuracies in textureless areas.",it is known that
3888.txt,"For instance, incoherence of 1 at a pixel, means that all the patches containing it map coherently .",For instance
3889.txt,The maximal coherence is the patch size.,null
3890.txt,This definition is illustrated in Figure 11.,is illustrated in
3891.txt,"In PatchMatch, the vast  majority  of final matches are ones that were directly propagated from neighboring patches or randomly  found  extremely  close to them.",null
3892.txt,"In CSH, different good quality matches that are spatially spread in the target image have a fair chance to be found by the algorithm.",null
3896.txt,This correlation between incoherence and reconstruction is shown experimentally in section 7.4.,is shown experimentally in
3897.txt,The combination of these CSH properties is useful in various image editing and denoising applications.,is useful in
3898.txt,"We demonstrate this in the most direct manner, using the reconstruction of a source image A, given a target image B and a dense patch map from A to B.",null
3899.txt,This kind of reconstruction is the main ingredient of the patch based versions of the above mentioned applications.,null
3900.txt,We use the code supplied with PatchMatch to calculate the image reconstruction and its quality.,null
3901.txt,It simply replaces each pixel with the average of the corresponding pixels that it is mapped to by all patches that contain it.,it is mapped to
3902.txt,This kind of averaging was shown X to maximize the Directional Similarity from A to B.,null
3903.txt,"We use as a baseline the ground-truth  mapping, which results in the best  possible  reconstruction  under  the Bidirectional Similarity framework.",results in
3904.txt,The results are summarized by the table in Figure 12.,are summarized by
3905.txt,The RMSE error is the square root of the mean  of the squared L2 norm between original and reconstructed pixels.,null
3906.txt,It can be seen from the table that the CSH average error is more than 20 percent lower than that of PatchMatch.Figure 13 clearly shows the correlation we discussed in Section 7.3.2 between mapping incoherence and reconstruction error.,It can be seen from the table that
3908.txt,We report the averages of each of these 3 percentiles over all sample patches from all the images.,null
3909.txt,"Similarly, we experiment on computing a KNN field between a video and itself.",null
3910.txt,"This would be a common building block in many block-based methods for video editing applications, which are out of the scope of this article.",null
3911.txt,"Here again, we use the same four scaled video clips and report average and standard deviation of the computed k = 25 NNs.",null
3912.txt,"These are compared relative to ground-truth errors, which were measured on 100 random patches.",null
3913.txt,The results are summarized in Figure 17.,are summarized in
3914.txt,"The running was executed on the entire VidPairs dataset, at four different combinations of patch and image dimensions.",null
3915.txt,"Figure 18 summarizes the average errors for each of the four configurations, for the different modes of CSH and PatchMatch respectively.",null
3916.txt,"As can be seen, in the case of CSH, allowing the additional degree of freedom enables    a reduction of the error by around 10%.",As can be seen
3917.txt,"PatchMatch is unable to benefit from the extra degrees of freedom, since the significant increase in the search space size makes its random search component less efficient.",is unable to
3918.txt,"We proposed an algorithm for computing ANN fields termed Coherency Sensitivity Hashing, which follows the concepts of LSH search scheme, but combines image coherency cues, as well as appearance cues in a novel manner.",as well as
3919.txt,"It was shown to be faster than previous methods and more accurate, especially in textured areas.",It was shown to
3920.txt,"In addition, its high incoherence improved reconstruction results, which are at the basis of many patch based methods.",
3921.txt,"Finally, some natural extensions of the basic search scheme were developed in order to facilitate their usage in many common patch-based algorithms.",
3922.txt,"General dynamic scenes involve multiple rigid and flexible objects, with relative and common motion, camera induced or not.",
3923.txt,The complexity of the motion events together with their strong spatio-temporal correlations make the estimation of dynamic visual saliency a big computational challenge.,
3924.txt,"In this work, we propose a computational model of saliency based on the assumption that perceptual relevant information is carried by high-order statistical structures.",
3925.txt,"Through whitening, we completely remove the second-order information of the data, gaining access to the relevant information.",
3926.txt,The proposed approach is an analytically tractable and computationally simple framework which we call Dynamic Adaptive Whitening Saliency  .,
3927.txt,"For model assessment, the provided saliency maps were used to predict the fixations of human observers over six public video datasets, and also to reproduce the human behavior under certain psychophysical experiments.",
3928.txt,"The results demonstrate that AWS-D beats state-of-the-art dynamic saliency models, and suggest that the model might contain the basis to understand the key mechanisms of visual saliency.",
3929.txt,"Experimental evaluation was performed using an extension to video of the well-known methodology for static images, together with a bootstrap permutation test which yields additional information about temporal evolution of the metrics statistical significance.Spatio-temporal saliency, visual attention, adaptive whitening, short-term adaptation, eye fixations.",
3930.txt,"In particular, the perception of visual  saliency allows human beings to fast detect, process and act over the most informative parts of a signal,  greatly simplifying the vision problem  .",
3931.txt,"As our nervous system has a limited ability to simultaneously process all incoming sensory information, a set of processescollectively called attentionselects and modulates the most relevant information for each behavior.",
3932.txt,"Multiple perceptive and cognitive operations, under a hierarchical control process, establish global priorities to highlight some locations, objects or features in the visual field  .",
3933.txt,This can be accomplished by controlling eye movements  to bring some locations/objects into the fovea   or by increasing the processing of visual  information in neurons that represent peripheral regions of visual field .,
3934.txt,"This peripheral vision is perceived with lower spatial resolution but with higher temporal resolution, it therefore seems to be more correlated with the processing of movement.",
3935.txt,"Both types of attention, can be inadvertently driven by visually appealing stimulus or willingly modulated depending on the individual goals  .",
3936.txt,"Since the first achievements in implementing the architecture proposed by Koch and Ullman ,  much research effort has been expended on the development of selective visual attention models based on saliency maps.",
3937.txt,"According to this hypothesis, attention is driven by low-level image features   different from those of their  neighborhoods.",
3938.txt,"Alternatively, an object-based mode of selection has also been suggested and implemented following two different strategies.",
3939.txt,"The first combines spatial saliency maps with the results  of a segmentation process to produce object-based saliency maps, while the second groups chunks of visual features, corresponding to proto-objects, as the units of saliency computation.",
3940.txt,"Currently, there exist an active debate about which space or object-based saliency maps are the best predictors of human fixations;  however,  this  issue  is controversial and remains unsettled.",
3941.txt,"The increasing popularity of visual attention models has extended their use in applications such as image and video compression, multisensory 3D saliency , object and action recognition , video surveillance.",
3942.txt,"However, in most models the saliency maps only include static features and this information is not necessarily salient in dynamic contexts; a static object with distinct color and/or texture may not be clearly perceived as relevant in a context with moving objects.",
3943.txt,"For this reason, the logical evolution of the static models is to incorporate motion features on their architectures.",
3944.txt,"Nevertheless, most of the methods proposed up to date only take into account the differences between consecutive frames without taking full account of further motion analysis.",
3945.txt,But this motion features do not guarantee saliency when dealing with videos where ego-motion or dynamic backgrounds are encountered.,
3946.txt,"To cope with these difficulties, it is necessary to assume non realistic oversimplifications of the general case, or embrace different viewpoints.",
3947.txt,"Our approach was built upon the idea of visual patterns of local energy, which from a spatialtemporal multiscale decomposition are able to capture relevant motion in video sequences without need for any assumption as the aforementioned.",
3948.txt,Ocular movements are exemplary measurable manifestations of visual attention.,
3949.txt,"From discrete fixations recorded by an eye tracker for a set of humans, a continuous human saliency map can be computed and then objectively compared to saliency maps obtained by computational models.",
3950.txt,Researchers have reached  a broad consensus on using this methodology to assess static saliency models   and to identify pending challenges .,
3951.txt,"Nevertheless, in the case of dynamic scenes the assessment methodology has to be extended to include new measures which take into account the behavior over time.",
3952.txt,"From a computational point of view, the problem of saliency map estimation is to devise a dissimilarity measure, defined over an appropriate visual feature space, which should be able to predict human fixations to some extent.",
3953.txt,"Our approach, named AWS-D  , extends the capabilities of the AWS for computing both static and dynamic saliency maps, trough two independent processing pathways.",
3954.txt,"Over each channel, the AWS-D is rooted on the hypothesis that saliency could have a deep connection with the variability of the local energy measured over a statistically decorrelated and normalized space.",
3955.txt,We provide below the arguments that support our decisions.,
3956.txt,"In the human visual system  , the mechanisms of visual attention codify and prioritize visual data.",
3957.txt,"This may be interpreted in terms of the classical sensory coding hypothesis of Barlow  , which claims that the neurons should codify the sensory information by reducing the high level of redundancy in input signal along the visual pathway.",
3958.txt,"Given that images are highly structured, this operation only removes correlations between pixels with low perceptually informative content, exposing the most visually appealing structures associated with high order statistics .",
3959.txt,The first place where the whitening mechanism appears is the retina.,
3960.txt,"Ganglion cells exhibit center surround receptive fields whose effect could be similar to data whitening, resulting in a signal re-encoding in photoreceptors that removes correlations in space, time and color.",
3961.txt,"This effect is roughly approximated by the color bands whitening in the first stage of our model, which gives a less redundant representation of the incoming signal adapted to its statistical structure.",
3962.txt,"However, the role of redundancy reduction in the retina   cannot be the same as in later stages like cortex .",
3963.txt,"There, its role could be favor the learning of data statistics in a decorrelated and normalized variance space, which only contains the most conspicuous higher order structures.",
3964.txt,"Under this assumption, our proposal aims to deter mine saliency by searching the space-time points with maximum variability in the distribution of the local energy across spatial-temporal scales and orientations , regarding mean distribution.",
3965.txt,"This approach has the following advantages: the mean distribution of local energy for each orientation is calculated through the mean over scales in the whitened space, and the dissimilarity measure can be simplified to an Euclidean metric, instead of obtaining the maximum variability on each point with respect to the mean distribution  of the local energy for the set of scales for each orientation.",
3966.txt,"In this normalized space, the Euclidean metric is equivalent to the Hotellings T-squared statistic in   a non normalized space.",
3967.txt,"Besides, the extracted visual features derive from an overcomplete representation of the image/video, obtained through a fixed bandpass filter set, that represents the long-term adaptation of the HVS to the statistics of natural images.",
3968.txt,"However, the role of redundancy reduction in the retina   cannot be the same as in later stages like cortex.",
3969.txt,"There, its role could be favor the learning of data statistics in a decorrelated and normalized variance space, which only contains the most conspicuous higher order structures.",
3970.txt,"Under this assumption, our proposal aims to determine saliency by searching the space-time points with maximum variability in the distribution of the local energy across spatial-temporal scales and orientations, regarding mean distribution.",
3971.txt,"This approach has the following advantages: the mean distribution of local energy for each orientation is calculated through the mean over scales in the whitened space, and the dissimilarity measure can be simplified to an Euclidean metric, instead of obtaining the maximum variability on each point with respect to the mean distribution  of the local energy for the set of scales for each orientation.",
3972.txt,"In this normalized space, the Euclidean metric is equivalent to the Hotellings T-squared statistic in   a non normalized space.",
3973.txt,"Besides, the extracted visual features derive from an overcomplete representation of the image/video, obtained through a fixed bandpass filter set, that represents the long-term adaptation of the HVS to the statistics of natural images.",
3974.txt,We propose an  extension  of  the  AWS  architecture to the spatial-temporal domain.,
3975.txt,"It exploits plausible BU saliency mechanisms like whitening for visual adaptation and multiresolution analysis, delivering a simple computational solution that combines static and dynamic saliency.",
3976.txt,"New elements include:1)Adaptation of the spatial-temporal scale decomposition to the statistics of each time interval, based on whitening.",
3977.txt,Contextual adaptation of the static approach is extended to a short-term adaptation in the space-time.,
3978.txt,This is to our knowledge the first attempt to implement an explicit short term visual adaptation of the feature basis as the key mechanism to determine dynamic saliency.,
3979.txt,"In the new equalized space, saliency is easily computed as the contribution of each point  in the space-time to the variability of local energy.2)Previous saliency models commonly rely on the knowledge of the explicit background model, the assumption of temporal coherence, or the estimation of optical flow or relative motions to compute motion saliency.",
3980.txt,Our approach is free of these restrictions.,
3981.txt,"Regarding evaluation methodology, we propose to analyze the statistical reliability of models predictions across video frames.",
3982.txt,"Besides, we adapted the shuffling technique to achieve a NSS metric   that tackles central bias and border effects.",
3983.txt,"4)A new video dataset was built in order to close two major gaps found in most of the existing public datasets through: 1) minimization of TD effects that may reduce inter-observer consistency, and 2) providing enough number of fixations.",
3984.txt,A wide variety of static saliency models has emerged over the last years based on different computational and mathematical paradigms.,
3985.txt,"Then, we provide a short review of the most notable ideas that have had repercussion in the dynamic saliency.",
3986.txt,"Under the paradigm of biological plausibility, an early approach by Itti was to add basic motion features   to their static model.",
3987.txt,"Later, Harel reformulated the previous model of Itti from a graph based perspective .",
3988.txt,"Le Meur  and Marat adopted similar and more elaborated approaches, linking dynamic relevance to the relative motionbetween consecutive framesof regions against the background.",
3989.txt,"Assuming the movement consistency through different scales and  time,  Culibrk  created a background multiscale model to segment the foreground.",
3990.txt,The most extended criterion to determine visual conspicuity is based on measures of center-surround   contrast over different visual features.,
3991.txt,Mahadevan and Vasconcelos quantify  saliency  based  on dynamic textures which model spatial-temporal patches without the need to compensate egomotion.,
3992.txt,Seo and Milanfar use a pixel/voxel level metric as the probability of it being salient.,
3993.txt,The main handicap of the C-S paradigm relies on the tendency to  favor  spatial  over  temporal contrast.,
3994.txt,"To get a more far-reaching movement analysis, it is necessary a spatial-temporal multiscale decomposition of a video frame volume to give more weight to the temporal dimension.",
3995.txt,"In this line, Belardinelli proposed an approach to determine coherent movements by identifying energy signatures on 2D planes in the space-time volume.",
3996.txt,There are at least three main groups  of  models  that identify salient points as those whose features deviate from normality or a priori expectations.,
3997.txt,The point of view adopted to learn the  normality  and  how to measure the distance to this pattern determines the different conceptual approaches.,
3998.txt,"In the first group, we can find the models with their basis linked to Information Theory and Natural Image Statistics.",
3999.txt,They use Independent Component  Analysis     to learn basis functions from patches of a set of representative natural images.,
4000.txt,The convolution of the image/video with those basis allows the  access  to the joint and conditional distributions of the visual features and determine the most informative points through statistics.,
4001.txt,"Representative examples of these models are AIM, SUNDAY or ICL.",
4002.txt,"In a second group of Bayesian approaches, Itti and Baldi
  formulate the hypothesis of the central role of   the spatial-temporal surprise in visual attention and compute a saliency map by the evaluation of the dissimilarities between the a priori and the a posteriori distributions of the visual features around each point, by using the Kullback-Lieber divergence.",
4003.txt,"Finally, we have the models based on transformed-domains.",
4004.txt,"In the first place,  the  spectral  models  are  based  on  the hypothesis that saliency measure is equivalent to the residual difference between the perceived image spectrum and the one expected for natural images  .",
4005.txt,Guo  et al.,
4006.txt,discovered that similar results are achieved using the inverse Fourier Transform of the phase spectrum.,
4007.txt,Li demonstrated that both approximations are equivalent and produce the same effect that a border detector convolved with a Gaussian filter.,
4008.txt,"More recently, the idea of the spectral residual has been extended to dynamic saliency by Bian and Cui.",
4009.txt,Similarly  proposes the PQFT model that extends the Fourier Transform to a windowed Fourier Transform of quaternions.,
4011.txt,"Lastly, the compressed-domain visual saliency models operate on the information found in a partial decoding of compressed video bitstream,
  and extract features such as block-based motion vectors, prediction residuals, block coding modes, etc.",
4012.txt,"Therefore, compressed-domain visual saliency models are attractive due to their lower computational cost and the adequacy for several Internet-based multimedia applications.",
4013.txt,"Recently, deep learning schemes have succeed in predicting human fixations  .",
4014.txt,"However, they do not discriminate among bottom-up saliency, biases and top down influences that are usually present in training data.",
4015.txt,"Besides, deep learning approaches do not explain psychophysical evidence, as illustrated in Fig.",
4016.txt,1,
4017.txt,"We  think  that  bottom-up  saliency  responds to basic coding principles that justify the development of models based on unsupervised signal processing, in order to disentangle bottom-up saliency from other influences on visual attention.",
4018.txt,Transparent forward coding schemes based on such principles   and deep learning schemes that learn biases and top-down guidance on specific contexts provide complementary insights.,
4019.txt,"Therefore, their combination may be expected to boost predictive capabilities in any situation.The architecture of the AWS-D model is divided in two main pathways: Frames are routed through an spatial path to compute a static saliency map for each of them, while  a temporal path processes shots of n consecutive frames in order to obtain their dynamic saliency maps.",
4020.txt,Both paths are fed with the output of the chromatic stage and are combined again at the output stage.,
4021.txt,The chromatic stage is responsible of whitening color components to adapt the chromatic space to the statistical structure of each frame.,
4022.txt,The latter integrates the static and dynamic saliency maps for each frame.,
4023.txt,Static and dynamic saliency maps have to be integrated to produce a single saliency map for each frame.,
4024.txt,"We have taken an approach similar to Bur  , placing the emphasis on the map with the clearly highest informative content, if any.",
4025.txt,"Otherwise, both maps are integrated through a competitive scheme implemented as a weighted sum.",
4026.txt,Weights are proportional to the relative significance of the corresponding maps.,
4027.txt,"We compute these values as the inverse of the number of local maxima of the saliency maps above a threshold T = m + , where m and  are estimated as the mean and standard deviation of the corresponding map.",
4028.txt,"More formally, the fusion is described by: We have selected two classic saliency experiments to quantitatively evaluate the performance of the AWS-D model: 1) reproducing results of human psychophysical experiments on bottom-up visual saliency, and 2) predicting human fixations while viewing videos.The experimental design was based on three pillars which guarantee objective appraisal of results: 1) wide diversity of videos to avoid biases that favor some models, 2) selection of objective measures supported by a broad scientific consensus and 3) comparing results against state-of-the-art bottom-up dynamic saliency models.After analyzing the characteristics of the previous public datasets, we found that most of them have some of the following shortcomings: a) low number  of fixations per frame high value of this parameter is desirable to get reliable statistics; lack of a set    of synthetic videos including a wide collection of dynamic pop-out effects and c) low value of the InterObserver Congruency   was used to save fixation positions of the two eyes.",
4029.txt,"The subjects were sited in front of a 1280 1024 pixel resolution screen, 60 cms away.",
4030.txt,The identification of fixations was done with the BeGazeTMsoftware.,
4031.txt,"Videos were classified into two main categories: real scenes  and synthetic sequences with pop-out dynamic effects , both with and without cases of camera egomotion.We compared our model with fourteen state-of-theart dynamic saliency models.",
4032.txt,The models were selected based on three criteria.,
4033.txt,"they incorporate dynamic features in their design and implementation,  they are representative  of  the diversity of the state-of-the-art and  authors code is publicly available.",
4034.txt,This model calculates the saliency map of each frame  from  the  50%  of the total number of fixations of all the subjects in the experiment.,
4035.txt,"It is a very optimistic upper threshold, that allows us to put in perspective the scores of all model under the same measure.",
4036.txt,"This model randomly selects pixels as salient in each frame, so its results can be used  as lower bounds for the scores of the models.",
4037.txt,This model predicted that the central positions of the image are more salient than further ones.,
4038.txt,"Its shape is a 2D Gaussian function fitted to frame sizes.We have used hybrid methods  , which involve saliency maps and a set of fixations acquired from human observers, to assess models?performance.",
4039.txt,"Owing to the dynamic nature of videos, the number of fixations on individual frames is usually low.",
4040.txt,"Therefore,  it  is  advisable  to  use  robust  measures to cope with data-poor situations.",
4041.txt,In the work of  Wilming   the  performance  of different evaluation measures were analyzed to conclude that the Area Under the receiver-operating-characteristic Curve seems to be the best choice for evaluating models of fixation selection.,
4042.txt,"Besides, we have used the normalized scanpath salience measure  due to its low demand for data and the ability to compensate the center bias effect.",
4043.txt,"We have discarded Kullback-Leibler Divergence, despite its highly consistent theoretical bases, because it needs lots of data to estimate probability density function, it is strongly influenced by the binning of this function, and it is of this bias are not compensated during the measurements, it could happen that CENTER model is able   to predict fixations better than most computational models.",
4044.txt,"Moreover, those models that somehow give the heaviest weights to central positions would have a comparative advantage.",
4045.txt,Zhang proposed to apply a shuffling technique to the AUC measurement  to compensate this bias.,
4046.txt,"Contrary to traditional approaches to AUC estimation, the false positive   are not randomly chosen for each frame, but they are the set of fixations on another frame randomly selected from the dataset.",
4047.txt,"This FP selection process is applied to calculate several AUC measures, and the s-AUC is the mean value of all these measures.",
4048.txt,"This shuffling results in a s-AUC value close to 0.5 for the CENTER control model, tackling center bias and border effects, and proving the best option for model comparison.",
4049.txt,"In this work, we extended the same methodology to deal with videos, so that FP are selected from among the fixations of a random frame of another randomly selected video from the  same  dataset.",
4050.txt,"Concerning the NSS measure, Borji concluded that it suffers from the C-B that represents an important shortcoming.",
4051.txt,"Nevertheless it is possible to compensate for C-B, by adapting the shuffling to give the s-NSS measure: where Nf is the number of video frames, SMi is the saliency map of frame i and NT P is the number of fixations in this frame, and xk is the position of The center-bias  refers to the tendency of human observers to look at the image center.",
4052.txt,A ranking based on a global measurement over each dataset needs to be made to compare the behavior    of a set of saliency models.,
4053.txt,This ordering should be complemented with statistical tests that answer the next questions: Is the rank ordering statistically significant?,
4054.txt,and  could the values obtained  for  each measure be explained by the random selection of fixations at each video frame?,
4055.txt,The first question is answered checking whether the A ranking based on a global measurement over each dataset needs to be made to compare the behavior    of a set of saliency models.,
4056.txt,"This ordering should be complemented with statistical tests that answer the next questions: The first question is answered checking whether the We use the bootstrap both to obtain the 95% BCa (Bias-Corrected and accelerated confidence intervals and to perform the permutation test, because it is less restrictive and more robust than classical statistical methods, and it does not make any assumption about data normality.Fig.",
4057.txt,4 shows a sample of the application of a permutation test together with the s-AUC measure.,
4058.txt,"The percentages %ut and %lt when the s-AUCt curve is above ut or below lt, respectively represent the percentages of time when the measured values are significant.",
4059.txt,"When the values are lower than lt, it exists a strong disagreement between human fixations and model predictions  .",
4060.txt,"The differences between scores of the H-50 model and the first classified have increased, now they are statistically significant.",
4061.txt,"Apart from the above mentioned exceptions, the results under s-NSS are similar.Temporal quantitative analysisReal videos make differences on temporal behavior more evident.",
4062.txt,The percentage of time that the AWS-D produces significant values under both measures is %ut 75%.,
4063.txt,"This percentage shrink by more than 10 percentage  points for the models included in the second group, and almost 58 percentage points compared with the last.",
4064.txt,"Nevertheless, the H-50 model is 15 percentage  points higher than AWS-D, leaving it half way between the ideal human observer and all the other computational models.",
4065.txt,Only three models   show a similar behavioral stability under egomotion.,
4066.txt,"On the contrary, the performance of the rest of the models is affected by this change.Fig.",
4067.txt,"7 shows the performance of the AWS-D model over the whole CITIUS dataset for three cases: using only static features, using only motion features, and considering both static and dynamic features  .",
4068.txt,The dynamic path achieves better performance than the static path and holds statistical significance for longer.,
4069.txt,The fusion scheme with motion priority exceeds the results obtained separately by static and dynamic paths.,
4070.txt,That indicates that the combination of both pathways provides the best approach to saliency estimation and it is statistically better than static-only approach with independence of the measure.,
4071.txt,Fig.,
4072.txt,8 shows exemplary cross-section of video frames in the five public datasets.,
4073.txt,Tabs.,
4074.txt,5-9 and Fig.,
4075.txt,"9 show the results obtained by the models.The model AWS-D heads four of the five rankings, independently of the measure.",
4076.txt,"Of utmost importance, in two of the five, the differences between AWS-D with the second classified are statistically significant.",
4077.txt,"With DIEM dataset, models MVE+SRN and OBDLMRF get the best scores, but not statistically signif icant from the ones reached by AWS-D.",
4078.txt,"The values   of the Kendal factor are in the interval [0.94, 0.99] revealing a strong agreement between the two measures.",
4079.txt,"Below the AWS-D model, rank-orders change across datasets, and also there is a high overlap among the intervals of confidence.",
4080.txt,"As expected, as  the variety and amplitude of the stimuli increase, the performance of the computational models go down with respect to the upper bound determined by the H-50 model, up to a maximum of 20%.Note that regarding time percentages of statistical significance with the s-AUC measure and CITIUS  , DIEM and GC datasets, the best models obtain average values around 60 70%, while the figures for the worst models are in the range 30%.",
4081.txt,"With the AE-UCFSA, ASCMN and CRCNS datasets the percentages are significantly lower, reaching the minimum  with the CRCNS dataset due to the low number of human fixations.",
4082.txt,"This provokes a widening of the signification intervals and although the s-AUC are high, they are not enough to pass the instantaneous significance thresholds.",
4083.txt,For that reason the results obtained with this dataset are not statistically significant.,
4084.txt,"The amount of fixations per frame of the CRCNS should be increased, as suggested by X.
Quantitative Analysis Fig.",
4085.txt,"10 shows a comparative visual assessment with the saliency maps of the best models against the human maps, using two videos for each public dataset used on this work.",
4086.txt,"In this work, a purely bottom-up model is proposed which is able to detect visual saliency both in static  and dynamic image sequences.",
4087.txt,The underlying principle behind the model is that saliency arises  on those points with maximum variability of the spatialtemporal local energy in a multiscale representation.The basic mechanism is adaptive whitening that reduces the redundancy present in input images based on their own second order statistics.,
4088.txt,"The results achieved clearly support the validity of bioinspired hierarchical processing, decorrelation, and whitening as suitable elements for the design of general bottom-up attention models, capable to process dynamic scenes.",
4089.txt,"Moreover, the clear advantage under egomotion conditions suggests a similar advantage of the model in future more realistic datasets of unconstrained attention in 3D environments.The ability of our model to predict human fixations and its performance over dynamic pop-out experiments demonstrate its superiority over existing stateof-the-art models.",
4090.txt,The assessment was done using standard metrics together with a reliability test.,
4091.txt,"This test was introduced in order to estimate the temporal significance of the models  , but also to assess the quality of the set of human fixations provided with each dataset.",
4092.txt,"Incidentally, the application of the shuffling technique to the NSS compensates the center bias eliminating one of its main handicaps, that makes it even more valuable as a measure to compare saliency models.Besides, a new video dataset for assessment of BU visual saliency models was presented.",
4093.txt,"The CITIUS dataset includes dynamic pop-out synthetic stimuli,  a large numbers of fixations on every video frame and the videos have been chosen to minimize the observers top-down bias and thus leaving indoor environments, mass sports and so on, out.",
4094.txt,"These characteristics make CITIUS a valuable video dataset to complement existing ones.We will concentrate future efforts on two areas: first, we expect to improve computational efficiency by exploring alternatives to the most memory/time consuming processes and through parallelization; second, we will explore the  extraction  of  saliency  at  the proto-object level by including competitive stages to empower the base-grouping mechanisms that the AWS-D model implicitly contains.",
4095.txt,"As an interesting and emerging topic, co-saliency detection aims at simultaneously extracting common salient objects from a group of images.",
4096.txt,"On one hand, traditional co-saliency detection approaches rely heavily on human knowledge for designing hand-crafted metrics to possibly reflect the faithful properties of the co-salient regions.",
4097.txt,"Such strategies, however, always suffer from poor generalization capability to flexibly adapt various scenarios in real applications.",
4098.txt,"On the other hand, most current methods pursue co-saliency detection in unsupervised fashions.",
4099.txt,"This, however, tends to weaken their performance in real complex scenarios because they are lack of robust learning mechanism to make full use of the weak labels of each image.",
4100.txt,"To alleviate these two problems, this paper proposes a new SP-MIL framework for co-saliency detection, which integrates both multiple instance learning   into a unified learning framework.",
4101.txt,"Specifically, for the first problem, we formulate the co-saliency detection problem as a MIL paradigm to learn the discriminative classifiers to detect the co-saliency object in the ""instance-level"".",
4102.txt,The formulated MIL component facilitates our method capable of automatically producing the proper metrics to measure the intra-image contrast and the inter-image consistency for detecting co-saliency in a purely self-learning way.,
4103.txt,"For the second problem, the embedded SPL paradigm is able to alleviate the data ambiguity under the weak supervision of co-saliency detection and guide a robust learning manner in complex scenarios.",
4104.txt,"Experiments on benchmark datasets together with multiple extended computer vision applications demonstrate the superiority of the proposed framework beyond the state-of-the-arts.Co-saliency detection, multiple-instance learning, self-paced learning.",
4105.txt,"Typically, image groups from certain sources, e.g., similar subjects, websites, or companies, are huge in size and share common objects or events.",
4106.txt,"Thus, it is of great interest to identify the common and attractive objects from all images in such groups for mining the intrinsic knowledge and facilitating further utilization from them.",
4107.txt,"However, in practice, the image groups are achieved under complex settings and scenarios, like diverse background, illumination conditions, and view point variations.",
4108.txt,"Consequently, this task is also of great challenge.",
4109.txt,"To tackle this problem, cosaliency detection has been proposed and attracts intensive research attention in the recent years   .",
4110.txt,"The main aim of the co-saliency detection task is to explore the most important information, i.e., the common and salient foreground object regions from a group of images weakly pre-annotated as containing such similar objects, while their object categories, intrinsic characteris-tics and locations in images are entirely unknown.",
4111.txt,"As one extension of the traditional saliency detection  , such a co-saliency detection task is evidently more challenging while more promising to perform in real applications.",
4112.txt,"It is not only expected to be used in multi-camera systems directly, but also hopeful to provide more precise common foreground prior to be served as a helpful preprocessing step for multiple related real-world applications, such as the video/image foreground cosegmentation and image co-localization.",
4113.txt,"In this paper, we not only focus on the fundament of this problem, i.e., developing insightful and effective approach for co-saliency detection, but also verify the effectiveness of using the proposed method to facilitate more practical computer vision applications.",
4114.txt,"Most previous methods for this task need to first manually design certain metrics for helping possibly explore the intra-image contrast and preserve the inter-image consistency, and then to directly integrate these metrics to demarcate the co-saliency regions among all images.",
4115.txt,"There are, however, mainly two limitations in such learning framework.",
4116.txt,"Firstly, the manually designed metrics are typically too subjective to generalize well and flexibly adapt various scenarios encountered in practice, especially due to the lack of thorough understanding of the biological mechanisms of human visual attention.",
4117.txt,"Secondly, most current methods pursue co-saliency detection in unsupervised fashions.",
4118.txt,"This, however, tends to weaken their performance in such complex scenarios, where there are only a relative small number of really informative data.",
4119.txt,"Actually, the co-saliency information is weakly an-notated to the image groups, where we coarsely know if there are co-salient regions in images or not.",
4120.txt,"However, the current methods have not made full use of such weak annotations in co-saliency detection.",
4121.txt,"For solving the first problem, we make the first effort to clarify a natural relationship between co-saliency detection and MIL problems, and accordingly utilize the latter to facilitate a self-learning strategy for producing the insightful metrics under the former problem.",
4122.txt,"Specifically, in co-saliency detection, images with  containing a certain kind of co-salient objects can be considered as positive bags and superpixel regions in each image can be considered as instances.",
4123.txt,"In this case, the co-saliency detection problem can be naturally reformulated as an MIL problem.",
4124.txt,"Basically, the instance-level MIL aims at learning the classifiers which can minimize the intra-class distance among positive instances from each positive bag and maximize the inter-class distance between positive and negative instances.",
4125.txt,The classifiers so learned can then be utilized to predict the locations of the co-salient objects in the instance  level.,
4126.txt,"Thus, by implementing MIL for co-saliency detection, the insightful metrics, which can well explore the intra-image contrast and preserve the inter-image consistency, are expected to be derived from the learned MIL classifiers, and co-saliency regions are hopeful to emerge from the recognized positive instances.As for the second problem, we propose an effective way to model the problem in a weakly supervised fashion, which can better take advantage of the coarse-level image labels and gradually transfer them to more fine-level superpixel labels.",
4127.txt,"Actually, since co-salient regions are always concealed inside many easily confused image regions in practical cases, robust learning strategy  which can learn from subsets of high-confidence data and thus possibly avoid the chaos derived from the large  amount of ambiguous data under such weak supervision context tends to be critical.",
4128.txt,"Inspired by the recently proposed selfpaced learning   theory, we embed an improved SPL paradigm into our framework to alleviate the data ambiguity and guide a robust learning manner in complex scenarios.",
4129.txt,The basic SPL model   mainly considers the sample easiness to gradually learn from the easy/faithful training samples to the complex/confusable ones.,
4130.txt,"In this paper, we additionally explore two helpful prior knowledges on the structure of co-salient objects in SPL, which are the sample diversity, and spatial smoothness , respectively.",
4131.txt,"Specifically, the sample diversity encourages the learner to select training instances from a wide range of images in each given image group, which can enable the subsequent learning process to better take account of the co-salient objects in different scales, view-points, poses and shapes.",
4132.txt,The spatial smoothness encourages the spatial adjacent instances are assigned with similar impotent weights.,
4133.txt,"Thus, the proposed sample diversity and spatial smoothness  factors can work complementarily to enforce the real-valued weights of the training instances to have both the good inter-image property and the good intra-image property.",
4134.txt,"In addition, different from the l2,1-norm-based sample diversity regularizer, this paper ameliorates the sample diversity term as a convex negative l0.5,1-norm, which not only more complies with the original SPL axiomic definition, but also naturally leads to a more rational real-valued sample weighting scheme rather than the binary one as in X.According to the above discussion, a novel SP-MIL framework is naturally constructed for co-saliency detection as shown in Fig.",
4135.txt,"By intrinsically integrating the aforementioned MIL and SPL paradigms into a unified model, the proposed SP-MIL model is expected to be able to discover the faithful co-saliency patterns from the large number of ambiguous image regions.",
4137.txt,"Specifically, the MIL component in SP-MIL facilitates to solve the cosaliency detection problem in a self-learning way, which is capable of automatically producing proper metrics to measure the intra-image contrast and the inter-image consistency for co-saliency detection.",
4138.txt,"In addition, integrated with the newly proposed self-paced regularizers, the SPL component in SP-MIL introduces an important sample selection mechanism to the learning framework and thus makes the proposed learning strategy more stable and robust in real complex scenarios.",
4139.txt,"Consequently, the limitations existed in current co-saliency detection methods can thus be ameliorated under the proposed self-learning framework.The basic framework of the proposed SP-MIL strategy is shown in Fig.",
4140.txt,"Given an image group, we consider the images within this group as the positive bags and the similar images searched from other groups as the negative bags.",
4142.txt,The superpixels in each image are considered as the instances.,
4143.txt,"After feature extraction, we use SP-MIL to alternatively update co-salient object detector and annotate pseudo-labels for training instances in a SPL manner.",
4144.txt,"Finally, the co-saliency maps are generated through spatial map recovery.",
4145.txt,"In summary, the contributions of this paper are mainly four-fold:By clarifying a natural relationship between cosaliency detection and MIL, we incorporate the MIL component into the proposed framework to learn implicit metrics for co-saliency detection.We propose a novel SPL formulation via introducing two useful prior knowledges for co-saliency detection, i.e., the sample diversity, and the spatial smoothness, in the learning regime, which can lead to the convex solutions and real-valued sample weighting scheme.?We propose a novel and general SP-MIL paradigm by integrating MIL and SPL into a unified model.",
4146.txt,The proposed SP-MIL model can gradually achieve faithful knowledge of co-saliency in a pure selflearning way.We extend the proposed approach to three typical computer vision applications and achieve the competitive or even better performance as compared with the state-of-the-art methods specifically designed on those problems.The rest of this paper is organized as follows.,
4147.txt,Section 2 introduces related works.,
4148.txt,Section 3 presents the proposed SP-MIL model.,
4149.txt,Section 4 describes the details of the proposed SP-MIL framework.,
4150.txt,Section 5 shows experimental results to substantiate the effectiveness of the proposed method.,
4151.txt,Section 6 extends the proposed approach to three real-world computer vision applications.,
4152.txt,"Finally, conclusions are drawn in Section 7.",
4153.txt,Co-saliency detection aims at finding out the common and salient regions from a group of related images just as humans review them.,
4154.txt,"Different from the conventional saliency detection, co-saliency detection needs to explore the interactive information in group level rather than in image level, which makes it far more challenging beyond traditional saliency detection issue in one image.",
4155.txt,The first wave of co-saliency detection methods was developed to discover co-saliency from image pairs.,
4156.txt,"Specifically, in 2010, Jacobs firstly defined visual co-saliency as the visual saliency of image pixels or regions in the context of other images.",
4157.txt,"Around one year later, Li proposed a co-multilayer graph model to explore the multi-image saliency and established a public co-saliency dataset.",
4158.txt,"Then, Chen   and Tan better enhanced the performance on this problem via the sparsedistribution-based representation and bipartite graph matching, respectively.",
4159.txt,"To further detect co-saliency from multiple images, the second wave of interest   appeared in 2013 with the work of Li.",
4160.txt,"Afterwards, Fu proposed a cluster-based algorithm to more comprehensively explore the contrast cue, the spatial cue, and the corresponding cue to detect the co-salient regions.",
4161.txt,"Liu further proposed a hierarchical segmentation based model, where the regional contrasts, global similarity, and object prior are calculated based on multiple-level segmentation.",
4162.txt,Cao imposed a rank constraint to exploit the relationship of multiple pre-designed saliency cues and then assigned the self-adaptive weight to generate the final cosaliency map.,
4163.txt,"Very recently, Zhang made the earliest effort to introduce the deep and wide information for co-saliency detection, where their Bayesian framework integrated the designed intra-image contrast and intragroup consistency metrics.",
4164.txt,"As can be seen, most existing methods heavily rely on manually designed metrics to explore the properties of the co-salient regions.Compared with the conference version of the work, this paper makes the following extensions: 1) We introduce an additional term in the self-paced regularizer to explore the spatial smoothness of the superpixel instances during the learning process.",
4165.txt,"Albeit looking simple, the added smoothness term can help evidently improve the performance of the proposed method, as verified in the results of Section 5.",
4166.txt,2) We compared with more state-ofthe-art approaches to demonstrate the effectiveness of the proposed framework in co-saliency detection task.,
4167.txt,3)  More comprehensive evaluations have also been conducted to analyze capability of the models and components in the proposed framework.,
4168.txt,"4) We substantially extended the applications of the proposed model to video foreground segmentation, activity localization, and object co-localization problems.",
4169.txt,All attained state-of-the-art performance in average as compared to the state-of-the-art techniques designed for those problems.,
4170.txt,Co-segmentation is closely related to the co-saliency detection.,
4171.txt,The difference of such two research topics mainly lies in three-fold aspects: 1) Co-saliency detection only focuses on discovering the common and salient objects from the given image groups while co-segmentation methods additionally tend to possibly precisely segment out the similar but non-salient background regions .,
4172.txt,Co-segmentation usually needs semior interactivesupervision while co-saliency detection is implemented in an unsupervised or super-weakly supervised manner.,
4173.txt,"3) Compared with co-segmentation, cosaliency, as a concept stemming from human vision, usually needs to introduce common pattern analysis into the contrast-based visual attention mechanism to reveal the sampling strategy of human visual system.",
4174.txt,Thus it also receives greater interest in the field of visual cognition.,
4175.txt,"As can be seen, image co-segmentation is a relative higherlevel computer vision task, where co-saliency detection models can be applied to replacing the user interaction to provide the informative prior knowledge of the visually similar objects under much weaker conditions and implemented as a pre-processing step for the cosegmentation task.",
4176.txt,"Another topic related to co-saliency detection is weakly supervised semantic segmentation    , whose goal is to assign semantic labels to each image pixel under the weak supervision of image-level annotations.",
4177.txt,"This topic was firstly proposed by Vezhnevets, which casted this task as a MIL problem and further leveraged the multi-task learning to import useful knowledge from a supplementary geometry context estimation task.",
4178.txt,"Afterwards, they further proposed a multi image model in X to recover the pixel labels via connecting superpixels from all training images in a data driven fashion and a Bayesian optimization framework in X to select the best model in a pre-defined parametric family of CRF models without using superpixel labels.",
4179.txt,"More recently, Yao described the intrinsic representation of superpixel regions via a discriminative deep feature learning framework and exploited both the global context about co-occurrence of visual classes and the local context around each image region to mine effective supervision information.",
4180.txt,"Based on the reconstruction error, Zhang evaluated the basis superpixels of each category and obtained the optimal classification model parameter via an iterative merging update algorithm.",
4181.txt,"Zhang presented a joint conditional random field model leveraging various contexts to address the social images with noisy image-level labels.To our best knowledge, the most essential difference between WSSS and co-saliency is that the former aims to learn the visual semantics from the weakly labeled data while the latter aims to learn the concept of co-saliency.",
4182.txt,"As there is no direct relationship between the visual semantics and the concept of cosaliency, the tactics and methodologies designed to address these two tasks also tend to be different.",there is no direct relationship between
4183.txt,"In addition, it is also obvious that WSSS inclines to understand the global scenes of the images while co-saliency detection only focuses on the co-salient object regions in the images.","In addition, it is also obvious that"
4184.txt,"Thus, co-saliency detection could benefit more to the object-centric computer vision tasks as we demonstrated in the following application section.",null
4185.txt,MIL was first proposed in X for classifying molecules in the context of drug design.,was first proposed in
4186.txt,A typical class of these MIL models focused on learning the desired classifiers in the "bag-level".,focused on
4187.txt,"These approaches, usually need to design mechanisms to map the instances of each bag into a ""bag-level"" training vector, where each instance is served as an individual dimension in the new feature space.",null
4188.txt,"To solve the finer-level problems existed in some challenging computer vision tasks, weakly supervised object localization  and saliency detection, another class of the MIL models is proposed to learn the desired classifiers in the ""instance-level"".",is proposed to
4189.txt,"An inspirational work was the mi-SVM proposed by Andrews, which heuristically solved the mixed integer quadratic programs in the extended SVM learning approach.",null
4190.txt,"Afterwards, Gehler introduced a novel objective function with the deterministic annealing algorithm to find better local minima.",null
4191.txt,"To further enhance the robustness of MIL, Cao introduced similarity weights to the instances and built an extended SVM-based predictive classifier by following a heuristic strategy.",null
4192.txt,"With a generalized soft-margin SVM, a primal form of the instance-level MIL formulation can be written as which aims to learn discriminative functions to separate positive and negative instances and assign accurate labels to each instance in the positive bags.",aims to
4193.txt,The notations of the variables will be explained in Section 3.1.,null
4194.txt,"Inspired by the learning process of humans/animals, the theory of self-paced   learning is proposed lately.",null
4195.txt,The idea is to learn the model iteratively from easy to complex samples in a self-paced fashion.,null
4196.txt,"The effectiveness of such a newly proposed learning regime, especially its robustness in highly corrupted data, has been validated in various computer vision tasks.",has been validated in
4197.txt,"For example, Supancic used the formalism of SPL to automatically learn robust appearance model in object tracking.",null
4198.txt,"For accommodating the ""hidden"" information of the samples into the learning procedure, Tang  proposed to adaptively select easy samples in each iteration to learn the powerful dictionary.",null
4199.txt,They also proposed a nonconvex regularizer to incorporate the information of diversity in X.,null
4202.txt,"Especially, the SPL paradigm has been integrated into the system developed by CMU Informedia team, and achieved the leading performance in challenging TRECVID MED/MER competition organized by NIST in 2014.",been integrated into
4203.txt,"Recently, Zhao also applied SPL in matrix factorization by gradually including matrix elements into the training process from easy to complex.",null
4204.txt,"In SPL, the goal is to jointly learn the model parameters wand the latent weight variable v by minimizing:which indicates the loss of a sample is discounted by a weight.",null
4205.txt,The notation of the variables can be referred to in Section  3.1.,be referred to
4206.txt,The first learning criterion is the sample diversity.,null
4210.txt,"As we know, a rational curriculum for a pupil should include not only the examples of suitable easiness matching her learning pace but also some diverse examples for her to possibly develop more comprehensive knowledge.",null
4211.txt,"Likewise, a rational SPL should consider not only the sample easiness but also the sample diversity.",null
4212.txt,This principle is more evident and natural in the co-saliency detection context.,null
4213.txt,"Essentially, the common objects appearing in each image of a certain image group are in different scales,view-points and exhibit different poses, shapes, structures and appearances  .",null
4214.txt,"Without the diversity regularizer, the learner tends to be stuck to a local region of training image space, which would lead to the poor sample selection performance during the learning process.",
4215.txt,"Therefore, an additional diversity regularizer is needed here to encourage selecting instances from different images and thus enforce the learner to take consideration of all the aforementioned diverse factors.",
4216.txt,"To this end, we propose a novel SPL regularizer: where y is the parameter imposed on the negative l0.5,1 term which favors selecting diverse samples residing in more bags.",
4217.txt,"The main idea of the proposed SP-MIL is to first distinguish faithful image co-saliency regions from easy   instances, and then gradually transfer the learned knowledge to recognize more complex ones.",
4218.txt,Such an idea can be formulated as.,
4219.txt,"That is, minimizing this diversity term tends to disperse non-zero elements of v over more bags, and thus favors selecting more diverse samples.",
4220.txt,"Consequently, this anti-group-sparsity representation is expected to realize the desired
diversity.",
4221.txt,The second learning criterion is the spatially smooth weights of the instances in each bag/image.,
4222.txt,"As a complementary regularizer term with the diversity term which aims to select instances from different images in the image group, the proposed smoothness term is to encourage the selected instances in each image to be located with the smooth connections, i.e., the spatial adjacent instances are assigned with similar impotent weights.",
4223.txt,We show an example to study this problem more clearly in Fig.,
4224.txt,"As we can see, without using the smoothness term, the selected instances  are located without a smooth connection and only a limited number of instances are selected in each image.1 is the parameter imposed on the spatial regularization term which encourages the solution with desired spatial smoothness.",
4226.txt,"As can be seen, it is a simple but effect way to encourage the instances with close spatial distance to share similar importance weights.",
4227.txt,"More importantly, by involving this regularization term, the obtained new regularizer still remains to be convex.",
4228.txt,"Thus, it can be effectively solved by adopting some off-the-shelf convex optimization toolkits.",
4229.txt,"As introduced in the next section, the gradient descend algorithm can be readily employed to solve the optimization problem.",
4230.txt,The proof is also listed in the supplementary material.,
4231.txt,"Alternatively, when additionally considering the spatial relationship of the training samples, we need to find the optimal solution of the model with the self-paced regularizer of X.",
4232.txt,"In this relatively more difficult case, the explicit solution of the problem cannot be obtained in theory.",
4233.txt,"The problem, however, is still convex and thus can also be efficiently solved by utilizing certain off-theshelf optimization techniques, e.g., the CVX toolbox  , to finely approach its global solution.",
4234.txt,"With the same architecture as the ""CNN-S"" model proposed in X, the CNN used in this paper consists of 13 convolutional layers, 5 pooling layers, and 1 fully connected layer, where the 5 convolutional layers before each polling layer are considered as the feature maps representing the image content from low level to high level.",
4235.txt,"As the convolution and polling operations in CNN lead to feature maps in different scales, we upsample each of the feature maps to the scale of the original input image.",
4236.txt,"Then, the obtained feature maps can represent each pixel of the input image.",
4237.txt,"To represent the superpixel regions extracted by X, we max-pool the feature vectors located within the corresponding superpixel regions.",
4238.txt,"The obtained 1888 dimensional feature vectors are the hypercolumn representations for the instances needed to be inferred in our SP-MIL model.In this section, we propose details of applying the SP-MIL algorithm, i.e., Algorithm 1, to automatically inferring the co-saliency of each superpixel region.",
4239.txt,First we discuss the initialization issue.,
4240.txt,"we need to initialize pseudo labels and SPL weights for all training instances firstly, and then iteratively train the co-saliency detector until convergence.",
4242.txt,"For initialization, we can just easily take any off-theshelf single-image saliency detection approach.",
4243.txt,"In this paper, we adopt the graph-based manifold ranking method due to its computational efficiency.",
4244.txt,"After obtaining the initial score of each superpixel, we select the top 10% superpixels in each positive bag, i.e., the image from the current image group, as the initial positive samples.",
4245.txt,"For negative samples, we follow X to extract the Gist and Color Histogram as the image feature and use the averaged image feature to represent the current image group.",
4246.txt,Then we follow X to search 20 similar images from other image groups based on the Euclidean distance.,
4247.txt,"Finally, the bottom 10% superpixels in the searched images are selected as the negative samples.",
4248.txt,"The weights of the initial positive samples are the initial saliency scores of these superpixels given by X, while the weights of all the initial negative samples are equal to 1.",
4249.txt,We then discuss the termination condition setting issue.,
4250.txt,Updating the co-saliency detector as well as  the  labels and weights of the training samples alternatively could progressively lead to a strong co-saliency detector.,
4251.txt,"To judge when the algorithm reach convergence, we calculate the Kullback-Leibler   divergence of two Gaussian distributions which are inferred by the positive samples in the previous and the current iteration, respectively.",
4252.txt,"In order to obtain co-saliency maps with satisfactory spatial recovery, we explore the spatial relationship of the adjacent superpixels in each image by adopting a graphbased manifold ranking model.",
4253.txt,"Different from the smoothness term used in X, such spatial map recovery step is to enforce the adjacent superpixels to have similar co-saliency values to present the smoothly high-lighted co-salient object regions in the obtained co-saliency maps rather than encouraging the self-paced regularizer to select and assign similar important weights to the spatially adjacent superpixel instances during the learning process.",
4254.txt,"Specifically, we adopt a graph model to smooth the cosaliency values of each superpixel by considering its adjacent ones.",
4255.txt,The graph is established by connecting the superpixels adjacent with each other as well as the superpixels at the four image boundaries.,
4256.txt,"Then, we set an adaptive threshold to select the foreground superpixels and use them to calculate the cosaliency values of other superpixels in each image via a ranking function  .",
4257.txt,We evaluated the proposed algorithm on two public benchmark datasets: the iCoseg dataset   and the MSRC dataset.,
4258.txt,To the best of our knowledge the iCoseg dataset is the largest publicly available dataset so far widely used for co-saliency detection.,
4259.txt,It contains 38 image groups of totally 643 images with manually labeled pixel-wise ground-truth masks.,
4260.txt,The MSRC dataset contains 7 image groups of totally 240 images with manually labeled pixel-wise ground truth masks.,
4261.txt,"The complex background of the MSRC dataset makes it more challenging for co-saliency detection.To evaluate the performance of the proposed method, we compared our approach with other state-of-the-art cosaliency detection methods based on five criteria: the precision recall  curve, the average precision , the ROC curve, the AUC, and the F-measure.",
4262.txt,"In addition, we also conducted comprehensive experiments to analyze the properties of the model and components in the proposed framework based on the two most widely used measures AP and F-measure.",
4263.txt,"To calculate these criteria for each co-saliency map, we first segmented it via a series of fixed thresholds from 0 to 255.",
4264.txt,"Then, the PR curve was drawn by using the precision rate versus the true positive rate at each threshold and the AP score was obtained by calculating the area under the PR curve.",
4265.txt,"F-measure was obtained by using a selfadaptive threshold T =  + E as suggested in X to segment the co-saliency maps, where  and E are the mean value and the standard deviation of the co-saliency map, respectively.",
4266.txt,"After obtaining the average precision and recall via the adaptive threshold T, we defined the Fmeasure as.",
4267.txt,"In our experiments, the CNN was implemented via the MatConvNet toolbox   and the parameter in convergence condition   as the ""OURS-fast"" model and define the proposed SP-MIL model with the regularizer as the ""OURS"" model.We further implemented experiments to compare the average execution time of our models with other state-ofthe-art methods.",
4268.txt,From Table 2 we can observe that the computational cost of OURS-fast model is less than most of the state-of-the-art methods and OURS model also has competitive computational complexity which is much less than the CSHS   method.,
4269.txt,"More encouragingly, both OURS-fast and OURS model can obtain the best performance as evaluated in the next section.",
4270.txt,"In this section, we compared the proposed co-saliency detection approach with 9 state-of-the-art methods.",
4271.txt,"Qualitative and quantitative comparison results on two benchmark datasets, i.e.",
4272.txt,"the iCoseg dataset and the MSRC dataset, are shown in Fig.",
4273.txt,"5 and 6, respectively.",
4274.txt,"Subjective comparison results: For subjective evaluation, we show some co-saliency maps generated by the different methods in Fig.",
4275.txt,"5, which consists of the examples from three image groups in the iCoseg dataset, i.e., the image groups of Panda, Cheetah, and Bear, as well as two image groups in the MSRC dataset, i.e., the image groups of Face and Building.",
4276.txt,The examples in the Panda and Cheetah groups indicate that the proposed approach can uniformly highlight the co-salient regions even if they exhibit different poses and shapes.,
4277.txt,The examples in the Bear and Building groups depict that the proposed approach can precisely detect the co-salient regions even if they are in different scales and points of view.,
4278.txt,"The examples in Face group indicate that the proposed approach can robustly suppress the background regions even when they are very complex and interferential.Quantitative comparison results: For quantitative comparison, we report the evaluation results in Fig.",
4279.txt,6,
4280.txt,"As can be seen, in the iCoseg dataset, the proposed approaches obviously improve the precision even when the recall is high, which implies that our methods have better capability to handle the tradeoff between the precision and recall.",
4281.txt,This also facilitates our methods to obtain the highest F-measure when using the adaptive threshold T to segment the co-saliency maps.,
4282.txt,"In addition, the comparison of the AP and AUC scores in this dataset also demonstrates that the PR and ROC curves of the proposed methods are better than other state-of-the-art methods, respectively.",
4283.txt,"Although SACS can also obtain competitive performance with the proposed methods in this dataset, the hand-designed metrics used by it cannot scope well in more complex scenes in the MSRC dataset as demonstrated below.",
4284.txt,"As for the MSRC dataset, all state-of-the-art methods cannot perform as well as in the iCoseg dataset as shown in Fig.",
4285.txt,6,
4286.txt,"In such challenging case, the proposed approach obtains promising performance than other competing methods.",
4287.txt,"It is easy to see that, as compared with other state-of-the-arts, the proposed approaches obtain obviously better performance in terms of all of the five evaluation criteria.",
4288.txt,"In PR curve, the proposed methods obtain the highest precision along all the recall values.",
4289.txt,"Similarly, the true positive rates of the proposed methods are also higher than other methods along all the false positive rates in ROC curve.",
4290.txt,"In this section, we comprehensively evaluated the proposed SP-MIL model by comparing it with two traditional MIL models and analyzing some baseline performance.",
4291.txt,The traditional MIL models used in this experiment are the ALSVM  .,
4292.txt,"In this experiment, we use the two traditional MIL models to replace the proposed SPMIL model for co-saliency inference, while other parts of the algorithm in the same settings.",
4293.txt,The experimental results are shown in Fig.,
4294.txt,"7, which depict that the traditional MIL models cannot obtain satisfactory performance in co-saliency detection.",
4295.txt,"The main reason is that the traditional MIL methods lack powerful sample selection theory to support them to discovery the most informative samples from a mass of ambiguous instances, especially when using them in the tasks with complex image content.",
4296.txt,"For further analyzing the factors considered in the proposed SP-MIL model, we reported the performance of some baseline models, including the SP-MIL model without considering the real-valued sample weights, the sample diversity, and the sample smoothness , the SPMIL model without considering the sample diversity and the sample smoothness   Even only adopting the most basic selfpaced regularizer, the proposed model,can still largely improve the performance of the traditional MIL models.",
4297.txt,The reason is that OUS-NW-ND-NS tends to select the "easy" instances  reflected by v during the learning process rather than directly using instances labelled by y as in traditional MIL models.,
4298.txt,"Essentially, as the training instances in our task have large ambiguity, learning with all these instances without sample selection can hardly extract the truthful knowledge, which leads to significant performance drop of the AL-SVM and mi-SVM.",
4299.txt,"Each of the three factors proposed in this paper could evidently contribute to the learning capability of the proposed SP-MIL model, which is invariant of the evaluation criterions and test datasets.",
4300.txt,"In this section, we further evaluated the contribution of the components, i.e., the training sample initialization, the co-saliency inference based on SP-MIL, the feature representation, and the spatial map recovery process, in the proposed framework.",
4301.txt,The experiments were implemented on the MSRC dataset.,
4302.txt,"To demonstrate the robustness of the proposed method, we also reported results based on five different initialization methods.",
4303.txt,From Fig.,
4304.txt,9 we can see that:  The initialization results obtained by the single-image saliency detection methods can only provide coarse estimation for co-saliency detection.,
4305.txt,"2) SP-MIL makes significant contribution to the final performance even with conventional features , while learning with deep features could obtain better results.",
4306.txt,"3) Without using the spatial map recovery process, our approach obtains a marginal performance drop, which indicates such post-processing step is helpful to refine the co-saliency maps on the foundation of the SP-MIL prediction.",
4307.txt,The proposed framework is robust to different initiation methods.,
4308.txt,"In summary, all the components in the proposed framework can benefit for the final results, while the most fundamental improvement comes from the proposed SP-MIL model.",
4309.txt,Video foreground segmentation aims at automatically discovering and segmenting the foreground objects in a given video  .,
4310.txt,"For this task, the proposed co-saliency detection approach can be used to provide such regions  of interest because the identical foreground objects in each frame usually share certain coherence.",
4311.txt,"Different from the video saliency detection methods which attempt to discover the foreground objects based on the shape and motion cues, our co-saliency detection approach provides an alternative solution to discover such objects in videos.",
4312.txt,Activity localization aims at localizing every occurrence of a given action within a long video.,
4313.txt,The action or activity required to be localized in each frame is usually displayed by the same one   person.,
4314.txt,"Thus, applying co-saliency detection approach to discover such distinct and frequently occurring person would help to localize the activity in the video.",
4315.txt,"To this end, we also apply the proposed approach to activity localization.",
4316.txt,"Specifically, we follow Tran to make evaluation on 39 videos from the UCF-Sport dataset , which contain three different actions: the ""running"", ""diving"", and ""horseriding"".",
4317.txt,"To use the proposed approach, we first combine all the frames labelled as containing the same action category into one group.",
4318.txt,"Then, we trained the SP-MIL model on these video frames and applied it to generating the cosaliency maps for each frame.",
4319.txt,"Afterwards, the threshold T was easily used to segment the generated co-saliency maps to obtain the binary maps.",
4320.txt,"Finally, the activities were localized by the bounding boxes generated by using the smallest rectangle to enclose the highlight regions in the binary maps of each frame.",
4321.txt,The experimental results are shown in Fig.,
4322.txt,10 and Table 4.,
4323.txt,"As can be seen, our method can obtain an average better performance as compared with two state-of-the-art techniques specifically designed on this task, OSTPD  and M2SOR.",
4324.txt,"Notice that OSTPD and M2SOR are the supervised methods needing human labelled action localizations during the training scheme, whereas our approach performs without using such information.Nowadays, it is of great interest to automatically colocalize the common objects in images obtained from the internet.",
4325.txt,"Similar to co-saliency detection, object co-localization aims at simultaneously localizing the common objects across a set of images which are usually obtained from social media.",
4326.txt,"Instead of co-saliency maps, the output of object co-localization is the bounding boxes which include the common objects.",
4327.txt,Object co-localization is still of great challenging because the objects within them often display a large degree of intra-class variation and inter-class diversity.,
4328.txt,"Since object co-localization shares the similar problem setting and challenges with cosaliency detection, it is expected that the proposed method can be beneficial for this task.",
4329.txt,"To demonstrate the effectiveness of the proposed approach in this application, we crawled the first 50 images returned by the Google image search with keywords ""Golden Retriever"", ""Kobe, Lakers"", and ""LaFerrari"".",
4330.txt,"Since the noisy images containing uncommon objects are beyond the scope of the proposed method, we followed X to remove these images before the experiments.",
4331.txt,As shown in Fig.,
4332.txt,"10, it is easy to observe that the images collected in each image group are of high diversity in pose, background, and points of view.",
4333.txt,"For obtaining the localization bounding boxes, we first applied the proposed approach to train the SP-MIL model in the crawled images and generate the co-saliency maps.",
4334.txt,Then the selfadaptive threshold T was easily used to segment the cosaliency maps.,
4335.txt,"After obtaining the binary maps, we generated the bounding boxes by using the smallest rectangle to enclose the highlight regions.",
4336.txt,"Following the previous work, we use the CorLoc evaluation metric.",
4337.txt,Fig.,
4338.txt,11 and Table 5 display several co-localization results.,
4339.txt,"It is interesting to see that even using such simple post-processing strategy, the proposed SP-MIL approach demonstrates evident benefit to this application, as compared with the previous state-of-the-art techniques designed for this task.In this paper, we have proposed a novel co-saliency detection approach which formulates the co-saliency detection under a MIL framework and introduces the SPL theory into the MIL framework for selecting training samples in a theoretically sound manner.",
4340.txt,"In addition, two useful prior knowledges, including sample diversity and sample smoothness were rationally embedded into such formulated SP-MIL model.",
4341.txt,Comprehensive experiments on two benchmark datasets have demonstrated the effectiveness of the proposed co-saliency detection approach as well as the quality of the proposed SP-MIL model.,
4342.txt,"Good performance of the proposed method in applications of video foreground segmentation, activity localization, and object co-localization has shown its potential usefulness in more extensive computer vision tasks.",
4343.txt,"For future work, we plan to  design a multi-class SPL model for learning of multiple categories of objects jointly;establish effective framework to perform co-saliency detection in more practical yet challenging scenarios where the collected image groups may contain noisy images; and perform large-scale co-saliency detection under a weaker assumption where the collected image group is not constrained to contain only one class of common objects.",
4344.txt,Recognition algorithms based on convolutional networks   typically use the output of the last layer as a feature representation.,
4345.txt,"However, the information in this layer may be too coarse spatially to allow precise localization.",
4346.txt,"On the contrary, earlier layers may be precise in localization but will not capture semantics.",
4347.txt,"To get the best of both worlds, we define the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel.",
4348.txt,"Using hypercolumns as pixel descriptors, we show results on three fine-grained localization tasks: simultaneous detection and segmentation, where we improve state-of-the-art from 49.7 mean APr to 62.4, keypoint localization, where we get a 3.3 point boost over a strong regression baseline using CNN features, and part labeling, where we show a 6.6 point gain over a strong baseline.",
4349.txt,"EATURES based on convolutional networks  have now led to the best results on a range of vision tasks: image classification , object segmentation and detection, action classification, pose estimation and fine-grained category recognition.",
4350.txt,We have thus moved from the era of HOG and SIFT to the era of convolutional network features.,
4351.txt,"Therefore, understanding these features and how best to exploit them is of wide applicability.",
4352.txt,"Typically, recognition algorithms use the output of the last layer of the CNN.",
4353.txt,"This makes sense when the task is assigning category labels to images or bounding boxes: the last layer is the most sensitive to category-level semantic information and the most invariant to ""nuisance"" variables such as pose, illumination, articulation, precise location and so on.",
4354.txt,"However, when the task we are interested in is finergrained, such as one of segmenting the detected object or estimating its pose, these nuisance variables are precisely what we are interested in.",
4355.txt,"For such applications, the top layer is thus not the optimal representation.",
4356.txt,"The information that is generalized over in the top layer is present in intermediate layers, but intermediate layers  are also much less sensitive to semantics.",
4357.txt,"For instance, bar detectors in early layers might localize bars precisely, but cannot discriminate between bars that are horse legs and bars that are tree trunks.",
4358.txt,"This observation suggests that reasoning at multiple levels of abstraction and scale is necessary, mirroring other problems in computer vision where reasoning across multiple levels has proven beneficial.",
4359.txt,"For example, in optical flow, coarse levels of the image pyramid are good for correspondence, but finer levels are needed for accurate measurement, and a multiscale strategy is used to get the best of both worlds  .",
4360.txt,"In this paper, we think of the layers of a convolutional network as a non-linear counterpart of the image pyramids used in optical flow and other vision tasks.",
4361.txt,Our hypothesis is that the information of interest is distributed over all levels of the CNN and should be  exploited  in  this  way.,
4362.txt,"We define the ""hypercolumn"" at a given input location as the outputs of all units above that location at all layers of the CNN, stacked into one vector.",
4363.txt,"On keypoint prediction, we show that a simple keypoint prediction scheme using hypercolumns achieves a 3.3 point gain in the APK metric over prior approaches working with only the top layer features.",
4364.txt,"While there isnt much prior work on labeling parts of objects, we show that the hypercolumn framework is significantly better than a strong baseline based on the top layer features.A version of this paper appeared at CVPR 2015.",
4365.txt,"This paper extends the conference version by introducing a more efficient version of our figure-ground prediction system that is an order of magnitude faster, and a detailed analysis of the error modes.",
4366.txt,"Before delving into the details of our approach, in this section we first provide some useful background on the tasks we are interested in and the models we build upon.The main motivating application in this paper is the task   of Simultaneous Detection and Segmentation .",
4367.txt,The goal in this task is to detect every instance of an object category in an image and segment it out.,
4368.txt,"It thus seeks to   go beyond the coarse bounding boxes output by a typical object detection system; now we want much more precise localization in the form of a pixel-precise segmentation.Note that this kind of an output is very different from    a semantic segmentation system, which assigns category labels to each pixel.",
4369.txt,"Thus a semantic segmentation system does not resolve individual instances: given two dogs in   an image, it would mark out all the dog pixels but will be unable to say how many dogs there are or where one dog begins and the other ends.",
4370.txt,This is a somewhat impoverished output.,
4371.txt,"We believe that delineating individual instances is important for downstream applications: a robot grasping a cup is interested in the precise boundaries of a particular cup, and not just a generic mass of ""cup stuff"".",
4372.txt,"Similarly, a graphics application might involve cropping an object out of one scene and pasting them into another, again requiring the precise segmentation of individual instances.The evaluation metric that we use to measure performance on this task extends the bounding box object detection metric using segments instead of bounding boxes.",
4373.txt,"Concretely, for each category, the algorithm produces a ranked list of object detections, each detection equipped with a predicted segmentation.",
4374.txt,"We go down this list, and for each detection we compute the intersection-over-union of its segmentation with each ground truth segment of this category.",
4375.txt,"We assign the detection to the highest overlapping ground truth object if the overlap is greater than a threshold, and if this ground truth object hasn't previously been assigned a higher ranked detection.",
4376.txt,"Detections matched to ground truth objects in this way are considered true positives, and others are false positives.",
4377.txt,We use this labeling to compute a precision recall curve and report the area under the curve as APr.,
4378.txt,"In this paper we build upon state-of-the-art object detection methods, seeking to augment or enrich their outputs with precise segmentations or part labelings.",
4379.txt,"In particular, we build on the R-CNN object detection system proposed by Girshick.",
4380.txt,R-CNN uses convolutional networks or CNNs   to classify bounding box object proposals.,
4381.txt,"Concretely, R-CNN first uses an off-the-shelf method such as Selective Search to produce a set of 2000 or so candidate bounding boxes per image.",
4382.txt,"In this paper we use MCG , which also produces candidate segmentations and achieves better recall.",
4383.txt,"Next, R-CNN crops each candidate bounding box out of the image, warps it to a fixed size and passes it through a convolutional network.",
4384.txt,"This convolutional network is first trained to classify whole images on a dataset such as ImageNet , and then finetuned on the task of object detection by training it to distinguish between well-localized and poorly localized bounding boxes.",
4385.txt,Further details are in X.,
4386.txt,This time we start with  candidate  segment proposals such as those produced by MCG.,
4387.txt,We then compute two sets of features on each proposal.,
4388.txt,"The first set of features simply takes the bounding box of the segment, crops and warps the box and passes it through a CNN as in R-CNN.",
4389.txt,"The second set of features also crops the bounding box, but masks out the background of the segment before passing it into the convolutional network.",
4390.txt,The two sets of features are concatenated and passed into a classifier.,
4391.txt,This entire architecture can be written as a single convolutional network consisting of two towers conjoined at the very end.,
4392.txt,"In both R-CNN and its SDS counterpart, it was observed that relying exclusively on the proposal generation mechanism to do a good job at localization is not enough; performance improves significantly if the convolutional network features are also used to predict a refined bounding box  or a refined segmentation.",
4393.txt,This second stage thus starts from an already detected but coarsely localized object and predicts a significantly better localization.,
4394.txt,"This second stage is where we focus our attention; our aim is to fully use all the information available in the convolutional network to localize the object better.Combining features across multiple levels: Burt and Adelson introduced Laplacian pyramids, a representation that is widely used in computer vision.",
4395.txt,"Koenderink and van Doorn  used ""jets"", which are sets of partial derivatives of intensity up to a particular order, to estimate edge orientation, curvature, etc.",
4396.txt,Malik and Perona  used the output of a bank of filters as a representation for texture discrimination.,
4397.txt,This representation also proved useful for optical flow] and stereo .,
4398.txt,"While the filter banks in these works cover multiple scales, they are still restricted   to simple linear filters, whereas many of the features in the hypercolumn representation are highly non-linear functions of the image.There has also been work in convolutional networks that combines multiple levels of abstraction and scale.",
4399.txt,Farabet  combine CNN outputs from multiple scales of     an image to do semantic segmentation.,
4400.txt,Tompson  use a similar idea for detecting parts and estimating pose.,
4401.txt,"However, the features being combined still come from the same level of the CNN and hence have similar invariance.",
4402.txt,Sermanet combine subsampled intermediate layers with the top layer for pedestrian detection.,
4403.txt,"In contrast, since we aim for precise localization, we maintain the high resolution of the lower layers and upsample the higher layers instead.",
4404.txt,Maire  also use multiple layers of a trained hierarchical representation for fine-grained localization tasks.,
4405.txt,"However, their representation is trained unsupervised using recursive sparse coding.",
4406.txt,"Contemporaneous with the conference version of this paper , Long  also use multiple layers for their fully convolutional semantic segmentation system.",
4407.txt,A similar approach to semantic segmentation was also described by Mostajabi .,
4408.txt,"More recently, Noh proposed a ""deconvolution"" network that progressively upsampled CNN featuremaps using learnt filters for semantic  segmentation.",
4409.txt,"Fischer  learnt a convolutional network that combined multiple layers to predict optical flow.Detection and segmentation: The task of simultaneous detection and segmentation task, introduced in X, requires one to detect and segment every instance of a category in the image.",
4410.txt,SDS differs from classical bounding box detection  in its requirement of a segmentation and from classical semantic segmentation in its requirement of separate instances.,
4411.txt,"There has been other prior work on segmenting  out instances of a category, mostly starting from bounding box detections.",
4412.txt,Borenstein and Ullman first suggested the idea of using class-specific knowledge for segmentation.,
4413.txt,Yang use figure ground masks associated with DPM detectors to segment out detected objects and reason about depth orderings.,
4414.txt,Parkhi use color models extracted from the detected cat and dog heads to segment them out.,
4415.txt,Dai and Hoiem generalize this reasoning to  all  categories.,
4416.txt,Fidler and  Dong  combine object detections from DPM  with semantic segmentation outputs from O2P to improve both systems.,
4417.txt,"Current leading methods use CNNs to score bottom-up object proposals, both for object detection  and for SDS.Pose estimation and part labeling: Current best performers for pose estimation are based on CNNs.",
4418.txt,Toshev and Szegedy use a CNN to regress to keypoint locations.,
4419.txt,"Tompson show large improvements over state-ofthe-art by predicting a heatmap for each keypoint, where the value of the heatmap at a location is the probability of the keypoint at that location.",
4420.txt,These algorithms show results in the setting where the rough location of the person is known.,
4421.txt,Yang and Ramanan propose a more realistic setting where the location of the person is not known and one has to both detect the person and identify his/her keypoints.,
4422.txt,"Gkioxari show some results in this setting using HOG-based detectors, but in their later work  show large gains using CNNs.Related to pose estimation is the task  of  segmenting out the different parts of a person, a task typically called ""object parsing"".",
4423.txt,Yamaguchi parse fashion photographs into clothing items.,
4424.txt,There has also been work on parsing pedestrians.,
4425.txt,Ionescu jointly infer part segmentations and pose.,
4426.txt,"However, the setting is typically tightly cropped bounding boxes of pedestrians, while we are interested in the completely unconstrained case.",
4427.txt,Wang and Yuille use compositional models of parts to label parts of objects assuming a tightly cropped bounding box.,
4428.txt,Wang consider an extension to CNN-based semantic segmentation where each pixel gets not only a category label but also a part label.,
4429.txt,"Again, this kind of an approach cannot resolve individual instances.",
4430.txt,We assume an object detection system that gives us a set of detections.,
4431.txt,"Each detection comes with a bounding box, a category label and a score  .",
4432.txt,The detections have already been subjected to non-maximum suppression.,
4433.txt,"For every detection, we want to segment out the object, segment its parts or predict its keypoints.For each task, we expand the bounding box of the detection slightly and predict a heatmap on this expanded box.",
4434.txt,The type of information encoded by this heatmap depends on the particular task.,
4435.txt,"For segmentation, the heatmap encodes the probability that a particular location is inside the object.",
4436.txt,"For part labeling, we predict a separate heatmap for each part, where each heatmap is the probability a location belongs to that part.",
4437.txt,"For keypoint prediction, again we output a separate heatmap for each keypoint, with each heatmap encoding the probability that the keypoint is at a particular location.Note that the size 50 above is arbitrary, and other sizes could be used.",
4438.txt,"We chose 50 in initial experiments to get sufficiently sharp masks without sacrificing computational efficiency.Because these feature maps are the result of convolutions and poolings, they do not encode any information about where in the bounding box a given pixel lies.",
4439.txt,"However, location can be an important feature.",
4440.txt,"For instance, in a person bounding box, the head is more likely to be at the top of the bounding box than at    the bottom.",
4441.txt,Thus a pixel that looks like a nose should be considered as part of the  person if it occurs at the top of  the box and should be classified as background otherwise.,
4442.txt,The reasoning should be the opposite for a foot-like pixel.,
4443.txt,"This  is  a  highly  non-linear  effect  of  location,  and  such reasoning cannot be achieved simply by a location-specific bias.",
4444.txt,.,
4445.txt,Such reasoning requires different classifiers for each location.,
4446.txt,Location is also needed to make better use of the features from the fully connected layers at the top.,
4447.txt,"Since these features are shared by all the locations in the  bounding box, they can at best contribute a global instance-specific bias.",
4448.txt,"However, with a different classifier at each location, we can have a separate instance-specific bias for each location.",
4449.txt,"Thus location-specific classifiers in conjunction with the global, instance-level features from the fully connected layer produce an instance-specific prior.",
4450.txt,"The simplest way to get a location-specific classifier is to train separate classifiers for each of the 50  50 locations.However, doing so has three problems.",
4451.txt,"One, it dramatically reduces the amount of data each classifier sees during training.",
4452.txt,"In our training sets, some categories may have only a few hundred  instances,  while  the  dimensionality of the feature vector is of the order of several thousand.",
4453.txt,"Thus, having fewer parameters and more sharing of data    is necessary to prevent overfitting.",
4454.txt,"Two, training this many classifiers is computationally expensive, since we will have to train 2500 classifiers for 20 categories.",
4455.txt,"Three, while we do want the classifier to vary with location, the classifier should change slowly: two adjacent pixels that are similar to each other in appearance should also be classified similarly.To train this interpolated classifier using off-the-shelf classification libraries, we use a simple heuristic and ignore the interpolation at train time, using it only at test time  .",
4456.txt,We divide each training bounding box into a K K grid.,
4457.txt,The training data for the kth classifier consists only of pixels from the kth grid cell across all training instances.,
4458.txt,Each classifier is trained using logistic regression.,
4459.txt,"This training methodology does not directly optimize the loss we would encounter at test time, but allows us to use off-the-shelf code such as liblinear   to train the logistic regressor.",
4460.txt,Training classifiers for segmentation and part localization: For each category we take bottom-up MCG candidates   that overlap a ground truth instance by 70% or more.,
4461.txt,"For each such candidate, we find the ground truth instance it overlaps most with, and crop that ground truth instance to the expanded bounding box of the candidate.",
4462.txt,"Depending on the task we are interested in  , we then use the labeling of the cropped ground truth instance to label locations in the expanded bounding box as positive or negative.",
4463.txt,"For SDS, locations inside the instance are considered positive, while locations outside are considered negative.",
4464.txt,"For part labeling, locations inside a part are positive and all other locations are negative.",
4465.txt,"For keypoint prediction, the true keypoint location is positive and locations outside a certain radius of the true location are labeled negative.One issue with the pipeline we have described above is that it requires cropping and warping each detected instance to a fixed size and passing it through a CNN.",
4466.txt,"While such an approach ensures there is sufficient resolution for fine-grained localization tasks, its computational complexity scales linearly with the number of detections.",
4467.txt,"If there are many highly overlapping detections, then this approach performs potentially redundant computation for each detection.",
4468.txt,"This computational challenge is an issue with the original R-CNN object detection system  , and a lot of recent research on object detection has aimed at speeding up RCNN.",
4469.txt,"The key idea behind these approaches is that instead of warping and computing features on each box proposal separately, some computation can be shared.",
4470.txt,"In particular, the convolutional layers are agnostic to the spatial extent of their input, and so they can be run once on the full image.",
4471.txt,"Then for any box proposal, one can simply crop out the corresponding box out of the resulting feature map to get a feature map for that proposal.",
4472.txt,This feature map can then be fed into subsequent fully connected layers.,
4473.txt,"However, fully connected layers accept a fixed sized input, whereas cropped feature maps will have varied sizes depending on the size of the box.",
4474.txt,He got around this by using a spatial pyramid to pool features before passing them into fully connected layers.,
4475.txt,A spatial pyramid grid divides the feature map into a fixed number of bins.,
4476.txt,"Features are then pooled over each bin, and the pooled  features  from all bins are concatenated into one vector and passed forward.",
4477.txt,This layer is called a spatial pyramid pooling layer or SPP or an ROI pooling layer.,
4478.txt,"Girshick  extended this idea into an end-to-end trainable system for object detection, called Fast R-CNN.The main speedup in such architectures comes from the fact that the convolutional features can be shared among  all the boxes.",
4479.txt,We can extend this idea to incorporate our hypercolumn predictions.,
4480.txt,"In other words, instead of obtaining separate convolutional feature maps for each box by passing the box separately through a CNN, we can pass  the entire image once through the convolutional layers of the CNN and simply crop the appropriate box from each image-level feature map to get the corresponding feature map for the box.",
4481.txt,"Then each such cropped feature map can be convolved with the appropriate classifier weights w(j) and the responses upsampled and summed as before.Note that the features from the fully connected layers, and any classifiers on them, are still separate for each box.",
4482.txt,"As in Fast R-CNN, these features are obtained by first using the ROI pooling layer to get a fixed length feature vector for each box and passed through two fully connected layers.Finally, as before, all this computation can be expressed as a unified network architecture.",
4483.txt,"This architecture is shown in Figure 3.During training, we use this network architecture and stochastic gradient descent to train this system, but only train the final classifier layers and leave all other layers frozen.",
4484.txt,"Because of the per-image nature of this architecture, each minibatch only contains one image.",
4485.txt,"However, to reduce noise in the gradients, we accumulate gradients over 20 minibatches at a time.",
4486.txt,In this paper we only evaluate this idea on the SDS task; however the same idea can also be used to speed up keypoint prediction or part labeling.Our first testbed is the SDS task.,
4487.txt,We  use  the  same datasets and benchmarks as those presented in X.,
4488.txt,We use the PASCAL VOC 2012 Main Train set for train ing  and  the  VOC  2012  Main  Val  set  for  testing.,
4489.txt,We  only use images for which segmentation annotations are available from X.,
4490.txt,Our baseline for this  task  is  the  algorithm  presented in X.,
4491.txt,This pipeline scores bottom-up region proposals  from X using CNN features computed on both the cropped bounding box of the region and the cropped region foreground.,
4492.txt,The regions are subjected to non-max suppression.,
4493.txt,"Finally, the surviving candidates are refined using figure-ground predictions based on the top layer features.",
4494.txt,"As our first system for SDS, we use the same pipeline   as above, but replace the refinement step with one based   on hypercolumns.",
4495.txt,.,
4496.txt,"We present results with this pipeline in section 5.1, where we show that hypercolumn-based refinement is significantly better than the refinement in X, and is especially accurate when it comes to capturing fine details of the segmentation.",
4497.txt,We also evaluate several ablations of our system to unpack this performance gain.,
4498.txt,"For ease of reference, we call this  System 1.",
4499.txt,One issue with this system is its computational cost.,
4500.txt,Extracting features from region foregrounds is expensive and doubles the time taken.,
4501.txt,Producing quality region proposals is also computationally significantly more expensive   than producing bounding box proposals.,
4502.txt,"To address these drawbacks, we propose as our second system the pipeline shown in Figure 4.",
4503.txt,This pipeline starts with bounding box detections after non-maximum suppression.,
4504.txt,We expand this set of detections by adding nearby high-scoring boxes that were removed by non-maximum suppression but may be better localized  .,
4505.txt,"This expanded set is only twice as large as the original set, and about two orders of magnitude smaller than the full set of bottom-up proposals.",
4506.txt,"For each candidate in this set, we predict a segmentation, and score this candidate using CNN features computed on the segmentation.",
4507.txt,"Because region-based features are computed only on a small set, and we no longer rely on expensive region proposal generators, the pipeline is much more efficient.",
4508.txt,"Further, this pipeline is also more general as it can work with any off-the-shelf object detection system.",
4509.txt,We call this system System 2.This pipeline relies crucially on our ability to predict      a good segmentation from just bounding boxes.,
4510.txt,We use hypercolumns to make this prediction.,
4511.txt,"In section 5.2, we show that these predictions are accurate, and significantly better than predictions based on the top layer of the CNN.",
4512.txt,The efficiency of this pipeline also allows us to experiment with larger but more expressive architectures.,
4513.txt,"While used the architecture proposed by Krizhevsky for both the box features and the region features, we show in section 5.2 that the architecture proposed by Simonyan and Zisserman is significantly better.Figure 5 shows the qualitative differences between our hypercolumn-based predictions and the predictions produced by the refinement proposed in X.",
4514.txt,"Our predictions capture more details in general, especially when it comes  to segmenting out thin structures, and are more resilient to occlusion.",
4515.txt,"Table 1 also shows the results of several ablations of our model  :inally, following X, we take our Hyp+FT+bbox-reg system and use the pasting scheme of X to obtain a semantic segmentation.",
4516.txt,"Intuitively, for each image, this pasting scheme chooses detections above a particular threshold, sorts the detections in increasing order of scores, and then splats the predicted figure ground masks in order from the lowest scoring to  the highest.",
4517.txt,"When doing the splatting, the higher scored detections can be pasted on top of lower scored detections, thus overriding them.",
4518.txt,"We get a mean IU of 54.6 on VOC2012 Segmentation Test, 3 points higher than X.For our experiments with System 2, we use the detections of R-CNN as the starting point.",
4519.txt,R-CNN uses CNNs to classify bounding box proposals from selective search.,
4520.txt,We use the final output after non-max suppression and bounding box regression.,
4521.txt,"However, to allow direct comparison with our previous experiments, we retrained R-CNN to work with box proposals from MCG.",
4522.txt,We do all training on VOC2012 Train.We first evaluate our segmentation predictions.,
4523.txt,"As before, we use the same network as the detector to compute the hypercolumn transform features.",
4524.txt,We first experiment with the Alexnet architecture.,
4525.txt,For computational reasons we do not do any finetuning.,
4526.txt,We use superpixel projection as before.We show results in Table 2.,
4527.txt,"Since we use only one network operating on bounding boxes instead of two working on both the box and the region, we expect a drop in performance.",
4528.txt,"We find that this is the case, but the loss is small: we get a mean APr of 49.1 at 0.5 and 29.1 at 0.7, compared to 51.9 and 32.4 when we have the region features.",
4529.txt,"In fact, our performance is nearly as good as X at 0.5 and about 4 points better at 0.7, and we get this accuracy starting from just the bounding box.To see how much of this performance is coming from the hypercolumn representation, we also run a baseline using just fc7 features.",
4530.txt,"As expected, this baseline is only able to output a fuzzy segmentation, compared to the sharp delineation we get using hypercolumns.",
4531.txt,"It performs considerably worse, losing 5 points at 0.5 overlap and almost 13 points at
0.7 overlap.We now replace the Alexnet architecture for the VGG architecture.",
4532.txt,"This architecture is significantly larger, but provides an 8 point gain in detection AP.",
4533.txt,We again retrain the R-CNN system using this architecture on MCG bounding box proposals.,
4534.txt,"Again, for the hypercolumn representation we use the same network as the detector.",
4535.txt,"We use the layers fc7, conv4 with a neighborhood of 1 and pool3 with a neighborhood of 3.",
4536.txt,We observe that the VGG architecture is significantly better than Alexnet: we get a boost of 7.5 points at the 0.5 overlap threshold and 8 points at the 0.7 threshold.,
4537.txt,"We also find that this architecture gives us the best performance on the SDS task so far: with simple bounding box detection followed by our hypercolumn-based mask prediction, we achieve a mean APr of 56.5 at an overlap threshold of 0.5 and a mean APr of 37.0 at an overlap threshold of 0.7.",
4538.txt,These numbers are about 6.8 and 11.7 points better than the results of X.,
4539.txt,"Last but not the least, we observe that the large gap between our hypercolumn system and the only-fc7 baseline persists, and is equally large for the  VGG  architecture.",
4540.txt,This implies that the gain provided by  hypercolumns  is not specific to a particular network architecture.,
4541.txt,Figure 6 visualizes our VGG results of X.,
4542.txt,"Last but not the least, we observe that the large gap between our hypercolumn system and the only-fc7 baseline persists, and is equally large for the  VGG  architecture.",
4543.txt,This implies that the gain provided by  hypercolumns  is not specific to a particular network architecture.,
4544.txt,Figure 6 visualizes our VGG results.We now implement the full pipeline proposed in Figure 4.,
4545.txt,"For this, we expand the initial pool of detections as follows.",
4546.txt,We pick boxes with score higher than a threshold that were suppressed by NMS but that overlap the detections by less than 0.7.,
4547.txt,We then do a non-max suppression with a lenient threshold of 0.7 to get a pool of candidates   to rescore.,
4548.txt,"Starting from 20K initial detections per category across the dataset, our expanded pool is typically less than 50K per category, and less than 600K in total.Next we segment each candidate using hypercolumns and score it using a CNN trained to classify regions.",
4549.txt,This network has the same architecture as VGG.,
4550.txt,"However, instead of a bounding box, this network takes as input the bounding box with the region background masked out.",
4551.txt,This network is trained as described in X.,
4552.txt,"We use features from the topmost layer of this network and concatenate them with the features from the top layer of the detection network, and feed these into an SVM.",
4553.txt,"For training data, we use our expanded pool of candidates on the training set, and take all candidates for which segmentation predictions overlap groundtruth by more than 70% as positive and those with overlap less than 50% as negative.",
4554.txt,"After rescoring, we do a non-max suppression using region overlap to get the final set of detections  .We get 60.0 mean APr at 0.5, and 40.4 mean APr at 0.7.",
4555.txt,These numbers are state-of-the-art on the SDS benchmark.,
4556.txt,Next we experiment with the faster version of hypercolumnbased prediction that uses shared feature maps  .,
4557.txt,We first quantify the speed gain.,
4558.txt,"We train a Fast R-CNN VGG network   on MCG bounding boxes, and use that  as a substrate to train the ""fast"" hypercolumn classifier.",
4559.txt,"Figure 7 plots the time  taken  to  segment  a  set  of  boxes in an image versus the number of boxes, for the ""slow"" crop-and-warp based hypercolumn classifier, and the ""fast"" hypercolumn classifier.",
4560.txt,"While the time taken by the slow system increases linearly with the number of boxes, the time taken by the fast system remains about the same no matter how many boxes we run it on.",
4561.txt,"In particular, it is able to segment 256 boxes in less than 250 milliseconds.We now evaluate whether this performance gain comes at the cost of any loss in accuracy.",
4562.txt,Table 3 shows experimental results using this fast figure-ground prediction.,
4563.txt,"We evaluate three alternatives:To make an apples-to-apples comparison between fast and slow figure-ground prediction,  we  run  our fast figure-ground predictor on  R-CNN detections and compare it with numbers reported  in the previous section.",
4564.txt,"Note that the fast figureground predictor uses a VGG network trained as  in Fast R-CNN as the substrate on which to compute features.Next we take detections from the Fast R-CNN system, and then segment each detection out using our fast figure-ground predictor.",
4565.txt,"Fast R-CNN takes about 500 milliseconds per image to detect all the objects, and the tens or hundreds of detections that are produced are segmented by our system in  a few hundred milliseconds.",
4566.txt,"The total time taken per image is thus less than a second.Finally we implement the detect-segment-rescore pipeline described in the previous section, with Fast R-CNN for the detection step and fast figure-ground prediction for the segmentation step.",
4567.txt,The rescore step remains the same as before.,
4568.txt,"We observe that in the apples-to-apples comparison when operating on the same set of detections, the slow figure-ground predictor is about 1.7 points better at 0.7 overlap.",
4569.txt,"Indeed, our fast system when applied  to Fast R-CNN detections is better by about 2 percentage points at 0.5 overlap.",
4570.txt,Girshick showed that Fast R-CNN is in fact better than vanilla R-CNN owing to the joint training of the bounding box regressor and the detector.,
4571.txt,This improvement in detection thus carries over to SDS.,
4572.txt,"Finally, rescoring the segmented objects as before pushes performance up to 62.4 for 0.5 overlap, 2 points  higher  than the slow system.",
4573.txt,"At 0.7 overlap, it is about 1 point below the slow system.",
4574.txt,"This might be an acceptable loss in performance considering the large gain in speed offered.We evaluate part localization in the unconstrained detection setting, where the task is to both detect the object and label its keypoints/segment its parts.",
4575.txt,"This is different from most prior work on these problems, which operates on the immediate vicinity of ground-truth instances.",
4576.txt,We start from the detections of X.,
4577.txt,We use the same features and network as in Section 5.1.,
4578.txt,"As before, we do all training on VOC2012 Train.We evaluate keypoint prediction on the ""person"" category using the protocol described in X.",
4579.txt,The test set for evaluating keypoints is the person images in the second half of VOC2009 val.,
4580.txt,"We use the APK metric , which evaluates keypoint predictions in a detection setting.",
4581.txt,Each detection comes with a keypoint prediction and a score.,
4582.txt,"A predicted keypoint within a threshold distance   of the ground-truth keypoint is a true positive, and is a false positive otherwise.",
4583.txt,The area under the PR curve gives the APK for that keypoint.,
4584.txt,We start from the person detections of X.,
4585.txt,We use bounding box regression to start from a better bounding box.,
4586.txt,As described in Section 4 we train a separate classifier for each keypoint using the hypercolumn representation.,
4587.txt,We use keypoint annotations collected by X.,
4588.txt,We produce a heatmap for each keypoint and then take the highest scoring location of the heatmap as the keypoint prediction.,
4589.txt,We only experiment with the slower crop-and-resize version of our system.The APK metric requires us to attach a score with each keypoint prediction.,
4590.txt,"This score must combine the confidence in the person detection and the confidence in the keypoint prediction, since predicting a keypoint when the keypoint is invisible counts as a false positive.",
4591.txt,For this  score we multiply the value of the keypoint heatmap at    the predicted location with the score output by the person detector  .Results are shown in Table 4.,
4592.txt,"We compare our performance to X, the previous best on this dataset.",
4593.txt,"Gkioxari finetuned a network for pose, person detection and action classification, and then trained an SVM to assign a score to the keypoint predictions.",
4594.txt,"Without any finetuning for pose, our system achieves a 1.8 point boost.",
4595.txt,"A baseline system trained using our pipeline but with just the fc7 features performs significantly worse than our system, and is even worse than a HOG-based method.",
4596.txt,This confirms that the gains we get are from the hypercolumn representation.,
4597.txt,"Figure 8 shows some example predictions.Finetuning the network as described in Section 4 gives an additional 1.5 point gain, raising mean APK to 18.5.We evaluate part labeling on the articulated object categories in PASCAL VOC: person, horse, cow, sheep, cat, dog, bird.",
4598.txt,We use the part annotations provided by x.,
4599.txt,"We  group the parts into top-level parts: head, torso, arms and legs   for person, head, torso, legs and tail for the four-legged animals and head, torso, legs, wings, tail for the bird.",
4600.txt,We train separate classifiers for each part.,
4601.txt,"At test time, we use the Hyp+bbox-reg+FT system from Section 5.1 to predict a figure-ground mask for each detection, and to every pixel in the figure-ground mask, we assign the part with the highest score at that pixel.",
4602.txt,We only experiment with the slower cropand-resize version of our system.,
4603.txt,"While it is a significant improvement on state-of-the-art, our approach is nowhere near perfect.",
4604.txt,"In this section, we explore what kinds of mistakes it makes, and what must be done to resolve those errors.One major limitation of our approach is that it is restricted to the bounding box produced by the object detector.",
4605.txt,"In particular, it cannot make any predictions outside the bounding box.",
4606.txt,"Thus if the bounding box underestimates the extent of the object, our approach will produce an incomplete segmentation, and miss keypoints and parts that fall outside the bounding box.To see how big a problem this is, we focused on the SDS task.",
4607.txt,"We took detections from System 2, with Fast R-CNN for the detection step and  fast  figure-ground  prediction  for the segmentation step.",
4608.txt,We then marked a detection as "incomplete" if the predicted segmentation covered less than 50% of the highest overlapping ground truth object.,
4609.txt,"Figure 10 shows example incomplete detections: in black is the bounding box, and in red the predicted segmentation  .",
4610.txt,"As  can  be  seen,  this  is  a common error mode.",
4611.txt,"To quantify the impact this error mode has on our performance, we computed an oracle performance by expanding each  incomplete  segmentation so that it covered the full object.",
4612.txt,"In other words, to each incomplete detection, we added pixels belonging to the ground-truth object that the detection had missed.",
4613.txt,The second column in Table 6 shows this oracle performance.,
4614.txt,"At an overlap threshold of 70%, this oracle does 8 points better, indicating that this is indeed a significant error mode and solving it can provide large gains.",
4615.txt,"The biggest offenders were boats, chairs, people, potted plants and sofas, each of which experienced more than a 10 point gain under this oracle.A second limitation arises from the fact that predictions for each pixel are made independently.",
4616.txt,This can lead to inconsistent predictions.,
4617.txt,"We observed that this problem was especially acute when the detection window included more than one object of that category, for instance when multiple people stand close to each other.",
4618.txt,"As an example, if there   are two people standing close by, the detection window corresponding to one of the people might include two heads.",
4619.txt,"Pixels on each head are classified independently, so our system would mark each pixel on each head as part     of the person, ignoring the anatomical fact that each person must have exactly one head.",
4620.txt,This results in "impure" segmentations: segmentations that span pixels from multiple nearby objects of the category.,
4621.txt,Figure 11 shows several examples.,
4622.txt,"To quantify this problem, we again took detections from the detect-segment-rescore pipeline described in the previous section  , with Fast R-CNN for the detection step and fast figure-ground prediction for the segmentation step.",
4623.txt,"For each segmented detection of a particular category, we looked at all the ground truth objects of that category    it intersected with.",
4624.txt,We then counted how many of these objects covered more than 10% of the predicted segmentation.,
4625.txt,"If there was more than one such object, then the detection was marked ""impure"".",
4626.txt,Of course one of these objects would have the largest intersection; we assumed that this ground truth object was the target object that this detection corresponded to.,
4627.txt,We then computed an oracle "purification" by removing pixels from the segmentation that belonged to the other ground truth objects.,
4628.txt,The third column in Table 6 shows the performance of this oracle.,
4629.txt,"At an overlap threshold of 70%, this oracle does about 3.5 points better.",
4630.txt,Thus this is also a significant error mode.,
4631.txt,"The largest offenders in this case are the animal categories: cats, cows, horses, people and sheep.",
4632.txt,"This is perhaps because of the very characteristic texture that cats, cows, horses and sheep have, making it harder    to tell nearby instances apart.",
4633.txt,"The prevalence of this error mode in the person category might be because people tend to interact very closely with each other, more so than other categories.",
4634.txt,Independent predictions for each pixel can also lead to inconsistent part predictions.,
4635.txt,"Object parts need to obey fairly rigid constraints imposed by object anatomy: the head of a person, for example, is a single coherent region that has to be attached to the torso.",
4636.txt,Figure 12 shows some  failure cases of our part predictions where such anatomical constraints are violated.In this paper we have proposed a system for using multiple layers of a trained convolutional network to achieve stateof-the-art performance in many fine-grained localization tasks.,
4637.txt,We have also proposed an efficient variant of our system that can make figure-ground predictions for hundreds of detected objects in a few hundred milliseconds.,
4638.txt,We have made the code for this variant publicly available  at https://github.com/bharath272/sds.,
4639.txt,"Finally, we have also presented a detailed analysis of the major error modes of our system that we hope will help guide future work in segmentation and fine-grained localization tasks.",
4640.txt,Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing.,
4641.txt,"In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image.",
4642.txt,The model is trained to maximize the likelihood of the target description sentence given the training image.,
4643.txt,Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions.,
4644.txt,"Our model is often quite accurate, which we verify both qualitatively and quantitatively.",
4645.txt,"Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset.",
4646.txt,"We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research.Image captioning, recurrent neural network, sequence-to-sequence, language model.Image captioning, recurrent neural network, sequence-to-sequence, language model.",
4647.txt,"BEING able to automatically describe the content of an image using properly formed English sentences is a very challenging task, but it could have great impact, for instance by helping visually impaired people better understand the content of images on the web.",
4648.txt,"This task is significantly harder, for example, than the well-studied image classification or object recognition tasks, which have been a main focus in the computer vision community  .",
4649.txt,"Indeed, a description must capture not only the objects contained in an image, but it also must express how these objects relate to each other as well as their attributes and the activities they are involved in.",
4650.txt,"Moreover, the above semantic knowledge has to be expressed in a natural language like English, which means that a language model is needed in addition to visual understanding.The main inspiration of our work comes from recent advances in machine translation.",
4651.txt,"For many years, machine translation was also achieved by a series of separate tasks  , but recent work has shown that translation can be done in a much simpler way using Recurrent Neural Networks and still reach state-of-the-art performance.",
4652.txt,"An ""encoder"" RNN reads the source sentence and transforms it into a rich fixed-length vector representation, which in turn in used as the initial hidden state of a ""decoder"" RNN that generates the target sentence.Here, we propose to follow this elegant recipe, replacing the encoder RNN by a deep convolution neural network .",
4653.txt,"Over the last few years it has been convincingly shown that CNNs can produce a rich representation of the input image by embedding it to a fixed-length vector, such that this representation can be used for a variety of vision tasks.",
4654.txt,"Hence, it is natural to use a CNN as an image ""encoder"", by first pre-training it for an image classification task and using the last hidden layer as an input to the RNN decoder that generates sentences.",
4655.txt,"We call this model the Neural Image Caption, or NIC.",
4656.txt,Our contributions are as follows.,
4657.txt,"First, we present an end-to-end system for the problem.",
4658.txt,It is a neural net which is fully trainable using stochastic gradient descent.,
4659.txt,"Second, our model combines state-of-art sub-networks for vision and language models.",
4660.txt,These can be pre-trained on larger corpora and thus can take advantage of additional data.,
4661.txt,"Finally, it yields significantly better performance compared to state-of-the-art approaches; for instance, on the Pascal dataset, NIC yielded a BLEU score of 59, to be compared to the current state-of-the-art of 25, while human performance reaches 69.",
4662.txt,"On Flickr30k, we improve from 56 to 66, and on SBU, from 19 to 28.",
4663.txt,"Third, we describe the lessons learned from participating in the first MSCOCO competition, which helped us to improve our initial model and place first in automatic metrics, and first   in human evaluation.",
4664.txt,"The problem of generating natural language descriptions from visual data has long been studied in computer vision, but mainly for video.",
4665.txt,"Traditionally, this has led to complex systems composed of visual primitive recognizers combined with a structured formal  language.",
4666.txt,"And Or Graphs or logic systems, which are further converted   to natural language via rule-based systems.",
4667.txt,"Such systems are heavily hand-designed, relatively brittle and have been demonstrated only on limited domains, e.g.",
4668.txt,traffic scenes or sports.The problem of still image captioning in natural language has recently enjoyed increased interest.,
4669.txt,"Recent advances in object recognition and detection as well as attribute recognition has been used to drive natural language generation systems, though these are limited in their expressivity.",
4670.txt,Farhadi  use detections to infer a triplet  of scene elements which is converted to text using templates.,
4671.txt,"Similarly, Li start off with detections and piece together a final description using phrases containing detected objects and relationships.",
4672.txt,"A more complex graph of detections beyond triplets is used by Kulkani, but with template-based text generation.",
4673.txt,More powerful language models based on language parsing have been used as well.,
4674.txt,"The above  approaches  have been able to describe images ""in the wild"", but they are heavily hand-designed and rigid when it comes to text generation.A large body of work has addressed the problem of ranking descriptions for a given image.",
4675.txt,Such approaches are based on the idea of coembedding of images and text in the same vector space.,
4676.txt,"For an image query, descriptions are retrieved which lie close to the image in the embedding space.",
4677.txt,"Most closely, neural networks are used to co-embed images and sentences together or even image crops and subsentences but do not attempt to generate novel descriptions.",
4678.txt,"In general, the above approaches cannot describe previously unseen compositions of objects, even though the individual objects might have been observed in the training data.",
4679.txt,"Moreover, they avoid addressing the problem of evaluating how good a generated description is.",
4680.txt,"More recently neural net based recognizer are used to detect a larger set of words and in conjunction with a language model sentences are generated.In this work we combine deep convolutional nets for image classification with recurrent networks for sequence modeling, to create a single network that generates descriptions of images.",
4681.txt,The RNN is trained in the context  of this single "end-to-end" network.,
4682.txt,"The model is inspired by recent successes of sequence generation in machine translation, with the difference that instead of starting with a sentence, we provide an image processed by a convolutional net.",
4683.txt,In the summer of 2015 a few approaches were introduced which follow the above general paradigm.,
4684.txt,"The closest works are by Kiros who use a neural net, but a feedforward one, to predict the next word given the image and previous words.",
4685.txt,A recent work by Mao uses a recurrent NN for the same prediction task.,
4686.txt,"This is very similar to the present proposal but there are a number of important differences: we use a more powerful RNN model, and provide the visual input to the RNN model directly, which makes it possible for the RNN to keep track of the objects that have been explained by the text.",
4687.txt,"As a result of these seemingly insignificant differences, our system achieves substantially better results on the established benchmarks.",
4688.txt,"Further, Kiros propose to construct  a joint multimodal embedding space by using a powerful computer vision model and an LSTM that encodes text.",
4689.txt,"In contrast to our approach, they use two separate pathways   to define a joint embedding, and, even though they  can  generate  text,  their  approach is highly tuned for ranking.",
4690.txt,A recurrent network is being used by Donahue who address in addition activity recognition and video description.,
4691.txt,"In addition, some approaches try to model in a more explicit fashion the visual anchoring of sentence parts claiming a performance benefit.",
4692.txt,Xu explore attention mechanisms over image regions where while  emitting  words the system can focus on image parts.,
4693.txt,An explicit word to region alignment is utilized during training by Karpathy.,
4694.txt,"Finally, Chen build a visual representation for sentence parts while generating the description.",
4695.txt,Further analysis of the above approaches were reported by Devlin.,
4696.txt,"In this paper, we propose a neural and probabilistic frame work to generate descriptions from images.",
4697.txt,"Recent advances in statistical machine translation have shown that, given a powerful sequence model, it is possible to achieve state-of- the-art results by directly maximizing the probability of the correct translation given an input sentence in an ""end-to- end"" fashion ?both for training and inference.",
4698.txt,"These models make use of a recurrent neural network which encodes the variable length input into a fixed dimensional vector, and uses this representation to ""decode"" it to the desired output sentence.",
4699.txt,"Thus, it is natural to use the same approach where, given an image  , one applies the same principle of ""translating"" it into its description.To make the above RNN more concrete two crucial design choices are to be made: what is the exact form of f and  how are the images and  words  fed  as  inputs  xt.",
4700.txt,"For  f we use a Long-Short Term Memory  net, which has shown state-of-the art performance on sequence tasks such as translation.",
4701.txt,This model is outlined in the next section.,
4702.txt,"For the representation of images, we use a Convolutional Neural Network  .",
4703.txt,"They have been widely used and studied for image tasks, and are currently state-of-the art for object recognition and detection.",
4704.txt,Our particular choice of CNN uses the recent approach of batch normalization and yields the current best performance on the ILSVRC 2014 classification competition.,
4705.txt,"Furthermore, they have been shown to generalize to other tasks such as scene classification by means of transfer learning.",
4706.txt,The words are represented with an embedding model.,
4707.txt,"The choice of f in X is governed by its ability to deal with vanishing and exploding gradients, the most common challenge in designing and training RNNs.",
4708.txt,"To address this challenge, a particular form of recurrent nets, called LSTM, was introduced and applied with great success to translation and sequence generation  .",
4709.txt,The core of the LSTM model is a memory cell c encoding knowledge at every time step of what inputs have been observed up to this step.The behavior of  the cell is controlled by "gates" layers which are applied multiplicatively and thus can either keep a value from the gated layer if the gate is 1 or zero this value if the gate is 0.,
4710.txt,"In particular, three gates are being used which control whether to forget the current cell value , if it should read its input   and whether to output the new cell value.",
4711.txt,The definition of the gates and cell update and output are as follows:where we represent each word as a one-hot vector St of dimension equal to the size of the dictionary.,
4712.txt,Note that we denote by S0 a special start word and by SN a special stop word which designates the start and end of the sentence.,
4713.txt,In particular by emitting the stop word the LSTM signals that a complete sentence has been generated.,
4714.txt,Our loss is the sum of the negative log likelihood of the correct word at each step as follows: The above loss is minimized w.r.t.,
4715.txt,"all the parameters of the LSTM, the top layer of the image embedder CNN and word embeddings We.We performed an extensive set of  experiments  to  assess the effectiveness of our model using several metrics, data sources, and model architectures, in order to compare to prior art.Although it is sometimes not clear whether a description should be deemed successful or not given an image, prior art has proposed several evaluation metrics.",
4716.txt,The most reliable is to ask for raters to give a subjective score on the usefulness of each description given the image.,
4717.txt,"In this paper, we used this to reinforce  that  some of the automatic metrics indeed correlate with this subjective score, following the guidelines proposed in X, which asks the graders to evaluate each generated sentence with a scale from 1 to 41.",
4718.txt,"For this metric, we set up an Amazon Mechanical Turk experiment.",
4719.txt,Each image was rated by 2 workers.,
4720.txt,The typical level  of  agreement  between  workers  is  65%.,
4721.txt,"For variance analysis, we perform boot- strapping  .",
4722.txt,Like X we report the fraction of scores which are larger or equal than a set of predefined thresholds.,
4723.txt,"The rest of the metrics can be computed automatically assuming one has access to groundtruth, i.e.",
4724.txt,human generated descriptions.,
4725.txt,"The most commonly  used  metric  so far in the image description literature has been the BLEU score  , which is a form of precision of word n-grams between generated and reference sentences 2.",
4726.txt,"Even though this metric has some obvious drawbacks, it has been shown to correlate well with human evaluations.",
4727.txt,"In this work, we corroborate this as well, as we show in Section 4.3.Besides BLEU, one can use the perplexity of the model  for a given transcription  .",
4728.txt,The perplexity is the geometric mean of the inverse probability for each predicted word.,
4729.txt,"We used this metric to perform choices regarding model selection and hyperparameter tuning in our held-out set,but we do not report it since BLEU is always preferred 3.",
4730.txt,"More recently, a novel metric called CIDER   has been introduced and used by the organizers of the MS COCO Captioning challenge.",
4731.txt,"In a nutshell, it measures consistency between n-gram occurrences in generated and reference sentences, where this consistency is weighted by n-gram saliency and rarity.",
4732.txt,"As all of the above metrics have various shortcomings, we provide in addition results using METEOR and ROUGE metrics.",
4733.txt,"Lastly, the current literature on image description has also been using the proxy task of ranking a set of available descriptions with respect to a given image.",
4734.txt,Doing so has the advantage  that  one  can use known ranking metrics like recall@k. On the other 1.,
4735.txt,"The raters are asked whether the  image  is  described  without  any errors, described with minor errors, with a somewhat related description, or with an unrelated description, with a score of 4 being the best and 1 being the worst.",
4736.txt,"In this literature, most previous work report BLEU-1, i.e., they only compute precision at the unigram level, whereas BLEU-n is a geometric average of precision over 1 to n-grams.",
4737.txt,"Even though it would be more desirable, optimizing for BLEU score yields a discrete optimization problem.",
4738.txt,"In general, perplexity and BLEU scores are fairly correlated.",
4739.txt,"hand, transforming the description generation task into a ranking task is unsatisfactory: as the complexity of images to describe grows, together with its dictionary, the number of possible sentences grows exponentially with the size of the dictionary, and the likelihood that a predefined sentence will fit a  new  image  will  go  down  unless  the  number  of such sentences also grows exponentially, which is not realistic; not to mention the underlying computational complexity of evaluating efficiently such a large corpus of stored sentences for each image.",
4740.txt,"The same argument has been used in speech recognition, where one has to produce the sentence corresponding to a given acoustic sequence; while early attempts concentrated on classification of isolated phonemes or words, state-of-the-art approaches for this task are now generative and can produce sentences from a large dictionary.Now that our models can generate descriptions of reasonable quality, and despite the ambiguities of evaluating an image description   we believe we should concentrate on evaluation metrics for the generation task rather than for ranking.For evaluation we use a number of datasets which consist  of images and sentences in English describing these images.",
4741.txt,"The statistics of the datasets are as follows: With the exception of SBU, each image has been annotated by labelers with 5 sentences that are relatively visual and unbiased.",
4742.txt,SBU consists of descriptions given by image owners when they uploaded them to Flickr.,
4743.txt,As such they are not guaranteed to be visual or unbiased and thus this dataset has more noise.The Pascal dataset is customary used for testing only after a system has been trained on different data such as any of the other four dataset.,
4744.txt,"In the case of SBU, we hold out 1000 images for testing and train on the rest as used    by X.",
4745.txt,"Similarly, we reserve 4K random images from the MSCOCO validation set as test, called COCO-4k, and use it to report results in the following section.",
4746.txt,"Since our model is data driven and  trained  end-to-end, and given the abundance of datasets, we wanted to answer questions such as ""how dataset size affects generalization"", ""what kinds of transfer learning it would be able to achieve"", and ""how it would deal with weakly labeled examples"".",
4747.txt,"As a result, we performed experiments on five different datasets, explained in Section 4.2, which enabled us to understand our model in depth.",
4748.txt,Many of the challenges that we faced when training our models had to do with overfitting.,
4749.txt,"Indeed, purely supervised approaches require large amounts of data, but the datasets that are of high quality have less than 100000 images.",
4750.txt,The task of assigning a description is strictly harder than object classification and data driven approaches have only recently become dominant thanks to datasets as large as ImageNet  .,
4751.txt,"As a result, we believe that, even with the results we obtained which are quite good, the advantage of our method versus most current human-engineered approaches will only increase in the next few years as training set sizes will grow.",
4752.txt,"Nonetheless, we explored several techniques to deal with overfitting.",
4753.txt,The most obvious way to not overfit is to initialize the weights of the CNN component of our system to a pretrained model.,
4754.txt,"We did this in all the experiments , and it did help quite a lot in terms of generalization.",
4755.txt,"Another set of weights that could be sensibly initialized are We, the word embeddings.",
4756.txt,"We tried initializing them from a large news corpus, but no significant gains were observed, and we decided to just leave them uninitialized for simplicity.",
4757.txt,"Lastly, we did some model level overfitting-avoiding techniques.",
4758.txt,"We tried dropout and ensembling models, as well as exploring the size of the model by trading off number of hidden units versus depth.",
4759.txt,"Dropout and ensembling gave a few BLEU points improvement, and that is what we report throughout the paper.",
4760.txt,Further details of the ensambling and additional training improvements used for the MS COCO challenge are described in Section 5.2.,
4761.txt,We trained all sets of weights using stochastic gradient descent with fixed learning rate and no momentum.,
4762.txt,"All weights were randomly initialized except for the CNN weights, which we left unchanged because changing them had a negative impact.",
4763.txt,We used 512 dimensions for the embeddings and the size of the LSTM memory.,
4764.txt,"Descriptions were preprocessed with basic tokenization, keeping all words that appeared at least 5 times in the training set.",
4765.txt,We report our main results on all the relevant datasets in Tables 1 and 2.,
4766.txt,"Since PASCAL does  not  have  a training set, we used the system trained using MSCOCO  .",
4767.txt,"The state-of-the-art results for PASCAL and SBU did not use image features based on deep learning, so arguably a big improvement on those scores comes from that change alone.",
4768.txt,"The Flickr datasets have been used recently , but mostly evaluated in a retrieval framework.",
4769.txt,"A notable exception is X, where they did both retrieval and generation, and which yields the best performance on the Flickr datasets up to now.",
4770.txt,Human scores in Table 2 were computed by comparing one of the human captions against the other four.,
4771.txt,"We do this for each of the five raters, and average their BLEU scores.",
4772.txt,"Since this gives a slight advantage to  our  system,  given the BLEU score is computed against five reference sentences and not four, we add back to the human scores the average difference of having five references instead of four.",
4773.txt,"Given that the field has seen significant advances in the last years, we do think it is more meaningful to report BLEU-4, which is the standard in machine translation moving forward.",
4774.txt,"Additionally, we report metrics shown to correlate better with human evaluations in Table 14.",
4775.txt,"Despite recent efforts on better evaluation metrics, our model fares strongly versus human raters.",
4776.txt,"However, when evaluating our captions using human raters  , our model fares much more poorly, suggesting more work is needed towards better metrics.",
4777.txt,"For a more detailed description and comparison of our results on the MSCOCO dataset, and other interesting human metrics, see Section 5.",
4778.txt,"In that section, we detail the lessons learned from extra tuning of our model w.r.t.",
4779.txt,"the original model which was submitted in a previous version of this manuscript versus the latest version for the competition .Since we have trained many models and we have several testing sets, we wanted to study whether we could transfer a model to a different dataset, and how much the mismatch in domain would be compensated with e.g.",
4780.txt,higher quality labels or more training data.,
4781.txt,The most obvious case for transfer learning and data size is between Flickr30k and Flickr8k.,
4782.txt,The two datasets  are similarly labeled as they were created by the same group.,
4783.txt,"Indeed, when training on Flickr30k  , the results obtained are 4 BLEU points better.",
4784.txt,"It is  clear  that  in  this  case,  we  see  gains  by adding more training data since the whole process is data-driven and overfitting prone.",
4785.txt,"MSCOCO is even bigger, but since the collection process was done differently, there are likely more differences in vocabulary and a larger mismatch.",
4786.txt,"Indeed,  all the BLEU scores degrade by 10 points.",
4787.txt,"Nonetheless, the descriptions are still reasonable.",
4788.txt,"Since PASCAL has no official training set and was collected independently of Flickr and MSCOCO, we report transfer learning from MSCOCO  .",
4789.txt,Doing transfer learning from Flickr30k yielded worse results with BLEU-1 at 53.,
4790.txt,"Lastly, even though SBU has weak labeling , the task is much harder with a much larger and noisier vocabulary.",
4791.txt,"However, much more data is available for training.",
4792.txt,"When running the MSCOCO model on SBU, our performance degrades from 28 down to 16.Having trained a generative model that gives p(S I), an obvious question is whether the model generates novel captions, and whether the generated captions are both diverse and high quality.",
4793.txt,Table 3 shows some samples when returning the N-best list from our beam search decoder instead of the best hypothesis.,
4794.txt,Notice how  the  samples  are diverse and may show different aspects from the same image.,
4795.txt,"The agreement in BLEU score between the top 15 generated sentences is 58, which is similar to that of humans among them.",
4796.txt,This indicates the amount of diversity our model generates.,
4797.txt,In bold are the sentences that are not present in the training set.,
4798.txt,"If we take the best candidate,  the sentence is present in the training set 80% of the times.",
4799.txt,"This is not too surprising given that the amount of training data is quite small, so it is relatively easy for the model      to pick ""exemplar"" sentences and use them to generate descriptions.",
4800.txt,"If we instead analyze the top 15 generated sentences, about half of the times we see a completely novel description, but still with a similar BLEU score, indicating that they are of enough quality, yet they provide a healthy diversity.",
4801.txt,"While we think ranking is an unsatisfactory way to evaluate description generation from images, many papers report ranking scores, using the set of testing captions as candidates to rank given a test image.",
4802.txt,"The approach that works best on these metrics  , specifically implemented a ranking-aware loss.",
4803.txt,"Nevertheless, NIC is doing surprisingly well on both ranking tasks, as can be seen in Tables 4 and 5.",
4804.txt,"Note that for the Image Annotation task, we normalized our scores similar to what used.Figure 4 shows the result of the human evaluations of the descriptions provided by NIC, as well as a reference system and groundtruth on various datasets.",
4805.txt,"We can see that NIC is better than the reference system, but clearly worse than the groundtruth, as expected.",
4806.txt,"This shows that BLEU is not  a perfect metric, as it does not capture well the difference between NIC and human descriptions assessed by raters.",
4807.txt,Examples of rated images can be seen in Figure 5.,
4808.txt,"It is interesting to see, for instance in the second image of the first column, how the model was able to notice the frisbee given its size.In order to represent the previous word St? as input to the decoding LSTM producing St, we use word embedding vectors, which have the advantage of being independent of the size of the dictionary.",
4809.txt,"Furthermore, these word embeddings can be jointly trained with the rest of the model.",
4810.txt,It is remarkable to see how the learned representations have captured some semantic from the statistics of the language.,
4811.txt,"Table 6 shows, for a few example words, the nearest other words found in the learned embedding space.",
4812.txt,Note how some of the relationships learned by the model will help the vision component.,
4813.txt,"Indeed, having ""horse"", ""pony"", and ""donkey"" close to each other will encourage the CNN to extract features that are relevant to horse-looking animals.",
4814.txt,"We  hypothesize that, in the extreme case where  we see very few examples of a class  , its proximity to other word embeddings should provide a lot more information that would be completely lost with more traditional bag-of-words based approaches.In the spring of 2015, as part of the MS COCO dataset a challenge was organized6.",
4815.txt,"Participants were recommended to train their algorithms on the MS COCO 2014 dataset,  and results on the validation and test sets were submitted on an evaluation server, with no more than 5 attempts in total per group, in order to limit overfitting on the test set.",
4816.txt,Human judges then evaluated the competing approaches and the winners were invited to present their approach at a workshop organized during CVPR 2015.,
4817.txt,"We entered the competition and the rest of this section explains the various techniques we have explored in this context, building on our baseline model described in the previous sections.",
4818.txt,The metrics used are discussed in in Section 4.,
4819.txt,"A special emphasis is on CIDER, which was chosen by the competition organizers to rank teams.",
4820.txt,As a result we use also during hyper-parameter selection.We found all the automatic metrics to correlate with each other quite strongly  .,
4821.txt,"Notably, the main difference of these metrics is on how humans rank on it versus several automatic image captioning systems.",
4822.txt,"Interestingly, BLEU score seems to be quite bad ; CIDER fares better; METEOR is the automatic metric where humans rank the highest.In this Section we analyze what components were improved with respect to the model which we originally studied in our CVPR 2015 work.",
4823.txt,Section 5.3 shows a summary     of the results on both automatic and human metrics from the MSCOCO competition.,
4824.txt,We summarize all the improvements in Table 8.,
4825.txt,"When we first submitted our image captioning paper to CVPR 2015, we used the best convolutional neural network at the time, known as GoogleLeNet  , which had 22 layers, and was the winner of the 2014 ImageNet competition.",
4826.txt,"Later on, an even better approach was proposed in X and included a new method, called Batch Normalization, to better normalize each layer of a neural network with respect to the current batch of examples, so as to be more robust to nonlinearities.",
4827.txt,"The new approach got significant improvement on the ImageNet task   and the MSCOCO image captioning task, improving BLEU-4 by 2 points absolute.In the original set of experiments, to avoid overfitting we initialized the image convolutional network with a pretrained model, but then fixed its parameters and only trained the LSTM part of the model on the MS COCO training set.For the competition, we also considered adding some fine tuning of the image model while training the LSTM, which helped the image model focus more on the kind of images provided in the MS COCO training set, and ended up improving the performance on the captioning task.",
4828.txt,"It is important to note that fine tuning the image model must be carried after the LSTM  parameters  have settled on a good language model: we found that, when jointly training both, the noise in the initial gradients coming from the LSTM into the image model corrupted the CNN and would never recover.",
4829.txt,"Instead, we train for about 500K steps  , and then switch to jointly train the model for an additional 100K steps.",
4830.txt,"Training was done using a single GPU , and step time was about 3 seconds.",
4831.txt,"Thus, training took over 3 weeks ?parallelizing training yielded somewhat worse results, though it increased the speed to convergence.",
4832.txt,The improvements achieved by this was 1 BLEU-4 point.,
4833.txt,"More importantly, this change allowed the model to transfer information from the image to the language which was likely not possible due to the insufficient coverage of the ImageNet label space.",
4834.txt,"It is plausible that the top layer CNN activations are overtrained on ImageNet-specific classes and could throw away interesting features  , thus the caption generation model may not output words corresponding to those features, without fine tuning the image model.",
4835.txt,"As explained  in  Section  3.1,  our  model  uses  an  LSTM  to generate the description  given  the  image.",
4836.txt,"As  shown  in Figure 3, LSTMs are trained by trying to predict each word of the caption given the current state of the model and the previous  word  in  the  caption.",
4837.txt,"At  inference,  for a new image, the previous word is obviously  unknown and is thus replaced by the word generated by the model itself at the previous step.",
4838.txt,There is thus a discrepancy between training and inference.,
4839.txt,"Recently, we proposed   a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous word, towards a less guided scheme which mostly uses the model generated word instead.",
4840.txt,"We applied this strategy using various schedules for the competition, and found that it improved up to 1.5 BLEU-4 points over using the standard training objective function.",
4841.txt,Ensembles   have long been known to be a very simple yet effective way to improve performance of machine learning systems.,
4842.txt,"In the context of deep architectures, one only needs to train separately multiple models on the same task, potentially varying some of the training conditions, and aggregating their answers at inference time.",
4843.txt,"For the competition, we created an ensemble of 5 models trained with Scheduled Sampling and 10 models trained with finetuning the image model.",
4844.txt,The resulting model was submitted to the competition.,
4845.txt,"In order to generate a sentence with our proposed approach, we described in Section 3.1 the use of BeamSearch, where we maintain a list of the top-k sequences of words generated so far.",
4846.txt,"For the competition, we actually tried several more beam sizes, and selected the size which generated the best sequences of words according to the CIDER metric, which we consider to be the metric most aligned with human judgements.",
4847.txt,"Contrary to our expectations, the best beam size turned out to be small: 3.",
4848.txt,"Note that, as the beam size increases, we score more candidate sentences and pick the best according to the obtained likelihood.",
4849.txt,"Hence, if the model was well trained and the likelihood was aligned with human judgement, increasing the beam size should always yield better sentences.",
4850.txt,The fact that we obtained the best performance with a relatively small beam size is an indication that either the model has overfitted or the objective function used to train it   is not aligned with human judgement.,
4851.txt,"We also observed that, by reducing the beam size  , we increase the novelty of generated sentences.",
4852.txt,"Indeed, instead of generating captions which repeat training captions 80% of the time, this gets reduced to 60%.",
4853.txt,"This hypothesis supports the fact that the model has overfitted to the training set, and  we see this reduced beam size technique as another way to regularize.",
4854.txt,Reducing the beam size was the single change that improved our CIDER score the most.,
4855.txt,This simple change yielded more than 2 BLEU-4 points improvement.,
4856.txt,"All the teams were allowed up to 5 submissions to the evaluation server on a large, unseen set of test images.",
4857.txt,"The leaderboard allowed for teams to monitor progress, and it motivated us to keep improving the accuracy of our model up to the deadline.",
4858.txt,"Despite the automatic metrics not fully characterizing the quality of the captions, strong correlations were present  .",
4859.txt,"Since we submitted our paper, and thanks to all the improvements, our BLEU-4 score improved by 8 points absolute  .",
4860.txt,The top 5 submission according  to the automatic metrics on the test set  are presented in Table 9.,
4861.txt,"The most promising 15 submissions to the MSCOCO challenge, as well as a human baseline, were evaluated on 5 different metrics:M1Percentage of captions that are evaluated as better or equal to human caption.",
4862.txt,Note that M1 and M2 were the  ones  used  to  decide the winner.,
4863.txt,"The others were merely experimental, but are reported here for completeness.",
4864.txt,"Finally, we show in Figure 6 a few example images together with the caption obtained by our original model, compared with the caption obtained by the final model submitted to the competition.",
4865.txt,"We  took a random sample   of 20 images from the development set, and picked the ones that looked most interesting  .",
4866.txt,"It is clear that the overall quality of the captions have improved significantly, a fact that should be obvious given the overall improvement in BLEU-4 from the improvements that we showed in this section was 8 points absolute.We have presented NIC, an end-to-end neural network system that can automatically view an image and generate a reasonable description in plain English.",
4867.txt,"NIC is based on    a convolution neural network that encodes an image into a compact representation, followed by a recurrent neural network that generates a corresponding sentence.",
4868.txt,The model is trained to maximize the likelihood of the sentence given the image.,
4869.txt,"Experiments on several datasets show the robustness of NIC in terms of qualitative results and quantitative evaluations, using either ranking metrics or BLEU, a metric used in machine translation to evaluate the quality of generated sentences.",
4870.txt,"Based on our initial results, we participated in the 2015 MS COCO challenge comparing approaches on the task of image captioning.",
4871.txt,We presented and analyzed in this paper the various improvements we have made to our basic NIC model and described the competition results which ranked our model in first position using both automatic and human evaluations.,
4872.txt,"It is clear from these experiments that, as the size of the available datasets for image description increases, so will the performance of approaches like NIC.Despite the exciting results on captioning, we believe it is just the beginning.",
4873.txt,The produced descriptions are one of many possible image interpretations.,
4874.txt,One possible direction is the have a system which is capable of more targeted descriptions ?either anchoring the descriptions to given image properties and locations or being a response to  a user specified question or task.,
4875.txt,Further research direction are better evaluation metrics or evaluation through higher level goals found in application such as robotics.,
4876.txt,Recommender systems are used to accurately and actively provide users with potentially interesting information or services.,
4877.txt,"Collaborative filtering is a widely adopted approach to recommendation, but sparse data and cold-start users are often barriers to providing high quality recommendations.",
4878.txt,"To address such issues, we propose a novel method that works to improve the performance of collaborative filtering recommendations by integrating sparse rating data given by users and sparse social trust network among these same users.",
4879.txt,"This is a model-based method that adopts matrix factorization technique that maps users into
low-dimensional latent feature spaces in terms of their trust relationship, and aims to more accurately reflect the users reciprocal influence on the formation of their own opinions and to learn better preferential patterns of users for high-quality recommendations.",
4880.txt,"We use four large-scale datasets to show that the proposed method performs much better, especially for cold start users, than state-of-the-art recommendation algorithms for social collaborative filtering based on trust.",
4881.txt,Many previous studies have  addressed  personalized recommendation systems.,
4882.txt,"Among existing techniques, collaborative filtering  is relatively simple and effective, and has been widely used by many commercial web sites.",
4883.txt,CF approaches attempt to utilize the available user-item rating data to make predictions about the users preferences.,
4884.txt,These approaches can be divided into two groups : memory-based  and model- based.,
4885.txt,"Memory-based approaches make predictions based on the similarities between users or items, while model-based approaches seek to create a prediction model from rating data through the use of machine learning.",
4886.txt,"In particular, matrix factorization based models have gained popularity in recent years due to their relatively high accuracy and scalability.",
4887.txt,"Although CF has developed rapidly and achieved huge success over the past two decades, both memory-based and model-based CF approaches have two challenges: data spar- sity and cold start, which greatly reduce their performance.",
4888.txt,Data sparsity occurs when available rating data are very few.,
4889.txt,"When cold start occurs, CF cannot provide satisfactory recommendations to those users who rarely rate items.",
4890.txt,One potential solution of these problems is to explore available social networks.,
4891.txt,"With the rapid development of web 2.0 technologies, in addition to the ratings of items contributed by users, the social information of users is much more readily obtained than before through social network- ing services .",
4892.txt,"It is believed that human beings usually acquire and disseminate information through their acquaintances such as friends, colleagues or partners, which implies that the underlying social networks of users might play a fundamental role in helping them filter information.",
4893.txt,"Trust relationship is one of the most important types of social information, because we are more likely to accept viewpoints from those we trust.",
4894.txt,"Thus, it creates a large opportunity, as well as a large challenge, to improve recommendation quality by sufficiently and effectively utilizing available trust information.",
4895.txt,Many memory-based approaches have been proposed to directly utilize or explore the available trust networks for use in recommendation systems.,
4896.txt,"Most generate predictions for a target user by aggregating the ratings of his/her direct  trusted friends, with the ratings given by users similar to him/her as usual, in different ways.",
4897.txt,"As reported in X, these methods are able to improve the coverage of recommendations compared against traditional memory-based CF .",
4898.txt,"However, the performance of such methods are largely dependent on the trust propagation models they adopt.",
4899.txt,"In addition, these methods are usually time-consuming, and thus are not suitable for handling large-scale applications because they need to calculate similarities over an entire rating matrix and whole trust network.",
4900.txt,"Instead of using trust ties to infer users' neighbors and then promote the accuracy of similarity calculation among users, as was done by most memory-based methods, matrix factorization based methods have been proposed to utilize trust information in a different style.",
4901.txt,"These methods simultaneously map users and items into low-dimensional feature spaces, and then train  a prediction model by optimizing some objective functions over rating and trust data.",
4902.txt,"SocialMF  is similar to RSTE, but uses a different implementation to take into account the interests of trusted friends by incorporating a regularization term as follows into its objective function: introduced several social regularization terms that are similar to  Eq.2.",
4903.txt,"Each  of  these  works  to  make  user  i's feature vector close to his/her trusted friends' feature vectors, and the main difference is that the trust value Tik  in social regularization model can be flexibly replaced by a traditional similarity in terms of ratings besides trust/social relationships.",
4904.txt,The authors of X proposed a circle-based method called CircleCon that is an extension of SocialMF.It's basic idea is that the friends of a user may vary with respect to categories of items.,
4905.txt,"According to different categories, it divides an available social network into different partitions, and then adopts the same regularization term in Eq.2 to train different prediction models.",
4906.txt,"For any one user, existing methods utilize the interest of his/her neighbors  to model his/her own interest.",
4907.txt,"In doing so, previous matrix factorization based methods  take  available  trust  ties as constraints to design objectives, making the interests of   a user close to the linear combination of their neighbors' interest during the process of matrix factorization.",
4908.txt,"However, in this work, we utilize the trust ties among users from a new perspective, and attempt to model user's interest more reasonably in terms of his/her own social/trust behaviors, browsing ratings/reviews, writing ratings/reviews, and adding trust friends, which can be obtained by studying the influence of global trust propagation on the formation of a users' opinions.",
4909.txt,"Our work is motivated by the observation  that users are caught in their social network of mutuality, and their opinions about items will be directly or indirectly affected by others through such a network.",
4910.txt,"More specifically, when a user is rating, he/she will be more likely affected by the existing ratings or reviews provided by others he/she trusts, and  in  the  same  way,   his/her  contributions  will   consequently have influence on the decisions of others who trust him/her.For instance, in online social networking sites such as Epinions if he/she thinks another user Q's opinions are relevant and helpful to him/her, he/she would be likely  to put Q into his/her own ""Trust list"".",
4911.txt,"Meanwhile, P 's attitude/behavior about those items will be affected by Q according to what extent P trusts Q. Consequently, through this kind of process, P 's interest will gradually be affected by others whom he/she trusts, and thus exerts a persistent influence on his/her further decisions.",
4912.txt,"In modeling this mutual influence, we propose a simple but effective way to map users into two low-dimensional spaces, truster space and trustee space, by factorizing trust networks according to the directional property of trust.",
4913.txt,"The vectors of truster  and trustee in two spaces describe ""to trust by browsing"" and ""to be trusted by writing"" behaviors of a user, respectively.",
4914.txt,"Viewed from another perspective, the truster vector represents a user's ""browsing interest"" which essentially catches the influence received by him/her from his/her trusted friends, while the trustee vector represents the user's ""writing interest"" which essentially catches the influence given by him/her to the friends who trust him/her.",
4915.txt,"Furthermore, the two spaces will be used in tandem with the user space and item space obtained by factorizing rating matrix to construct novel fusing models and to predict the genuine interest of users in a more reasonably way.",
4916.txt,"Previously, we have published a conference paper to briefly present and preliminarily validate the aforementioned idea, which will be extensively extended in this work by supplementing new models, algorithms, theoretical analysis as well as sufficient experimental results.",
4917.txt,The rest of the paper is organized as follows.,
4918.txt,In Section 2 we propose a novel matrix factorization based social CF method named TrustMF.,
4919.txt,"In Section 3, we discuss the rationale of TrustMF from a probabilistic view and then contribute a more general framework, named TrustPMF, to predict a user's preferences more effectively by fitting rating data and trust data in an approximate, rather than deterministic, way.",
4920.txt,"In Section 4, we validate the performance of TrustMF and TrustPMF by comparing them with several representative methods on four large real-world datasets.",
4921.txt,We have performed matrix factorization just based on either rating data or trust data.,
4922.txt,"In this section, we will present our matrix factorization model to fuse both.",
4923.txt,"As mentioned before, users of social networking such as Epinions are able to browse and generate opinions  on items they are interested in and then build their respective trust nets based on such opinions.",
4924.txt,"Through tangled  trust  ties,  the  opinions  of  an  individual  will  be affected by others and vice versa.",
4925.txt,"Here we first propose a truster model to characterize the first aspect, or how others will affect a specific user's opinions.",
4926.txt,Individuals will affect each other during the process of reviewing and making decisions.,
4927.txt,This point is emphasized in our work.,
4928.txt,"Therefore, your opinions/attitudes on items  will be more or less affected by your trustees.",
4929.txt,"Meanwhile, your decisions will inevitably influence the choices of your trusters.",
4930.txt,"Comprehensively, it suggests that the observed ratings are actually generated according to the propagation of such twofold influence among users.",
4931.txt,such that more social activities will result in more accurate recommendations for them.,
4932.txt,"Truster and trustee models favor those users having more browsing and writing activities, respectively.",
4933.txt,"However, TrustMF tries to provide high-quality recommendations for both kinds of users.",
4934.txt,"We now propose a synthetic probabilistic model to model the influence of both browsing and writing behaviors on preference formation, named as TrustPMF, by simultaneously considering truster features B and trustee features W .",
4935.txt,"In order to sufficiently validate the performance of our proposed methods, we choose four representative data sets related to social collaborative filtering for our experiments, which are taken from popular social networking web sites including Epinions, Douban and Flixster.",
4936.txt,"Each of these social networking services allows users to rate items, browse/write reviews, add friends, and hence provide ratings, reviews and social relations.",
4937.txt,"Note, the trust network in Epinions is directed, while the friend networks in Douban and Flixster are undirected because the new friend requests in these two web sites must be verified and approved by both parties.",
4938.txt,"Therefore, a friend network can be deemed as a special trust network, in which friends trust each other.",
4939.txt,"In all datasets, rating scales from 1 to 5.",
4940.txt,The statistics of the four datasets are presented in Table 2.,
4941.txt,"Both two datasets are published by X. Epinions is extremely sparse, containing 49289 users, 139738 items, 664823 ratings and 487183 trust relations.",
4942.txt,"The items in Ep Ext refer to articles   written by users rather than typical products, but can still be used for validating CF methods.",
4943.txt,"Ep Ext also contains distrust relations, which we do not consider in this work, and are removed.",
4944.txt,We also removed users or items with no ratings because they are meaningless to experimental evaluation.,
4945.txt,"The Ep Ext we finally obtained contains 120492 users, 755760 items, 13668320 ratings and 606259 trust relations.",
4946.txt,"This dataset is published by the  authors  of X, which contains 129490 users, 58541 items, 16830839 ratings and 169952 friend relations.",
4947.txt,"However, it missed some mutual relations that should appear in the dataset  We supplement those missed relations into the dataset.",
4948.txt,This dataset is published by X.,
4949.txt,"The original dataset contains 1049 users, 626 items, 8077 ratings and 11648 social relations.",
4950.txt,"In this dataset, most of users have not rated any items.",
4951.txt,"We  removed those users or items with no ratings, which are meaningless to experimental evaluation.",
4952.txt,"Finally, the dataset we obtained contains 14612 users, 48 items, 877 ratings and 26 social relations.",
4953.txt,We employ cross-validation for learning and testing.,
4954.txt,"For the experiments conducted on datasets Ep Ext, Douban and Flixster, we use a 2-fold cross-validation.",
4955.txt,We randomly divide the rating data into two equal parts; in each time we use one part as training set and another part as test set .,
4956.txt,"Since Epinions is extremely sparse in terms of ratings, we select a larger part of the data for training.",
4957.txt,"For this dataset, we use a 5-fold cross-validation that randomly divides the rating data into five equal parts, in each time we use one part as test set and the remaining four parts as the training set.",
4958.txt,"In addition, we conduct each experiment five times and then take the mean as the final result for each experiment discussed below.",
4959.txt,We now validate the performance of the proposed TrustMF and TrustPMF methods by comparing the results on the four datasets with their competitors.,
4960.txt,"MAE  and RMSE , two benchmark error evaluation metrics, are used here.",
4961.txt,"Table 4 shows the results of MAE and RMSE computed  on  the  predictions for all users, where Tr-PMF, Te-PMF and TPMF refer to Truster-PMF, Trustee-PMF and TrustPMF, respectively.",
4962.txt,"From the table, we can see the following points.",
4963.txt,"First, TrustPMF  performs the  best  of  all  in  terms  of  both  MAE  and RMSE on all four datasets.",
4964.txt,"The improvements against respective competitors given in the table show that our methods can significantly improve the quality of recommendations, especially for Epinions, a highly sparse dataset.",
4965.txt,"Second, TrustMF achieves a second-best performance except on the dataset Ep Ext in terms of MAE.",
4966.txt,"hird, because the rating data  of Epinions  is extremely sparse , the traditional CF method PMF performs much worse than the social recommendation methods SoRec, RSTE and SocialMF.",
4967.txt,"However, when the rating data is relatively dense, such as in the Douban or Flixster , PMF shows a comparable, and sometimes better, performance than them.",
4968.txt,"Finally, for Epinions and Ep Ext that both contain directed trust networks, TrustPMF is more accurate than Truster-PMF or Trustee-PMF.",
4969.txt,"However, for Douban and Flixster that contain undirected friend networks, the performance of Truster-PMF and Trustee-PMF is similar to TrustPMF.",
4970.txt,"This is mainly because the browsing interest pattern  and writing interest pattern  learned from the symmetric friend networks are nearly identical, and hence the recommendation quality improvement that results from their combination is limited.",
4971.txt,"In summary, the last two rows of Table 4 give the average ranks of all methods in terms of both MAE and RMSE, reflecting their respective comprehensive performance on different datasets.",
4972.txt,"As mentioned in Section 1, cold start is one big challenge faced by CF  methods.",
4973.txt,We  now  evaluate  the  capabilities of addressing cold start users by respective competitors.,
4974.txt,"Generally, those who have rated five or fewer ratings are deemed as cold start users.",
4975.txt,"Cross-validation is still used in the test but we only care about the accuracy of predictions for cold start users .And the social relation number on average of cold start user in Epinions, Ep  Ext, Douban and Flixster are 5.38, 1.47,23.97 and 27.43, respectively.",
4976.txt,"Table 5 shows that TrustPMF performs the best once again on datasets Epinions, Ep Ext and Flixster while TrustMF performs the best on Douban, and achieve more remarkable improvements against other CF methods than the case of testing all users.",
4977.txt,"This experiment indicates that, compared with current CF methods, our proposed TrustPM- F and TrustMF have demonstrated the ability to provide high quality recommendations to cold start users.",
4978.txt,We conduct an additional experiment to further check the capabilities of the different methods to utilize sparse trust  data for recommendation.,
4979.txt,"Distinct from previous validations that focus on comparing the global quality of recommendations in terms of the average accuracy over all users, here we are particularly interested in testing the performance of respective social CF methods  with regard to different categories of users.",
4980.txt,"We first cluster all users into several groups according to their degrees in social networks, and then calculate the prediction error over each group.",
4981.txt,The degree distribution of each group of users and the average number of ratings in each group are shown in Fig.,
4982.txt,5,
4983.txt,"As we see, for each dataset, the more social ties uses have, the more ratings they will contribute.",
4984.txt,Fig.,
4985.txt,"6 shows the recommendation quality of different methods in terms of RMSE , from which we can observe following points.",
4986.txt,"First, TrustPMF demonstrates the highest quality for all groups on all datasets, particularly for users who occupy only a few trust ties, indicating that TrustPMF can utilize sparse trust data more effectively than current social CF methods.",
4987.txt,"Second, the performance of all six methods varies to different extents with respect to different groups, but the result curves of the different methods have similar trends.",
4988.txt,"This means that users who occupy more social ties will contribute more to ratings, and consequently the predictions  for  them  are  expected to be more accurate.",
4989.txt,This indicates that some users with more social relations  might not receive desired recommendations from recommender systems.,
4990.txt,"One possible reason for this is that some active users tend to add more and more friends, or trust more and more users, without real intentions, and these casual social ties will greatly reduce the ability to learn their genuine interest patterns.",
4991.txt,"This experiment demonstrates that social networks can be used to improve the performance of collaborative filtering, and have potential to help recommendation systems target ""extremely social"" users for whom it is hard to provide accurate recommendations.",
4992.txt,"Now we use the metrics that are widely used in IR  to further evaluate different algorithms.Specifically, we use Precision, Recall and F1-score to test if algorithms can precisely and completely find all favorite items for target user, and use NDCG to quantitatively measure the consis-tency between the item rankings generated by algorithms and the ground truths.",
4993.txt,"Based on the metrics, we tested the PMF, SoRec, RSTE, SocialMF and our proposed TrustPMF listed in Table 3 across four datasets in  Table  2.",
4994.txt,"Limited  by  space,  here  we just report the results of Epinions and Douban, two representative datasets, in the sense that Epinions contains a directed trust network while Douban contains a undirected friend network.",
4995.txt,Similar results are obtained for the other two datasets.,
4996.txt,Tables 6 and 7 also show the experimental results in terms of NDCG.,
4997.txt,"In both cases of all users and cold start users, TrustPMF performs better than others, especially for Einions dataset.",
4998.txt,"Notably, in terms of NDCG all methods perform better in the case of cold start users on both datasets.",
4999.txt,"That is, the NDCG values calculated for cold start users are larger than those for all users.",
5000.txt,The main reasons are two-fold.,
5001.txt,"On one hand, it is more difficult for algorithms to correctly rank a big set than a small one under the NDCG metric.",
5002.txt,"On the other hand, cold start users usually occupy much less observed ratings in testing set and thereby the item sets to be ranked for them are very small.",
5003.txt,"Very recently, two new social recommendation methods, TrustSVD and SPF , have been proposed.",
5004.txt,"TrustSVD incorporates the ideas of both the SVD++  and the Truster  model, aiming   to capture user and item biases as well as the explicit and implicit influence of both rated items and trusted users.",
5005.txt,SPF extends the Poisson factorization model to integrate the implicit feedbacks of users and the social networks among the same users.,
5006.txt,"Next, we will evaluate the performance of the two state-of-the-art methods and the TrustPMF in terms of rank-based metrics.",
5007.txt,"These three model-based methods are also compared to a popularity baseline, which naively ranks items only according to their universal popularity in terms of the quantity of ratings received by them respectively.",
5008.txt,Data sparsity and cold starts present challenges to traditional collaborative filtering methods used in recommendation systems.,
5009.txt,"We addressed these issues by more effectively utilizing additional trust data, and proposed a novel method based on social collaborative filtering by trust that was motivated by the observation that individuals will affect each other during the reviewing process.",
5010.txt,"By properly identifying the twofold influence of trust propagation on the generation of a user's preferences, we first propose a truster model and a trustee model, and then combine them into the TrustMF model.",
5011.txt,"The truster and trustee models map users into the same latent feature spaces, but with different implications that can explicitly describe the feedback of how users affect or follow the opinions of others.",
5012.txt,"Moreover, a more general and flexible framework referred to as the TrustPMF is proposed, which is able to provide a probabilistic view for understanding the Truster, Trustee and TrustMF models, and can furthr enhance recommendation quality by incorporating both browsing and writing preferences in a more flexible way.",
5013.txt,"As shown by a series of vigorous validations, the TrustPMF performed significantly better than current CF methods across four large-scale datasets.",
5014.txt,"This was especially true for the cold start users who have few ratings, or occupy only a few trust ties.",
5015.txt,"In addition to positive ratings and positive social ties , the available negative ratings  and negative social ties are equally important for comprehensively learning a user's preferences.",
5016.txt,We propose a novel approach for enhancing depth videos containing non-rigidly deforming objects.,
5017.txt,Depth sensors are capable of capturing depth maps in real-time but suffer from high noise levels and low spatial resolutions.,
5018.txt,"While solutions for reconstructing 3D details in static scenes, or scenes with rigid global motions have been recently proposed, handling unconstrained non-rigid deformations in relative complex scenes remains a challenge.",
5019.txt,Our solution consists in a recursive dynamic multi-frame super-resolution algorithm where the relative local 3D motions between consecutive frames are directly accounted for.,
5020.txt,We rely on the assumption that these 3D motions can be decoupled into lateral motions and radial displacements.,
5021.txt,This allows to perform a simple local per-pixel tracking where both depth measurements and deformations are dynamically optimized.,
5022.txt,The geometric smoothness is subsequently added using a multi-level L1 minimization with a bilateral total variation regularization.,
5023.txt,The performance of this method is thoroughly evaluated on both real and synthetic data.,
5024.txt,"As compared to alternative approaches, the results show a clear improvement in reconstruction accuracy and in robustness to noise, to relative large non-rigid deformations, and to topological changes.",
5025.txt,"Moreover, the proposed approach, implemented on a CPU, is shown to be computationally efficient and working in real-time.",
5026.txt,"sensing using 3D technologies, structured light cameras or time-of-flight  cameras, has seen a revolution in the  past years where sensors such as the Microsoft Kinect version 1 and 2 are today part of accessible consumer electronics .",
5027.txt,"The ability of these sensors in directly capturing depth videos in real-time has opened tremendous possibilities for applications in gaming, robotics, surveillance, health care.",
5028.txt,"These sensors, unfortunately, have major shortcomings due to their high noise contamination, including missing and jagged measurements, and their low spatial resolutions.",
5029.txt,This makes it impossible to capture detailed 3D features indispensable for many 3D computer vision algorithms.,
5030.txt,The face data in Fig.1 is an example of such challenging raw depth measurements.,
5031.txt,Running a traditional face recognition algorithm on this type of data would result in a very low recognition rate.,
5032.txt,"Some solutions have been proposed in the literature for recovering these details but mostly in the context of static 3D  scene  scanning,  with  LidarBoost  and its extension and KinectFusion being the most known methods.",
5033.txt,The current major challenge is when the object or objects in the scene are subject to non-rigid deformations.,
5034.txt,"Indeed, LidarBoost and KinectFusion are rigid depth fusion approaches,and they immediately fail in providing any reasonable result on non-rigidly deforming scenes, the focus of this paper.",
5035.txt,"We proposed the UP-SR algorithm, which stands for Upsampling for Precise Super-Resolution, as the first dynamic multi-frame depth video super-resolution  algorithm that can enhance depth videos containing non-rigidly deforming scenes without any prior assumption on the number of moving objects they contain or on the topology of these objects.",
5036.txt,"These advantages were possible thanks to a direct processing on depth maps without using connectivity information inherent to meshing as used in subsequent methods, namely, KinectDeform  and DynamicFusion .",
5037.txt,"The UP-SR algorithm is, however, limited to lateral motions as it only computes 2D dense optical flow but does not account for the full motion in 3D, known as scene flow, or the 2.5D motion, known as range flow.",
5038.txt,It consequently fails in the case of radial deformations.,
5039.txt,"Moreover, it is not practical because of a heavy cumulative motion estimation process applied to a number of frames buffered in the memory.",
5040.txt,This paper presents a solution that improves over the UPSR algorithm by keeping its advantages and solving its two limitations ?not considering 3D motions and using an inefficient cumulative motion estimation.,
5041.txt,The proposed solution is based on the assumption that the 3D motion of a point can be approximated by decoupling the radial component from the lateral ones.,
5042.txt,This approximation allows the handling of non-rigid deformations while reducing the computational complexity associated with an explicit full 3D motion estimation at each point.,
5043.txt,"Moreover, a recursive depth multi-frame SR is formulated by replacing UPSR's cumulative motion estimation with a point-tracking operation locally at each pixel.",
5044.txt,"Similarly to earlier approaches for a recursive SR, we use a Kalman filter for tracking except that     we treat each pixel separately as opposed to considering the full image.",
5045.txt,"As a result, the proposed solution efficiently runs multiple Kalman filters in parallel on local depth values and on their radial displacements.",
5046.txt,A subsequent processing is required in order to recover the smoothness property of a depth map and correct theartifacts caused by this per-pixel filtering.,
5047.txt,"To that end, we propose a  multi-level  version  of  the  L1  minimization  with  a bilateral total variation  regularization originally given in X.",
5048.txt,The proposed algorithm leads to a new approach for estimating range total variation regularization originally given in X.,
5049.txt,The proposed algorithm leads to a new approach for estimating range flow by pixel tracking with a Kalman filter.,
5050.txt,"It is important to note that while this flow contributes in handling non-rigid deformations in 3D, the effectiveness of the proposed SR algorithm comes from how this flow is employed in the UP-SR reconstruction framework.",
5051.txt,"Indeed, merely applying the estimated range flow in another depth SR method does not give satisfactory results.",
5052.txt,"An overview of the proposed algorithm, named recUP-SR, is given in Fig.",
5053.txt,2,
5054.txt,A first visual illustration of the  erformance of the proposed algorithm on a low quality depth video of a highly non-rigidly deforming face is given in Fig.,
5055.txt,1,
5056.txt,"In summary, the contribution of this paper is a new mutliframe depth SR algorithm which has the following properties: Accuracy in depth video reconstruction.",
5057.txt,Robustness to non-rigid deformations and to noise.,
5058.txt,Robustness to topological changes.,
5059.txt,Independence of the number of moving objects in the scene.,
5060.txt,Real-time implementation on a CPU.,
5061.txt,"This paper is an extended version of X with additional theoretical details and clarifications explaining the transition from the earlier UP-SR algorithm to the recUP-SR algorithm proposed  herein, and an extended explanation of the proposed multi-level iterative deblurring.",
5062.txt,A significantly extended experimental part is also provided containing original analyses based on new results.,
5063.txt,The remainder of the paper is organized as follows: Section 2 gives an overview of the different categories of depth enhancement approaches and a review of range flow algorithms.,
5064.txt,Section 3 formulates the problem of depth video SR and describes the necessary background on UP-SR.,
5065.txt,The proposed recursive depth video SR algorithm is presented in Section 4.,
5066.txt,Experimental evaluations are presented and discussed in Section 5.,
5067.txt,"Finally, the conclusion is given in Section 6.",
5068.txt,Three categories of approaches for the enhancement of depth videos containing non-rigid deformations may be distinguished  as detailed below.,
5069.txt,"This category of methods is based on the assumption that there   is a correspondence between the edges of a depth map and the edges of another modality of a better quality, often chosen to be   a 2D intensity image of the same scene .",
5070.txt,"Such an image is considered to be a guidance image whose properties, in terms of structure, signal to noise ratio  and resolution, can be transferred to its corresponding depth map in order to obtain  an enhanced version.",
5071.txt,Diebel and Thrun proposed the first work in this category .,
5072.txt,"Their approach consists in a multiresolutional Markov Random Field  defined to integrate both modalities, depth and 2D intensity, and used to estimate a depth map of the same resolution as the resolution of the intensity image.",
5073.txt,"In 2007, Kopf and Yang proposed the concept of   joint bilateral upsampling, which is an adapted version of the bilateral filter for fusing a low resolution  depth  map with a high resolution 2D image.",
5074.txt,"In X, the JBU multi-modal filter was extended to considering not only a 2D image as a guidance image but also the depth map itself.",
5075.txt,These weighting-based filters may be viewed as implicit guided regularization approaches.,
5076.txt,"In an explicit guided regularization approach, a regularization function that translates the prior properties of a guidance image is added to a data fidelity term to form a cost function to be optimized as in X.",
5077.txt,These more sophisticated approaches are as of today the most effective ones in the category of multi-modal fusion.,
5078.txt,Another variant in this category are methods using passive stereo imaging in combination with low quality active depth sensors.,
5079.txt,"However, besides the fact that all approaches in this category require an additional camera, they are also highly dependent on the assumption of correspondence between 2D intensity and depth images.",
5080.txt,This requires a perfect calibration and synchronization of a multi-camera system and a perfect data mapping.,
5081.txt,The first work in this category is by Mac Aodha known as patch-based single image SR.,
5082.txt,"This method, as implied by its name, follows a patch-based approach where an LR patch is reconstructed from a large dictionary of synthetic noise-free HR depth patches.",
5083.txt,The boundaries of overlapping patches follow a special treatment to keep smoothness properties.,
5084.txt,An important contribution of X is the large database of  HR  depth  maps  used to create the dictionary.,
5085.txt,The idea there is to run a search for similar patches only using the repetitive information already available in the depth map to be enhanced.,
5086.txt,"To compute the similarity between depth patches, the PatchMatch algorithm by Barnes was redefined in 3D under invariance to 3D rigid motions.",
5087.txt,"In X, a patchwork assembly algorithm for depth single image SR was proposed merging the concept of using a training database and the concept of self-similarity .",
5088.txt,The problem was formulated as an MRF optimization which could optionally add information from an HR 2D intensity image following the same principle of multi-modal fusion approaches.,
5089.txt,"Another work at the frontier of the two categories, learning-based and multimodal fusion approaches, was proposed earlier by Li in  X.",
5090.txt,Using multiple frames to recover depth details has been successful in the case of static scenes or scenes with global rigid motion.,
5091.txt,"Since these methods and their immediate  derivatives,  the real challenge that the research community has been facing is extending the multi-frame depth enhancement concept to scenes with non-rigid deformations.",
5092.txt,There have been few attempts to handle single object scanning under relative small non-rigidities by replacing a global rigid registration with a non-rigid alignment .,
5093.txt,"These techniques, however, cannot handle large deformations, and are not very practical for real-time applications.",
5094.txt,Real-time non-rigid reconstruction approaches have been achieved with the help of a template  which  is  first  acquired  then used for tracking of non-rigidities with a good flexibility.,
5095.txt,"Recently, we have proposed KinectDeform , the first nonrigid version of KinectFusion.",
5096.txt,"It does not require any template, and similarly to KinectFusion, provides an enhanced smoother reconstruction over time with the addition of handling non-rigid deformations in the scene.",
5097.txt,"KinectDeform has been successfully tested on an Asus Xtion Pro Live camera , equivalent to Microsoft Kinect structured light version 1.",
5098.txt,"It cannot, however, perform well on lower resolution, noisier ToF cameras such as the PMD camboard nano.",
5099.txt,"Indeed, its registration module requires denser raw acquisitions.",
5100.txt,DynamicFusion is another recent nonrigid version of KinectFusion.,
5101.txt,"Thanks to a GPU implementation, it has been tested on a Kinect camera in real-time.",
5102.txt,"However, its reconstruction accuracy has not been evaluated, and it has only been validated visually.",
5103.txt,"Moreover, it builds on the assumption    of having only one moving  object  in  the  scene.",
5104.txt,"In  addition,  its reported limitations are its sensitivity to complex scenes and scenes with changes in topology.",
5105.txt,"Also, similarly to KinectDeform, one may suspect DynamicFusion not to be able to perform well on a lower resolution noisier ToF camera.",
5106.txt,The UP-SR algorithm falls under this category of dynamic multi-frame approaches.,
5107.txt,"Indeed, it exploits the deformations collected over time in an inverse SR reconstruction framework.",
5108.txt,UPSR was shown in  X to have a higher reconstruction accuracy as compared to representative methods from the first  and second categories of depth enhancement methods.,
5109.txt,"Its major drawbacks, however, are its limitation to lateral motions and its computational complexity.",
5110.txt,"Using range flow in place of optical flow is a natural first step towards reconstructing non-lateral, i.e., radial, local deformations.",
5111.txt,"In what follows, we review related literature on range flow estimation.",
5112.txt,"In order to handle 3D non-rigid deformations, it is important to consider the full 3D motion per pixel or the range flow.",
5113.txt,"The range flow constraint has been first proposed in X, and later appeared in other references.",
5114.txt,This constraint is usually used in     a variational framework to estimate the range flow.,
5115.txt,"However, estimating a dense range flow, i.e., a three dimensional vector for each point is still computationally complex and not achievable in real-time, at least, not with a subpixel accuracy.",
5116.txt,Using RGBD depth cameras has allowed a multi-modal approach for range flow estimation by defining a global energy functional combining the range flow and the 2D optical flow constraints.,
5117.txt,"In addition    to the challenge of reducing the computational complexity, these algorithms have to handle erroneous measurements of depth sensors such as flying pixels, and missing and invalid values.A common approach is to define a smoothness condition to be used as a regularization term in the global optimization.",
5118.txt,"In X, a probabilistic approach is followed by using a particle filter.",
5119.txt,This concept is the closest to our range flow estimation where information is recursively propagated to the next frame.,
5120.txt,"Recently, the aTGV-SF algorithm has been proposed where the flow is directly calculated in 3D by back-projection, resulting in a joint estimation of the lateral and radial motions.",
5121.txt,"To our knoweledge, this is reported to be currently the best performing range flow algorithm in terms of accuracy and runtime.",
5122.txt,We will use it as a reference in our evaluation.,
5123.txt,"As explained in Section 1, the current paper improves UP-SR.",
5124.txt,"In Section 3, the necessary background on UP-SR is given after formalizing the problem of multi-frame SR.",
5125.txt,"In order to be able to carry a per-pixel processing, essential for handling non-rigid deformations, one needs to properly align these pixels between consecutive frames.",
5126.txt,"In order to compare our algorithm with stateofart methods, we use a scene with a highly nonrigidly moving object.",
5127.txt,We use the publicly available "Samba"  data.,
5128.txt,This data corresponds to a real sequence of a dancing lady scene in full 3D.,
5129.txt,"This sequence contains both nonrigid radial motions and selfocclusions, represented by arms and leg movements, respectively.",
5130.txt,We use the publicly available toolbox V-REP to create from the "Samba" data a synthetic depth sequence with fully known ground truth.,
5131.txt,We choose to fix a depth camera at a distance of 2 meters from the 3D scene.,
5132.txt,Its resolution is 10242 pixels.,
5133.txt,The camera is used to capture the depth sequence.,
5134.txt,Then we downsample the obtained depth sequence with r = 4 and further degrade it with additive Gaussian noise with standard deviation  varying from 0 to 50mm.,
5135.txt,"The created LR noisy depth sequence is then superresolved using stateofart methods: the conventional bicubic interpolation, UP- SR, SISR, and the proposed recUP-SR. Table 1 reports the 3D reconstruction error of each method at different noise levels.",
5136.txt,"Then, we compare the accuracy of the reconstructed 3D super?resolved scene with stateofart results.",
5137.txt,The comparison is done by backprojecting the reconstructed HR depth images to the 3D world using the camera matrix and calculating the 3D Root Mean Squared Error  of each backprojected 3D point cloud with respect to the ground truth 3D point cloud.,
5138.txt,"The comparison is done at two levels: Different  parts  of  the  reconstructed 3D body, namely, arm, torso, and leg, and full reconstructed 3D body.",
5139.txt,"As expected, by applying the conventional bicubic interpolation method directly on depth images, a large error is obtained.",
5140.txt,This error is mainly due to the flying pixels around object boundaries.,
5141.txt,"Thus, we run another round of experiments using a modified bicubic interpolation, where we remove all flying pixels by defining a fixed threshold.",
5142.txt,"Yet, the 3D reconstruction error is still relatively high across all noise levels, see Table 1.",
5143.txt,This is due to the fact that bicubic interpolation does not profit from the temporal information provided by the sequence.,
5144.txt,"We observe  in Table 1 that the proposed method provides, most of the time, better results as compared  to  stateofart  algorithms.",
5145.txt,"In order to visually evaluate the performance of the proposed recUP-SR algorithm, we plot the superresolved results for one frame of the dancing girl sequence in 3D.",
5146.txt,We evaluate the performance of the recUP-SR algorithm at different levels.,
5147.txt,"First, we show how it is efficient in filtering both the depth value as well as  the  radial  displacement  and  hence the corresponding velocity.",
5148.txt,"Then we evaluate the range flow estimation, and finally, we show the importance of deblurring.",
5149.txt,We start with a simple and  fully  controlled  scene  containing one 3D object moving radially with respect to the camera.,
5150.txt,The considered object is a synthetic hand.,
5151.txt,One of the main contributions of this paper is the estimation of range flow by point tracking with a Kalman filter.,
5152.txt,We visually evaluate the accuracy of this flow on a known sequence of a hand nonrigidly deforming and captured with the PMD CamBoard Nano camera.,
5153.txt,We qualitatively compare this result with the stateofart range flow algorithm aTGV-SF .,
5154.txt,The result for one frame is given in Fig.,
5155.txt,8,
5156.txt,"One can see that the proposed approach provides  a smoother and more homogeneous flow, which is more accurate.",
5157.txt,"Moreover, this flow is computed at a frame rate of 19 frames per second on a CPU and without parallelization considering r = 2, which is faster than aTGV-SF's reported runtime of 1 frame per second using an optimized code.",
5158.txt,We have used the publically available aTGV-SF Matlab code which took around 200 seconds for one frame.,
5159.txt,We have kept the same parameters used with the PMD CamBoard Nano camera as in X.,
5160.txt,The aTGV-SF  flow  was also used to super-resolve a depth scene containing a non- rigidly deforming object.,
5161.txt,The proposed SR consists in median filtering all registered frames using the estimated flow after back- projecting them to the 3D world.,
5162.txt,We give the result of aTGV-SF as well as our result recUP-SR in Fig.,
5163.txt,"9, respectively.",
5164.txt,This result shows that the proposed algorithm outperforms aTGV-SF  at the level of the flow and also at the SR level.,
5165.txt,Fig.,
5166.txt,"9 gives the result of using the flow of recUP-SR  in the SR of aTGV-SF , and vice versa.",
5167.txt,"This shows that while the flow estimated through recUP-SR is good and outperforms stateofart methods, it is not sufficient to directly use it in a multi-frame SR algorithm.",
5168.txt,"Using the aTGV-SF in the proposed SR algorithm, however, provides a more acceptable result although still inferior to the proposed recUP-SR .",
5169.txt,"This is confirmed by the corresponding 3D rendering given in  Fig 10, and can be explained by the fact that the proposed recUP- SR algorithm is a simultaneous filtering of the flow and also the depth values.",
5170.txt,This ensures an effective reconstruction of non-rigid depth scenes.,
5171.txt,"By considering the deblurring step alone without engaging in the perpixel temporal filtering process, we can see that the 3D RMSE is almost constant throughout the sequence as shown in Fig.",
5172.txt,11 .,
5173.txt,This can be explained by the fact that there is no engagement of temporal information.,
5174.txt,Instead only a spatial filtering is applied at each frame independently of each other.,
5175.txt,"Finally, by looking at the obtained results in Fig.",
5176.txt,"11, we find that the best performance is achieved by combining the spatial and the temporal filters, with an advantage of using the proposed multilevel deblurring approach over the onelevel conventional deblurring approach.",
5177.txt,Note that an intensive search is applied to find the   best deblurring parameters which lead to the smallest 3D RMSE error.,
5178.txt,In Fig.,
5179.txt,"12, we show the physical effects of the previously discussed cases by plotting the corresponding 3D superresolved results of the last HR depth frame in the sequence.",
5180.txt,"Starting from the first column, we show the LR noisy faces for different noise levels.",
5181.txt,The filtered results using a perpixel Kalman filtering are shown in the second column where we see how the noise has been attenuated.,
5182.txt,"Finally, we tested recUP-SR on a cluttered scene of moving hands transferring a ball from one hand to another.",
5183.txt,"This scene is quite complex where it contains multiple objects moving with nonrigid deformations, and selfocclusions with one hand passing over the second one.",
5184.txt,"Moreover, the scene contains a challenging case of topology changes represented by hands touching each other and then separating.",
5185.txt,We  note that a strong temporal filtering leads     to a longer time for convergence in  the case  of selfocclusions or nonsmooth motions.,
5186.txt,"Similarly, a strong spatial filtering leads to undesired over-smoothing effects and hence removing the fine details from the final reconstructed HR depth sequence.",
5187.txt,"Thus, in order to handle such a scene, a tradeoff between the temporal and spatial filtering has to be achieved.",
5188.txt,Obtained results in Fig.,
5189.txt,16 show the robustness of the proposed algorithm in handling this kind of scenes.,
5190.txt,Full video of results is available through this link.,
5191.txt,We have proposed a new algorithm to enhance the quality of low resolution noisy depth videos acquired with cost-effective depth sensors.,
5192.txt,This algorithm improves upon the UP-SR algorithm  which was able to handle non-rigid deformations but limited to lateral motions.,
5193.txt,"The newly proposed algorithm, recUP-SR, is designed to handle non-rigid deformations in 3D thanks to a perpixel filtering that directly accounts for radial displacements in addition to lateral ones.",
5194.txt,This algorithm is formulated in a dynamic recursive way that allowed a computationally efficient real-time implementation on CPU.,
5195.txt,"Moreover, as compared to state-of-the- art methods, the processing on depth maps while approximating local 3D motions has allowed to maintain a good robustness against topological changes and independence of the number of moving objects in the scene.",
5196.txt,This property is a clear advantage over most recent methods that explicitly compute a flow in 3D and apply a processing on meshed point clouds.,
5197.txt,"In order to keep smoothness properties without losing details, each filtered depth frame is further refined using a multilevel iterative bilateral total variation regularization after filtering and before proceeding to the next frame in the sequence.",
5198.txt,This post-processing is shown experimentally to give the best final results in terms of 3D error without having access to full information about the scene and the sensor.,
5199.txt,"Supported by the experimental results on both synthetic and real data, we believe that recUP-SR opens new possibilities for computer vision applications using cost-effective depth sensors in dynamic scenarios with non-rigid motions.",
5200.txt,Further developments in the case of strong self-occlusions are still required.,
5201.txt,"As shown, the proposed recUP-SR algorithm needs a number of depth measurements before converging, which is not suitable for some applications.",
5202.txt,"Moreover, a realistic depth sensor noise model is more complex than the Gaussian model considered in this work.",
5203.txt,An extended work would be to adapt the proposed solution to a more elaborate noise model on depth measurements.,
5204.txt,"This paper aims to develop a novel cost-effective framework for face identification, which progressively maintains a batch of classifiers with the increasing face images of different individuals.",
5205.txt,"By naturally combining two recently rising techniques: active learning , our framework is capable of automatically annotating new instances and incorporating them into training under weak expert recertification.",
5206.txt,"We first initialize the classifier using a few annotated samples for each individual, and extract image features using the convolutional neural nets.",
5207.txt,"Then, a number of candidates are selected from the unannotated samples for classifier updating, in which we apply the current classifiers ranking the samples by the prediction confidence.",
5208.txt,"In particular, our approach utilizes the high-confidence and low-confidence samples in the self-paced and the active user-query way, respectively.",
5209.txt,The neural nets are later fine-tuned based on the updated classifiers.,
5210.txt,"Such heuristic implementaion is formulated as solving a concise active SPL optimization problem, which also advances the SPL development by supplementing a rational dynamic curriculum constraint.",
5211.txt,The new model finely accords with the "instructor-student-collaborative" learning mode in human education.,
5212.txt,The advantages of this proposed framework are two-folds: The required number of annotated samples is significantly decreased while the comparable performance is guaranteed.,
5213.txt,A dramatic reduction of user effort is also achieved over other state-of-the-art active learning techniques.,
5214.txt,The mixture of SPL and AL effectively improves not only the classifier accuracy compared to existing AL/SPL methods but also the robustness against noisy data.,
5215.txt,"We evaluate our framework on two challenging datasets, which include hundreds of persons under diverse conditions, and demonstrate very promising results.",
5216.txt,"With the growth of mobile phones, cameras and social networks, a large amount of photographs is rapidly created, especially those containing person faces.",
5217.txt,"To interact with these photos, there  have  been  increasing demands of developing intelligent systems  with face recognition techniques .",
5218.txt,"Thanks to several recently proposed pose/expression normalization and alignment-free approaches , identifying face in the wild has achieved remarkable progress.",
5219.txt,"As for the commercial product, the website ""Face.com""  once  provided  an  API  to automatically detect and recognize faces in photos.",
5220.txt,The main problem in such scenarios is to identify individuals from images under a relatively unconstrained environment.,
5221.txt,"Traditional methods usually handle this problem by supervised learning, while it is typically expensive and time-consuming to prepare a good set of labeled samples.",
5222.txt,"Since only a few data are labeled, Semi-supervised learning  may be a good candidate to solve this problem.",
5223.txt,"But it has been pointed out by X: Due to large amounts of noisy samples and outliers, directly using the unlabeled data may significantly reduce learning performance.",
5224.txt,This paper targets on the challenge of incrementally learning a batch of face recognizers with the increasing face images of different individuals.,
5225.txt,Here we assume that the person faces can be basically detected and localized by existing face detectors.,
5226.txt,"However, to build such   a system is quite challenging in the following aspects.Person faces have large appearance variations  caused by diverse views and expressions as well as facial accessories and aging.",
5227.txt,"The different lighting condition is also required to be considered in practice.It is possible that only a few labeled samples are accessible at the beginning, and the changes of personal faces are rather unpredictable over time, especially under the current scenarios that there are large amount of images swarmed into Internet every day.Satisfaction of user experience is one of the critical concerns.",
5228.txt,"Even though a few user interventions  could be allowed, the user effort is desired to be kept minimizing over time.",
5229.txt,Conventional incremental face recognition methods such as incremental subspace approaches  often fail on complex and large-scale environments.,
5230.txt,Their performances could be dropped drastically when the initial training set of face images is either insufficient or inappropriate.,
5231.txt,"In addition, most of existing incremental approaches suffer from noisy samples or outliers in the model updating.",
5232.txt,"In this work, we propose a novel active self-paced learning framework  to handle the above difficulties, which absorbs powers of two recently rising techniques: active learning and selfpaced learning.",
5233.txt,"In particular, our framework tends to conduct a ""Cost-less-Earn-more"" working manner: as much as possible pursuing a high performance while reducing costs.",
5234.txt,"The basic approach of the AL methods is to progressively select and annotate most informative unlabeled samples to boost the model, in which user interaction is allowed.",
5235.txt,"The sample selection criteria is the key in AL, and it is typically defined according to the classification uncertainty of samples.",
5236.txt,"Specifically, the samples of low classification confidence, together with other informative criteria like diversity, are generally treated as good candidates for model retraining.",
5237.txt,"On the other  hand,  SPL is a recently proposed learning regime  to  mimic the learning process of humans/animals that gradually incorporates easy to more complex samples into training, where an easy sample is actual the one of high classification confidence by the currently trained model.",
5238.txt,"Interestingly, the two categories of learning methods select samples with the opposite criteria.",
5239.txt,This finding  inspires us to investigate the connection between the two learning regimes and the possibility of making them complementary to each other.,
5240.txt,"Moreover, as pointed out in X, learning based features are considered to   be able to exploit information with better discriminative ability for face recognition, compared to the hand-crafted features.",
5241.txt,We thus utilize the deep convolutional neural network for feature extraction instead of using handcraft image features..,
5242.txt,"In sum, we aim at designing a cost-effective and progressive learning framework, which is capable of automatically annotating new instances and incorporating them into training under weak expert recertification.",
5243.txt,"In the following, we discuss the advantage of our ASPL framework in two aspects: ""Cost-less"" and ""Earn-more"".",
5244.txt,"Our framework is capable of building effective classifiers with less labeled training instances and less user efforts, compared with other state-of-the- art algorithms.",
5245.txt,This property is achieved by  combining the active learning and self-paced learning in the incremental learning process.,
5246.txt,In  certain  feature  space of model training as Fig.,
5247.txt,"1   illustrates,  samples  of low classification confidence are scattered and close to the classifier decision boundary while high confidence samples distribute compactly in the intra-class regions.",
5248.txt,Our approach takes both categories of samples into consideration for classifier updating.,
5249.txt,"The benefit of this strategy includes: High-confidence samples can be automatically labeled and consistently added into model training throughout the learning process in a self-paced fashion, particularly when the classifier becomes more and more reliable at later learning iterations.",
5250.txt,This significantly reduce the burden of user annotations and make the method scalable in large-scale scenarios.,
5251.txt,"The low-confidence samples are selected by allowing active user annotations, making our approach more efficiently pick up informative samples, more adapt to practical variations and converge faster, especially in the early learning stage of training.",
5252.txt,The mixture of self-paced learning and active learning effectively improves not only the classifier accuracy but also the classifier robustness against noisy samples.,
5253.txt,"From the perspective of AL, extra highconfidence samples are automatically incorporated into the retraining without cost of human labor in each iteration, and faster convergence can be thus gained.",
5254.txt,"These introduced high-confidence samples also contribute to suppress noisy samples in learning, due to their compactness and consistency in the feature space.",
5255.txt,"From the SPL perspective, allowing active user intervention generates the reliable and diverse samples that can avoid the learning been misled by outliers.",
5256.txt,"In addition, utilizing the CNN facilitates to pursue a higher classification performance by learning the convolutional filters instead of hand-craft feature engineering.",
5257.txt,"In brief, our ASPL framework includes two main phases.",
5258.txt,"At the initial stage, we first learn a general face representation using an architecture of convolutional neural nets, and train a batch of classifiers with a very small set of annotated samples of different individuals.",
5259.txt,"In the iteration learning stage, we rank the unlabeled samples according to how they relate to the current classifiers, and retrain the classifiers by selecting and annotating samples in either active user-query or selfpaced manners.",
5260.txt,We can also make the CNN fine-tuned based on the updated classifiers.,
5261.txt,"The key point in designing such an effective interactive learning system is to make an efficient labor division between computers and human participants, we should possibly feed computable and faithful tasks into computers, and to possibly arrange labor-saving and intelligent tasks to humans.",
5262.txt,"The proposed ASPL framework provides a rational realization to this task   by automatically distinguishing high-confidence samples, which can be easily and faithfully recognized by computers in a self-paced way, and low-confidence ones, which can be discovered by requesting user annotation.",
5263.txt,The main contributions of this work are several folds.,
5264.txt,"i)To the best of our knowledge, our work is the first  one to make a face recognition framework capable of automatically annotating high-confidence samples and involve them into training without need of extra human labor in a purely self-paced manner under weak recertification of active learning.",
5265.txt,"Especially in that along the learning process, we can achieve more and more pseudolabeled samples to facilitate learning totally for free.",
5266.txt,Our framework is thus suitable in practical large-scale scenarios.,
5267.txt,The proposed framework can be easily extended to other similar visual recognition tasks.,
5268.txt,ii) We provide a concise optimization problem and theoretically interpret that the proposed ASPL is an rational implementation for solving this problem.,
5269.txt,"iii) This work also advances  the SPL development, by setting a dynamic curriculum variation.",
5270.txt,The new SPL setting  better  complies  with  the "instructor-student-collaborative" learning mode in human education than previous models.,
5271.txt,iv) Extensive experiments on challenging CACD and CASIA-WebFace datasets show that our approach is capable of achieving competitive or even better performance under only small fraction of sample annotations than that under overall labeled data.,
5272.txt,A dramatic reduction  of user interaction is achieved over other state-of-the-art active learning methods.,
5273.txt,The rest of the paper is organized as follows.,
5274.txt,Section  II presents a brief review of related work.,
5275.txt,"Section III overview the pipeline of our framework, followed by  a discussion of model formulation and optimization in Section IV.",
5276.txt,"The experimental results, comparisons and component analysis are presented in Section V. Section VI concludes the paper.",
5277.txt,"In this section, we first present a review for the incremental face recognition, and then briefly introduce related developments on active learning and self-paced learning.",
5278.txt,"Incremental  Face  Recognition.There are two categories of methods addressing the problem of identifying faces with incremental data, namely incremental subspace and incremental classifier methods.",
5279.txt,The first category mainly includes the incremental versions of traditional subspace learning approaches such as principal component analysis  and linear discriminant analysis .,
5280.txt,"These approaches map facial features into a subspace, and keep the eigen representations  updated by incrementally incorporating new samples.",
5281.txt,"And face recognition is commonly accomplished by the nearest neighbor-based feature matching, which is computational expensive when a large number of samples are accumulated over time.",
5282.txt,"On the other hand, the incremental classifier methods target on updating the prediction boundary with the learned model parameters and new samples.",
5283.txt,Exemplars include the incremental support vector machines and the online sequential forward neural network .,
5284.txt,"In addition, several attempts have been made to absorb advantages from both of the two categories of methods.",
5285.txt,"For example, Ozawa proposed to integrate the Incremental PCA with the resource allocation network in an iterative way.",
5286.txt,"Although these mentioned approaches make remarkable progresses, they suffer from low accuracy compared with those of batch-based state-of-the- art face recognizers, and none of these approaches have been successfully validated on large-scale datasets .",
5287.txt,"And these approaches are basically studied in the context of fully supervised learning, i.e., both initial and incremental data are required to be labeled This branch of works mainly focus on actively selecting and annotating the most informative unlabeled samples, in order to avoid unnecessary and redundant annotation.",
5288.txt,"The key part of active learning is thus the selection strategy, i.e., which samples should be presented to  the  user  for  annotation.",
5289.txt,"One  of the most common strategies is the certainty-based selection, in which the certainties are measured according to the predictions on new unlabeled samples obtained from the initial classifiers.",
5290.txt,"For example, Lewis proposed to take the most uncertain instance as the one that has the largest entropy on the conditional distribution over its predicted labels.",
5291.txt,Several SVM-based methods  determine the uncertain samples as they are relatively close to the decision boundary.,
5292.txt,The sample certainty was also measured by applying a committee  of classifiers in X.,
5293.txt,"These certainty-based approaches usually ignore the large set of unlabeled instances, and are thus sensitive to outliers.",
5294.txt,A number of later methods present the information density measure by exploiting the information of unlabeled data when selecting samples.,
5295.txt,"For example, the informative samples are sequentially selected to minimize the generalization error  of the trained classifier on the unlabeled data, based on a statistical approach  or prior information .",
5296.txt,"In X, instances are taken to maximize the increase of mutual information between the candidate instances and the remaining ones based on Gaussian Process models.",
5297.txt,The diversity of the selected instance over the unlabeled data has been also taken into consideration.,
5298.txt,"Recently, Elhamifar presented a general framework via convex programming, which considered both the uncertainty and diversity measure for sample selection.",
5299.txt,"However, these mentioned active learning approaches usually emphasize those low-confidence samples while ignoring the other majority of high-confidence samples.",
5300.txt,"To enhance the discriminative capability, wang et al.",
5301.txt,"proposed a unified semi-supervised learning framework, which incorporates the high confidence coding vectors of unlabeled data into training under the proposed effective iterative algorithm, and demonstrate its effectiveness in dictionary-based classification.",
5302.txt,"Our work inspires by this work, and also employs the high-confidence samples to improve both accuracy and robustness of classifiers.",
5303.txt,Inspired by the cognitive principle of humans/animals.,
5304.txt,The SPL model  finely simulates the learning process of human education.,
5305.txt,"Specifically, it builds an ""instructor-student collaborative"" paradigm, which on one hand utilizes prior knowledge provided by instructors as a guidance for curriculum designing, and on the other hand leaves certain freedom to students to ameliorate the actual curriculum according to their learning pace .",
5306.txt,"Such a model not only includes all previous SPL/CL methods as its special cases, but also provides a general guild line to extend     a rational SPL implementation scheme against certain learning task.",
5307.txt,"Based on this framework, multiple SPL variations have been recently proposed, like SPaR.",
5308.txt,"The SPL related strategies have also been recently attempted in a series of applications, such as specific-class segmentation learning, visual category discovery, long-term tracking, action recognition and background subtraction.",
5309.txt,"Especially, the SPaR method, constructed based on the general formulation , was applied to the challenging  SQ/000Ex  task of the TRECVID MED/MER competition, and achieved the leading performance among all competing teams.",
5310.txt,It is interesting that the function of SPL is very complementary to that of AL.,
5311.txt,"The SPL methods emphasize easy samples   in learning, which correspond to the high-confidence intra-class samples, while AL inclines to pick up the most uncertain and informative samples for the learning task, which are always located in low-confidence area near classification boundaries.",
5312.txt,"SPL is capable of easily attaining large amount of faithful pseudo-labeled samples with less requirement of human labors , while tends to underestimate the roles of those most informative ones intrinsically configuring the classification boundaries; on the contrary,  AL  inclines to get informative samples, while need more human labors to manually annotate these samples with more carefully annotation.",
5313.txt,We thus expect to effectively mix these two learning schemes to help incremental learning both improve the efficiency with less human labors and achieve better accuracy and robustness  of the learned classifier against noisy samples.,
5314.txt,This constructs the basic motivation of our ASPL framework for face identification under large-scale scenarios.,
5315.txt,"In this section, we illustrate how our ASPL model works.",
5316.txt,As illustrated in Fig.,
5317.txt,"2, the main stages in our framework pipeline include: CNN pretraining for face representation, classifier updating, high-confidence sample pseudo-labeling in a self-paced fashion, low-confidence sample annotating by active users, and CNN fine-tuning.",
5318.txt,"Before running the ASPL framework, we need to pretrain a CNN for feature extraction based on a pre-given face dataset.",
5319.txt,These images are extra selected without overlapping to all our experimental data.,
5320.txt,"Since several public available CNN architectures have achieved remarkable success on visual recognition, our framework supports to directly employ these architectures and their pretrained model as initialized parameters.",
5321.txt,"In our all experiments, AlexNet is utilized.",
5322.txt,"Given the extra selected of annotated samples, we further fine-tune the CNN for learning discriminative feature representation.",
5323.txt,"At the beginning, we randomly select few images for each individual, extract feature representation for them by pretrained CNN, and manually annotate labels to them as the starting point.",
5324.txt,"In our ASPL framework, we use one-vs-all linear SVM as our classifier updating strategies.",
5325.txt,"In the beginning, only a small part of samples are labeled, and we train an initial a classifier for every individual using these samples.",
5326.txt,"As the framework gets mature, samples manually annotated by the AL and pseudo-labeled by the SPL are growing, we adopt them to retrain the classifiers.",
5327.txt,"We rank the unlabeled samples by their important weights via the current classifiers, e.g., using the classification prediction hinge loss, and then assign pseudo-labels to the topranked samples of high confidences.",
5328.txt,This step can be automatically implemented by our system.,
5329.txt,"Based on certain AL criterion obtained under the current classifiers, rank all unlabeled samples, select those top-ranked ones  from the unlabeled samples, and then manually annotate these samples by active users.",
5330.txt,"After several steps of the interaction,we make the neural nets fine-tuned by the backward propagation algorithm.",
5331.txt,"All self-labeled samples by the SPL and manually annotated ones by the AL are added into the network, we utilize the softmax loss to optimize the CNN parameters via stochastic gradient decent approach.",
5332.txt,"In this section we will discuss the formulation of our proposed framework, and also provide a theoretical interpretation of its entire pipeline from the perspective of optimization.",
5333.txt,"In specific, we can theoretically justify that the entire pipeline of this framework finely accords with a solving process for an active self-paced learning  optimization model.",
5334.txt,Such a theoretical understanding will help deliver more insightful understanding on the intrinsic mechanism underlying the ASPL system.,
5335.txt,"Considering the user annotation may contain outliers , we introduce a verification step in the AL process.",
5336.txt,"Specifically, in this step we first employ the current classifiers to obtain the prediction scores of all the annotated samples.",
5337.txt,"Then we re-rank them and select Top-L ones with lowest prediction scores and ask the user to verify these selected samples, i.e., double- checking them.",
5338.txt,"We  can set L as a small number, since we do believe the chance of human making mistakes is low.",
5339.txt,"In sum, we improve the robustness of the AL process by further validating Top-L most uncertain samples with the user.",
5340.txt,"In this way, we can reduce the effects of accumulated human annotation errors and enable the classifier to be trained in a robust manner.",
5341.txt,"When we utilize the current classifiers  to predict the label of unlabeled samples, those predicted as more than two positive labels  actually represent these samples making the current classifiers ambiguous.",
5342.txt,We thus adopt them as so called "low confident" samples and require active user to manually annotate them.,
5343.txt,"Actually, in this step, other ""low-confidence"" criterion can be utilized.",
5344.txt,We employed this simple strategy just due to its intuitive rationality and efficiency.,
5345.txt,"After the AL process, if active user annotates the selected unlabeled samples with u unseen person classes, new classifiers for these unseen classes are needed to be initialized without affecting the existed classifiers.",
5346.txt,"Moreover, there is another difficulty that the samples of the new class are not enough for classifier training.",
5347.txt,"Thanks to the proposed ASPL framework, we can employ the following four steps to address above mentioned issues.",
5348.txt,"For each of these new class  samples,  search  all  the unlabeled samples and pick out its K-nearest neighbors from the unseen class set U in the feature space;Require active user to annotate these selected neighbors to enrich the positive samples for these new person classes;
This step corresponds to the instructor's role in human education, which aims to guide a student to involve more informative curriculums in learning.",
5349.txt,"Different from the previous fixed curriculum setting in SPL throughout the learning process, here the curriculum is dynamically updated based on the  self-paced  learned  knowledge  of the model.",
5350.txt,Such an improvement  better  simulates the general learning process of a  good  student.,
5351.txt,"With the learned knowledge of a student increasing, his/her instructor should vary the curriculum settings imposed on him from more in the early stage to less in later.",
5352.txt,This learning manner evidently should conduct a better learning effect which can well adapt the personal information of the student.,
5353.txt,"In this section, we first introduce the datasets and implementation setting, and then discuss the experimental results and comparisons with other existing approaches.",
5354.txt,"CACD is a large-scale and challenging dataset for evaluating face recognition and retrieval, and it contains a batch of images of 2, 000 celebrities collected from Internet, which are varying in age, pose, illumination, and occlusion.",
5355.txt,And only a  subset  of  200  celebrities  are manually annotated by Chen.,
5356.txt,"For better convincing evaluation, we augment this subset by extra labeling 300 individuals and obtain a set of 56, 138 images in total.",
5357.txt,We detect the facial points using the method proposed in X and align the faces based on the eye locations.,
5358.txt,The experiments on both of the datasets are conducted as the following steps.,
5359.txt,"We first randomly select 80% images of each individual to form the unlabeled training set, and the rest samples are used for testing, according to the setting in the existing active learning method.",
5360.txt,"Then, we randomly annotate n samples of each person in the training set to initialize the classifier.",
5361.txt,"To get rid of the influence of randomness, we average the results over 5 times of execution with different sample selections.",
5362.txt,All of the experiments are conducted on a common desktop PC with i7 3.4GHz CPU and a NVIDIA Titan X GPU.,
5363.txt,"On the two above mentioned datasets, we evaluate the performance of incremental face identification in two aspects: the recognition accuracy and user annotation amount in the incremental learning process.",
5364.txt,The recognition accuracy is defined as the rank-one rate for face identification.,
5365.txt,We compare our ASPL framework with several existing active learning algorithms and baseline methods under the same setting: Annotate a few samples in each step based on prediction uncertainty and sample diversity; CCAL: Select only one sample having lowest prediction confidence; AL RAND: Randomly select unlabeled samples to be annotated during the training phase.,
5366.txt,"This method discards all active learning techniques and can be considered as the lower bound, and iv) AL ALL: All unlabeled samples are annotated for training the classifier.",
5367.txt,This method can be regarded as the upper bound .,
5368.txt,"For fair comparison, all of these methods utilize the same feature representation as ours in the beginning.",
5369.txt,"As the training iteration increase, active user annotation is employed to those selected most informative and representative samples.",
5370.txt,"Then, CNN fine-tuning is also exploited to improve the feature extractor for ASPL, CPAL, CCAL, AL RAND, AL ALL.",
5371.txt,he architecture of AlexNet  is utilized in our all experiments.,
5372.txt,"Thanks  to the well pre-training, the CNN updating is only implemented few times during ASPL iteration in  all  our experiments, each  only  containing  no  more  than  5 CNN updating steps.",
5373.txt,"We generally conducted CNN steps after around 5 rounds of the SPL and AL updating, and the learning rate is set as 0.001 for all layers.",
5374.txt,"Equal importance is imposed between the previous training examples and the newly labeled examples, and CNN is updated using the stochastic gradient decent methods with the momentum 0.9 and weight decay 0.0005.",
5375.txt,The results on the two datasets are reported in Fig.,
5376.txt,"3 , respectively, where we can observe how the recognition accuracy changes with increasingly incorporating more unlabeled samples.",
5377.txt,"In CACD dataset, to achieve the same recognition accuracy, ASPL model requires few annotation of the unlabeled data.",
5378.txt,"On the other hand, ASPL outperforms the competing methods in accuracy when the same amount annotations.",
5379.txt,ASPL can still have a superior performance as the iteration goes on.,
5380.txt,The similar results and phenomena can be discovered in CASIA-WebFace-Sub dataset.,
5381.txt,"As one can see that, ASPL only requires about 40% and 45% annotations to achieve the-state-of-art performance on CACD and CASIA-WebFace-Sub dataset, respectively.",
5382.txt,"While the compared methods AL RAND, CCAL and CPAL all requires about 81% and 65%, respectively.",
5383.txt,"Hence, our ASPL can performs as well as the AL ALL with minimal annotations.",
5384.txt,"Note that the performances of RAND and CCAL are relatively close, and the similar results were reported in X.",
5385.txt,"According to the explanation in X, this comes from the fact that many samples have low prediction confidences and distribute not densely in the feature space.",
5386.txt,"Thus, the randomizing sample selection achieves similar results compared to CCAL.",
5387.txt,"In SPL , classifier is first trained using the initial samples.",
5388.txt,"With the current classifier, easy samples are preferred to be selected in the early training steps, and thus it is expected that the performance of SPL heavily relies on the initial samples.",
5389.txt,"Fortunately, by incorporating with active learning, ASPL can evidently alleviate this problem.",
5390.txt,"To  verify this, we compare the performance  of  ASPL  and  SPL on 20 randomly selected individuals of CASIA-Webface-Sub dataset.",
5391.txt,The result is shown in Fig.,
5392.txt,5,
5393.txt,"Given the same initialized feature representations, we also conduct the experiments to analyze the performance vs different initial portions to be handled by AL on this dataset.",
5394.txt,The results are illustrated in Fig.,
5395.txt,6,
5396.txt,As one can see from Fig.,
5397.txt,"5, with different initial samples, ASPL reaches similar/stable results as the training continues, while SPL still varies a lot.",
5398.txt,This result indicates that the AL component is effective in handling the poor initialization.,
5399.txt,Fig.,
5400.txt,"6 illustrates that though poor performance is obtained at the beginning, the performance of our model increases during the training process.",
5401.txt,"In summary, our model is insensitive to the diversity and quantity of initial samples.",
5402.txt,"To justify the effectiveness of our ASPL for handling unseen new classes, we conduct the following experiment on the CASIA- WebFace-Sub dataset: We compare the performance of incrementally giving some classes  and directly giving all person classes.",
5403.txt,"Specifically, given all person classes, we initialize all the classifiers at the beginning of the training and optimize them without handling unseen new classes.",
5404.txt,We denote this variant as ASPL .,
5405.txt,"The experimental result is illustrated in Table 2 and shows that our proposed ASPL can handle unseen new classes effectively without substantially performance drop or even with slightly better performance, compared with the all classes given version ASPL.",
5406.txt,Annotation required for large scale dataset.,
5407.txt,"To demonstrate that our ASPL can be adopted under large scale scenario, we analyze the training phase of ASPL on the large scale CASIA-WebFace-Sub dataset.",
5408.txt,As illustrated in Fig.,
5409.txt,"7, the x-axis denotes the number of training iterations and the y-axis denotes the amount of required user annotation.",
5410.txt,The curve in Fig.,
5411.txt,7 demonstrates that our proposed ASPL model requires relatively larger annotations when the training iteration number is small.,
5412.txt,"As the training continues, the amount required annotations began to be reduced due to the gradually mature model incrementally ameliorated in the learning process.",
5413.txt,This observation indicates that the burden of user annotations would be indeed relieved when the classifier becomes reliable at the later learning stage of the proposed ASPL method.,
5414.txt,"Moreover, as illustrated in Table 3, with the increase of user annotations over time, ASPL can automatically assign more reliable pseudo-labels to the unlabeled samples selected in the self-paced way.",
5415.txt,"In  this  paper,  we  have  introduced,  first,  an  effective framework to solve incremental face identification, which build classifiers by progressively annotating and selecting unlabeled samples in an active self-paced way, and second, a theoretical interpretation of the proposed framework pipeline from the perspective of optimization.",
5416.txt,"Third, we evaluate our approach on challenging scenarios and show very promising results.",
5417.txt,"In future work, we can generalize our framework into other generic large-scale object recognition  tasks .",
5418.txt,"Moreover, we plan to study the parallelized version of our framework that can be deployed in distributed computing environments.",
5419.txt,The two underlying premises of automatic face recognition are uniqueness and permanence.,
5420.txt,This paper investigates the permanence property by addressing the following: Does face recognition ability of state-of-the-art systems degrade with elapsed time between enrolled and query face images?,
5421.txt,"If so, what is the rate of decline w.r.t.",
5422.txt,the elapsed time?,
5423.txt,"While previous studies have reported degradations in accuracy, no formal statistical analysis of large-scale longitudinal data has been conducted.",
5424.txt,"We conduct such an analysis on two mugshot databases, which are the largest facial aging databases studied to date in terms of number of subjects, images per subject, and elapsed times.",
5425.txt,"Mixed-effects regression models are applied to genuine similarity scores from state-of-the-art COTS face matchers to quantify the population-mean rate of change in genuine scores over time, subject-specic variability, and the inuence of age, sex, race, and face image quality.",
5426.txt,"Longitudinal analysis shows that despite decreasing genuine scores, 99% of subjects can still be recognized at 0.01% FAR up to approximately 6 years elapsed time, and that age, sex, and race only marginally inuence these trends.",
5427.txt,"The methodology presented here should be periodically repeated to determine age-invariant properties of face recognition as state-of-the-art evolves to better address facial aging.Automatic face recognition systems operating on face images acquired in controlled conditions, such as mugshots or driver's license photos, have achieved accuracies as high as 99% true accept rate  at a false accept rate  of 0.1% in large-scale evaluations conducted by the National Institute of Standards and Technology .Technological advancements in automatic face recognition have progressively tackled challenges caused by variations in facial pose, illumination, and expression.",
5428.txt,"Current efforts are breaking ground on robustness to ""faces in the wild""  to account for PIE, occlusion, and partial face images.",
5429.txt,"Comparatively, aging variations  have received considerably less attention in the face recognition community.",
5430.txt,Published studies on facial aging in the context of automatic face recognition have primarily employed crosssectional techniques where a population of individuals who differ in age are analyzed according to differences between age groups.,
5431.txt,"However, cross-sectional analysis cannot adequately explore age-related effects because assumptions of independent observations require that there be only one measurement per individual in the study.",
5432.txt,Past and future measurements are either not considered or are summarized into a single measurement which loses information; trends of individuals over time are not analyzed.,
5433.txt,"Hypotheses about facial aging are, instead, longitudinal by nature and require multiple measurements of the same individuals over time to reveal trends in comparison scores with respect to facial aging.",
5434.txt,To what extent facial aging affects the performance of automatic face recognition systems is of more than academic concern.,
5435.txt,"Because the appearance of the face changes throughout a person's life, most identity documents containing face images expire after a designated period of time; U.S. passports are only valid for ve years for minors and ten years for adults, while U.S. driver's licenses typically require renewal every ve years.",
5436.txt,"Additionally, to our knowledge, ensuring that a new  photo has been submitted for renewal is not veried, especially for renewals by mail or online.",
5437.txt,Validity periods of such identity documents may be too long if these photos are to be used with state-of-the-art face matching systems.,
5438.txt,Fig.,
5439.txt,1 shows that elapsed times of eight to ten years between two face images can cause false non-match errors.,
5440.txt,Studying how the actual comparison scores change over time is important for understanding the implications of operating with a global threshold1 on face recognition accuracy.,
5441.txt,"While longitudinal studies for automatic iris recognitionand ngerprint recognition  have been published, to our knowledge, no large-scale longitudinal study of automatic face recognition performance has been reported in the literature.",
5442.txt,We aim to ll this gap by addressing the following question: How robust are state-of-the-art automatic face recognition systems to facial aging?,
5443.txt,"In this paper, we conduct a longitudinal analysis of the performance of state-of-the-art COTS face matchers on two longitudinal face image databases consisting of repeat criminal offenders  from two different law enforcement agencies .",
5444.txt,The COTS matchers used here are among the top-ranked performers in the FRVT 2013 face recognition evaluation.,
5445.txt,"The contributions of this paper can be 
summarized as follows:Longitudinal analysis of two of the largest longitudinal databases studied to date.",
5446.txt,"LEO LS contains 3152 images of 5636 subjects, and PCSO LS contains 14784 images of 18007 subjects, where the average time span between a subject's multiple image acquisitions is 6.1 and 8.5 years, respectively.",
5447.txt,Such large-scale databases allow for evaluation of performance at low FAR values .,
5448.txt,Previous studies evaluated at 1% FAR and higher.Determine the age-invariant properties of current state-of-the-art face matchers.,
5449.txt,"Rates of change over time in genuine comparison scores are analyzed using mixed- effects regression models, which are appropriate for longitudinal data.",
5450.txt,"In doing so, we quantify  the population-mean rate of change in genuine scores over time and  the variability in subject-specic longitudinal trends .",
5451.txt,"We also investigate the inuence of age at enrollment, sex, race, and face image quality.Methodology and analysis tools for advancing the development and evaluation of age-invariant face recognition algorithms.",
5452.txt,The analysis conducted in  this  paper  can be applied to any matcher and any database.,
5453.txt,Periodic reevaluation will be necessary as face recognition technology evolves to better address facial aging.,
5454.txt,Our previous longitudinal analysis of automatic face recognition was rst published in X.,
5455.txt,The present work extends and renes our previous study in signicant ways.,
5456.txt,The primary differences are as follows.,
5457.txt,We study longitudinal effects of both aging  and age .,
5458.txt,The remainder of this paper is organized as follows.,
5459.txt,Section 2 highlights related work on facial aging as it pertains to automatic face recognition.,
5460.txt,Section 3 details the two longitudinal face databases used in this study.,
5461.txt,Section 4 explains the methodology used for longitudinal analysis.,
5462.txt,Section 5 gives results for both the PCSO LS and LEO LS face databases.,
5463.txt,Section 6 summarizes our observations about the current longitudinal capabilities of automatic face recognition.,
5464.txt,"Almost all of the published studies that investigate the effects of facial aging on automatic face recognition performance adopt the following approach:  divide the database  into partitions depending on age group or time lapse,  report summary performance measures  for each partition independently, and then draw conclusions from the differences in performance across the partitions.",
5465.txt,Partitioning of data  based on age group or time lapse is often arbitrary and varies from one study to another.,
5466.txt,Erbilek and Fairhurst show that different age group partitionings result in different performance trends for both iris and signature modalities .,
5467.txt,"Furthermore, this cohort-based analysis with summary statistics cannot address whether age-related performance trends are due to changes in genuine comparison scores, impostor  comparison scores, or both.",
5468.txt,Multilevel  statistical models have been used for determining important factors  to explain the performance of face recognition systems.,
5469.txt,Beveridge apply generalized linear mixed models to verication decisions made by three algorithms in the FRGC Exp.,
5470.txt,4 evaluation.,
5471.txt,"In addition to eight levels of FAR as a covariate, they analyze gender, race, image focus, eye distances, age, and elapsed time.",
5472.txt,"The limitations of this study include the maximum elapsed time between face images of the same subject is less than one year, and it only involves 351 subjects.",
5473.txt,"Poh utilized regression models to estimate subject-specic biometric  performance trends over time, but the database used only contains 150 subjects and the elapsed times are less than two years.",
5474.txt,"The longitudinal study on face recognition in this paper follows the general methodology of linear mixed-effects statistical models outlined in X for iris recognition and for ngerprint recognition.The two main databases used for research on facial aging, including automatic age estimation, age progression, and age-invariant face recognition, are FG-NET and MORPH .",
5475.txt,Panis provide a recent overview     of research that has utilized the FG-NET database.,
5476.txt,"While the public release of these databases greatly encouraged progress in these areas, the databases are not suitable for longitudinal analysis because  FG-NET contains only 82 subjects in total, and MORPH contains only a small number of subjects with multiple images over time .The Cross-Age Celebrity Dataset was recently released, containing 16346 images of 2000 celebrities across 10 years.",
5477.txt,"However, because the images were downloaded from the web, the unconstrained quality makes it difcult to statistically model the effects of facial aging.",
5478.txt,"Variations in pose, illumination, expression, etc.may largely inuence the trends in similarity scores.",
5479.txt,"Such covariates are difcult to quantify in order to ""tease out""these effects from the longitudinal effects, so standardized imaging is preferable for the longitudinal study conducted in this paper.",
5480.txt,"Relatively constrained images, such as mugshots,help to ensure that other effects, such as PIE variations, are captured in the noise term in the statistical models.",
5481.txt,"For the above reasons, our longitudinal analysis utilizes two new longitudinal face databases, detailed in Section 3.",
5482.txt,Operational face image datasets maintained by government and law enforcement agencies can contain longitudinal records of individuals of magnitudes that are infeasible to collect in laboratory settings .,
5483.txt,"These agencies routinely collect face images of the same individuals over time and have been doing so for relatively long durations, primarily for applications involving driver's licenses, visa and passport applications/renewals, frequent travelers, and multiple arrests of repeat criminal offenders.",
5484.txt,The sources of face images in our longitudinal analysis are mugshot bookings.,
5485.txt,"While we acknowledge that lifestyle factors  may increase aging rates for some individuals in this population , these accelerated agers are expected to be outliers in the statistical models in our analysis; the overall trends should be relatively robust to this factor.",
5486.txt,"Additionally, we were not able to access any other longitudinal face data.",
5487.txt,We did attempt to use longitudinal face images from the State Department visa databases.,
5488.txt,"However, we discovered that roughly 5% of genuine face images were duplicate photo submissions , so the corresponding inaccurate age information rendered it unsuitable for longitudinal study.",
5489.txt,"The two databases used in this longitudinal study , denoted LEO LS and PCSO LS, are  subsets  of  subjects  and images from two larger mugshot databases initially consisting of 3.7 and 1.5 million images, respectively.",
5490.txt,"The following criteria were used to compile the subsets: Each subject has at least 4 or 5  face images that were  acquired over at least a 5 year time span, and each pair of consecutive images is time-separated by at least one month.",
5491.txt,Database statistics are shown in Fig.,
5492.txt,"2.The facial variations in the PCSO S and LEO LS databases are well-controlled because the mugshots adhere to standards similar to those detailed in the ANSI/NISTITL 2011 face image standards.6 The standards specify that mugshots should be captured at frontal pose, with neutral expression, uniform illumination, and a background set to 18% gray, for examples.",
5493.txt,"Because these databases are both from operational sources, some confounding factors  are  still present, such as minor pose and expression variations .",
5494.txt,"We also observed rare occurrences of facial occlusions or injury, as shown in Fig.",
5495.txt,"4, but have retained such images in this study.",
5496.txt,"For both databases, we only include white and black race subjects in this study because there are too few subjects of other races to do a meaningful statistical analysis.",
5497.txt,"Since human labeling errors pertaining to demographic attributes and subject ID can be inadvertently introduced in large-scale legacy databases, we determine the sex, race,  and  date of birth of a subject as the majority vote from each subject's records to ensure consistent labels within each subject.",
5498.txt,"Identifying all such errors was not feasible due to the large size of these databases, but a cursory examination of the PCSO LS database revealed 134 subject records that contained multiple identities .",
5499.txt,These subject records were removed from our study.,
5500.txt,Face comparison scores  were obtained from various commercial face matchers with the aim of evaluating current state-of-the-art longitudinal performance.,
5501.txt,"Two matchers were applied to the PCSO LS database, and comparison scores were obtained from four different matchers for the LEO LS database.8 As shown in Table 3, COTS-A  and COTS-B were the overall most accurate matchers.",
5502.txt,"Due to space limitations, longitudinal results are only reported for COTS-A and COTS-B throughout the remainder of the paper.",
5503.txt,COTS-A and COTS-B were both among the top-3 performers in the FRVT 2013 .,
5504.txt,"The original mugshot images were input to each COTS matcher, and a total of 26216 and 129773 genuine scores were computed for the LEO LS and PCSO LS databases respectively, under the scenario where  each  subject's  set of face images are compared to his/her enrollment image.",
5505.txt,The response variable for all mixed-effects models in this study are standardized genuine comparison scores.,
5506.txt,"However, to evaluate face recognition performance, trends in genuine scores should be considered in context with an impostor distribution.",
5507.txt,"For both the LEO  LS and PCSO  LS databases, we computed all possible impostor scores  to calculate thresholds at different xed FAR values.",
5508.txt,"For example, is used to determine when genuine scores drop below the threshold, causing false rejection errors.",
5509.txt,"Mixed-effects models  are widely used in various scientic disciplines for studying data that is hierarchically structured, including longitudinal data of repeated observations over time .",
5510.txt,"In our case, face images are grouped by subject because we have repeated observations of each individual in our study.",
5511.txt,"When data is structured in such a manner, responses from the same cluster/group/individual are correlated with each other and across time.",
5512.txt,Mixed-effects models enable analysis of variation in the response  that occurs at different levels of the data hierarchy.An example of cross-sectional vs. longitudinal analysis.,
5513.txt,Face images of six example subjects from the PCSO LS database.,
5514.txt,"The enrollment face image  is the youngest image of each subject, and all query images are in order of increasing age.",
5515.txt,"In this study, genuine similarity scores are computed by comparing the query images of each subject to his/her enrollment image.",
5516.txt,"In X, a cross-sectional approach  is applied, which incorrectly assumes that all the scores are independent.",
5517.txt,"In X, OLS is instead applied six times, separately to each subject's set of scores.",
5518.txt,The slope estimated by cross-sectional analysis is much atter than the slopes of subject-specic trends in .,
5519.txt,"The longitudinal analysis in this paper utilizes mixed-effects models, which provide ""shrunken"" OLS estimates for each subject, where the OLS trends shrink towards a population-mean trend, further accounting for the correlation that exists between scores from the same subject.Ideally, longitudinal data collection would observe all individuals in the study following the exact same schedule over the entire duration of interest.",
5520.txt,"However, longitudinal data is typically not this nicely structured because it is difcult to collect, or it must be analyzed retrospectively, as is the case with the mugshot databases used in this study.",
5521.txt,"Instead, longitudinal data is most often time-unstructured and unbalanced, meaning individuals in the study population are observed at different schedules and have different numbers of observations.",
5522.txt,"For the mugshot databases, this translates to different rates of recidivism for each subject.",
5523.txt,Fig.,
5524.txt,"2 shows that subjects in the LEO LS and PCSO LS databases have anywhere from 4 to more than 20 mugshots, and Fig.",
5525.txt,5 shows that the age spans of the subjects are highly unstructured.,
5526.txt,"Mixed-effects models can handle imbalanced and time-unstructured data and are preferable over other approaches because they model both the mean response , as well as the covariance structure .",
5527.txt,"In longitudinal data, this covariance structure has a complicated form which stems from the fact that error terms are not independent.",
5528.txt,The remainder of this section provides details of the models and covariates of interest.,
5529.txt,Deviance can be used to compare nested models  that are t to the same data.,
5530.txt,"To compare non-nested models, AIC and BIC penalize the log-likelihood based on the complexity of the models11 and the sample size.",
5531.txt,Smaller values indicate better t for all three goodness-of-t measures.,
5532.txt,"We rst focus on analysis of the PCSO LS database, starting with simpler models  and progressing to more complex models including covariates for subject sex/race and face image quality.",
5533.txt,We then present results for the LEO LS database.,
5534.txt,Recall that models are discussed in Section 4 and equations are provided in Table 4.,
5535.txt,All models in our analysis are t with full maximum likelihood estimation via iterative generalized least-squares  using the lme4 package  for R .,
5536.txt,"When parametric model assumptions are violated, it is common to resort to non-parametric bootstrap to  estab lish condence intervals for the parameter estimates, as followed  in  Yoon   and  Jain.",
5537.txt,"Hence,  for  the  PCSO LS database, we conduct a non-parametric bootstrap by case resampling ; 1000 bootstrap  replicates  are  generated by sampling 18007 subjects with replacement.",
5538.txt,"Multilevel models are t to each bootstrap replicate, and the mean parameter estimates over all 1000  bootstraps are reported.",
5539.txt,"Tests for xed effects parameters can be conducted by examining the bootstrap condence intervals.Table 5 gives the bootstrap parameter estimates , variance components, and goodness-of-t for the models in Table 4.",
5540.txt,"Longitudinal change estimated by Model BT implies that the population-mean trend will drop below the thresholds for 0.01% and 0.1% FAR after 19.1 and 24.0 years elapsed time, respectively, but this only provides insight into performance on subjects in the population with average  genuine scores over time.",
5541.txt,"A reliable face recognition system must be able to recognize much more than just 50% of the population it encounters, so we are also interested in the spread of the population around the population-mean trend.",
5542.txt,"Do all subjects closely follow the population-mean trend, or is there large variability between subjects?",
5543.txt,Do biometric zoo effects extend to rates of change over time?,
5544.txt,we investigate whether face image  quality measures can be used to improve the model t.,
5545.txt,"The quality measures considered are interpupillary distance  and a ""frontal"" score, both of which are output by COTS-A.",
5546.txt,"While higher frontalness indicates better quality, the range of the frontal score has little meaning, since its computation is proprietary.",
5547.txt,We standardize the frontalness score so we can interpret model parameters as standard deviations from the mean of the frontalness scores from all images in PCSO LS.,
5548.txt,"After nding that neither of the quality measures alone explain variation in genuine scores as well as Model BT with only elapsed time as covariate, we then added the quality measures to Model BT, resulting in Model Q in Table 4.",
5549.txt,"Table 6 gives estimated level-1 residual variation and goodness-of-t for models with frontalness, IPD, and both frontalness and IPD .",
5550.txt,Model QF has a better overall t than Model QI.,
5551.txt,Table 7 gives the elapsed times  for when population-mean scores cross thresholds at 0.001% and 0.01% FAR for different values of frontalness and IPD.,
5552.txt,Note how changing frontalness has a greater impact on when population-mean genuine scores cross the thresholds than changes in IPD.,
5553.txt,"Model QFI with both measures of quality further reduces both the level-1 residual variation and values of goodness-of-t values The values of 100 and 120 pixels for IPD in Table 7 were chosen  because  we  observed  systematic  changes  in IPDs over time; in particular, mean IPD varies around 100 pixels from 1994?002 but increases to a consistent 120 pixels starting in 2003.",
5554.txt,"This observation, along with correspondence with Pinellas County Sheriff's Ofce, suggests that booking agencies began to adhere to imaging standards around this time.",
5555.txt,"To investigate whether this aspect of the data confounds the estimation of longitudinal effects ,  we also tested for a difference in slope prior to 2003 versus after 2003 by using a piecewise linear formulation for the mixedeffects model.",
5556.txt,We found that slope after 2003 was signicantly atter.,
5557.txt,"Additional face quality factors known to cause changes in face recognition performance are illumination, expression, and occlusions.",
5558.txt,"However, there are no widely accepted methods for quantifying such variations in face images and doing so is beyond the scope of this paper.",
5559.txt,Table 8 gives results for the models in Table  4 t to COTS-B genuine scores from the LEO LS database.,
5560.txt,Fixed-effects parameter estimates are given with standard errors; boot- strapping was not conducted for LEO LS models because the error terms better follow Gaussian distributions  .,
5561.txt,Model results are summarized as follows.,
5562.txt,"Model E results indicate that intercepts are 0.0565 and 0.4238 standard deviations higher for black and male subjects, respectively .",
5563.txt,"Slopes are not statistically different for black and white subjects, but the population-mean slope for males is steeper than for females.",
5564.txt,These population-mean trends are shown in Fig.,
5565.txt,14 for different ages at enrollment.,
5566.txt,Fig.,
5567.txt,"14 also shows that the differences between subject race are minor compared to differences between males and females, as was also the case for COTS-A on the PCSO LS database.",
5568.txt,"Population-mean trends indicate that genuine scores signicantly decrease with increasing elapsed time between enrollment  images, as expected.",
5569.txt,"However, population-mean trends  do not fall below thresholds at 0.01% FAR until after 15 years elapsed time.",
5570.txt,"This suggests that in a practical application, an average individual's genuine scores decrease at a rate that will not affect the recognition accuracy at 0.01% FAR until more than 15 years since enrollment.",
5571.txt,Signicant subject-specic variability around the population-mean trends is observed; genuine scores for some subjects decline at much faster rates than the population-mean.,
5572.txt,Analysis of the estimated variance in subject-specic parameters  allowed for estimation of subject-based accuracies .,
5573.txt,"For example, the models estimate that genuine scores for 99% of the population will remain above the threshold at 0.01% FAR until 6.5 years elapsed time for PCSO LS and 5.5 years for LEO LS.",
5574.txt,Other calculations are also within approximately one year for both databases.,
5575.txt,"Subject-specic variance in rates of change  is only marginally attributable to subject age at enrollment, sex, and race.",
5576.txt,"Subject sex was the most signicant factor for between-subject differences in genuine scores, with males having signicantly higher genuine scores than females.",
5577.txt,The magnitude of the difference suggests that false reject errors may occur approximately two years earlier for females than for males.,
5578.txt,"Longitudinal analysis, in general, is an important, yet very difcult, problem.",
5579.txt,"To the best of our knowledge, no proper statistical analysis has yet been conducted for studying face recognition performance on a large population over periods of time longer than ve years.",
5580.txt,"In this paper, we attempted to analyze the covariates of interest that were available to us , but there are additional covariates that cannot be accounted for because we do not have the information.",
5581.txt,"Despite this, the longitudinal study on automatic face recognition presented here utilizes two of the largest, deepest, and longest face image databases studied to date, and the COTS matchers are representative of current state-of-the-art.",
5582.txt,"Given that the performance of face recognition systems continues to improve, longitudinal analysis should be conducted periodically to reevaluate robustness to facial aging .Future work includes: Evaluation of face identication performance over time.",
5583.txt,Observations about recognition accuracy in this paper apply to verication scenarios  operating with a global threshold.,
5584.txt,Development of a single face quality measure for mugshot type face images.,
5585.txt,Longitudinal analysis on different face cropping to investigate the impact of changing hairstyle over time.,
5586.txt,"In this paper, we investigate and exploit the influence of facial expressions on automatic age estimation.",
5587.txt,"Different from existing approaches, our method jointly learns the age and expression by introducing a new graphical model with a latent layer between the age/expression labels and the features.",
5588.txt,"This layer aims to learn the relationship between the age and expression and captures the face changes which induce the aging and expression appearance, and thus obtaining expression-invariant age estimation.",
5589.txt,"Conducted on three age-expression datasets, our experiments illustrate the improvement in performance when the age is jointly learnt with expression in comparison to expression-independent age estimation.",
5590.txt,"The age estimation error is reduced by 14.43%, 37.75% and 9.30% for the FACES, Lifespan and NEMO datasets respectively.",
5591.txt,"The results obtained by our graphical model, without prior-knowledge of the expressions of the tested faces, are better than the best reported ones for all datasets.",
5592.txt,The flexibility of the proposed model to include more cues is explored by incorporating gender together with age and expression.,
5593.txt,The results show performance improvements for all cues.,
5594.txt,"Automatic age estimation is an important research field in the area of computer vision and has many applications such as human-computer interaction, security, and surveillance.",
5595.txt,"In general, the human age is derived from facial aging cues.",
5596.txt,The aging of adults is primar ily perceived via skin changes .,
5597.txt,"During aging, the human face loses  collagen  beneath  the  skin  leading  to thinner, darker, and more leathery skin .",
5598.txt,Age-induced facial wrinkles become more distinct as a result of repeated activation of facial muscles and they start to appear in different directions depending on these muscles.,
5599.txt,"For example, vertical wrinkles intensify  between the eyebrows while horizontal wrinkles become more apparent close to the eye corners.",
5600.txt,Many research efforts are done in the last years to automatically estimate the age from faces.,
5601.txt,Age estimation systems generally consist of an aging feature extraction step and a classification/regression step.,
5602.txt,A thorough survey on age synthesis  and  estimation  can be found in X.,
5603.txt,Early work by Kown and Labo used head shape changes for young stages as  aging  cues.,
5604.txt,"More specifically, ratios of distances between facial landmarks are computed.",
5605.txt,"To model the aging process over the years, Geng introduced the  aging pattern subspace.",
5606.txt,A prerequisite is to have sufficient training aging patterns which is a limiting factor due to the difficulty of collecting such datasets.,
5607.txt,Other approaches use Active Appearance Model  where the face shape and appearance are parameterized in one model.,
5608.txt,Guo  projected the face image into a low-dimensional age manifold.,
5609.txt,Spatially Flexible Patches  are introduced by Yan where local features are extracted from face regions together with their position information.,
5610.txt,The resulting features are then modeled by Gaussian mixtures.,
5611.txt,Traditional features like LBP and Gabor are employed to extract aging features.,
5612.txt,Guo employ Biologically-Inspired Features  for age estimation tasks obtaining state-of-the-art performance.,
5613.txt,External factors like facial expressions cause changes in facial muscles which distort the aging cues.,
5614.txt,A facial expression is explained by a combination of these changes in the face which are called Action Units .,
5615.txt,A problem in age estimation is that expression-related muscles overlap with aging-induced facial changes.,
5616.txt,"For example, smiling involves the activation of some facial muscles leading to raising the cheeks and pulling the    lip corners.",
5617.txt,This influences the aging wrinkles around the mouth and near the eyes.,
5618.txt,"Consequently, the aging  cues changes caused by expressions show the necessity of separating the influence of expression when estimating the age.",
5619.txt,Most of the existing age estimation methods assume that faces show little or no expressions and ignore the changes of the face appearance induced by them.,
5620.txt,Guo study human age estimation under facial expression changes.,
5621.txt,Their method learns the correlation between two expressions at a time .,
5622.txt,"To predict the age across two expressions, the face is mapped from one expression to another .",
5623.txt,"Next, the age is predicted from the ""mapped"" face.",
5624.txt,"For the face aging representation, BIF features and Marginal Fisher Analysis  are used.",
5625.txt,Zhang  employ a weighted random subspace method to solve cross-expression age estimation.,
5626.txt,"In their method, several feature sets are generated first, then subspaces are built for these sets.",
5627.txt,"Next, a classifier is learnt for each subspace and predictions of all classifiers are fused to produce the final prediction.",
5628.txt,Their method does not require different expressions from the same subjects as opposed to X.,
5629.txt,"However, both methods require the expressions of test images to be known before predicting the age which limits their applicability.",
5630.txt,"In our previous paper, we propose a different approach.",
5631.txt,"Instead of learning the age across two expressions, we jointly learn the age and expression and model their relationship.",
5632.txt,The aim is to achieve expression- invariant age estimation.,
5633.txt,"In  our  approach, one model is learnt for all expressions.",
5634.txt,"To  predict  the  age,  the age and expression are inferred jointly, and hence prior- knowledge of the expression of the test face is not required.",
5635.txt,"More specifically, we introduce a new graphical model which contains a latent layer between the age/expression labels and the facial features.",
5636.txt,This layer captures the relationship between the age and expression.,
5637.txt,"During training, the age and expression variables are observed.",
5638.txt,This allows the latent layer to learn the configurations which map the features to the age for different expressions and thus obtaining expression-invariant age estimation.,
5639.txt,"For testing, the age  and expression labels are unknown and the method finds the values of age, expression and latent layer which together maximize their compatibility with the features.",
5640.txt,The contributions of our work in X are:  we show how age-expression joint learning improves the age prediction compared to learning age independently from expression.,
5641.txt,"As opposed to existing methods, the proposed method predicts the age across different facial expressions without prior-knowledge of the expression labels of the test faces.",
5642.txt,Our results outperform the best reported results on age- expression datasets .,
5643.txt,"In this paper, we extend our work in X by providing more insights in our model.",
5644.txt,"Specifically, we investigate the role of the age/expression loss function and how changes in the structure affect the performance.",
5645.txt,"Furthermore, we extend our model to incorporate different tasks  which leads to improvements in performance.",
5646.txt,The proposed graphical model aims to jointly learn the relationship between age and expression.,
5647.txt,"To  this end,   an inter-connected latent layer is introduced.",
5648.txt,The latent variables encode the changes in face appearance.,
5649.txt,"These variables are not explicitly defined, but learnt from the training data.",
5650.txt,"The graphical model has four sets of connections: First, connections between the face subregions and the latent variables.",
5651.txt,These connections are designed to capture the changes of  face  appearance  related  to  age  and expression.,
5652.txt,"Second, connections between the face subregions and the age/expression labels are formed.",
5653.txt,The aim here is to directly infer the age/expression from the features.,
5654.txt,"Third, connections between the latent variable modeling the relationship between the face subregions.",
5655.txt,"Finally, connections are established between the latent variables, age, and expression.",
5656.txt,The last type of connections is designed to relate the age with expression which allows the joint learning between them.,
5657.txt,"Next, we discuss the model formulation and explain the inference and learning techniques.",
5658.txt,Algorithm 1 outlines the steps of the proposed algorithm.,
5659.txt,"In line 4, the parameters are initialized.",
5660.txt,Line 4 the latent variables are estimated by using   the current parameters.,
5661.txt,"In line 9, f is obtained corresponding to the convex part of the optimization problem.",
5662.txt,"In line 10, g is computed corresponding to the linear part of the optimization problem.",
5663.txt,"By solving the optimization problem of the two terms in line 2, the new parameters are obtained.",
5664.txt,Line 12 computes the objective value of the optimization function.,
5665.txt,"This process is repeated until the decrement of the object function is below a threshold E, indicated in line.",
5666.txt,"The goal of the proposed approach is to capture the relationship between the age and expression and, hence, alleviate the influence of expression in age estimation.",
5667.txt,"In this section, we conduct a number of experiments to validate our model.",
5668.txt,"First, our model is evaluated using the age-expression datasets FACES  and Lifespan .",
5669.txt,"Next, we vary the number of the hidden states.",
5670.txt,The aim here is to explore the relationship between the performance and the complexity of the model.,
5671.txt,"Finally, we test the proposed model on the expression recognition task using FACES and Lifespan datasets.",
5672.txt,The Lifespan dataset is a collection of faces of subjects from different ethnicities showing different expressions.,
5673.txt,"The expression subsets have the following sizes: 580,258, 78, 64, 40, 10, 9, and 7 for neutrality, happiness,surprise, sadness, annoyed, angry, grumpy, and disgust,respectively.",
5674.txt,The  ages  of  the  subjects  range  from 18 to 93 years and in total there  are  74  different  ages.,
5675.txt,The dataset has no labeling for the subject identities.,
5676.txt,We  follow the setup of  and use the neutral  and happy subsets.,
5677.txt,Fig.,
5678.txt,4  show  the  age  distributions for the Lifespan dataset.,
5679.txt,"Although the age distributions of both datasets cover a wide range of ages, FACES dataset is more challenging for age prediction since its expression variation  is larger than the one in Lifespan dataset .The NEMO dataset  has 564 subjects and 2058 images recorded in total.",
5680.txt,There are two types of expression: happiness and neutrality that have 995 and 1090 images respectively.,
5681.txt,The dataset contains 60 different ages ranging from 8 to 76 years.,
5682.txt,"We divide the images into two subsets so that each subset has half of the images of each expression.For feature extraction, eye centers are first automatically detected and the faces are registered and cropped.",
5683.txt,"Then, the faces are divided into 8   8 patches and a local feature vector is extracted for each patch.",
5684.txt,"Finally, the patch local descriptors are concatenated together to form the face descriptor.",
5685.txt,"To extract the features from each patch, we use Local Binary Pattern.",
5686.txt,"It  is a simple, efficient, and rotation-invariant approach and uccessfully used for age prediction to capture the skin texture details.",
5687.txt,"In our experiments, we use 8  sampling points with a radius equal to 1.",
5688.txt,"As in previous setups, the datasets are divided into 5 folds.",
5689.txt,"For the FACES dataset, the expression distributions are uniform for all the  5 folds, and none of the subjects appears in  more  than  one  fold.",
5690.txt,"For the Lifespan dataset, the dataset  is split randomly into 5 folds.",
5691.txt,"As the subject identities are not available, a subject overlap between the training and test samples is possible.",
5692.txt,The results are measured quantitatively by Mean Absolute Error.,
5693.txt,Example faces and age distributions of FACES datasets.,
5694.txt,"The expression distribution for FACES dataset is uniform where each subject shows six basic expressions: neutrality, happiness, anger, fear, disgust, and sadness.",
5695.txt,Example faces and age distributions of Lifespan datasets.,
5696.txt,The Lifespan dataset contains neutral and happy  faces.,
5697.txt,"In this experiment, we evaluate our method on the FACES, Lifespan and NEMO datasets.",
5698.txt,Here we compare two cases.,
5699.txt,"First, learning the age independently the from expression.",
5700.txt,"Second, learning the age jointly with the expression.",
5701.txt,"In both cases, the same 5-fold age-expression datasets are used for evaluation.",
5702.txt,"For the expressionindependent learning, a multi-class SVM is used as a baseline.",
5703.txt,"In the expression-joint learning, we use the proposed graphical model and the number of hidden states is set to 3 .",
5704.txt,"For the model learning, the expression is observed and the potential function in equation 3 is applied.",
5705.txt,The results for the proposed model are shown in Table 1.,
5706.txt,"For both datasets, our graphical model significantly reduces the prediction error in comparison to independent learning The errors reported in X for FACES, Lifespan and NEMO datasets are shown in Table 1.",
5707.txt,"Although both methods assume prior-knowledge of the expression of tested samples, our model outperforms their results for the three datasets.",
5708.txt,"We also report the performance of other widely used classifiers, such as random forests  and linear classifiers with sparse  coefficients.",
5709.txt,"For these classifiers, we tune the parameters of the models and report the best results obtained.",
5710.txt,"As shown in table 1, the proposed algorithm outperforms these widely used methods in five out of six experiments.",
5711.txt,We further compare our age estimation approach with the joint classification method by X.,
5712.txt,The method was proposed to recognize facial expressions while reducing the influence of human aging.,
5713.txt,"In their method, the authors simply divide the dataset into four age groups and consider each expression within each age group as a new class.",
5714.txt,"Then, classification is performed on the newly defined classes.",
5715.txt,"For facial feature extraction, they manually labeled 31 fiducial points and applied Gabor filters on the locations of those points.",
5716.txt,The four age group classification accuracy using the joint learning method is reported.,
5717.txt,"To   make  a  fair  comparison,  and  since  the  authors manually labeled 31 fiducial points  on  the  face, we use our features and compare only the joint learning methods.",
5718.txt,"Detailed results for independent and  joint  learning for FACES, Lifespan and NEMO dataset are shown in Tables 2, 3 and 4 where the  error  for  each  expres sion subset is shown separately.",
5719.txt,"The error is reduced   for all expression subsets, however, in different rates.",
5720.txt,"The largest improvement is achieved for neutrality with , while the smallest improvement is obtained for the anger and the disgust expressions .",
5721.txt,This is explained as anger and disgust expressions induce more profound changes in the face appearance than the other expressions which makes age prediction/perception more difficult.,
5722.txt,Our model clearly outperforms the existing methods  by a wide margin which further proves the effectiveness of our approach.,
5723.txt,The hidden states capture the changes in the face appearance.,
5724.txt,"To further illustrate this point, we show the face regions corresponding to each hidden state.",
5725.txt,"More specifically, the averages of the bottom and top regions are computed .",
5726.txt,"For the bottom regions, the first hidden state corresponds to the face appearance where the mouth  is  open,  the  third  hidden  state  represents  a depressed lip corner, and the second hidden state corresponds to a normal face appearance.",
5727.txt,"For the top regions, the second hidden state represents the face appearance where  the  eye  is  slightly  closed  while  the first and the third states correspond to open eye appearances.",
5728.txt,The  error first decreases when increasing the number of hidden states to 3 as it allows the model to differentiate more changes in the face appearance.,
5729.txt,"However, it increases with more hidden states .",
5730.txt,This might be as the model becomes more complex and hence more prone to overfitting to the training data.,
5731.txt,"In this experiment, we consider a different, yet related, task: how age information can improve the recognition of expressions.",
5732.txt,"Although aging affects how people exhibit expressions, much of automatic expression recognition methods do not use the age of the subject to recognize expressions.",
5733.txt,This is mainly due to the lack of expression datasets with a sufficiently large age range.,
5734.txt,"Motivated by the introduction of recent age-expression datasets, Guo recently proposed a method to recognize facial expressions while reducing the influence of human aging.",
5735.txt,"We apply our model on the FACES, Lifespan and NEMO datasets to recognize the expression.",
5736.txt,The results are shown in Table 5.,
5737.txt,Our method improves the expression recognition performance for FACES dataset by 2.38%.,
5738.txt,"However, the accuracy on Lifespan and NEMO is comparable to the one acquired by independent learning.",
5739.txt,"This maybe explained by the observation that there are only two expressions in Lifespan and NEMO compared to six ones in FACES, and hence the expression variation within Lifespan dataset is smaller than it is within FACES.",
5740.txt,"Consequently, the margin of improvement is smaller for Lifespan and the joint learning method obtains comparable accuracy.",
5741.txt,"The detailed recognition accuracies for each expression subset are shown in Tables 6, Table 7 and Table 8.",
5742.txt,We compare the proposed method with the one in X.,
5743.txt,"As the authors manually labeled 31 fiducial points on  the face and extracted the features using their locations, a direct comparison of the results will  not  be  fair.",
5744.txt,"Thus, we test the method in X  using  our features.",
5745.txt,The datasets are divided into the same four age groups .,
5746.txt,"Then, a new class for Lifespan and NEMO dataset respectively.",
5747.txt,The obtained accuracy  is lower than the one acquired by our model.,
5748.txt,is created for each expression/age group combination resulting  in  24 for  the  FACES  and  8 new  classes for Lifespan and NEMO dataset respectively.,
5749.txt,The obtained accuracy  is lower than the one acquired by our model.,
5750.txt,As shown in the left of Fig.,
5751.txt,"7, with varying R, the accuracy of age estimation varies slightly.",
5752.txt,"However, for expression estimation, as shown in the right of Fig.",
5753.txt,"7,the accuracy changes from 0.874 to 0.94.",
5754.txt,"When R is small, the accuracy is around 0.9.",
5755.txt,"With increasing values of R, the accuracy goes up to 0.93 for the Lifespan dataset and 0.94 for the FACES dataset.",
5756.txt,"For higher values of R, the accuracy drops significantly for both datasets.",
5757.txt,"For NEMO dataset, the performance varies very slightly.",
5758.txt,"Since R is the penalty of a wrong prediction of expressions during training, relatively small R may result in an under fit for expression recognition.",
5759.txt,"However, large values of R may result in an over fit for expression recognition.",
5760.txt,"In this section, the computational complexity is analyzed of the proposed algorithm  and independent learning .",
5761.txt,"For independent learning, since we need to perform age and expression estimation independently, the total time of the two tasks is provided.",
5762.txt,"For the proposed algorithm, the age and expression are estimated simultaneously.",
5763.txt,The results show that joint learning of different cues such as age and expression improves the performance of each cue.,
5764.txt,"Besides age and expression, in this section, we introduce gender in our model as an example to show how other cues can be incorporated.",
5765.txt,Four experiments are conducted on FACES dataset to show the advantage of the proposed model.,
5766.txt,"As shown in Table 11, the first row shows the results of different cues with independent learning, where a multiclass SVM is used per cue.",
5767.txt,The second row shows the results of jointly learning the age and gender.,
5768.txt,The model here is the same as for jointly learning the age and expression.,
5769.txt,"The third row shows the results of jointly learning the age, gender and expression.",
5770.txt,"The results show that by jointly learning age, gender and expression, the performance improves for each cue.",
5771.txt,The fourth row shows the result of X.,
5772.txt,"Although the age estimation of X is slightly better  than  the  proposed  method,  the gender and expression estimation of the proposed method outperforms .",
5773.txt,"This shows that the proposed method is a more suited for joint learning age, gender and expression.FGNET dataset contains 1002 facial images from 82 subjects of Caucasian descendant.",
5774.txt,"The ages range from  0 to 69 years, however the age distribution is skewed to younger ages .",
5775.txt,We use the same features for both the proposed algorithm .,
5776.txt,"Since different datasets have different age range, besides testing on the whole dataset, we also report the result ignoring the images which are not in the scope of the training dataset.",
5777.txt,"As shown in Table 12, we train the model on the dataset FACES, and evaluate on the dataset FGNET and Morph.",
5778.txt,The proposed algorithm outperforms on FGNET while performs comparably on Morph.,
5779.txt,"Although  cross  dataset  evaluation  is  not  in the scope of this paper, the experiments show that   the proposed algorithm performs well on both the two datasets in comparison to existing algorithms.",
5780.txt,"In such cases, the hidden layer will learn the relationship between the age and multiple variables  instead of one variable at a time.",
5781.txt,"Moreover, beside facial expressions, other attributes can be learnt collectively within the proposed graphical model such as gender and race.",
5782.txt,"Second, the proposed approach does not require the expression labels of the test samples to be known while the existing methods  assume prior-knowledge of the expressions.",
5783.txt,"In this paper, an expression-invariant age predictor is proposed by jointly learning the age and expression.",
5784.txt,We introduce a graphical model with a latent layer to learn the relationship between the age and expression.,
5785.txt,This layer is designed to capture the changes in the face which induce the aging and expression appearance.,
5786.txt,"Conducted on three age-expression datasets , our experiments show the improvement in performance when the age is jointly learnt with expression in comparison to expression-independent age estimation.",
5787.txt,"The age estimation error is reduced by 14.43%, 37.75% and 9.30% for the FACES, Lifespan and NEMO datasets respectively.",
5788.txt,"Using our model, without prior-knowledge of the expressions of the tested faces, the acquired results are better than the best  reported ones for all datasets.",
5789.txt,The flexibility of the proposed model to include more cues is explored by incorporating gender together with age and expression.,
5790.txt,The results show improvement of performance for all cues.,
5791.txt,"Feature extraction, deformation handling, occlusion handling, and classification are four important components in pedestrian detection.",
5792.txt,Existing methods learn or design these components either individually or sequentially.,
5793.txt,The interaction among these components is not yet well explored.,
5794.txt,This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation.,
5795.txt,We formulate these four components into a joint deep learning framework and propose a new deep network architecture.,
5796.txt,"By establishing automatic, mutual interaction among components, the deep model has average miss rate 8.57%/11.71% on the Caltech benchmark dataset with new/original annotations.",
5797.txt,"Pedestrian detection is a key technology in automotive safety, robotics, and intelligent video surveillance.",
5798.txt,It has attracted a great deal of research interest.,
5799.txt,"The main challenges of this task are caused by the intra-class variation of pedestrians in clothing, lighting, backgrounds, articulation, and occlusion.",
5800.txt,"In order to handle these challenges, a group of interdependent components are important.",
5801.txt,"First, features should capture the most discriminative information of pedestrians.",
5802.txt,"Well-known features such as Haar-like features, SIFT, and HOG are designed to be robust to intra-class variation while remain sensitive to inter-class variation.",
5803.txt,"Recently, deeply learned features are found to be effective in pedestrian detection and generic object detection.",
5804.txt,"Second, deformation models should handle the articulation of human parts such as torso, head, and legs.",
5805.txt,The state-of-the-art deformable part-based model in X allows human parts to articulate with constraint.,
5806.txt,"Third, occlusion handling approaches  seek to identify the occluded regions and avoid their use when determining the existence of a pedestrian in a window.",
5807.txt,"Finally, a classifier decides whether a candidate window shall be detected as enclosing a pedestrian.",
5808.txt,"SVM , boosted classifiers, random forests, and their variations are often used.",
5809.txt,"Although these components are interdependent, their interactions have not been well explored.",
5810.txt,"Currently, they are first learned or designed individually or  sequentially,  and then put together in a pipeline.",
5811.txt,The interaction among these components is usually achieved using manual parameter configuration.,
5812.txt,Consider the following three examples.,
5813.txt,The HOG feature is individually designed with its parameters manually tuned given the linear SVM classifier being used in X.,
5814.txt,Then the HOG feature is fixed when people design new classifiers.,
5815.txt,"A few HOG feature parameters are tuned in X and fixed, and then different part models are learned in X.",
5816.txt,"By fixing HOG features and deformable models, occlusion handling models are learned in X, using the part-detection scores as input.",
5817.txt,As shown in Fig.,
5818.txt,"1, the motivation of this paper is to establish automatic interaction in learning these key components.",
5819.txt,"We hope that jointly learned components, like members with team spirit, can create synergy through close interaction, and generate performance that is greater than individually learned components.",
5820.txt,"For example, well-learned features help to locate parts, meanwhile, well-located parts help to learn more discriminative features for different parts.",
5821.txt,This paper formulates the learning of these key components into a unified deep learning problem.,
5822.txt,The deep model is especially appropriate for this task because it can organize these components into different layers and jointly optimize them through back-propagation.,
5823.txt,"This paper makes the following three main contributions.A unified deep model for jointly learning feature extraction, a part deformation model, an occlusion model and classification.",
5824.txt,"With the deep model, these components interact with each other in the learning process, which allows each component to maximize its strength when cooperating with others.",
5825.txt,We enrich the operation in deep models by incorporating the deformation layer into the convolutional neural networks.The features are learned from pixels through interaction with deformation and occlusion handling models.,
5826.txt,Such interaction helps to learn more discriminative features.,
5827.txt,It has been proved that deep models are potentially more capable than shallow models in handling complex tasks .,
5828.txt,They have achieved spectacular progress in computer vision.,
5829.txt,"Deep models for pedestrian detection focus on feature learning , contextual information learning , and occlusion handling.",
5830.txt,Recent reviews and performance evaluations are provided in X.,
5831.txt,Many features are utilized for pedestrian detection.,
5832.txt,"Haar-like features, HOG , and dense SIFT  are designed to capture the overall shape of pedestrians.",
5833.txt,"First order color features like color histograms, various channel features, second-order color features like color- self-similarity and co-occurrence features are also used for pedestrian detection.",
5834.txt,Texture feature like LBP are used in X.,
5835.txt,"Other types of features include the covariance descriptor ,  depth ,  segmentation  results  ,  3D geometry , motion , and their combinations .",
5836.txt,All the features mentioned above are designed manually.,
5837.txt,"Recently, researchers have become aware of the benefit of learning features from training data.",
5838.txt,"Similar to HOG, they use local max pooling or average pooling to be robust to small local misalignment.",
5839.txt,"However, these approaches do not learn the variable deformation properties of body parts.",
5840.txt,The approaches in X learn features and a part-based model sequentially but not jointly.,
5841.txt,"Since pedestrians have non-rigid deformation, the  ability  to handle deformation improves detection performance.",
5842.txt,Deformable part-based models are used in X for handling translational movement of parts.,
5843.txt,"To handle more complex articulations, size change and rotation  of parts are modeled in X, and mixture of part appearance and articulation types are modeled in X.",
5844.txt,"In these approaches, features are manually designed.",
5845.txt,"Recently, the learning of deformation from convolutional layers is presented in X.",
5846.txt,"First, par visibility learning is learned in our approach but not learned in these approaches.",
5847.txt,"Second, these approaches can only place the deformation handling after the convolutional layers, which restricts the deep architecture especially for AlexNet, ZF-Net and VGG with fully connected layers.",
5848.txt,We provide a CNN design and show that deformation handling can be used even for the models with fully connected layers by treating them as the filter for full body.,
5849.txt,"In order to handle occlusion, many approaches have been proposed for estimating the visibility of parts.",
5850.txt,Some  of  them  use the detection scores of blocks or parts as input for visibility estimation.,
5851.txt,The approach in X handles occlusion by designing multiple classifiers.,
5852.txt,Some use other cues like segmentation results and depth.,
5853.txt,"However, all these approaches learn the occlusion modeling separately from feature extraction and part models.",
5854.txt,"The widely used classification approaches include various boosting classifiers, histogram intersection kernel SVM , latent SVM , multiple kernel SVM , structural SVM , and probabilistic models .",
5855.txt,"In these approaches, classifiers are adapted to training data, but features are designed manually.",
5856.txt,"If useful information has been lost at feature extraction, it cannot be recovered during classification.",
5857.txt,"Ideally, classifiers should guide feature learning.",
5858.txt,"In summary, previous works treat the components individually or sequentially.",
5859.txt,This paper takes a global view of these components and is an important step towards joint learning of them for pedestrian detection.,
5860.txt,An overview of our examplar deep model is shown in Fig.,
5861.txt,2,
5862.txt,In this model:Input image data are obtained by warping the candidate box into 3 channels.Part scores are obtained from the 20 part detection maps using a deformation modeling layer.,
5863.txt,This layer outputs 20 part scores.,
5864.txt,Details are given in Section 3.,
5865.txt,"The visibility reasoning of 20 parts is used for estimating the label y; that is, whether a given window encloses a pedestrian or not.",
5866.txt,"Details are given in Section 3.At the training stage, all the parameters are optimized through back-propagation .The detection windows of different sizes are warped into images with height 84 and width 28, in which pedestrians have height 60 and width 20.",
5867.txt,Then the 3-channel input data for CNN are obtained as follows:Fig.,
5868.txt,3 shows the three channels for a pedestrian patch.,
5869.txt,"In this way, information about pixel values at different resolutions and information of primitive edges are utilized as  the  input of the first convlutional layer to extract features.",
5870.txt,The first convolutional layer and its following average pooling layer use the standard CNN settings.We empirically find that it is better to arrange the images and edge maps into three concatenated channels instead of eight separate channels.,
5871.txt,"In order to deal with illumination change, the data in each channel is preprocessed to be zero mean and unit variance.",
5872.txt,"Normally, the filter size of a convolutional layer is fixed .",
5873.txt,"Since the parts of pedestrians have different sizes, we design the filters in the convolutional layer with variable sizes when obtaining part detection maps.",
5874.txt,As shown in Fig.,
5875.txt,"4,  we design parts at three levels with different sizes.",
5876.txt,"There are six small parts at level 1, seven medium-sized parts at  level  2, and seven large parts at level 3, as shown in Fig.4.The parts model A and the filters B learned at the second convolutional layer.",
5877.txt,"We follow X and visualize the filter that optimizes the corresponding stimuli of the neurons, which is also used in X.A part at an upper level is composed of parts at the lower level.",
5878.txt,Parts at the top level are also the possible occlusion statuses.,
5879.txt,Gray color indicates occlusion.,
5880.txt,The other two levels are body parts.,
5881.txt,"In the figure, the head-shoulder part appears twice because this body part itself can generate an occlusion status.",
5882.txt,Fig.,
5883.txt,4 shows a few part filters learned with our deep model.,
5884.txt,They are visualized using the activation maximization approach in X.,
5885.txt,The figure shows that the head-shoulder at level 2 and the head-shoulder at level 3 extract different visual cues from the input image.,
5886.txt,The head-shoulder filters in Fig.4 contain more detailed silhouette information on heads and shoulders than the head-shoulder filter learned with HOG in Fig.,
5887.txt,1,
5888.txt,The two-legs filter in Fig.4 is visually more meaningful than the one learned with HOG in Fig.,
5889.txt,1,
5890.txt,"In order to learn the deformation constraints of different parts, we propose the deformation handling layer for the CNNs.The deformation layer can represent the widely used quadratic constraint of deformation in the deformable part model .The approach in X only learns the visibility relationship from part scores.",
5891.txt,Both HOG  features  and  the  parameters  for the deformation model are fixed in X.,
5892.txt,"In this paper, features, deformable models, and visibility relationships are jointly learned.",
5893.txt,In order to learn the parameters in the two convolutional layers and the deformation layer in Fig.,
5894.txt,"2, prediction error is back-propagated through s.
The extended model is based on the Fast-RCNN framework.",
5895.txt,"At the first stage, we use the VGG net for region proposal,which is pre-trained on ImageNet and finetuned on Caltech-Train.",
5896.txt,"At the second stage, the extended deep model introduced in Section 4 is used for classifying the proposed regions as containing pedestrians or background.",
5897.txt,"The second stage is called region classification stage.With the threshold being 0.2, around 13 proposal regions per image are retained as the region proposal for pedestrian classification at the testing stage.",
5898.txt,"More proposal regions are retained at the training stage for preserving more training samples, fewer proposal regions are retained at the testing stage for faster speed.To train the extended deep model, we adopt two steps.Step 1: learn the extended deep model without visibility reasoning.",
5899.txt,Two kinds of implementations are tried in implementing the part branch.,
5900.txt,"The first implementation places Relu before the deformation layer and uses tanh as the activation function to get the deformable part score, and then uses the Euclidean loss for training part branch.",
5901.txt,"The other implementation does not place non-linear activation function before the deformation layer and chooses sigmoid as the activation function to get the part score, and then uses the cross entropy loss for training the part branch.",
5902.txt,Both implementations have similar results.,
5903.txt,"Step 2: with the model parameters in Step 1 as initial point, the extended deep model with visibility reasoning is trained.",
5904.txt,"In the training stage, layers from VGG are initialized by the VGG16 model pre-trained on ImageNet, and the other new layers are initialized from zero-mean Gaussian distribution.",
5905.txt,"The visibility reasoning layer is  implemented by fully connected layer, they can be easily implemented by convolution.And the distance transform is used for the deformation layer, which is also applicable for convolution.",
5906.txt,The model in this paper can be made fully convolutional although we run it as   a classifier for each window separately using the roipooling.The labels and evaluation code provided by Dollar online are used for evaluation following the criteria proposed in X.,
5907.txt,"As in X, the log-average miss rate is used to summarize the detector performance, and is computed by averaging the miss rate at nine FPPI rates that are evenly spaced in the log-space
in the range from 10? to 100.",
5908.txt,"In the experiments, we evaluate the  performance on  the  reasonable subset  of  the  evaluated datasets.",
5909.txt,"This subset, which is the most popular portion of the datasets, consists of pedestrians who are more than 49 pixels in height, and whose occluded portions are less than 35%.",
5910.txt,"To evaluate on the Caltech-Test dataset, the Caltech-Traindataset is used to train our model.",
5911.txt,The recent best performing approaches on Caltech-Test also use Caltech-Train as training data.,
5912.txt,"At the training stage, there are approximately 60000 negative samples and 4000 positive samples from the Caltech-Train dataset.",
5913.txt,A one-layer CNN  is obtained by directly feeding the  extracted features  in  Fig.,
5914.txt,2 into a linear classifier.,
5915.txt,A two-layer CNN is constructed by convolving the extracted feature maps with another convolutional layer and another pooling layer.,
5916.txt,Adding more convolutional and pooling layers on the top of the two-layer CNN does not improve the performance.,
5917.txt,"Both CNNs have the same input and settings as the first convolutional layer and pooling layer of UDN, but do not have the deformation layer or the visibility estimation layer.",
5918.txt,This experiment shows that the usage of deformation and visibility layers outperforms CNNs.,
5919.txt,"The ConvNet-U-MS in X, which uses unsupervised feature learning for two-layer CNN, does not perform well on Caltech-Test.",
5920.txt,It has an average miss rate of 77%.Input  channel  design.,
5921.txt,Fig.10 shows  the experimental results of investigating the influence of input channels introduced in Section 3.2.,
5922.txt,"When the input data only has the first Y-channel image, the average miss rate is 47%.",
5923.txt,The inclusion of the second chennel of color images with a lower  resolution reduces the miss rate by 5%.,
5924.txt,Including the third channel of edge maps reduces the miss rate by a further 3%.Joint Learning.,
5925.txt,Fig.,
5926.txt,10 shows the experimental results on investigating different degrees of joint learning.,
5927.txt,The first convolutional and pooling layers of UDN correspond to the feature extraction step.,
5928.txt,"Therefore, the output of the  two  layers can be replaced by any other features, either manually designed or pre-learned.",
5929.txt,"For a fair comparison on the ETH dataset, we follow the training setting commonly adopted by state-of-the-art approaches ; that is, using the INRIA training dataset in X to train UDN.",
5930.txt,"There are approximately 60000 negative samples and 2, 000 positive samples from the INRIA Training dataset, after the pruning of the  HOG+CSS+SVM  detector.",
5931.txt,Fig.11 shows the experimental results on ETH.,
5932.txt,It can be seen that the basic UDN model is still  among the top  ranking approaches on this dataset.,
5933.txt,Many studies have found that deep models favor large-scale training data.,
5934.txt,The  INRIA  training set has fewer positive training samples than Caltech-Train.,
5935.txt,"Therefore, the difference of miss rates between UDN and existing approaches is smaller than that on Caltech-Test.",
5936.txt,Area under curve  is another measurement commonly used for evaluating the performance of pedestrian detection.,
5937.txt,Fig.,
5938.txt,"12 shows the average miss rate computed from AUC, which indicates that UDN also outperforms many sate-of-the- art methods under AUC.",
5939.txt,"In this section, we evaluate the proposed extended model introduced in Section 4 on the Caltech dataset.",
5940.txt,"We evaluate the performance on the reasonable subset of the evaluated datasets, which is for pedestrians over  50  pixels  tall,  with no or partial occlusion.",
5941.txt,In section 4 we use the training data of Caltech provided by Dolla.,
5942.txt,"As  pointed out by Zhang  in X , the label in X is noisy and influences both training and testing accuracy.",
5943.txt,The annotations are refined in X.,
5944.txt,"In this section, we use the new annotations provided in X for both learning the model using the Caltch-Train and evaluation using the Caltech-Test.",
5945.txt,We further examine the effectiveness of part branch and  the deformation layer separately.,
5946.txt,The baseline VGG16 in Fig.,
5947.txt,"14 without the part branch has average miss rate 13.36%.Based on the joint model, the experimental results investigating influence from the number of parts for each  branch  are shown in Fig.",
5948.txt,14,
5949.txt,It can be seen that  the  use  of  9 parts is better than 4 or 16  parts.,
5950.txt,We  use  9  parts  as  our final implementation.,
5951.txt,"Since the model has 3 branches and each branch has 9 parts, there are 27 parts in all.",
5952.txt,Fig.,
5953.txt,15 shows the visualization of the learned filters for full body and body parts using the DeepVisualization in X.,
5954.txt,The visualized filter for the full-body branch in Fig.,
5955.txt,15 covers the full body of a pedestrian.,
5956.txt,It is not good for representing the legs of the pedestrian.,
5957.txt,The filters for the part branch in Fig.,
5958.txt,15 are stitched for better visualization quality.,
5959.txt,It can be seen that the filters for parts provide more details of pedestrians.,
5960.txt,Fig.,
5961.txt,"16 shows the learned deformation map.This paper proposes a unified deep model that jointly learns four components ?feature extraction, deformation handling, occlusion handling and classification for pedestrian detection.",
5962.txt,"Through interaction among these interdependent components, joint learning achieves detection accuracy improvement on benchmark pedestrian detection datasets.",
5963.txt,Detailed experimental comparisons clearly show that the proposed new model can maximize the strength of each component when all the components cooperate with each other.,
5964.txt,"We enrich the deep model by introducing the deformation layer, which has great flexibility to incorporate various deformation handling approaches.",
5965.txt,We expect even larger improvement by training our UDN on much larger-scale training sets in the future work.,
5966.txt,Instance-level object segmentation is an important yet under-explored task.,
5967.txt,Most of state-of-the-art methods rely on region proposal methods to extract candidate segments and then utilize object classification to produce final results.,
5968.txt,"Nonetheless, generating reliable region proposals itself is a quite challenging and unsolved task.",
5969.txt,"In this work, we propose a Proposal-Free Network to address the instance-level object segmentation problem, which outputs the numbers of instances of different categories and the pixel-level information on  the coordinates of the instance bounding box each pixel belongs to, and  the confidences of different categories for each pixel, based on pixel-to-pixel deep convolutional neural network.",
5970.txt,"All the outputs together, by using any off-the-shelf clustering method for simple post-processing, can naturally generate the ultimate instancelevel object segmentation results.",
5971.txt,The whole PFN can be easily trained without the requirement of a proposal generation stage.,
5972.txt,Extensive evaluations on the challenging PASCAL VOC 2012 semantic segmentation benchmark demonstrate the effectiveness of the proposed PFN solution without relying on any proposal generation methods.,
5973.txt,"Over the past few decades, two of the most popular object recognition tasks, object detection and semantic segmentation, have received a lot of attention.",
5974.txt,"The goal of object detection is to accurately predict the semantic category and the bounding box location for each object instance, which is a quite coarse localization.",
5975.txt,"Different from object detection, the semantic segmentation task aims to assign the pixelwise labels for each image but provides no indication of the object instances, such as the number of object instances and precise semantic region for any particular instance.",
5976.txt,"In this work, we follow some of the recent works and attempt to solve a more challenging task, instance-level object segmentation, which predicts the segmentation mask for each instance of each category.",
5977.txt,We suggest that the next generation of object recognition should provide a richer and more detailed parsing for each image by labeling each object instance with an accurate pixel-wise segmentation mask.,
5978.txt,"This is particularly important for real-world applications such as image captioning, image retrieval, 3-D navigation and driver assistance, where describing a scene with detailed individual instance regions is potentially more informative than describing roughly with located object detections.",
5979.txt,"However, instance-level object segmentation is very challenging due to high occlusion, diverse shape deformation and appearance patterns, obscured boundaries with respect to other instances and background clutters in real world scenes.",
5980.txt,"In addition, the exact number of instances of each category within an image is dramatically different.",
5981.txt,"Recently, tremendous advances in semantic segmentation and object detection  have been made relying on deep convolutional neural networks .",
5982.txt,Some previous works have been proposed to address instance-level object segmentation.,
5983.txt,"In general, these previous methods take complicated preprocessing such as bottom-up region proposal generation or post-processing such as graphical inference as the requisite.",
5984.txt,"Specifically, the recent two approaches, SDS and the one proposed by Chen, use the region proposal methods to first generate potential region proposals and then classify on these regions.",
5985.txt,"After classification, post-processing such as non-maximum suppression  or Graph-cut inference, is used to refine the regions, eliminate duplicates and rescore these regions.",
5986.txt,"Note that most region proposal techniques typically generate thousands of potential regions, and take more than one second per image.",
5987.txt,"Depending on the region proposal techniques, the common pipelines are often trained using several independent stages.",
5988.txt,These separate pipelines rely on independent techniques at each stage and the targets of the stages are significantly different.,
5989.txt,"For example, the region proposal methods try to maximize region recalls while the classification optimizes for single class accuracy.",
5990.txt,"In this paper, we propose a simple yet effective Proposal- Free Network for solving the instance-level segmentation task.",
5991.txt,The motivation of the proposed network is illustrated in Figure 1.,
5992.txt,The pixels belonging to the same instance can be naturally clustered as an instance.,
5993.txt,"For simplicity, we use the term instance locations to denote the coordinates of the bounding box of the instance each pixel belongs to.",
5994.txt,We reformulate the instance-level segmentation task in the proposed network by directly inferring the regions of object instances from the global image context.,
5995.txt,The proposed PFN framework is shown in Figure 2.,
5996.txt,"To solve the semantic instance-level object segmentation task, three sub-tasks are addressed: category-level segmentation, instance location prediction for each pixel, and number prediction of instances for each category in the entire image.",
5997.txt,"First, the convolutional network  is  fine  tuned  based  on the pre-trained VGG classification net to predict  the category-level segmentation.",
5998.txt,"In this way, the domain- specific feature representation on semantic segmentation for each pixel can be learned.",
5999.txt,"Second, by fine-tuning on the category-level segmentation network, the instance locations for each  pixel  as well as the number of instances of each category are simultaneously predicted by the further updated instancelevel segmentation network.",
6000.txt,"The prediction target for each pixel is called as instance locations, which consists of four coordinates offsets of each pixel with respect to that of  the top left corner and the bottom right corner of the bounding box of each  instance.",
6001.txt,The  precise  prediction  of instance locations is very crucial for segmenting the heavily occluded instances.,
6002.txt,"To obtain more precise instance location prediction for each pixel, multi-scale prediction streams with individual supervision  are appended to jointly encode local details from  the  early, fine layers and the global semantic information from the deep, coarse layers.",
6003.txt,"The feature maps from deep layers often focus on the global structure, but are insensitive to local boundaries and spatial displacement.",
6004.txt,"In contrast, the feature maps from early layers can sense better the local  detailed boundaries.",
6005.txt,The fusion layer combining multi-scale predictions is utilized before the final prediction layer.,
6006.txt,"Third, the number of instances of all categories are described with a real number vector and also regressed with Euclidean loss in the instance-level segmentation network.",
6007.txt,Note that the number of instances embraces the category level information  and instance-level information .,
6008.txt,"Thus, the intermediate feature maps from the category-level segmentation network and the instance-level feature maps after the fusion layer from the instance-level segmentation network are concatenated together, which can be utilized  to jointly predict the number of instances.",
6009.txt,"In the testing stage, the number of instances and pixellevel information including category-level confidences and coordinates of the instance bounding box each pixel belongs to, can together help generate the final instance-level segmentation results after clustering.",
6010.txt,"Note that any off-the- self clustering method can be used for this simple postprocessing, and the predicted number of instances specifies the exact number of clusters for the corresponding category.",
6011.txt,Comprehensive evaluations and comparisons on the PAS- CALVOC 2012 segmentation benchmark well demonstrate that the proposed proposal-free network yields results that significantly surpass all previous published methods.,
6012.txt,It should be noted that all previous works utilize the extra region proposal extraction algorithms to generate the region candidates and then feed these candidates into a classification network and complex post-processing steps.,
6013.txt,"Instead, our PFN generates the instance-level segmentation results in a much simple and more straightforward way.Deep convolutional neural networks  have achieved great success in object classification,object   detection  and  object segmentation .",
6014.txt,"In this section, we discuss the most relevant work on object detection, semantic segmentation and instance-level object segmentation.The box proposals are extracted either by the hand-crafted pipelines such as selective search , EdgeBox  or the designed convolutional neural network such as deep MultiBox  or region proposal network .",
6015.txt,"For instance, the region proposal network simultaneously predicts object bounds and objectiveness scores to generate a batch of proposals and then uses the Fast R-CNN  for detection.",
6016.txt,"Different from these  prior  work,  Redmon  first proposed a You Only Look Once  pipeline that predicts bounding boxes and class probabilities directly from full images in one evaluation.",
6017.txt,"Our work shares some similarities with YOLO, where the region proposal generation is discarded.",
6018.txt,"However, our PFN is based on the intuition that the pixels inferring similar instance locations can be directly collected as a single instance region.",
6019.txt,The pixel-wise instance locations and the number of instances of each category are simultaneously optimized in one network.,
6020.txt,"Finally, the fine-grained segmentation mask of each instance can be produced with our PFN instead of the coarse outputs depicted by the bounding boxes from YOLO.The most recent progress in object segmentation was achieved by fine-tuning the pre-trained classification network with the groundtruth category-level masks.",
6021.txt,"For instance, Dai estimated segmentation masks for training by extracting region proposals from the annotated boxes.",
6022.txt,"Papandreou utilized the foreground/background segmentation methods to generate segmentation masks, and conditional random field inference is used to refine the segmentation results.",
6023.txt,Zheng formulated the conditional random fields as recurrent neural networks for dense semantic prediction.,
6024.txt,"Different from the category-level prediction by these previous methods, our PFN  targets  at  predicting  the instance-level object segmentation that provides more powerful and informative predictions to enable the real-world vision applications.",
6025.txt,"These previous pipelines using the pixel-wise cross-entropy loss for semantic segmentation cannot be directly utilized for instance-level segmentation because different instances are often distinguished by their spatial translations, and the output size of prediction maps cannot be constrained to a pre-determined number due to the uncertain maximal number of instances of all categories in all images.",
6026.txt,Recently several approaches which tackle the instance-level object segmentation have emerged.,
6027.txt,Most of the prior works utilize the region proposal methods as the requisite.,
6028.txt,"For example, Hariharan classified region proposals using features extracted from both the  bounding  box  and  the  region  foreground  with a jointly trained CNN.",
6029.txt,"Similar to X, Chen  proposed to use the category-specific reasoning and shape prediction through exemplars to further refine the results after classifying the proposals.",
6030.txt,Dai trained to classify the region-level feature maps that are masked out based on region proposals.,
6031.txt,Other works have resorted to the object detection task to initialize the instance segmentation and the complex post-processing such as integer quadratic program and probabilistic model to further determine the instance segments.,
6032.txt,Hariharan defined the hypercolumn at a pixel as the vector of activations of all CNN units above that pixel to allow more precise localization.,
6033.txt,"Dai proposed to use multi-task network cascades for differentiating instances, estimating masks, and categorizing objects.",
6034.txt,"Ren introduced an integrated recurrent network with an attention mechanism, which sequentially employs a box proposal network, a segmentation network and a scoring network to obtain instance-level predictions.",
6035.txt,These  prior  works  based  on  region  proposals  are very complicated due to several pre-processing and post- processing steps.,
6036.txt,"In addition, combining independent steps is not an optimal solution because the local and global context information cannot be incorporated together for inferring.",
6037.txt,"In contrast, our PFN directly  predicts  pixel wise instance location maps and uses a simple clustering technique to generate instance-level segmentation results.",
6038.txt,"In particular, Zhang  predicted depth-ordered instance labels of the image patch and then combined predictions into the final labeling via the Markov Random Field inference.",
6039.txt,"However, the number of instances to be present in each image patch is limited to be smaller than 6 , which makes it not scalable for real-world images with an arbitrary number of possible object instances.",
6040.txt,"Instead, our network predicts the number of instances in a totally data-driven way by the trained network, which can be naturally scalable and easily extended to other instance-level recognition tasks.Recently, more research interests have been attracted to develop kinds of ""proposal-free""-like pipelines that aim to generate instance-level object segmentation without relying on any proposal generation.",
6041.txt,Note that all these methods were proposed after the first submission of this paper.,
6042.txt,"For example, Uhrig proposed to produce a semantic segmentation and instance-aware angle map that encoding the instance centroids.",
6043.txt,They also used ground-truth pixel-wise depth labeling for training.,
6044.txt,Bai learned the energy map of the watershed transform with the assumption that instances naturally correspond to basins in the energy map.,
6045.txt,employed both semantic segmentation and object boundary prediction to separate instances.,
6046.txt,Liu trained sequential grouping networks to progressively group instance segments.The detailed network architecture and parameter setting of PFN.,
6047.txt,"First, the category-level segmentation network is fine-tuned based on the pre-trained VGG-16 classification network.",
6048.txt,The cross-entropy loss is used for optimization.,
6049.txt,"Second, the instance-level segmentation network that simultaneously predicts the number of instances of all categories and the instance location vector for each pixel is further fine-tuned.",
6050.txt,"The multi-scale prediction streams  are appended to the intermediate convolutional layers, and are then fused to generate ultimate instance location predictions.",
6051.txt,The regression loss is used during training.,
6052.txt,"To predict the number of instances, the convolutional feature maps and the instance location maps are concatenated together for inference, and the Euclidean loss is used.",
6053.txt,The two losses from two targets are jointly optimized for the whole network training.The proposed PFN is fine-tuned based on the publicly available pre-trained VGG 16-layer classification network for the dense category-level segmentation task.,
6054.txt,We utilize the "DeepLab-CRF-LargeFOV" network structure as the basic presented in X due to its leading accuracy and competitive efficiency.,
6055.txt,"The important convoluational filters are shown in the top row of Figure 3, and other intermediate convolutional layers can be found in the published model file.",
6056.txt,"The reception field of the ""DeepLab-CRF- LargeFOV"" architecture is 224224 with zero-padding, which  enables  effective  prediction  of  the  subsequent instance locations that requires the global image context for reasoning.",
6057.txt,The loss function is the sum of pixel-wise cross-entropy in terms of the confidence maps .,
6058.txt,"During testing, the fully-connected conditional random fields are employed to generate more smooth and accurate segmentation maps.",
6059.txt,This fine-tuned category-level network can generate semantic segmentation masks for the subsequent instancelevel segmentation for each input image.,
6060.txt,"Then the instance-level network is fine-tuned based on the category-level network, where the C + 1 category-level predictions are eliminated.",
6061.txt,Note that we use two separate stages from optimizing category-level segmentation and instance-level segmentation.,
6062.txt,The intuition is that category-level segmentation prefers the prediction that is insensitive for different object instances of a specific category while instance-level segmentation aims to distinguish between individual instances.,
6063.txt,The motivations of two targets are significantly different.,
6064.txt,"Therefore the convolutional feature maps, especially for the latter convolutional layers, cannot be  shared.",
6065.txt,We  verify the superiority of subsequently fine-tuning two separate networks for two tasks in  the  experiment.,
6066.txt,"In  addition,  the performance on instance-level segmentation is much better when fine-tuning the instance-level network based  on the category-level segmentation network compared to the original VGG-16.",
6067.txt,This may be because the category- level segmentation can provide a better start for parameter learning where the basic segmentation-aware convolutional filters have already been well learned.,
6068.txt,The instance-level segmentation network takes an image with an arbitrary size as the input and outputs the corresponding instance locations for all the pixels and the number of instances belonging to each category.Another sub-task of PFN is to predict the numbers of instances of all categories.,
6069.txt,The number of instances of the input image that account for the object instances of each category naturally contains the category-level information and instance-level information.,
6070.txt,"As shown in Figure 3, the feature maps of the last convolutional layer from the previously trained category-level segmentation network and the instance location predictions
are combined together to form the fused  feature  maps  with 1024 + 4 channels.Note that inconsistent global image category predictions from number vectors of instances and pixel-wise category- level segmentation are often observed.",
6071.txt,"For example, as illustrated in the first row of Figure 4, the number prediction of instances infers 4 person instances and 2 bicycle instances while the category-level segmentation indicates three categories  appearing in the image.",
6072.txt,Thus it is necessary to keep the  predicted  global image category to be consistent between the number prediction of instances and the pixel-wise segmentation.,
6073.txt,Note that the number prediction task of instances is much simpler than pixel-wise semantic segmentation due to dense pixel-wise optimization targets.,
6074.txt,"We can thus use the number prediction of instances to refine the produced category-level segmentation.In addition, the predicted segmentation result is not perfect due to the noisy background pixels.",
6075.txt,"The instance locations of pixels belonging to one object have much higher possibilities to form a cluster while the predictions of background pixels are often quite random, forming very small clusters.",
6076.txt,"Therefore, we experimentally discard those clusters, whose numbers of pixels are less than 0.1% of the pixels in the segmentation mask.",
6077.txt,"Finally, after obtaining the final clustering result for each category, the instancelevel object segmentation result can  be  easily  obtained  by combining all the clustering results of all categories.",
6078.txt,Example results after constraining the number of pixels of each clustered instance region are shown in Figure 5.The proposed PFN is extensively evaluated on the PASCAL VOC 2012 validation segmentation benchmark .,
6079.txt,"We compare our method with four state-of-the-art algorithms: SDS , CFM , Chen and MNC .",
6080.txt,"Following the baselines, the instance-level segmentation annotations from SBD dataset are used when training all variants of the PFN, since VOC 2012 did not provide all annotations of the training set for  instance- level segmentation.",
6081.txt,The training set for the segmentation task  on  VOC  2012  is  used  for  training  all  the  models and we use the 1449 images in the validation set for testing.,
6082.txt,"Note that, both SBD dataset and VOC 2012 provide annotations of instance-level object segmentation for the 1449 images on VOC 2012 validation set.",
6083.txt,"As compared  in  X,  VOC  2012  provides  very  elaborated segmentation annotations for each instance while SBD just gives the whole region.",
6084.txt,"Since Chen re-evaluated the performance of the method in X with the annotations from VOC 2012 validation set, most of our evaluations are thus performed with respect  to the annotations from VOC 2012 when comparing with X.",
6085.txt,"For comparison with  HC,CFM and MNC  that use 5623 images for training and 5732 for testing according to VOC 2012 detection split, we also evaluate the performance of PFN with the annotations from SBD dataset.",
6086.txt,"For fair comparison with state-of-the-art instance level segmentation methods, APr and APr metrics are used following SDS.",
6087.txt,The APr metric measures the average precision under 0.5 IoU overlap with ground-truth segmentation.,
6088.txt,"Hariharan et al.All networks in our experiments are trained and tested based on the published  DeepLab code , which is implemented based on the publicly available Caffe platform on a single NVIDIA GeForce Titan GPU with 6GB memory.",
6089.txt,"We first train the category- level segmentation network, which is then used to initialize our instance-level segmentation network for fine tuning.",
6090.txt,"For both training stages, we randomly initialize all new layers by drawing weights from a zero-mean Gaussian distribution with standard deviation 0.01.",
6091.txt,"We use mini-batch size of 8 images, initial learning rate of 0.001 for pre-trained layers, and 0.01 for newly added layers in all our experiments.",
6092.txt,We decrease the learning rate to 1/10 of the previous one after 20 epochs and train the two networks for roughly 60 epochs one after the other.,
6093.txt,"The momentum and the weight decay are set as 0.9 and 0.0005, respectively.",
6094.txt,"The same training setting is utilized for all our compared network variants.In addition, the separate processing steps obstruct introducing the elaborately crafted neural network tricks  for refining object masks.",
6095.txt,"On the contrary, our PFN directly optimizes the final structured outputs that correspond to the target instance-level object segmentation.",
6096.txt,The intermediate convolutional features in our framework are learned to simultaneously exploit the region grouping of different object instances and the semantic object categorization.,
6097.txt,The unified joint optimization of our PFN is the key to achieving better segmentation and categorization performance.,
6098.txt,"Table 2 and Table 5 present the comparison of the proposed PFN with two state-of-the-art methods using APr metric at IoU score 0.5 and 0.6 to 0.9, respectively.",
6099.txt,We directly use their published results on PASCAL VOC  2012 validation set for fair comparison.,
6100.txt,All results  of the state-of-the-art methods were reported in X which re-evaluated the performance of X using VOC 2012 validation set.,
6101.txt,"For fair comparison, we also report the results of PFN using the Alexnet architecture as used in two baselines.",
6102.txt,"""PFN Alexnet"".",
6103.txt,"Following the strategy presented in X, we convert the fully connected layers in Alexnet to fully convolutional layers, and all other settings are the same as those used in ""PFN"".Meanwhile, our ""PFN Alexnet"" is significantly superior over the two baselines, i.e.",
6104.txt,53.9% vs 43.8% and 46.3% in APr metric.,
6105.txt,Further detailed comparisons in APr over 20 classes at IoU  scores  0.6  to  0.9  are  listed in Table 5.,
6106.txt,"By utilizing the more powerful VGG-16 network architecture, our PFN can substantially improve the performance and outperform these two baselines by over 18.5% for SDS and 16.0% for the method of Chen et al.This verifies the effectiveness of our PFN although it does not require extra region proposal extractions as the pre-processing step.",
6107.txt,The detailed APr scores for each class are also listed.,
6108.txt,"In general, our method shows dramatically higher performance than the baselines.",
6109.txt,"Especially, in predicting small object instances  or object instances with a lot  of  occlusion  , our method achieves a larger gain.",
6110.txt,"This demonstrates that our network can effectively deal with the internal boundaries between the object instances and robustly predict the instance-level masks with various appearance patterns or occlusion.We further evaluate the effectiveness of our important components of PFN, including the training strategy, network structure, the number prediction of instances, testing strategy and upperbounds, respectively.",
6111.txt,"To validate different architecture variants of our PFN more fairly, we randomly select 1,449 images from the training set as the validation set for all our ablation experiments and the rest images in the training set for training the networks.",
6112.txt,The performance over all the categories by all variants is reported in Table 3 and Table 4.Note that our PFN training includes two stages: the category-level segmentation network and the instance-level network.,
6113.txt,"To justify the necessity of using two stages, we evaluate the performance of training a unified network that consists of the category-level segmentation, pixel-wise instance location prediction and the number prediction of instances in one learning stage, namely ""PFN unified"".",
6114.txt,We explore  other options to predict the numbers of instances of all categories for each image.,
6115.txt,"""PFN w/o category-level"" only utilizes the instance location predictions as the feature  maps for predicting numbers of instances and the category- level information is totally ignored.",
6116.txt,The large gap between "PFN w/o category-level" and "PFN" verifies the importance of using category-level information for predicting numbers of instances.,
6117.txt,"Because the instance location predictions only capture the numbers of instances of all categories and category-level information is discarded, the exact number of instances for a specific category thus cannot be inferred.",
6118.txt,"The importance of incorporating instance-level information is also verified by comparing ""PFN w/o instance-level"" with ""PFN"", 60.8% vs 61.7% in APr.",
6119.txt,"This shows that the number prediction of instances can benefit from the pixel-wise instance location prediction, where more fine-grained annotations are provided for learning better feature maps.We also test different strategies for generating final instance-level segmentations during testing.",
6120.txt,"Note that during spectral clustering, the similarity of two pixels is computed by considering both the prediction instance locations with four dimensions and two spatial coordinates of each pixel.",
6121.txt,"By eliminating the coordinates  in the similarity function, a significant  decrease  in APr can be seen by comparing ""PFN w/o coordinates"" with ""PFN"", 57.6% vs 61.7%.",
6122.txt,"This verifies that the spatial coordinates can enhance the local neighboring connections during clustering, which can lead to more reasonable and meaningful instance-level segmentation results.In addition, we also test  the  performance  influenced  by using different feature  representations   considered in the similarity function during clustering.",
6123.txt,"First, we evaluate the version that uses the predicted center coordinates transformed fromthe predicted top-left and down-right coordinates as the additional features in the similarity function.",
6124.txt,It achieves 0.9% improvement in terms of APr metric on 0.5 IoU over our "PFN" that only uses the predicted top-left and down-right coordinates as features.,
6125.txt,"Second, our PFN achieves 1.3% higher performance over the version that uses the predicted center coordinates, height and width as the feature instead of predicted top-left and down-right coordinates.",
6126.txt,These experiments prove that the redundant feature representation can improve the discriminative capability of segmenting instances during the clustering step.We also show some failure cases of our PFN in Figure 7.,
6127.txt,The heavily occluded instances and some small object instances are difficult to identify and segment due to the imprecise prediction for instance location.,
6128.txt,"In addition, the instance-level object segmentation results are also affected by imprecise category-level segmentation.",
6129.txt,"In this paper, we present an effective proposal-free network for fine-grained instance-level segmentation.",
6130.txt,"Instead of utilizing extra region proposal methods as the requisite, PFN directly predicts the instance location vector for each pixel that belongs to a specific instance and the numbers   of instances of all categories.",
6131.txt,The pixels that predict the same or close instance locations can be directly regarded as belonging to the same object instance.,
6132.txt,Significant improvements over the state-of-the-art methods are achieved by PFN on the PASCAL VOC 2012 segmentation benchmark.,
6133.txt,Extensive evaluations of different components of PFN are conducted to validate the effectiveness of our method.,
6134.txt,"In future work, we plan to extend our framework to the generic multiple instances in outdoor and indoor scenes, which may have higher degrees of clutters and occlusion.",
6135.txt,"Furthermore, the current framework may fail to detect heavily occluded instances due to the wrongly predicted instance locations and numbers of instances.",
6136.txt,We  will address this problem  by incorporating the spatial layout contexts of occluded instances into the neural network prediction.,
6137.txt,"In this paper, we present a novel method for real-time 3D hand pose estimation from single depth images using 3D Convolutional Neural Networks .",
6138.txt,Image-based features extracted by 2D CNNs are not directly suitable for 3D hand pose estimation due to the lack of 3D spatial information.,
6139.txt,"Our proposed 3D CNN-based method, taking a 3D volumetric representation of the hand depth image as input and extracting 3D features from the volumetric input, can capture the 3D spatial structure of the hand and accurately regress full 3D hand pose in a single pass.",
6140.txt,"In order to make the 3D CNN robust to variations in hand sizes and global orientations, we perform 3D data augmentation on the training data.",
6141.txt,"To further improve the estimation accuracy, we propose applying the 3D deep network architectures and leveraging the complete hand surface as intermediate supervision for learning 3D hand pose from depth images.",
6142.txt,Extensive experiments on three challenging datasets demonstrate that our proposed approach outperforms baselines and state-of-the-art methods.,
6143.txt,"A cross-dataset experiment also shows that our method has good generalization ability.Furthermore, our method is fast as our implementation runs at over 91 frames per second on a standard computer with a single GPU.Articulated 3D hand pose estimation is one of the core technologies for human computer interaction   in virtual reality and augmented reality applications, since this technology provides a natural way for users to interact with virtual environments and virtual objects.",
6144.txt,"The estimated 3D hand pose can also be used for gesture recognition, such as sign language recognition and driver hand gesture analysis.",
6145.txt,"However, it is still challenging to achieve efficient and robust hand pose estimation performance because of large variations in hand pose, high dimensionality of hand motion, severe self-occlusion and self-similarity of fingers in the depth image.",
6146.txt,Many recent works on hand pose estimation have achieved good performance due to the success of Convolutional Neural Networks  and the availability of large hand pose datasets.,
6147.txt,"Most of these methods directly take the depth image as input to 2D CNNs which output heat-maps , 3D joint locations or hand model parameters.Nevertheless, we argue that image-based features extracted by 2D CNNs are not directly suitable for 3D hand pose estimation due to the lack of 3D spatial information.",
6148.txt,"For example, in X, the initial result of 2D CNN is poor, and  it is iteratively refined by a feedback loop to incorporate 3D information from a generative model.",
6149.txt,Ge better utilize the depth cues by projecting the depth image onto three views and applying multi-view CNNs to regress three views' heat-maps .,
6150.txt,"However, the multi-view CNNs still cannot fully exploit 3D spatial information in the depth image, since the projection from 3D to 2D will lose certain information.",
6151.txt,"Although increasing the number of views may improve the performance, the computational complexity will increase when using more views.",
6152.txt,"In this paper, we propose a 3D CNN-based hand pose estimation approach that can capture the 3D spatial structure of    the input and accurately regress full 3D hand pose in a single pass, as illustrated in Figure 1d.",
6153.txt,"Specifically, human hand is first segmented from the depth image; the 3D point cloud of the hand is encoded as 3D volumes storing the projective Directional Trun- cated Signed Distance Function values, which are then fed into a 3D convolutional neural network.",
6154.txt,We design a 3D deep dense network to boost the learning ability of the network.,
6155.txt,The output of this network is a lower dimensional representation of 3D hand joints' relative locations in the 3D volume.,
6156.txt,"By performing PCA reconstruction and coordinate transformations, we can finally obtain the 3D hand joint locations in the camera's coordinate system.",
6157.txt,"Benefiting from 3D features extracted by 3D convolutions, our method is able to understand the hand pose structure in 3D space and infer 3D hand joint locations efficiently and robustly.Compared to previous CNN-based methods for hand poseestimation, our proposed 3D CNN-based method has the following advantages:Our proposed 3D CNN is capable of learning 3D features from the 3D volumetric representation for accurate 3D hand pose estimation.",
6158.txt,"Compared to 2D CNN-based methods that regress 3D joint locations from 2D features , 3D CNN can directly regress 3D joint locations from 3D features in a single pass.",
6159.txt,"This not only achieves superior estimation accuracy, but also avoids the time-consuming iterative refinement process.",
6160.txt,Our proposed 3D CNN can be easily trained in an end-to-end manner.,
6161.txt,"Both the 3D shallow plain network and the 3D deep dense network we designed in this paper can run at real-time speed on a single GPU.Our proposed method is robust to variations in hand sizes and global orientations, since we perform 3D data augmentation on the training set.",
6162.txt,"Different from traditional data augmentation that performs 2D transformations on 2D images, our proposed 3D data augmentation applies 3D transformations on 3D point clouds, thus can better enrich the training data in 3D space.",
6163.txt,This paper is an extension of our conference paper.,
6164.txt,The new contributions of this paper are summarized as follows:We have proposed leveraging the complete hand surface as intermediate supervision for learning 3D hand pose from depth images.,
6165.txt,"Experimental results have shown that, with the intermediate hand surface completion step, the estimation accuracy of 3D hand pose can be further improved.e have investigated the performance of deep neural network architectures when applied in our proposed 3D CNN-based framework for  3D  hand  pose  estimation  to improve the learning ability.",
6166.txt,"Experimental results have shown that the 3D deep dense network can achieve better performance than the 3D shallow plain network.To better understand 3D CNNs, we have visualized the input patterns that produce given activations in the 3D feature volumes.",
6167.txt,Local and global 3D structures of hand have been observed in these patterns.We have conducted more extensive self-comparison experiments and have compared with more state-of-the-art methods on one additional hand pose dataset ICVL.,
6168.txt,We  have also conducted a cross-dataset experiment and qualitatively compared with the Intel RealSense SDK.,
6169.txt,Experimental results have shown that our method can achieve good performance in real-time and has good generalization ability.The reminder of this paper is organized as follows: Some related work for 3D hand pose estimation is discussed in Section 2.,
6170.txt,"Since our method takes 3D volumes as input, we first introduces different volumetric representations in Section 3, then describe the proposed 3D CNN-based method in Section 4.",
6171.txt,"Section 5 provides experimental results, and Section 6 concludes this paper.",
6172.txt,"Methods for hand pose estimation from depth images can be categorized into model-driven approaches, data-driven approaches and hybrid approaches.",
6173.txt,Model-driven approaches fit an explicit deformable hand model to depth images by minimizing a hand-crafted cost function.,
6174.txt,"The commonly used optimization methods are Particle Swarm Optimization , Iterative Closest Point and their combination.",
6175.txt,The 3D shape model is represented by Linear Blend Skinning model Gaussian mixture model.,
6176.txt,Some models require to define user-specific parameters and motion constraints.,
6177.txt,"These approaches are sensitive to initialization, since they usually take advantage of temporal information.",
6178.txt,The estimation errors will be accumulated when previous frames' estimations are inaccurate.,
6179.txt,Data-driven approaches learn a mapping from depth image to hand pose from training data.,
6180.txt,"Some early works  focus on example-based method that searches the most similar images in a dataset to the input hand image, but cannot work well in high dimensional space.",
6181.txt,"Inspired by the pioneering work of human pose estimation, apply random forests and their variants as a discriminative model.",
6182.txt,"Limited by the hand-crafted features, methods based on random forests are difficult to outperform current CNN-based methods in hand pose estimation.",
6183.txt,Our work is related to the CNN-based data-driven approach.,
6184.txt,Tompson first propose to employ CNNs to predict heat-maps representing the probability distribution of 2D joint positions in the depth image.,
6185.txt,Ge improve this method by predicting heat-maps on multiple views in order to better utilize the depth information.,
6186.txt,"Oberweger train a feedback loop containing a discriminative network for initial pose estimation, a generative network for pose synthesizing and   a pose update network for improving the pose estimation.",
6187.txt,Zhou  propose to predict hand model parameters instead of  the joint locations by adopting CNNs.,
6188.txt,Sinha extract activation features from CNNs to synchronize hand poses in nearest neighbors by using the matrix completion algorithm.,
6189.txt,Ye propose a spatial attention network with a hierarchical hybrid method for hand pose estimation.,
6190.txt,Wan use deep generative models which can exploit unlabeled depth images for training.,
6191.txt,Guo  propose a region ensemble network by dividing feature maps into multiple regions and ensemble regional features to get final prediction.,
6192.txt,All these methods use 2D filters  in 2D CNNs to extract 2D features which are lack of 3D spatial information.,
6193.txt,"Thus, mapping from 2D features to 3D joint locations is difficult.",
6194.txt,"In this work, we lift the 2D CNN to 3D CNN which can understand 3D spatial information and extract 3D features for 3D hand pose estimation.Hybrid approaches combine a data-driven approach based per-frame reinitialization with a model driven approach based optimization.",
6195.txt,These methods are usually applied for hand tracking since they utilize temporal information to achieve smooth results.,
6196.txt,"However, in this paper, we focus on 3D hand pose estimation from single depth images without using any temporal information, which can be used for robust reinitialization in hybrid hand tracking approaches.3D deep learning 3D CNNs have been successfully applied  in video and dynamic hand gesture analysis  for  recognition  tasks, which regard time as the third dimension.",
6197.txt,"3D CNNs are also applied to extract 3D features from 3D data, such as CAD models and depth images.",
6198.txt,3D ShapeNets learn powerful 3D features by using the Convolutional Deep Belief Network for modeling 3D shapes.,
6199.txt,Qi show that the 3D CNN with low input volume resolution can still achieve good object classification accuracy by applying subvolume supervision and anisotropic probing.,
6200.txt,Song and Xiao  propose to use 3D CNN for 3D object detection in RGB-D images.,
6201.txt,"Maturana and Scherer propose VoxNet, a 3D CNN that can process LiDAR, RGB-D and CAD data for object recognition.",
6202.txt,They also apply the 3D CNN for landing zone detection .,
6203.txt,Yumer and Mitra propose to use the 3D CNN to learn deformation flows from CAD models for 3D shape deformation.,
6204.txt,Song  propose a 3D CNN for semantic scene completion.,
6205.txt,"Although these works achieve state-of-the-art results in their problems, none of them focuses on articulated pose estimation that requires to localize a set of articulated 3D joints from single depth images in real-time.",
6206.txt,Our proposed 3D CNN-based hand pose estimation method takes a volumetric representation as the input of the neural network.,
6207.txt,The objective for encoding the observed hand depth image as a volumetric representation is to generate 3D volumes providing sufficient and meaningful information of the hand in 3D space from the depth image in real-time.,
6208.txt,The 3D volumes will be fed into the 3D CNNs to learn 3D features for subsequent 3D hand joint location regression.,
6209.txt,We need to strike a balance between prediction accuracy and computational cost to determine the volume resolution M .,
6210.txt,"If the volume resolution is too large, it will be time-consuming and memory intensive to compute the volumetric representation.",
6211.txt,"If  the volume resolution is too small, the volumetric representation cannot give sufficient information for 3D hand pose estimation.",
6212.txt,"In this work, M is chosen as 32, which proves to have good estimation accuracy and computational efficiency for 3D hand pose estimation according to the experiments in Section 5.3.1.In this section, we first describe the network architectures and   the loss function applied for 3D hand pose regression.",
6213.txt,"To tackle the problems of self-occlusion and large variations in global orientations, we further introduce the methods of 3D hand surface completion and 3D data augmentation.",
6214.txt,"In the end of this section, we visualize and analyze 3D patterns learned by 3D CNNs.Our proposed 3D CNN takes three volumes of the projective D-TSDF as inputs and output a vector containing F  elements.",
6215.txt,"As shown in Figure 3, we design two network architectures: the 3D shallow plain network and the 3D deep dense network.Deep convolutional networks with shortcut connections have shown powerful learning ability for image recognition, since the shortcut connection can alleviate the gradient vanishing problem.",
6216.txt,We apply the deep dense network architecture in our proposed 3D CNN-based hand pose estimation method.,
6217.txt,"As shown in Figure 3b, we design a 3D deep dense network containing 28 convolutional layers and 3 fully-connected layers.",
6218.txt,"Following the architecture in X, we apply bottleneck layers in each dense block to reduce the number of model parameters.",
6219.txt,Experiments  in Section 5.3.5 will show that the 3D deep dense network can One of challenges in 3D hand pose estimation is that the input depth image only captures partial hand surface and suffers from the self-occlusion problem.,
6220.txt,"To tackle this problem, we leverage the complete hand surface as intermediate supervision for learning 3D hand pose from depth images.",
6221.txt,"More specifically, we estimate the complete hand surface using a data-driven  approach  and  take advantage of the estimated complete hand surface for 3D hand pose estimation.",
6222.txt,"As shown in Figure 4, we apply the 3D U-Net  architecture for estimating the complete hand surface from the captured partial hand surface.",
6223.txt,"Similar to X, we use the unsigned truncated distance function  as the network output, since it is not necessary to differentiate known and unknown space for the distance function of the complete hand surface.",
6224.txt,The ground truth of the complete hand surface is generated by using the model fitting method X with a 3D hand model.,
6225.txt,"When training the 3D U-Net, we minimize the smooth L1  loss defined in X using   the ADAM optimizer .",
6226.txt,"After generating the TDF volume of the complete hand surface, we concatenate it with the original projective D-TSDF volumes and feed them into a 3D DenseNet for 3D hand pose estimation.",
6227.txt,"The 3D U-Net and the 3D DenseNet are pre-trained separately, and are fine tuned in an end-to-end manner.",
6228.txt,"Experiments in Section 5.3.6 will show that, with the intermediate supervision of hand surface completion, the accuracy of 3D hand pose estimation can be further improved.Another challenge of 3D hand pose estimation is that hand pose has large variations in global orientations and hand sizes.",
6229.txt,"In order to make the 3D CNN model robust to different orientations and sizes and improve its generalization ability, we perform 3D data augmentation on the training data for both pose regression and surface completion networks.",
6230.txt,"Different from existing 2D image data augmentation, our method directly rotate and stretch the hand points in 3D space.",
6231.txt,"In order to analyze 3D features extracted by the 3D CNN, we visualize the input patterns that produce given activations in the 3D feature volumes by adopting the guided backpropagation method proposed in X which is a modification of the deconvolution based visualizing approach proposed in X.In Figure 6, we visualize some 3D patterns learned in a 3D shallow plain network which is fully trained on the MSRA hand pose dataset.",
6232.txt,We take three input volumes with  different hand poses as examples in Figure 6.,
6233.txt,"In order to reconstruct 3D patterns, 3D feature volumes generated from 3D convolutional layers are projected down to the input voxel space by using the guided backpropagation method.",
6234.txt,"For each convolutional layer of each hand pose, we choose four feature volumes as examples in Figure 6.",
6235.txt,"To show which parts of the input volume cause high activations in the 3D feature volume, we crop the reconstructed 3D pattern volume inside the receptive field corresponding to the highest activation in the 3D feature volume.",
6236.txt,We also show the relative location of the receptive field in the input 3D volume.,
6237.txt,"The receptive field sizes of the 1st convolutional layer L1, the 2nd convolutional layer L2 and the 3rd convolutional layer L3 in the 3D shallow plain network are 5, 10 and 20, receptively.",
6238.txt,"As can be seen in Figure 6, from low layer L1 to high layer L3, neurons can capture patterns from local to global.",
6239.txt,"Neurons in L1 capture low-level local geometry structures, such as the corners and edges.",
6240.txt,"Neurons in L2 capture mid-level shape structures of the hand, such as the hand finger tips  and palm edges.",
6241.txt,Neurons in L3 capture high- level global structures of the hand.,
6242.txt,"It is interesting to note that, in patterns of L3, the contrast in regions of hand joints is obvious, which indicates that the learned high layer feature volumes focus on regions of hand joints.",
6243.txt,The hierarchical nature of 3D features is consistent with that in the 2D CNNs as observed in X.,
6244.txt,The MSRA dataset  contains nine subjects' hand depth images captured by the Intels Creative Interactive Gesture Camera.,
6245.txt,"Each subject performs 17 hand gestures, and each hand gesture contains about 500 frames.",
6246.txt,There are more than 76K frames in this dataset.,
6247.txt,"In the following experiments on this dataset, we train on eight subjects and test on the remaining subject.",
6248.txt,This is repeated nine times for all subjects.,
6249.txt,The ICVL dataset  contains 12  training sequences having 22K frames and two testing sequences having 1.6K frames captured by the Intel's Creative Interactive Gesture Camera.,
6250.txt,This dataset additionally provides a training set in which the original training samples are in-plane rotated 14 times.,
6251.txt,"However, in our experiments, instead of using the additional training set, we apply the 3D data augmentation by randomly rotating and stretching the original training samples eight times.",
6252.txt,"Thus, the augmented training set in our experiments contains 176K frames.",
6253.txt,The ground truth of each frame contains K = 16 hand joints' 3D locations including three joints for each finger and one joint for the palm center.Three metrics are employed to evaluate the hand pose estimation performance in our experiments.,
6254.txt,The first metric is the perjoint mean error distance over all test frames.,
6255.txt,"The second metric is the proportion of good frames in which the worst joint error is below a threshold, which is a strict measure.",
6256.txt,"The third metric is the proportion of joints within an error threshold.We train and evaluate our proposed 3D CNN models for 3D hand pose estimation on a computer with two Intel Core i7 5930K 3.50GHz CPUs, 64GB of RAM and an Nvidia GeForce GTX 1080 GPU having 8GB of GPU memory.",
6257.txt,The 3D CNN models are implemented within the PyTorch framework.,
6258.txt,"For network training parameters, we choose the batch size as 16, the momentum as 0.9 and the weight decay as 0.0005.",
6259.txt,"The learning rate is set as 0.01 for the 3D regression network, and is divided by 10 after 50 epochs.",
6260.txt,"For the 3D U-Net, the learning rate is set as 0.001.",
6261.txt,The training is stopped after 60 epochs to prevent overfitting.,
6262.txt,We apply the same hyper-parameters for all experiments on all datasets.,
6263.txt,All the weights of 3D convolutional layers in 3D CNNs are randomly initialized using the method proposed in X.,
6264.txt,We evaluate the impact of different volume types on the estimation accuracy on MSRA dataset using the 3D plain network without data augmentation.,
6265.txt,"As can be seen in Figure 7 , among occupancy grid, accurate TSDF, projective TSDF and projective D-TSDF,  the projective D-TSDF performs best.",
6266.txt,"It is worth noting that the performance of occupancy grid is comparable with those of accurate TSDF and projective TSDF, which indicates that the 3D CNNs can learn effective 3D features from the occupancy grid, although the occupancy grid cannot differentiate voxels before and behind the observed surface.",
6267.txt,"But the projective D-TSDF, which encodes more information on three directions, outperforms the occupancy grid.",
6268.txt,"For the real-time performance, the average computation time to generate occupancy grid, accurate TSDF, projective TSDF and projective D-TSDF on the same GPU are 1.4ms, 30.2ms, 1.9ms and 2.9ms, respectively.",
6269.txt,"Thus, considering both the estimation accuracy and the  real-time performance, the projective D-TSDF is overall best.",
6270.txt,"As  shown  in  Figure  7  , when using the same input volume, the method using 2D data augmentation outperforms the method without using data augmentation.",
6271.txt,"When using 3D data augmentation in the training stage, the estimation accuracy is further improved.",
6272.txt,"It is worth noting that, although the 3D rotated point cloud is not exactly the same as the real point cloud, the network trained with 3D   data augmentation can still achieve better performance than the network trained with 2D data augmentation, which indicates that the network can benefit from the 3D augmented data.Compared with the ground truth, our estimation is more blurry and loses some details of the complete hand surface.",
6273.txt,The average L1 loss of estimated TDF volume against the ground truth TDF volume of the complete surface is 0.112 in voxel space of which the truncation distance is 2.5.,
6274.txt,The average errors of 3D hand pose estimation using hand surface completion and without using hand surface completion are presented in Table 1.,
6275.txt,"As can be seen, no matter using the 3D deep residual network or the 3D deep dense network, the surface completion step can further improve the estimation accuracy.",
6276.txt,"In addition, in order to evaluate the importance of the complete hand surface on hand pose estimation, we use the ground truth of the complete hand surface combined with the original partial hand surface as network input to estimate the 3D hand pose.",
6277.txt,"As presented in the last row of Table 1, the networks can achieve much smaller estimation errors when using the ground truth of the complete hand surface, which shows the potential of our method to achieve smaller pose estimation error if the complete hand surface could be estimated more accurately.On MSRA dataset, we compare our 3D CNN-based hand pose estimation method with seven state-of-the-art methods: the hierarchical regression method , the joint matrix factorization and completion method , the multi-view CNN-based method, the local surface normals based method , the crossing nets using deep generative models , the improved 2D CNN with hand pose prior and refinement, the region ensemble network  and the pose guided structured REN.",
6278.txt,"Note that since the hierarchical regression method has been shown superior to the methods  in X, we indirectly compare our method with X.As shown in Figure 10, our 3D CNN-based method out- performs state-of-the-art methods on the MSRA dataset.",
6279.txt,The proportion of good frames over different error thresholds is shown in Figure 10.,
6280.txt,Our method achieves the best performance when the error threshold is larger than 10mm.,
6281.txt,"For example, when the error threshold is 30mm, the proportion of good frames of   our method is about 6%, 10%, 20%, 22%, 28%, 33% and 39% higher than those of the methods in X.In order to make a fair comparison with the spatial attention network based hierarchical hybrid method in X, we evaluate the proportion of joints within different error thresholds on the subset of 11 hand joints following the experiment in X .",
6282.txt,"As shown in Figure 11, our method is superior to the methods in X over all the error thresholds.",
6283.txt,"For example, the proportion of joints within error threshold 20mm of our method is about 20% more than that of the method in X.We also compare the mean error distance  of  our  method  with those of the methods in X.",
6284.txt,"As shown in Figure 11 , our method achieves the smallest mean error distance on most joints, and the mean error distance over all joints of our method is about 5.5mm, 6.5mm, 2mm and 1.5mm smaller than those of methods in X.",
6285.txt,"On ICVL hand pose dataset, we compare our 3D CNN-based hand pose estimation method with eight state-of-the-art methods: the latent regression forest, the hierarchical regression method , the hand  model  parameter  based  method ,  the LSN method , the crossing nets using deep generative models , the REN method , the DeepPrior++ method , and the Pose-REN method .",
6286.txt,"As shown in Figure 12 , our method outperforms these eight methods over most of the error thresholds on this dataset.",
6287.txt,"To evaluate the generalization ability of our 3D CNN-based hand pose estimation method, we perform a cross-dataset experiment, in which the 3D CNN model is trained on the whole MSRA dataset and is evaluated on the whole dataset released in X.",
6288.txt,"According to the evaluation metric in X, we calculate the mean error distances for the wrist and the five fingertips.",
6289.txt,"As shown  in Table 2, we compare our 3D CNN-based method with model based tracking methods reported in X, which are FORTH , PSO, as well as the multi-view CNN- based method .",
6290.txt,"As can be seen, our method achieves the second best result on three subjects and on the average error over all subjects.",
6291.txt,But our method does not use any ground truth of the testing data and is performed on cross-dataset which is more challenging.,
6292.txt,"Thus, the overall second best result achieved by our method in this cross-dataset experiment indicates that our 3D CNN-based method has good generalization ability.",
6293.txt,"Some qualitative results for MSRA, NYU and ICVL datasets are shown in Figure 13.",
6294.txt,We compare our 3D deep dense network  with the baseline method of 2D deep dense network as described in Section 5.3.4.,
6295.txt,"As can be seen in Figure 13, when using the same residual network architecture, our 3D CNN-based method can better utilize the depth information and provide more accurate estimation than the 2D CNN-based method.",
6296.txt,We also conduct qualitative comparison with the Intel RealSense SDK.,
6297.txt,We train the 3D CNN model on the whole MSRA dataset and apply this pre-trained 3D CNN model to perform real-time hand pose estimation with the Intel RealSense SR300 Depth Camera in real scenarios.,
6298.txt,Qualitative results of our 3D CNN-based method and the Intel RealSense SDK are shown in Figure 14.,
6299.txt,"As can be seen, the Intel RealSense SDK does not accommodate complex hand poses as accurately as our method.",
6300.txt,"For example, in the 4th column of Figure 14, when the little finger is occluded by the ring finger, the Intel RealSense SDK makes wrong estimation of ring finger joints' locations; in the 6th column of Figure 14, the Intel RealSense SDK confuses the index finger with the middle finger; in the 2nd, 8th and 9th columns of Figure 14, the Intel RealSense SDK confuses the ring finger with the little finger.",
6301.txt,"By contrast, benefiting from the 3D CNN which can better exploit the 3D information, our method     is able to correctly estimate the hand poses in these cases.",
6302.txt,"More comparisons are presented in our demo video, available online.We present a novel 3D CNN-based hand pose estimation method in this paper.",
6303.txt,"By adopting the projective D-TSDF,  we encode    the hand depth image as a 3D volumetric representation which    is then fed into the 3D CNN.",
6304.txt,We show that the 3D  CNN  mapping the 3D volumes to 3D joint locations in a single pass     is easy to be trained in an end-to-end manner.,
6305.txt,The 3D deep dense network can further improve the learning ability for 3D hand pose estimation.,
6306.txt,"To make the 3D CNN robust to various hand sizes  and global orientations, we perform 3D data augmentation on the training data.",
6307.txt,"To tackle the self-occlusion problem, we leverage the complete hand surface as intermediate supervision for learning 3D hand pose.",
6308.txt,Experimental results indicate that our proposed 3D CNN-based approach achieves state-of-the-art performance for 3D hand pose estimation on three challenging datasets and is able to run in real-time with good generalization ability.,
6309.txt,"Chip designers place on-chip thermal sensors to measure local temperatures, thus preventing thermal runaway situations in many-core processing architectures.",
6310.txt,"However, the quality of the thermal reconstruction is directly dependent on the number of placed sensors, which should be minimized, while guaranteeing full detection of all the worst case temperature gradient.",
6311.txt,"In this paper, we present an entire framework for the thermal management of complex many-core architectures, such that we can precisely recover the thermal distribution from a minimal number of sensors.",
6312.txt,The proposed sensor placement algorithm is guaranteed to reduce the impact of noisy measurements on the reconstructed thermal distribution.,
6313.txt,"We achieve significant improvements compared to the state of the art, in terms of both computational complexity and reconstruction precision.",
6314.txt,We also study the practical limits of the proposed method and show that we do not need realistic workloads to learn the model and efficiently place the sensors.,
6315.txt,"In fact, we show that the reconstruction error is not significantly increased if we randomly generate the power-traces of the components or if we have just a part of the correct workload.Index TermsSensor placement, thermal management, thermal monitoring.",
6316.txt,Technological advancements of the lithographic process steadily increase the amount of components that can be placed on a single die.,
6317.txt,"If we assume that the power consumed by these components does not decreases significantly with the technological progress , we have an increase of the power density, and subsequently, of the produced heat.",
6318.txt,Many-core system-on-chip  have their performance limited by such increased heat density.,
6319.txt,"More precisely, unfavorable thermal patterns increase the overall failure rate of the system , reduce performance , significantly increase leakage power consumption and cooling costs.",
6320.txt,"In the past, passive thermal management schemes were used to limit the problems induced by thermal phenomena.",
6321.txt,"For example, designers would organize the floorplan by placing the highest power density components closer to the heat sink.",
6322.txt,"However, in recent architectures such components are not easily identifiable since they depend on the workload execution patterns and, unfortunately, these patterns are not fully known at design time.",
6323.txt,"Furthermore, these issues are amplified in many-core designs, where thermal hot-spots are generated without a clear spatio-temporal pattern due to the dynamic task set execution nature, based on external service requests, as well as the dynamic assignment to cores by the many-core OS.",
6324.txt,"An example of these architecture and their critical thermal behavior is shown in Fig.1, where you can observe the layout of a 64-cores architecture designed by STM  and an example of its thermal distribution at run-time.",
6325.txt,Note how the cores are not anymore regularly organized and how they tend to spread non-uniformly.,
6326.txt,Such irregularity is forced by the complex constraints imposed during the floorplanning optimization and generates irregular thermal distributions with possibly many unpredictable hot-spots.,
6327.txt,"Thermal sensors have been already included into SoC designs, however their position have only been manually tuned because the knowledge of the temperature in a couple of locations was, until now, sufficient.",
6328.txt,"Nowadays, it has become necessary to precisely measure the temperature distribution of the entire die and optimize the workload of the different components to maximize the performance while avoiding hotspots or large gradients of temperature.",
6329.txt,"At the same time, each temperature sensor has a significant impact in terms of occupied area and consumed power, therefore we would like to place as few sensors as possible.",
6330.txt,It is not yet clear how to optimize their placement to maximize the collected information about the thermal distribution.,
6331.txt,"In fact, such aspects are quite complex and recently received significantattention.",
6332.txt,"In this paper, we consider the following two subproblems as core to design an efficient thermal monitoring system:Thermal distribution reconstruction.",
6333.txt,"Given a fixed amount of sensors, where do we place them so that we maximize the precision of the reconstructed thermal distributions?",
6334.txt,"Then, we propose to base the solutions of the aforementioned two sub-problems on the use of a linear low-dimensional subspace to represent the thermal distributions.",
6335.txt,"Such models are interesting because they are sufficiently precise while being extremely simple, thus requiring limited computational resources.",
6336.txt,"Linear models have been already considered in the past for thermal monitoring applications , but many questions have been raised regarding their practical feasibility.",
6337.txt,"First, such models must be optimized and they require a set of thermal distributions representing the operations of the SoC under all the possible workloads.",
6338.txt,It is clear that such data is hard to gather at the design phase; that is when we would like to optimize the sensors locations.,
6339.txt,"More precisely, we need to know three main inputs to simulate the thermal distributions: the floorplan, the workload of the SoC, and the power traces of the components under such workload.",
6340.txt,"In this paper, we show that it is not necessary to have an exact description of the typical workload at design-time to reconstruct precisely the thermal distribution at run-time.",
6341.txt,"In fact, we show that it is possible to optimize the model and place the sensors using a randomly generated workload without having significant losses in terms of reconstruction error.",
6342.txt,"Second, the performance of linear models depends strongly on the locations of the sensors.",
6343.txt,"In fact, the noise corrupting the collected measurements can be dramatically amplified if the sensors are misplaced.",
6344.txt,"We propose to optimize the sensor placement using FrameSense, a greedy algorithm based on a theoretical framework that we recently proposed.",
6345.txt,"Under some mild assumptions regarding the linear model, we can guarantee that the proposed algorithm is near-optimal in terms of reconstruction error and increases the noise stability of the framework.",
6346.txt,"Moreover, such theoretical framework has already shown appealing performance in other domains, such as adaptive sensor scheduling.",
6347.txt,The proposed framework improves significantly the monitoring performance over the state of the art.,
6348.txt,"For example, consider the 64-cores architecture shown in Fig.",
6349.txt,"1a and typical scenario of one temperature sensor per core corrupted by a noise with variance s2 4, we can improve the reconstruction error from 3 to less than 1.4 .",
6350.txt,"Even if we increase the amount of temperature sensors by 50 percent, that is from 64 to 96, the previous methods can only reach an average reconstruction error of 2.4 , while our method can go down to almost 1.",
6351.txt,The remainder of the paper is organized as follows: in Section 2 we describe previous approaches and state-of-theart methods for the recovery of the thermal distribution of SoC designs.,
6352.txt,We state and provide a solution to the problem of thermal reconstruction and the relative sensor placement in Section 3.1.,
6353.txt,We conclude with a comparative analysis of the performance of the proposed methods in Section 4 by means of extensive numerical simulations.,
6354.txt,"The thermal distribution of a SoC can be estimated using three different strategies: Solution of the direct problem, given the heat sources and the physical model of the temperature diffusion process.Solution of an optimization problem, given the value of the temperature in some locations and some a-priori model for the thermal distributions.Empirical approaches, where the thermal distribution is estimated by means of external devices, such as infrared cameras.The first approach requires the knowledge of the heat sources, that can be ascribed to the knowledge of the detailed power consumption of the different components.",
6355.txt,"Often, performance counters are used to estimate the power traces at run-time.",
6356.txt,"However, the estimation of the thermal distributions from the power traces is a computationally expensive task, requiring the complex thermal models characterizing the thermal dissipation of the SoC.",
6357.txt,"Recently,  proposed to reduce the complexity of these methods by using directly the performance counter to estimate the temperature, without the intermediate step represented by the power traces.",
6358.txt,"On the other hand, the optimization problems are generally ill-posed.",
6359.txt,"In fact, it is impossible to solve the inverse problem from few, spatially localized, noisy measurements without some a-priori constraints on the thermal map, such as limited bandwidth.",
6360.txt,The performance is significantly impacted by the small number of available sensors and the structure we consider for the thermal map.,
6361.txt,Nowroz  proposed a low-pass approximation strategy to reduce the number of sensors that are placed using an energy-based algorithm.,
6362.txt,This sensor allocation algorithm has been improved by Reda using a heuristic iterative approach to approximate an NPhard problem.,
6363.txt,The authors in X proposed a grid-based uniform sensor placement followed by interpolation to approximate the temperature.,
6364.txt,"These works estimated entire thermal maps, but the precision of the estimates is limited by the sub-optimality of the chosen models for the thermal distribution.",
6365.txt,Other works have notable performance but are not focused on the estimation of the entire thermal map.,
6366.txt,"Namely, the approach in X employs the correlation in power distribution to estimate the expected value of temperature at different locations of the chip using a dynamically tuned Kalman filter.",
6367.txt,"The problem of noisy measurements has also been already considered; for example, a method based on the correlation between the different sensor has been presented in X.",
6368.txt,"Recently, different researchers studied the estimation of the entire thermal map based on the temperature correlation between different locations .",
6369.txt,"First , we have proposed in  an approach where we approximate the data with a low dimensional linear model based on such correlations.",
6370.txt,Such method brought an intuitive interpretation of the sensor placement problem together with appealing performance .,
6371.txt,"However , we have show edin  that the sensor placement algorithms can be further improved.",
6372.txt,"Contemporaneously, Zhou et al.",
6373.txt,proposed a reconstruction algorithm and an optimization of the sensor placement based on information theory .,
6374.txt,"Their reconstruction algorithm is substantially equivalent to the one proposed in X, without the low-dimensional approximation.",
6375.txt,"Such difference, as we will see in the numerical experiments, has a significant impact on the stability w.r.t.",
6376.txt,the noise affecting the measurements.,
6377.txt,The methods based on external cameras are generally considered to be the most precise ones.,
6378.txt,"However, the increased precision comes at the cost of practical considerations.",
6379.txt,"In fact, such methods cannot be used for run-time operations and are generally studied for two different purposes: the calibration of the on-chip temperature sensors or the study of the thermal behavior of prototypes at design phase.",
6380.txt,"We underline the existence of hybrid methods, mixing techniques taken by the different methods.",
6381.txt,"For example, the authors of propose to use the information coming from the thermal sensors together with the performance counters to estimate the thermal distribution.",
6382.txt,This approach reduces the computational complexity of the methods solely based on performance counters and mitigates the effects of the noise corrupting the thermal sensors.,
6383.txt,The fusion and the integration of the two data sources to obtain the thermal distributions is usually accomplished by a Kalman filter.,
6384.txt,"Such implementations have shown the ability to track precisely the temperature profile at the cost of the computational complexity, which is significantly higher than standard approaches.",
6385.txt,"In this paper, we propose a framework for the problem of thermal monitoring of a many-core SoC.",
6386.txt,We assume to know the floorplan of the SoC and the time-varying power consumption of the components when handling some expected workload.,
6387.txt,The proposed framework is divided in two parts: design-time and run-time algorithms.,
6388.txt,We give a visual description of the framework in Fig.,
6389.txt,2,
6390.txt,"The thermal simulation part is not covered in this paper, since it is possible to choose different algorithms and methods depending on the SoC architecture.",
6391.txt,"In our case, we use 3D-ICE , a flexible fast compact transient thermal model for the thermal simulations of SoCs.",
6392.txt,This thermal simulator consider both the dynamic and static power consumptions.,
6393.txt,"The static power is modeled in the system as a additive percentage of the dynamic power, that is mostly consumed in those units that are not active.",
6394.txt,"At run-time, the system is extremely simple: we collect the measurements from the sensors and, knowing the linear model and the sensors positions, we estimate the thermal distribution using an optimal least square estimator.",
6395.txt,"Note that we propose the algorithm for the reconstruction but we do not study the details of its implementation, that should be adjusted according to each specific architecture.",
6396.txt,"In what follows, we describe each part of the framework in terms of mathematical abstraction and algorithmic solutions.We start the description of the proposed framework from the run-time phase.",
6397.txt,"More precisely, we mathematically state the concept of temperature sensing and the recovery of the thermal distribution using the sensed data.In what follows, we propose to learn the model C from the principal component analysis  of the temperature distributions.",
6398.txt,"Note that we considered also other models, such as the one based on non-negative matrix factorization, but their performance were not sufficiently interesting to be included in this paper.",
6399.txt,PCA has been already proposed to model thermal distributions and showed promising results .,
6400.txt,"In fact, if the thermal distributions of F are well approximated by a K dimensional subspace, then the PCA generates the optimal model C. In certain scenarios, characterized by a limited amount of available resources, we may prefer other methods.",
6401.txt,"For example, certain architectures cannot afford the memory load to store the matrix C. Prior works proposed to use models based on the discrete cosine transform .",
6402.txt,"Such models have a clear advantage in terms of memory used, since they do not require to store C in the system.",
6403.txt,"Unfortunately, the DCT based models do not outperform the PCA model as we do not design entirely C. Moreover, it is not possible to exploit all the traditional computational advantages of DCT transforms.",
6404.txt,"In fact, while we can compute efficiently the DCT transform, once we select some rows to represent the sensors measurements we destroy the structure of the DCT transform and loose any computational advantage.",
6405.txt,A comparison of the reconstruction performance between PCA and DCT is proposed in Section 4 and it shows that PCA is always the best choice unless there exist stringent limits on the memory available for runtime operations.,
6406.txt,"Therefore, we assume to use the PCA for the linear model training and we show its pseudo-code in Algorithm 2.",
6407.txt,"As explained in Section 3.3, the reconstruction of thermal distributions relates to precisely estimatingbf from possibly noisy measurements fL.",
6408.txt,"In a typical scenario, we are given a number of sensors L and a set P of P possible locations, that is a subset of the area of the SoC.",
6409.txt,"Moreover, assume that either we have or can find an optimized linear model C for the thermal distributions F, as described in Section 3.2.",
6410.txt,Significant research efforts have been directed towards the design of an efficient algorithm with polynomial complexity that can find a sensor placement minimizing the reconstruction error.,
6411.txt,"Note that such problem is common to many disciplines, thermal management of SoCs just being one of them.",
6412.txt,"Such algorithms can be usually divided in three categories: greedy algorithms, heuristics-based algorithms, and convex relaxations.",
6413.txt,The reader can find a detailed review of sensor placement algorithms for generic linear inverse problems in X.,
6414.txt,"For the specific case of thermal management, early efforts focused on the localization of hotspots, which are localized peaks of temperature.",
6415.txt,"However, such techniques are bound to fail as technology progresses, since the number and the unpredictability of hotspots are increasing.",
6416.txt,"Recently, researchers refocused their efforts on studying methods to estimate the entire thermal distribution from the few collected measurements.",
6417.txt,Such methods are similar in terms of scope and approach to the ones designed for generic linear problems.,
6418.txt,"In this work, we propose to use FrameSense, a greedy sensor placement algorithm based on the theoretical results we described in X.",
6419.txt,Such an algorithm has significant advantages over the state of the art: it has theoretical guarantees and among the lowest computational complexities.,
6420.txt,The pseudo code of FrameSense is given in Algorithm 3.,
6421.txt,"Note that, it is the only algorithm in the literature that has guaranteed performances in terms of MSE.",
6422.txt,We test the proposed models with a real high-end manycore architecture designed for signal processing and dataintensive embedded applications that has been already taped out.,
6423.txt,This architecture hosts 64 cores designed for multiple program multiple data parallel computing.,
6424.txt,"The cores are grouped in four clusters with independent power and clock domains and connected with a fully asynchronous network-on-chip, see Fig.",
6425.txt,1a.,
6426.txt,The chip is implemented with STM 28 nm CMOS technology  and has a power density of 55 W=cm2.,
6427.txt,The power traces of the SoC components are generated by running benchmarks on an instruction-level architectural simulator equipped with an accurate and detailed power model.,
6428.txt,Such power traces are generated with a time resolution of 1 ms and are successively used to generate a set of thermal distribution representing the temperature of the SoC at run-time.,
6429.txt,"As a thermal simulator, we chose 3D-ICE,that is based on a transient and compact thermal model, and we tuned it for the STM technology.",
6430.txt,"To insure that the thermal distributions match correctly the layout of the many-core architecture, the floorplan that maps the power consumption of the hardware units  to the surface of the silicon die has been extracted by processing the post synthesis layout.",
6431.txt,"Moreover, to compute precise and realistic temperatures, we initially implemented a model of the chip on a commercial computational fluid dynamics program, named ANSYS CFX.",
6432.txt,The purpose of this setup is to extract the correct values for the boundary conditions of the heat dissipation in a steady state worst case simulation.,
6433.txt,"Once the heat transfer coefficients are obtained, the silicon die is modeled in 3D-ICE to perform the transient thermal simulations.",
6434.txt,Note that the thermal properties of materials as well as geometries of the package are taken from X.,
6435.txt,"In this paper, we did not consider intra and inter-die variations due to process variations .",
6436.txt,"Nonetheless, it is possible to extend our results in this direction given the existence of an accurate model.",
6437.txt,"While we analyzed thermal distributions originated by several workloads, in this paper we discuss the results for three fundamental ones.",
6438.txt,Such workloads are designed to represent exhaustively the thermal scenarios that can be expected by such a 64-cores SoC.,
6439.txt,"We did not consider the standard SPEC benchmarks for two reasons:it is more interesting to use workloads representing different phases, such as parallel or sequential computation, to study the thermal behavior of a manycore architecture.The characteristics of the three datasets are summarized in Table 1 and described more in details in what follows.",
6440.txt,The first benchmark is a parallel 64 ?,
6441.txt,64 matrix-matrix multiplication that distributes the load evenly among the 64 available processing units.,
6442.txt,The multiplication is repeated to generate a load of 75 ms during which a uniform and constant heat flux is produced as in the typical scenario of an extremely parallel application.,
6443.txt,The second benchmark is a two-phases sorting algorithm run on a vector storing 16K float values.,
6444.txt,"In the first phase, individual cores are activated in sequence to sort their corresponding sixteenth part of the input using the insertion sort algorithm.",
6445.txt,"Then, in the second phase, the cores run in parallel to merge the ordered sub-vectors to get the final output, as in the merge sort algorithm.",
6446.txt,The number of active cores in this latter phase is halved at every iteration.,
6447.txt,The whole application is repeated on different input vectors to generate a trace of 150 ms reproducing the scenario of a parallel application with data dependencies.,
6448.txt,"The third dataset is generated by means of Poisson processes  bounded by the idle and maximum power consumptions of cores, memories and other hardware modules in the chip.",
6449.txt,"Such a workload, while being synthetic and randomly generated, has a sign i ficant role since we show the possibility to use it to train the model and optimize the sensor placement successfully for the real data.The obtained thermal distributions are further processed for Matlab.",
6450.txt,"Given the symmetry of the architecture, all the numerical simulations consider each cluster of 16 cores independently.",
6451.txt,Note that such strategy does not imply any loss of detail or precision.,
6452.txt,"In this section, we compare the performance of the linear model based on PCA proposed in Section 3.2 against the model based on the DCT transform on the three dataset representing the different workloads described in Section 4.1.",
6453.txt,"For the DCT model, we considered an optimized version of the model proposed in X, where the components of the model are chosen by assuming a generic low-pass profile without studying the distribution of the specific architecture.",
6454.txt,"More precisely, we select the components of the DCT transform showing the average largest coefficients over the thermal distributions belonging to the chosen training set.",
6455.txt,"For each dataset, we measure the approximation error .The results are given in Fig.",
6456.txt,3,
6457.txt,We note two main facts:The performance achieved by the PCA is significantly better  than the one of the DCT model.,
6458.txt,"This is expected since the PCA generates an optimized model, while the DCT-based model simply selects K columns out of a given set.The performance gap between PCA and DCT increases with K, meaning that PCA better exploits the increase of degrees of freedom.With this numerical experiment, we tested the capability of the proposed techniques to capture a precise lowdimensional linear model C from a training set F. N o t e that the approximation error is just one of the aspects that defines the performance of a thermal monitoring system, but it is often the critical one to have a precise thermal reconstruction.The results are given in Fig.",
6459.txt,"4, where we note that for each dataset, a subset of 1 percent of randomly selected thermal distributions is enough to have rd close to one.",
6460.txt,"Therefore, having a non-exhaustive dataset is in general not critical to successfully learn the PCA model.",
6461.txt,"In the next section, we further strengthen our result by showing that random power traces on a realistic floorplan are sufficient to learn a reliable model C.
While designing an SoC and its thermal monitoring system, we may not yet know the workload.",
6462.txt,It would be then impossible to optimize the model and the sensor placement.,
6463.txt,"Here, we show that actually we do not need the powertraces.",
6464.txt,"In particular, we can use the randomly generated ones while maintaining reasonably good performance.",
6465.txt,"In an ideal scenario, we know exactly the thermal distributions set F generated by the expected workload.",
6466.txt,"Assume that bdMc thermal distributions of F are not known, where d is defined as in Section 4.3.",
6467.txt,"We replace the missing thermal distributions with the ones obtained using random power traces, such as the ones generated for the first dataset.",
6468.txt,We would like to measure the loss of precision of the learned model due to the increasing use of random data.,
6469.txt,"Again, we use the cost function defined in  and the results are given in Fig.",
6470.txt,5,
6471.txt,"While a certain loss of precision can be observed, it is extremely limited.",
6472.txt,"Moreover, if we consider to train the model exclusively with the thermal distributions generated by random power-traces, that is d !",
6473.txt,"0, then the reconstruction error is of the same order of magnitude.",
6474.txt,"Our result indicates the possibility to learn the model and place the sensors without knowing the expected workload, it suffices to use a random one.",
6475.txt,The approximation error defines the quality of the model but it is not the only merit figure.,
6476.txt,"Once we place the sensors, the reconstruction error ?",
6477.txt,may significantly vary due to the conditioning of the inverse problem .,
6478.txt,"Therefore, we compare the different models described in Section 3.2 according to their reconstruction error for different amounts of sensors.",
6479.txt,"Note that if K decreases, it is easier to estimate the parameters but then the approximation error increases.",
6480.txt,"On the other hand, if K increases it is harder to estimate the parameters a but the model C is more precise.",
6481.txt,The choice of the optimal K is not trivial and we perform a search over the parameter space.,
6482.txt,"More precisely, for each L and each model, we measure the minimum reconstruction error obtained w.r.t.",
6483.txt,the varying model complexity K. The results are given in Fig.,
6484.txt,"6, where we note that the PCA is the best model in terms of reconstruction error.",
6485.txt,"Moreover, the advantage of the PCA w.r.t.",
6486.txt,the DCT in terms of approximation error is maintained in terms of reconstruction error.,
6487.txt,"Therefore, according to our experiments, the PCA is the technique generating the model with the best approximation and reconstruction error.",
6488.txt,"As we have already mentioned, there are many parameters impacting the performance of a thermal monitoring system, such as the number of parameters, the chosen model and the reconstruction technique.",
6489.txt,"Here, we would like to compare the quality of different sensor placement algorithms while maintaining all other parameters fixed.",
6490.txt,"Therefore, we choose as a linear model the one optimized using the PCA.",
6491.txt,"Then, we optimize the sensor placement using a few algorithms from the literature and measure the reconstruction error.",
6492.txt,"For each algorithm, the reconstruction error is computed for different errors of L and K, and for each L we pick the minimum value achieved w.r.t.",
6493.txt,"the number of parameters K.
Note that these algorithms have been designed to optimize the sensor placement for different scenarios and models.",
6494.txt,"However, the proposed experiment is interesting to compare these algorithms when all other parameters are fixed.",
6495.txt,The results for the three considered dataset are shown in Fig.,
6496.txt,"7, where we note that FrameSense is significantly better than the other algorithms for almost every L.
In the previous experiment, we compared the performance of the sensor placement algorithms when using the linear model C. As we previously mentioned, the results are interesting and informative but they cannot be considered as a global measure of the different sensor placement algorithms because most of the algorithms are designed to work jointly with a specific reconstruction model, that may be significantly different from the considered linear one.",
6497.txt,"Therefore, we compare the following three thermal monitoring techniques:our proposed method that is based on a linear model optimized using the PCA and FrameSense as sensor placement algorithm.",
6498.txt,"This is an improved version of the algorithm described in X; in particular,FrameSense has been proved to be theoretically near-optimal,the thermal monitoring approach based on spectral methods described in X, that uses a DCT-based linear model and the energy-center algorithm previously described,the information-theoretic method proposed in X, that uses the correlation matrix Sfand an entropybased algorithm to recover the thermal distributions.",
6499.txt,"Each technique is composed by a sensor placement algorithm, a model for the temperature distributions and a reconstruction algorithm.",
6500.txt,"However, the gap between the two methods increases with K in favor of FrameSense.",
6501.txt,"Therefore, FrameSense with the PCA linear model achieves the optimal performance.",
6502.txt,"Note that the spectral method is significantly worse than the other two methods, but this is not surprising given the use of a DCT basis,that cannot be deeply optimized.",
6503.txt,Note how the proposed method outperforms the others in terms of precision.,
6504.txt,Another interesting aspect is the role of the lowdimensional model C as a regularization mitigating the measurement noise.,
6505.txt,"In fact, when using the PCA model and FrameSense and if the number of sensors is sufficiently high, the reconstructed thermal distributions have a lower error level w.r.t.",
6506.txt,"the noise in the measurements collected by the sensors.As a conclusive part of the numerical experiments, we would like to analyze the computational complexity and the memory cost of the different reconstruction methods.",
6507.txt,Note that we do not analyze such costs for the sensor placement algorithms because it is an off-line procedure and its costs are generally not critical.,
6508.txt,The analysis is summarized in Table 2.,
6509.txt,"First, we note that the only significant difference regards the memory cost of the methods.",
6510.txt,"In particular, the Spectral method does not need to store an entire matrix CLbecause the coefficients are usually stored in the system.",
6511.txt,"However, if we choose to not to store the matrix but just the indexes of the sensor positions and of the chosen components, we need to compute the matrix multiplication  and the pseudo-inverse of CLat run-time, resulting in a significantlyhighercomputationalcost.",
6512.txt,"Therefore, the benefits of the DCT models are extremely limited and we indicate the PCA model to be the optimal one for the thermal monitoring applications.",
6513.txt,"These considerations are confirmed when we look at the feasibility of a run-time implementation of the proposed algorithms in the considered architecture.Then, the execution of Algorithm 1 in the P2012 many-core platform only implies less than a 5 percent overhead in the total execution time  just using one core in P2012, thus a really negligible amount in the case of the global execution in the P2012 platform containing four 16processor clusters .",
6514.txt,"As a conclusive remark, we underline that part of the computational complexity of the thermal reconstruction can be mitigated if we merge such operation within the workload optimization.",
6515.txt,We describe the details of such an idea in Appendix B.,
6516.txt,"In this work, we proposed a framework to optimally reconstruct thermal maps of many-core SoC using a small number of sensors.",
6517.txt,"We defined an optimal approximation of thermal maps to reduce the number of parameters to estimate, without loosing precision.",
6518.txt,We reconstructed the thermal maps using a least square approach and we exposed the critical role of the sensor location for the quality of the thermal monitoring.,
6519.txt,"We concluded proposing a greedy sensor allocation algorithm that minimizes the reconstruction error by minimizing a proxy function, namely the frame potential.",
6520.txt,The sensor placement algorithm improves the coherence-based one we previously proposed and is inspired by the recent theoretical findings described in X.,
6521.txt,"We compared the proposed method against two algorithms among the state of the art, namely the informationtheoretic method  and the spectral method .",
6522.txt,We demonstrated the higher fidelity of our reconstruction using a smaller number of sensors.,
6523.txt,We showed how the proposed reconstruction algorithm is more stable w.r.t.,
6524.txt,"the noise introduced by the electronics or by sensor calibration inaccuracies, thanks to the regularization imposed by the linear model C. Moreover, we investigated the challenges surrounding the learning and the optimization of the linear model C, one of the main critical points of the framework.",
6525.txt,We showed that a training set formed by an incomplete collection of thermal distributions is enough to learn a precise model C. We remarked that even a training set generated by random power traces leads to a reasonably good model.,
6526.txt,"Note that such discovery has a great potential, since it allows the design of thermal monitoring systems without knowing precisely the workload of the SoC.",
6527.txt,Fuzzy logic Taguchi method is used to optimize parameters for wire bonding process.,
6528.txt,"The proposed FLTM integrates orthogonal arrays, signal-to-noise ratios, response tables, analysis of variance , fuzzy logic, and multiple performance characteristics index.",
6529.txt,"The main process parameters for wire bonding are ultrasonication time, ultrasonication power, bond force, bond force time, and search force.",
6530.txt,The output responses include ball shear and ball size.,
6531.txt,"The orthogonal arrays, signal-to-noise ratios, and response tables reduce the number of experiments needed to find the best factor-level combinations.",
6532.txt,The significant control factors are determined by ANOVA.,
6533.txt,"In engineering practice, ball size increases as ball shear increases, but an excessively large ball size causes a short circuit, whereas an excessively small ball size cannot provide enough ball shear.",
6534.txt,"Due to the two contradictory output responses, the FLTM is used to find the best process parameters.",
6535.txt,"The experimental results show that the process parameters obtained by the FLTM result in a smaller ball size and a larger ball shear compared with those obtained by statistical methods, artificial intelligence techniques, and previous designs.Wire bonding, Taguchi method, fuzzy logic, multiple performance characteristics index.Wire bonding process is the key process in an integrated circuit chip-package.",
6536.txt,"The trend in wire bonding process is increasing precision and increasing finenessofpitch.Forhigh level performance, designing the best process parameters is essential.",
6537.txt,Sheaffer  and Groover used the response surface method to optimize process parameters.,
6538.txt,Hu used the Taguchi method to study gold wire weakening in thermo-sonic bonding.,
6539.txt,Other studies have used fuzzy-rule-based methods to set wire bonding parameters .,
6540.txt,"Recently, computational intelligence techniques have been developed and successfully applied in the semiconductor manufacturing process.",
6541.txt,Taguchi method has been combined with artificial neural network to optimize parameter settings for gold wire ball formation.,
6542.txt,Su and Chiang used neural networks and genetic algorithms to optimize operating parameters for wire bonding.,
6543.txt,"Hou  integrated Taguchi method, neural networks, and GAs to optimize process parameters for wire bonding.",
6544.txt,Hou integrated neural networks and artificial immune algorithms to optimize parameters for a wire bonding process.,
6545.txt,Chang and Hung used a neural network-based prediction model to optimize embedded processes of a gold wire bonding structure for a stacked die package.,
6546.txt,The developed technology enabled the use of the same die sizes used for wire bonding interconnections with no additional processing.,
6547.txt,Jiang used the design of experiment for copper wire-bonding in integrated circuit packaging manufacturing.,
6548.txt,The experimental study showed that the flow rate of forming gas was a key factor in forming qualified free air balls and for establishing a workable process window.,
6549.txt,Su and Yeh used Taguchi method to optimize a Cu wire bonding process.,
6550.txt,"The methods increased production yield from 98.5% to 99.3%, which resulted in a savings of approximately USD 0.7 million.",
6551.txt,"To optimize parameters for a wire bonding process, Sibalija  and Sibalija and Majstorovic  developed integrated models for experimental design processes with multiple correlated responses.",
6552.txt,"Their models included three stages: expert system, Taguchi method, and neural networks/GAs.",
6553.txt,Sibalija and Majstorovic presented a generic optimization methodology for selecting process parameters in multiresponse processes.,
6554.txt,"In the first stage, a quality loss function and multivariate statistical methods were used to synthesize responses into a single process performance measure.",
6555.txt,"In the second stage, neural networks were used to build a process model, and a simulated annealing algorithm was used to optimize wire bonding process parameters.",
6556.txt,"In another study by Tsai, an adaptive diagnostic system for quality control of a Cu wire bonding process combined Grey relational analysis and a neurofuzzy technique.",
6557.txt,"Han reported that the main factors in wire bonding are, in order of influence, ultrasonication power, bonding force, and bonding time.",
6558.txt,The authors obtained bonded Au wires with sufficient stability for use in microwave modules.,
6559.txt,Tsai proposed a hybrid intelligent approach to deriving robust parameter settings for a fine-pitch Cu wire bonding process with multiple quality characteristics.,
6560.txt,"In practice, consumers and designers usually consider multiple performance characteristics  of a product/decision.",
6561.txt,"Although the mentioned-above approaches appear promising, it is difficult to apply these presented approaches to deal with the MPCs problems of wire bonding process.",
6562.txt,"So, further studies are needed to determine which method is the most suitable when limited data are available and when output responses have multiple contradictory objectives.",
6563.txt,The design of experiment approaches are usually used to systematically select and analyze parameters in the studied problems.,
6564.txt,"Among the design of experiment approaches, the Taguchi method, a popular approach used in the industry, is a statistical experimental method of implementing and evaluating improvements in processes and products.",
6565.txt,The main principle is to enhance quality by minimizing the effects of the causes of variations rather than by eliminating the causes themselves.TheTaguchi method minimizes the number of experiments needed to study a large number of design variables.The better factor-level combinations are determined by orthogonal arrays and signal-to-noise ratios.,
6566.txt,The Taguchi experimental design process uses analysis of variance to determine the smallest number of experiments needed to identify the most important control factors.,
6567.txt,The Taguchi method has been widely used in many applications due to its efficiency and effectiveness .,
6568.txt,Fuzzy logic is a mathematical theory of inexact reasoning used to model the human reasoning process in linguistic terms.,
6569.txt,Fuzzy logic is highly suitable for defining relationships between system inputs and desired outputs.,
6570.txt,Fuzzy controllers and fuzzy reasoning are particularly useful for complex industrial systems that cannot be modeled precisely even when the assumptions and approximations are clearly identified.,
6571.txt,"For the MPCs problems, a weighting approach is typically used for each response.",
6572.txt,"In practice, however, weighting each response is extremely difficult.",
6573.txt,Weighting is a particularly interesting research problem when the number of MPCs is large.,
6574.txt,Most previous applications of Taguchi method have only focused on a single quality characteristic and have paid relatively little attention to MPCs.,
6575.txt,Fuzzy logic analysis simplifies the solution procedure for MPC problems.,
6576.txt,"By setting up a reasoning procedure for each performance characteristic, the MPCs can be transformed into a single value in a multi-performance characteristic index .",
6577.txt,"Specifically, the semiconductor industry requires a systematic reasoning approach to using Taguchi method and fuzzy logic for simultaneous optimization of MPCs to improve efficiency in solving problems involving multiple contradictory objectives.",
6578.txt,Such an approach would be particularly useful for solving problems involving output responses that have multiple contradictory objectives.,
6579.txt,"This study integrates OA, SNR, response table, ANOVA, fuzzy logic, and MPCI for parameter optimization of a wire bonding process.",
6580.txt,Fuzzy decision-making logic enables the use of fuzzy reasoning for setting MPCs and for integrating MPCs into a single performance index.,
6581.txt,The resulting fuzzy logic Taguchi method  proposed in this study can then be used to optimize MPCs and wire bonding process parameters.,
6582.txt,This paper is organized as follows.,
6583.txt,Section 2 defines the research problem.,
6584.txt,The optimization methodology is briefly described in Section 3.,
6585.txt,The proposed approaches are introduced in Section 4.,
6586.txt,Section 5 presents optimal results and experimental validations.,
6587.txt,"Finally, Section 6 concludes the study.",
6588.txt,Figure 1 shows how the wire bonding process is used to connect a fine gold wire from the integrated circuit bond pad to the inner lead of the substrate.,
6589.txt,"The first step of the process is positioning the capillary above a bond pad of the die with a ball, which is formed on the end of the wire.",
6590.txt,"When the capillarydescends,thecontactbetweentheballanddieforms the first bond, which is called the ball bond.",
6591.txt,A thermo-sonic bonding system combines ultrasonic power and vibration force.,
6592.txt,Heat is also applied to the pad to increase bonding efficiency.,
6593.txt,"After the ball is bonded to the die, the capillary raises to the loop height.",
6594.txt,The capillary then feeds the wire to the inner lead of the substrate.Thecapillarythenrises away from the lead.,
6595.txt,"At a preset height, a new ball is formed on the tail of the gold wire, which extends from the capillary end.",
6596.txt,A hydrogen flame or an electric spark may be used to form the ball.,
6597.txt,"The cycle is then complete, and the next ball bond can be X.According to the manufacturing experience of a Taiwan semiconductor company, the five main process parameters for the first and second bonds, ultrasonication time, US power, bond force , BF time, and search force , are the key factors in Au wire bonding.",
6598.txt,"The five process parameters cannot be ignored, and are needed to determine the most suitable values when limited data are available and when output responses have multiple contradictory objectives.",
6599.txt,"Notably, Pequegnat  reported that electrical flame off  parameters substantially affect the micro-hardness of free air balls composed of Au or Cu.",
6600.txt,"Han indicated that the factors that affect wire bonding are, in order of influence, US power, bonding force and bonding time.",
6601.txt,The authors obtained bonded Au wires with sufficient stability for use in microwave modules.,
6602.txt,"Therefore, the main process parameters for the first and second bonds are US time, US power, BF, BF time, and SF.",
6603.txt,"The SF is the downward force of the capillary when it contacts the pad.According to the practical experience of a Taiwan semiconductor company, ball size and ball shear are the two main quality measures for the case studied in this paper.",
6604.txt,"In engineering practice, a larger ball bond results in a larger ball shear in a wire bonding process.",
6605.txt,"However, a large ball bond causes short circuits,and a small ball size cannot provide sufficient ball shear.",
6606.txt,"Therefore, the two output responses  are contradictory, i.e., ball shear increases as ball size decreases.",
6607.txt,"Any new product development or modification requires a trial run, which is often costly in terms of time and cost.",
6608.txt,"In this case, the costs include the gold wire and labor.",
6609.txt,"Most manufacturing processes use much more complex, multi-steporprofiledbondingprocessesthathavemanymore parameters.",
6610.txt,"Although this study focused on a simple Au wire bonding process, good control of two confounding variables and two opposite goals was required to achieve high performance and quality.",
6611.txt,"Therefore, a systematic method is needed to optimize wire bonding process parameters.This section briefly describes the methods applied in this study, Taguchi method and fuzzy logic.Taguchi method is a powerful tool for solving problems in robust design.",
6612.txt,Robust-parameter design is an engineering method used to optimize process and product parameters that have low sensitivity to variations and to minimize the development and manufacturing costs of designing high-quality products.,
6613.txt,Two major tools used in the Taguchi method are the OA and the SNR.,
6614.txt,Many design experiments use OA matrices for selecting the best combinations of factor levels in each experimental run and for analyzing data.,
6615.txt,"In an OA matrix, numbers are arranged in rows and columns where each column represents a specific factor and each row expresses the factor-level in each run.",
6616.txt,The matrix is called an OA because all columns can independently assess one another.,
6617.txt,The OA is described in detail in studies such as X.,
6618.txt,"In communication engineering, SNR is used as a performance indicator.",
6619.txt,"This concept was first applied in experimental design by Dr. Genichi Taguchi, an electronic and communication engineer.",
6620.txt,The SNR concept is a useful indicator and measurement of the quality and improvements achieved by reducing variability.,
6621.txt,"In the case of repetitive data, the control factors used to improve quality and to reduce variation can be identified by changes in the average response and by changes in the amount of variation.",
6622.txt,"The SNR, which converts some replications into a single value, affects the amount of variation present and the average response.",
6623.txt,"Based on their characteristics in discrete and continuous cases, SNRs can be classified into three types: nominal-is-best, larger-the-better, and smallerthe-better.",
6624.txt,Only continuous cases are discussed here.,
6625.txt,"Additional details are presented in X .Taguchi recommended multiplying the common logarithm of this SNR by 10, which obtains the SNR in decibels.",
6626.txt,This logarithm has been applied in communications for many years.,
6627.txt,"For engineering applications, a large SNR is preferable, and the following equation is used for a smaller-the-better characteristic.A fuzzy logic system comprises a fuzzifier, membership functions, a fuzzy rule base, an inference engine, and a defuzzifier.",
6628.txt,"First, the fuzzifier uses membership functions to fuzzify the given input parameters.",
6629.txt,The inference engine then generates fuzzy values by applying fuzzy rules based on fuzzy reasoning.,
6630.txt,"Finally, the defuzzifier converts the fuzzy values into crisp output values.",
6631.txt,"For example, fuzzy reasoning can be described as two-input, one-output fuzzy logic.",
6632.txt,"The fuzzy rule base consists of a group of ifthen control rules withtwoinputs,x1andx2, and one output,y.Based on these rules, the max-min compositional operation  yields a fuzzy output.",
6633.txt,"Finally, this study used the center of gravity defuzzification method to transform the fuzzy inference output into a non-fuzzy value, i.e., MPCI in this study.",
6634.txt,"This study considered five factors in wire bonding experiments: US time, US power, BF, BF time, and SF.",
6635.txt,Each factor was divided into three levels to account for non-linear effects based on the original process parameters as references.,
6636.txt,Each original parameter value was set to level 2 of three levels.,
6637.txt,Levels 1 and 3 were then set according to expert knowledge.,
6638.txt,The experiments in this study required five three-level columns to assign the five factors.,
6639.txt,"For this purpose, L27 was selected because it has thirteen three-level columns.",
6640.txt,"The output responses are ball size and ball shear, which are contradictory objectives.",
6641.txt,"To maximize ball shear and minimize ball size, the  of the smaller-the-better feature in Eq.",
6642.txt,is used for ball size since a smaller ball size has a lower cost and is unlikely to cause a short circuit.,
6643.txt,The  of the largerthe-better feature in Eq is used for the ball shear since the larger ball shear provides a larger shear force.,
6644.txt,The response tables of two different outputs are built to find the best factor-level combinations for their objectives.,
6645.txt,"When building the response table, the effects of different factors are set as follows: Efl= average of sum of ifor factor f at level l, where f is the factor name, l is the level number, and i is the experiment number.",
6646.txt,"After the 27 experiments of L27 are performed, the response table of the Taguchi method is used to investigate the  of each factor level.",
6647.txt,The best factor-level combinations obtain a smaller ball size and a larger ball shear.,
6648.txt,The response table shows the average  of each factor level and maximum average  of each factor.,
6649.txt,The main objective is to use the response table to findthebest level for each factor.,
6650.txt,The best factor level has the highest Efl value in the experimental region.,
6651.txt,"That is, the 27 experiments revealed the factor-level combinations that obtained the best results, even though not all factor-level combinations were considered.",
6652.txt,"Additionally, ANOV A analyses of two different outputs are performed to find the factors that significantly affect the smaller the ball size, the larger the ball shear'' characteristic in the wire bonding process.",
6653.txt,The two inputs to the fuzzy logic analysis are the SNRs of ball size and ball shear.,
6654.txt,"Each input assigns three fuzzy subsets, which were extracted from trends in experimental data by experts in the field.",
6655.txt,"The trapezoidal, Gaussian, and triangular types were used as fuzzy logic membership functions  for the study.",
6656.txt,"For example, the trapezoidal MF is a curve that defines how each point in the input space is mapped to a membership value between 0 and 1.",
6657.txt,Figs.,
6658.txt,"2-3 show trapezoidal membership functions for ball size and ball shear, respectively.",
6659.txt,"Five fuzzy subsets, which also adopt the trapezoidal membership functions, are assigned to the MPCI output.",
6660.txt,Figure 4 shows the trapezoidal membership functions for the MPCI output.,
6661.txt,The two inputs and one output are used to calculate various membership degrees of the fuzzy sets.,
6662.txt,"Table 1 shows the nine fuzzy rules that are directly derived according to the larger the SNR, the better the performance'' characteristic.",
6663.txt,"The Mamdani method  was used to transform the fuzzy inference output into a non-fuzzy value, i.e., the MPCI value.",
6664.txt,A higher MPCI value indicates a better performance characteristic.,
6665.txt,Mamdani method transforms the fuzzy output into a crisp value by setting MFs for input and output variables and by using the max-min inference method.,
6666.txt,The Mamdani method is also used to fuse the expert experiences of a Taiwan semiconductor company into the inference mechanism in the consequent part as shown in Figs.,
6667.txt,2-4 and Table 1.,
6668.txt,The practical industrial application of the FLTM was demonstrated in the engineering design problem of parameter optimization for a wire bonding process.,
6669.txt,"First, Taguchi method was used to perform experiments and to accumulate data indicating the effects of the ball size and the ball shear.",
6670.txt,"The effects of ball size and ball shear on wire bonding performance were governed by five factors: US time , US power, BF , BF time , and SF .",
6671.txt,"The original process parameters were US time  of 8, US power of 160, BF of 15, BF time  of 10, and SF of 13.",
6672.txt,"To account for nonlinear effects and to minimize the required number of experiments, a three-level L27 OA was used.",
6673.txt,Each parameter value was originally set to the middle level of three levels.,
6674.txt,"That is, the original process parameter combination was A2B2C2D2E2.",
6675.txt,Table 2 shows how each parameter was separated into three levels to reflect nonlinear effects.,
6676.txt,"The three levels of US time  were 5, 8, and 10, and those of US power were 7, 10, and 12.",
6677.txt,"The three levels of SF were10,13,and15.Instead of 243experiments, the L27 OA required only 27 experiments.The two experimental outputs in this study, ball size and ball shear, were converted by using SNR, which has the higher-the-better characteristic.",
6678.txt,"Table 3 shows the L27experimental results for the five experimental parameters, which included two experimental outputs, ball size and ball shear, and their corresponding s.",
6679.txt,"Table 4 shows the response table for each factor for ball size, and Fig.",
6680.txt,"5 plots the effects of the factors on ball size, which were obtained by computing the 1 for each factor level in Table 3.Table 4 shows that factor levels 3, 1, 1, 2, and 3 were selected for factors A, B, C, D, and E, respectively.",
6681.txt,Factors that significantly affected wire bonding performance were then identified by ANOVA.,
6682.txt,Table 5 shows the ANOVA results for ball size.,
6683.txt,"For a confidence level of at least 90%, the most important factors were factors B and C. Factors B and C had F-ratios of 33.561 and 22.216, respectively, which were very large, and both factors had confidence levels of 100%.",
6684.txt,"That is, factors B and C significantly affected ball size.",
6685.txt,"Therefore, B1 and C1 significantly affected ball size in the wire bonding process.",
6686.txt,"Table 6 shows the response table for the effects of each factor on ball shear, and Fig.",
6687.txt,6 plots the effects of each factor on ball shear according to the 2computed for each factor level in Table 3.,
6688.txt,"Table 6 shows that factor levels 1, 3, 3, 3, and 3 were selected for factors A, B, C, D, and E, respectively.",
6689.txt,"Thus, the best factor-level combination for ball shear was.",
6690.txt,Table 7 shows the ANOV A results for ball shear.,
6691.txt,"For a confidence level of at least 90%, the most important factors were factors A, B, C, and D, which had F-ratios of 3.638, 87.659, 9.533, and 6.643, respectively, which were very large.",
6692.txt,"The confidence levels for Factors A, B, C, and D were 95.02%, 100%, 99.81%, and 99.21%, respectively.",
6693.txt,"That is, factors A, B, C, and D significantly affected ball shear.",
6694.txt,"Therefore, factors A1, B3, C3, and D3 significantly affected ball shear in the wire bonding process.",
6695.txt,The above ANOVA analysis results show that factors B and C had the largest effects on ball size and ball shear.,
6696.txt,"AsseeninTables4and6,Figs.5and6,itcouldbeconcluded that the optimal values of A, B, C, D for ball size differ from those for ball shear; hence the FTLM is developed to find the best combination of parameter levels for optimizing two objective simultaneously.",
6697.txt,"Therefore, two sets of SNRs, one for ball size and one for ball shear, were used to optimize process parameters in fuzzy logic analysis.",
6698.txt,"Table 8 shows the MPCIs obtained for L27based on the s obtained for ball size and for ball shear by performing Mamdani method with trapezoidal, Gaussian, and triangular MFs.",
6699.txt,"Tables 9-11 show the response table for the effect of each factor on MPCI obtained by using trapezoidal, Gaussian, and triangular MFs, respectively.",
6700.txt,Figs.,
6701.txt,"7 plot the effects of each factor on the MPCI when using trapezoidal, Gaussian, and triangular MFs, respectively.",
6702.txt,The effects were determined by computing the MPCI of each factor level in Table 8.,
6703.txt,Tables 9-11 and Fig.,
6704.txt,"7 show that trapezoidal, Gaussian, and triangular MFs obtain the same three factor levels.",
6705.txt,"Tables 9-11 show that factors levels 1, 2, 1, 3, and 3 are selected for factors A, B, C, D, and E, respectively.",
6706.txt,"For example, Table 12 shows the ANOV A results for MPCI when using a trapezoidal MF.",
6707.txt,"For a confidence level of at least 90%, factors B, C, and D are the most important factors.",
6708.txt,"TheirF-ratio values are 4.619, 2.916, and 3.282, respectively, which are very high.",
6709.txt,"The confidence levels of factors B, C, and D are 97.60%, 92.00%, and 93.91%, respectively.",
6710.txt,"That is, factors B, C, and D significantly affect MPCI.",
6711.txt,"Therefore, the statistically significant factors in the wire bonding process are B2, C1, and D3 on MPCI.",
6712.txt,Table 13 compares the previous design and FLTM in terms of parameters and experimental values obtained for average ball size and average ball shear in 10 independent experiments.,
6713.txt,The previous design data were provided by a Taiwan semiconductor company.,
6714.txt,"The standard deviations that 0.196 and 0.214 for ball size and ball shear, respectively, obtained by the proposed FLTM were also smaller than the standard deviations that 0.246 and 0.245 for ball size and ball shear, respectively, obtained by the previous design.",
6715.txt,The response surface methodology  and the multiple regression method were used to model the relationship between the synthetic performance measure and process parameters.,
6716.txt,"The RSM model contains an intercept, linear terms, interactions, and squared terms, while the MRM model has the same terms as the RSM model except for interactions.",
6717.txt,"Models trained using RSM and MRM have five process parameters and one output corresponding to the single performance measure, which combines the normalized  values for ball size and the normalized  values for ball shear.",
6718.txt,Table 13 shows the best parameters and experimental values obtained by the RSM with GA and by the MRM with GA for average ball size and average ball shear in 10 independent experiments.,
6719.txt,"The standard deviations were 0.296 and 0.287 for ball size and ball shear, respectively, obtained by the RSM with GA, while the standard deviations were 0.288 and 0.285 for ball size and ball shear, respectively, obtained by the MRM with GA.",
6720.txt,The back-propagation neural network  was used to model the relationship between the synthetic performance measure and process parameters.,
6721.txt,"Each of the developed networks has five neurons in the input layer corresponding to five process parameters and one neuron in the output layer corresponding to the single performance measure,which combines the normalized  values for ball size and the normalized  values for ball shear.",
6722.txt,Table 13 shows the best parameter values and experimental values obtained by the BPNN with GA for average ball size and average ball shear in 10 independent experiments.,
6723.txt,"The standard deviations were 0.288 and 0.248 for ball size and ball shear, respectively, obtained by the BPNN with GA. To evaluate the suitability of FLTM for finding process parameters and for solving the two contradictory output responses, performance was compared among FLTM, RSM with GA, MRM with GA, and BPNN with GA.",
6724.txt,The objectives were minimizing ball size and maximizing ball shear.,
6725.txt,"The evolutionary parameters of the GA in the computational experiments were population size of 50, crossover rate of 0.8, and mutation rate of 0.1.",
6726.txt,The GA experiments were performed in 30 independent runs.,
6727.txt,"The neuron activation functions of hidden and output neurons of the BPNN were logistic sigmoid and identity, respectively.",
6728.txt,The number of neurons in the hidden layer was iteratively optimized by developing several neural networks and observing the mean-squared-error index of the output error.,
6729.txt,The network training process continued until training and testing errors no longer decreased or until testing errors increased.,
6730.txt,Table 13 shows that the average ball sizes obtained by FLTM and by BPNN with GA were smaller than those obtained by the previous design and that average ball shear values obtained by FLTM and by BPNN with GA were larger than those obtained by the previous design.,
6731.txt,The results obtained by the FLTM and by the BPNN with GA met the objectives of the smaller-the-better characteristic for ball size and the largerthe-better characteristic for ball shear.,
6732.txt,"However, the average ball sizes obtained by RSM with GA and by MRM with GA were larger than those obtained by the previous design, and the average ball shear values obtained by RSM with GA and by MRM with GA were larger than those obtained by the previous design.",
6733.txt,The results obtained by RSM with GA and by MRM with GA did not achieve the smaller-the-better objective for ball size.,
6734.txt,"Additionally, the average ball size obtained by FLTM is smaller than that obtained by BPNN with GA, and the average ball shear obtained by FLTM is larger than that obtained by BPNN with GA.",
6735.txt,Fig.,
6736.txt,8 compares the bonding results for process parameters obtained by FLTM and by the previous design.,
6737.txt,"The comparison shows that the process parameters obtained by FLTM result in a smaller ball size and a larger ball shear compared to those obtained by RSM with GA, MRM with GA, BPNN with GA, and the previous design.",
6738.txt,"Furthermore, the standard deviations obtained by the proposed FLTM were also smaller than those obtained by RSM with GA, MRM with GA, BPNN with GA, and the previous design.",
6739.txt,The comparisons show that the proposed FLTM is an effective tool for optimizing process parameters for the smaller-the-better characteristic of ball size and for the larger-the-better characteristic of ball shear in a wire bonding process.,
6740.txt,Additional advantages of the FLTM approach in designing optimal process parameters for wire bonding are discussed below.,
6741.txt,"Although Cu wire bonding is gradually replacing Au wire bonding, their yields differ.",
6742.txt,"The objective of this study was to apply fuzzy-logic-based techniques in a wire bonding process, regardless of the material.",
6743.txt,The proposed FLTM method is a systematic reasoning approach to using Taguchi method and fuzzy logic for simultaneous optimization of multiple performance characteristics.,
6744.txt,"This study considered Au wire bonding, which is an actual industrial process currently used by a Taiwan semiconductor company.",
6745.txt,"Notably, the FLTM can be used to solve problems involving multiple contradictory objectives in the semiconductor industry, regardless of whether the materials are Au, Cu, or Sn.",
6746.txt,Practical application of the process parameter settings obtained by the proposed method by a Taiwan semiconductor company has indeed increased production efficiency.,
6747.txt,The Taguchi method is a robust design approach to using statistical experimental design concepts.,
6748.txt,An OA enables analysis of numerous design variables with a small number of experiments.,
6749.txt,"Since an OA is a fractional factorial matrix, it ensures a balanced comparison of levels of any factor or interactions of factors.",
6750.txt,Using an OA to collect the appropriate data for wire bonding can reduce development and manufacturing costs.,
6751.txt,"In this study, SNRs and response tables were used to find the best factor-level combinations, and ANOVA was used to identify the significant control factors.",
6752.txt,"Integration of OA, SNR, response table, and ANOVA intheoptimizationofprocessparametersofanindustrialwire bonding process obtained promising performance improvements.Combining fuzzy logic with MPCI in process parameter optimization enables simultaneous consideration of all quality characteristics of interest to designers and customers.",
6753.txt,The conventional approach to solving optimization problems involving multiple quality characteristics is to weight each output response.,
6754.txt,"However, the current practice in the industry is to perform weighting based on the field experience of the engineer, which introduces many uncertainties.",
6755.txt,The fuzzy logic procedure used in MPCI reduces human uncertainties and does not require complex mathematical computations.,
6756.txt,The system simulations in this study applied fuzzy logic in MPCI.,
6757.txt,"Compared to conventional methods, the output results satisfy more requirements of designers and customers.",
6758.txt,"Although, from a theoretical perspective,the proposed FLTM appears to be a relatively minor innovation, the experiments in this study confirmed that the proposed FLTM substantially improves the smaller-thebetter characteristic of ball size and the larger-the-better characteristic of ball shear in a wire bonding process.",
6759.txt,"That is, the proposed FLTM method has immediate real-world applications and can promote the further transfer of fuzzylogic-based technology from academia to industry.",
6760.txt,Here it should be noticed that a Taiwan semiconductor company has alreadybegunusingthesystematicFLTMapproachproposed in this study to optimize wire bonding process parameters instead of using the conventional non-systematic trial-anderror method.,
6761.txt,"That is, a Taiwan semiconductor company has benefited from use of the developed method.",
6762.txt,"The proposed design method uses a fuzzy-logic-based approach to solving the design problem of parameter optimization for a wire bonding process, so it can consider multiple performance characteristics.",
6763.txt,"The experimental results discussed above indicate that the proposed FLTM approach indeed performs comparably to RSM with GA, MRM with GA, and BPNN with GA.",
6764.txt,"Besides, the proposed FLTM outperforms the nonfuzzy-logic-based techniques currently used in the industry.",
6765.txt,Both RSM and MRM are well-defined and commonly used statistical techniques for process design and optimization in many domains.,
6766.txt,Multiresponse optimization problems can be efficiently solved by combining RSM and MRM with other methods .,
6767.txt,"However, a limitation of RSM and MRM in multiple response problems is that they do not enable simultaneous optimization of multiple responses in highly non-linearprocessesinwhichmultipleoutputsareinfluenced by a large number of variables.",
6768.txt,"In these cases, RSM and MRM models may not find the overall best solution and are easily trapped in local minima .",
6769.txt,The BPNN has attractive theoretical properties and can model nonlinear interactions and has been successfully used to model many industrial process systems in recent years.,
6770.txt,"For modeling, the BPNN has several advantages over conventional methods.",
6771.txt,"However, sufficient data are essential for accurate prediction and optimization results.",
6772.txt,"In other words, the common limitation of the above methods is that characteristic data must be sufficient for analyzing, modeling, and optimizing.",
6773.txt,"Therefore, the main issue is which method is most suitable for solving a specific problem when available data are limited.",
6774.txt,This study demonstrated that the proposed FLTM effectively solves the smaller-the-better characteristic for ball size and the largerthe-better characteristics for ball shear in a wire bonding process.,
6775.txt,"The major contribution of this study is the integration of OA, SNR, response table, ANOV A, fuzzy logic, and MPCI in the proposed FLTM to optimizing wire bonding process parameters.",
6776.txt,The FLTM reduces the time and cost of designing process parameters for wire bonding with no loss of effectiveness.,
6777.txt,An OA is used to collect experimental data for ball size and ball shear in wire bonding.,
6778.txt,"The SNRs, response table, and ANOV A are used to analyze the two contradictory output responses for ball size and ball shear.",
6779.txt,The FLTM solves the two contradictory output responses and explores the better process parameters.,
6780.txt,"Experiments confirmed that the process parameters obtained by the FLTM achieve a smaller ball size and a larger ball shear compared to those obtained by conventional methods, including RSM with GA, MRM with GA, BPNN with GA, and the previous design.",
6781.txt,"In conclusion, wire bonding process parameters optimized by the proposed FLTM obtain superior ball size and ball shear compared to other methods.",
6782.txt,We present a method for quantifying a risk for killer defects at layer level and estimating yield for substrate packages using information from design files.,
6783.txt,"To calculate risk ranks and predicted yield, we define a risk distance that is a key parameter extracted from designs using image processing techniques.",
6784.txt,"In order to validate our model, we analyze two different designs, each having multiple layers, and compare with data from baseline lots.",
6785.txt,It is shown that there is an inverse correlation between risk layer ranks and yield.,
6786.txt,Estimated yield based on our model is compared with baseline yield for four layers of the second design.,
6787.txt,"The model-to-baseline yield difference is less than 1% for three layers we tested.Index TermsYield prediction, yield estimation, metrology sampling, integrated circuit packaging, circuit analysis, assembly.",
6788.txt,Yield has been used as one of the most critical parameters in the manufacturing environment since it directly impacts the manufacturing profit.,
6789.txt,Yield is defined as a ratio of the number of good units that meets all manufacturing requirements to the total number of manufactured units .,
6790.txt,The overall yield can be broken down into several components depending on the purpose of application.,
6791.txt,"The most commonly used components are: line yield, die yield, assembly yield, and final test yield.",
6792.txt,Having accurate yield model is important for the following reasons.,
6793.txt,Give work priority for factory line: Any products performing less than expected yield need to be addressed for yield improvement activities.,
6794.txt,Cost estimate: The model can be used to predict manufacturing costs under development.,
6795.txt,Resource estimate: The model can be used to estimate how much human/tool resources are needed.,
6796.txt,Schedule estimate: The model can be used to estimate the required time to achieve a yield target.,
6797.txt,"Feedback to new design: The model can be used to determine possible design changes to achieve a yield target within a desired timeframe.In order to understand IC yield, a number of yield models have been proposed and the three commonly used yield models are the Poisson model, the Seed's model and the negativebinomial model.",
6798.txt,"The first model used to predict IC yield was derived from the Poisson distribution function, which is given by the following form.A is the CA of defect size x. X is a defect size probability density function.",
6799.txt,The CA can be defined as the open critical area and the short critical area.,
6800.txt,The key to any yield model using the CA is to understand defect density distribution as a function of defect size.,
6801.txt,A commonly accepted PDF is shown in Fig.,
6802.txt,1,
6803.txt,"Historically, as chip sizes continued to increase, the Poisson model tended to underestimate yield for large die size.",
6804.txt,"Because of this reason, a new model was developed by Murphy.",
6805.txt,He assumed that Gaussian distribution would be a reasonable estimate for the defect density PDF.,
6806.txt,Seed took the model by Murphy but used exponential distribution rather than Gaussian to obtain the relationship below.These three equations are a function of the CA which is the key for accurate yield prediction.,
6807.txt,"There are mainly three different methods for critical area analysis: standard methods, statistical methods, and approximation methods.",
6808.txt,The standard method includes the shape expansion method that computes a particle size which causes O/S.,
6809.txt,"To get the average CA, the CA for each defect size needs to be integrated following the equation .",
6810.txt,The statistical method randomly places a pre-defined particle shape with different sizes on the IC layout and checks for O/S using Monte Carlo simulation.,
6811.txt,"In general, previous two methods are CPU intensive, so the approximation method is proposed for improving computation speed.",
6812.txt,"In this paper, we propose layer level risk rank metric and a yield prediction model using extracted design parameters.",
6813.txt,We take a different approach for yield prediction.,
6814.txt,"Instead of calculating the average CA, we defines a distance metric called ""risk distance"".",
6815.txt,One of the challenges for the CA calculation is to know the defect size distribution shown in Fig.,
6816.txt,1,
6817.txt,"Depending on the manufacturing phase, one may not have reliable defect size distribution data because it might depend on tool capabilities to catch up with unexpected new defect modes during technology development phase and defect size extraction algorithms.",
6818.txt,"Thus, instead of using defect size distribution, we use killer defect PDF as a function of risk distance group for yield model, which allows us to comprehend complex design structures and still extract meaningful design metrics that can be correlated to yield loss.",
6819.txt,One of the benefits for layer level risk assessment is that we can focus on risky layers for yield improvement activities.,
6820.txt,"As the number of layers increase, more critical it is to have the layer priority, for example, for metrology sampling to increase a velocity of development and reduce manufacturing costs.",
6821.txt,"Although we focus on only short killer defects in this paper, the same concept should be able to apply for open killer defects as well.",
6822.txt,Our paper is organized as follows.,
6823.txt,"In Section II, a design parameter extraction algorithm is described.",
6824.txt,We define risk metrics and the yield prediction model using the extracted risk distance.,
6825.txt,"In Section III, we present model validation results.",
6826.txt,Yield from Design 1 baseline lots from our factory line is compared with layer risk ranks extracted from the design to validate the layer risk model.,
6827.txt,"Then, estimated yield for Design 2 will be predicted from the model based on Design 1 data and compared with actual Design 2 yield.",
6828.txt,The conclusion is given in Section IV.,
6829.txt,"In order to evaluate risk levels for each net structure and layer, we analyze substrate design files.",
6830.txt,The key parameter is the minimum distance from one net to the closest net from each net boundary point.,
6831.txt,Fig.,
6832.txt,2 illustrates the concept and it is the magnified image of a certain area in Design 1.,
6833.txt,In Fig.,
6834.txt,"2, the top left white region is a net structure 1 and the bottom right white region is a net 2, which is the closest net structure from the net 1.",
6835.txt,Fig.,
6836.txt,2 illustrate the edge boundaries for each net.,
6837.txt,The red circle at the net 1 boundary indicates the edge location of the single boundary point.,
6838.txt,The green line shows the minimum distance to the corresponding net 2 edge boundary point.,
6839.txt,The minimum distance to the closest net point is calculated for all boundary points.,
6840.txt,Fig.,
6841.txt,3 shows the high-level flow of the risk metric calculations which can be divided into three parts.,
6842.txt,"Firstly, we take a design file for a single layer and then do image preprocessing to identify object boundary locations.",
6843.txt,"Secondly, geometrical information is calculated based on the preprocessed image.",
6844.txt,"Lastly, the extracted data such as object numbers, a set of minimum distances, feature names defined in a printed circuit board  file, are combined to calculate the key risk metrics.At first, we prepare a bitmap image from a design Gerber file and import it as an image file into our MATLAB program.Once we obtain the design file, each isolated object is labeled and this label information is also used to correlate with the actual net names defined in the PCB file.",
6845.txt,The Canny edge detector is used to obtain edge boundaries for tracing each edge pixel.,
6846.txt,An example labeled edge image is shown in Fig.,
6847.txt,4,
6848.txt,"In this image, a plane structure is at the top and the other objects are pads/traces, some geometrical features.",
6849.txt,"Each object has its corresponding labeling number.Using labeled information, we start from the net 1's top left edge pixel point as an initial point to determine a set of minimum distances from the net 1 to closest net points.",
6850.txt,"For finding the closest point of the other net from N1p1, we limit a search area with some threshold value to speed up our algorithm.",
6851.txt,"If we cannot find any closest point within the predefined search area, we treat this net as an isolated structure and ignore it.",
6852.txt,"If the closest point can be found, we store the minimum distance, label this point as N2p1 and store this point for defining a next search box.",
6853.txt,"Now, by doing edge boundary tracing of the net 1 clockwise, we determine N1p2 and want to find a next set of distances from N1p2 to another closest point N2p2.",
6854.txt,"We use the previously stored point N2p1 to define a search area, assuming that N2p2 should be closer from N2p1.",
6855.txt,"If N2p2 cannot be found within the initial search area, we increase a search area with some amount to accommodate any object transition, i.e., in the example in Fig.",
6856.txt,"4,when object transition from the plane and the Obj 1 happens, the search area will be increased.",
6857.txt,We calculate the minimum distance and store N2p2 as a next search control point.,
6858.txt,"By repeating these procedures, we will get a set of minimum distances between each net as shown in Fig.",
6859.txt,"5.Since open happens within a single net as opposed to short which happens between nets, the approach for calculating minimum distances is a little bit different from the short distance calculation.",
6860.txt,"At first, similar to the minimum distance calculation for short, we start from the top left edge pixel as an initial starting point and take the predefined search area from the edge boundary image.",
6861.txt,Then we label edge objects within the search area.,
6862.txt,"For example, if we take a single horizontal metal pattern edge boundary, we have two parallel lines.",
6863.txt,Then the top line is labeled as the object 1 and the bottom one as the object 2.,
6864.txt,"Using this labeled information, we calculate the minimum distance from the top edge to the bottom edge.",
6865.txt,"By repeating the same procedure for each edge point, we can obtain a set of minimum distances for open as shown in Fig.",
6866.txt,"6.Once a set of minimum distances are obtained, we sum up these distances based on predefined distance groups.",
6867.txt,"For example, any distance between 0 [um] and 0.9x [um] is summed and stored as a risk 1 distance group, and between x and 1.9x into a risk 2 distance group and so on.",
6868.txt,We define such group as "risk distance group".,
6869.txt,"Finally, we correlate object label information with actual net names using pad and trace connecting point coordinates and corresponding net name information extracted from the PCB file.",
6870.txt,"Using these coordinates, we can select the object label number and correlate with the net name.We define a normalized layer level risk value Rlayer#N as follows.The subscript n represents each risk bin.",
6871.txt,The reason we need the weighting factor is that the risk of short should be higher for net structures having a shorter net-to-net distance rather than ones having a longer net-tonet distance.,
6872.txt,The weighting factors are determined by defect occurrence rate at each risk distance group from any single design.,
6873.txt,"In general, lots from a test vehicle or pilot lots from a revenue product are used to calculate the weighting factors.",
6874.txt,"Then, these pre-assigned weighting factors are used to calculate expected yield for actual revenue product designs, as long as the process technology is identical.",
6875.txt,"If process conditions change, we need to re-calculate these weighting factors to reflect the latest factory capabilities.",
6876.txt,Rlayer#N is normalized by the maximum value among the all layers.Fig.,
6877.txt,7 is the color map example of the short risk distance group.,
6878.txt,In this image the plane structure is excluded for illustration purpose.,
6879.txt,The red shows the highest risk distance and yellow is risk 2 group and so on.,
6880.txt,"Based on the risk distances, we can now calculate Rlayer using Equation.",
6881.txt,Fig.,
6882.txt,"8 shows the layer level risk Rlayer for each layer from Design 1, which has 9 layers.",
6883.txt,This figure illustrates the layer level relative risk rank.,
6884.txt,"In order to validate our layer risk model, Rlayer is compared with the actual yield values which are illustrated in Fig.",
6885.txt,9,
6886.txt,Fig.,
6887.txt,9 shows yield versus Rlayer to validate our model.,
6888.txt,"Due to our current layer sampling plan, yield data for some layers are not available.",
6889.txt,The actual yield values are not shown in this plot.,
6890.txt,"We can observe the trend that as the layer level risk Rlayer decreases, yield increases.",
6891.txt,The result suggests that Rlayer can be used as a risk metric for making priority decision for any yield improvement activities or any metrology sampling.,
6892.txt,"For example, if it is determined that automated optical inspection can support only up to 3 different operations based on the tool availability and the number of lots start per week, it is reasonable to choose the layer L2, L3 and L4 as the initial sampling layers.Our yield model is a function of the killer defect PDF, the killer defect density and the risk distances as described in Equation.",
6893.txt,"In order to calculate expected yield, we need to know the killer defect PDF as a function of the risk distance groups.",
6894.txt,Fig.,
6895.txt,10 shows the actual short killer locations for Design 1.,
6896.txt,Color illustrates the corresponding risk distance groups.,
6897.txt,"For example, the red dots indicate that these defects occurred at the risk 1 distance group areas, the pink dots at the risk 2 distance areas and so on.",
6898.txt,"Once we know defect distribution at each risk distance group, we can calculate the killer defect PDF.",
6899.txt,Fig.,
6900.txt,11 shows the PDF from Design 1 using the 14 baseline lots.,
6901.txt,The actual values are excluded from the plot.,
6902.txt,"Now, we can calculate yield based on our model, given defect density.",
6903.txt,Fig.,
6904.txt,12 shows the yield model based on the short killer PDF given in Fig.,
6905.txt,11,
6906.txt,"Again, the actual values are excluded from the plot.",
6907.txt,"Fig.12  illustrates yield distribution across a large range of defect density, which follows the exponential function.",
6908.txt,Fig.12 shows the magnified region of Fig.,
6909.txt,12  with the some individual lot yield values for model validation purpose.,
6910.txt,The circles and crosses are yield from L8 and L7 respectively.,
6911.txt,"As we can see from the plot, our model matches well with actual lot yield.",
6912.txt,"Finally, using the killer defect PDF from Design 1, estimated yield for Design 2 is calculated.",
6913.txt,"Here the assumption is that when we run Design 2 through our factory line, the short killer defect PDF remains the same between Design 1 and Design 2.",
6914.txt,"Using the risk distance groups calculated from the design files, we can calculate expected yield for each layer of Design 2.",
6915.txt,"Since actual yield cannot be provided, we provide the difference in yield [%] between the estimate based on our model and actual yield calculated from our factory line in TABLE I.",
6916.txt,"For this specific product and layers, our model to actual yield difference is less than 1 %.In this paper, we present a method of quantifying layer level risks using the risk distance metric.",
6917.txt,The key design parameter extraction algorithm is presented.,
6918.txt,The layer level risk rank is compared with baseline yield using Design 1.,
6919.txt,"We observe the trend that as Rlayer decreases, yield increases.",
6920.txt,"Based on this result, Rlayer rank can be considered as one of the key metrics for making any priority decision in the factory line or yield improvement activities.",
6921.txt,"Then, our yield model is validated using killer defect PDF from baseline lots from Design 1.",
6922.txt,We see that our model matches with actual yield for different layers.,
6923.txt,"Finally, estimated yield for Design 2 is compared with actual yield.",
6924.txt,We observe a correlation with our prediction model and actual yield within less than 1% yield difference for given design and process conditions.,
6925.txt,Building computational models to account for the cortical representation of language plays an important role in understanding the human linguistic system.,
6926.txt,"Recent progress in distributed semantic models , especially transformer-based methods, has driven advances in many language understanding tasks, making DSM a promising methodology to probe brain language processing.",
6927.txt,DSMs have been shown to reliably explain cortical responses to word stimuli.,
6928.txt,"However, characterizing the brain activities for sentence processing is much less exhaustively explored with DSMs, especially the deep neural network-based methods.",
6929.txt,What is the relationship between cortical sentence representations against DSMs?,
6930.txt,What linguistic features that a DSM catches better explain its correlation with the brain activities aroused by sentence stimuli?,
6931.txt,Could distributed sentence representations help to reveal the semantic selectivity of different brain areas?,
6932.txt,"We address these questions through the lens of neural encoding and decoding, fueled by the latest developments in natural language representation learning.",
6933.txt,We begin by evaluating the ability of a wide range of 12 DSMs to predict and decipher the functional magnetic resonance imaging  images from humans reading sentences.,
6934.txt,Most models deliver high accuracy in the left middle temporal gyrus and left occipital complex.,
6935.txt,"Notably, encoders trained with transformer-based DSMs consistently outperform other unsupervised structured models and all the unstructured baselines.",
6936.txt,"With probing and ablation tasks, we further find that differences in the performance of the DSMs in modeling brain activities can be at least partially explained by the granularity of their semantic representations.",
6937.txt,We also illustrate the DSM's selectivity for concept categories and show that the topics are represented by spatially overlapping and distributed cortical patterns.,
6938.txt,"Our results corroborate and extend previous findings in understanding the relation between DSMs and neural activation patterns and contribute to building solid brainmachine interfaces with deep neural network representations.Brainmachine interfaces, distributed semantic representations, neural decoding, neural encoding.",
6939.txt,Understanding the mental representations of linguistic items that enable humans to communicate has always been one of the central goals in cognitive neuroscience.,
6940.txt,"In recent years, functional neuroimaging approaches have provided remarkable insights concerning the neural representations of individual word concepts and interconcept relations .",
6941.txt,"However, characterizing the representations of more complex units, such as sentences, remains a considerable challenge.",
6942.txt,How the neural circuits respond to sentence-level linguistic stimuli and whether brain activity can be directly decoded to infer what a subject is attending to are not fully resolved.,
6943.txt,"These questions have, respectively, been studied as brain encoding and decoding.Brain encoders predict the neural responses to the linguistic stimuli of interest, which sheds light on how the brain organizes and processes language through neural circuits.",
6944.txt,"Brain decoders categorize and reconstruct the human perception by mining the neural activation patterns, potentially forming the basis of the noninvasive brainmachine interfaces.",
6945.txt,"Though distinct in motivation, the encoding and decoding models share a core purpose: the associative mapping between linguistic stimuli and the evoked brain responses.",
6946.txt,"To computationally fit the mapping, the representations of functional magnetic resonance imaging  signals and the linguistic stimuli are necessary.",
6947.txt,"To construct semantic representations of sentence stimuli, it is natural to draw upon related work in natural language processing.",
6948.txt,Distributed semantic models are currently the dominant text representation methods in the NLP community.,
6949.txt,"Based on the idea that words similar in meaning occur in similar contexts, the original DSMs calculate semantic vectors of words by exploring the linguistic co-occurrence pattern of a given corpus.",
6950.txt,"Then, in the constructed representation space, the similarity between two semantic vectors reflects the similarity of those words.",
6951.txt,"The resulting vectors reliably predict human judgments in multiple tasks, from meaning similarity judgments to concept categorization .",
6952.txt,Neuroimaging studies have also demonstrated that the extracted word vectors can be used to model semantic representations in the brain.,
6953.txt,"More recently, the family of DSMs has been extended beyond single words to express the meanings of sentences and discourses.",
6954.txt,"Benefiting from the upsurge of deep neural networks, its methodology also evolved from solely co-occurrence counting to capturing much more diverse semantic, syntactic, and perceptive features of the given text.",
6955.txt,The sentence-level DSMs roughly fall into two classes: unstructured and structured models.,
6956.txt,"Unstructured models, such as averaging among a word vector sequence, do not explicitly account for sentence structure, thus enjoying minimal parameters and fast training speed.",
6957.txt,These models are also currently the most widely used DSMs to probe cortical sentence representations .,
6958.txt,"In contrast, structured models can capture the sentence structure at the cost of a higher computational expense.",
6959.txt,"Some of the structured models, such as BERT and InferSent , have delivered excellent performance in predicting human similarity judgments and downstream NLP tasks, potentially better correlating with the human brain activation patterns.",
6960.txt,"Nevertheless, compared with the wide adoption of unstructured approaches, most of them have scarcely been explored to probe the neural representations.",
6961.txt,"In this article, we bridge the latest advances of representation learning in NLP with brain encoding and decoding.",
6962.txt,"As shown in Fig.1, we build a bidirectional mapping between sentence stimuli and the corresponding brain activations, with 12 DSMs to encode sentence representations.",
6963.txt,"Both unstructured and structured models are carefully selected, as outlined in Fig.1, to conduct a comprehensive evaluation.",
6964.txt,"In the encoding evaluation, the DSMs are first compared with respect to predicting cortical activities throughout 27 specific ROIs in language and visual networks.",
6965.txt,This approach not only allows us to confirm what kind of DSMs better account for brain activities but also revisits previous findings in splitting the cortical semantic system from the data-driven perspective.,
6966.txt,We find that encoders trained with transformer-based DSMs consistently outperform other unsupervised structured models and all of the unstructured baselines in predicting brain activities in both the language and the visual networks.,
6967.txt,"Aggregating the results, the prediction accuracy for the left middle temporal gyrus and left lateral occipital cortex exceeds those of other regions.",
6968.txt,"In the decoding evaluation, decoders trained with different DSMs are tested by identifying the stimuli from brain activation patterns.",
6969.txt,"In addition to the reliable performance of the transformer-based models, we find that InferSent's decoding accuracy is comparable to those of the transformers in most subtasks.Text representations produced by most neural network-based DSMs are dense and not easily interpretable.",
6970.txt,"To gain deeper insights into the experimental results, we study two aspects.",
6971.txt,We first decompose what differences in features captured by DSMs best explain their different correspondence with brain activation patterns.,
6972.txt,"Fueled by a set of probing tasks, the DSMs' abilities to account for the surface, syntactic, and semantic properties of a sentence are scored and correlated with the encoding and decoding accuracy.",
6973.txt,"For the language networks, semantic probing scores of DSMs significantly correlate with encoding accuracy on more ROIs than syntactic and surface probing.",
6974.txt,We validate the findings with a set of ablation tasks.,
6975.txt,"Second, we aggregate the encoding results of all DSMs on different topics and display them among the brain language and vision networks.",
6976.txt,"We find that a topic is not exclusively selective to certain ROIs, but rather represented by spatially overlapping and distributed cortical patterns.",
6977.txt,The findings of this article not only demonstrate the weaknesses and advantages of different DSMs in explaining cortical sentence processing.,
6978.txt,The results offer deeper insight into the connection between the two manifestations of mental meanings: the neural activation patterns and the extrinsic linguistic representations.,
6979.txt,We hope these findings could boost mutual promotion between understanding cortical linguistic representations and developing machine-learning semantic representation models.,
6980.txt,The rest of this article is organized as follows.,
6981.txt,The experimental setup and the sentence stimuli for collecting the fMRI data sets are briefed in Section II-A.,
6982.txt,How to train and evaluate the brain encoders and decoders is detailed in Sections II-BII-D.,
6983.txt,"Section II-E introduces the 12 DSMs tested in this article, Sections II-F and II-G describe the probing and ablation tasks to explain the encoding and decoding performance of the DSMs.",
6984.txt,Section III presents the experimental results.,
6985.txt,"In Section III-A, we report the neural encodingresults.",
6986.txt,"We first show the pairwise matching accuracy in language and visual networks, then explain the encoding performance with probing and ablation tasks, and finally discuss the topic distribution among different ROIs derived from the encoding performance.",
6987.txt,"In Section III-B, we report the decoding results in a similar order to that in Section III-A.",
6988.txt,"However, in Sections III-B3 and III-B4, we further show the distribution patterns of informative voxels and the decoding performance with voxels constrained in several functional networks.",
6989.txt,"We use the fMRI neural activation data published in X, acquired on a whole-body 3-Tesla Siemens Trio scanner with a 32-channel head coil.",
6990.txt,Two experiments are carried out in the original work to collect imaging data.,
6991.txt,"Experiment 1 involves the scanning of eight subjects, while experiment 2 involves the scanning of five subjects.",
6992.txt,"The sentence stimuli are organizedin the hierarchy of topicpassagesentence in both experiments, as shown in Fig.1.",
6993.txt,"In experiment 1, 96 passages are presented, each consisting of four sentences about a particular concept.",
6994.txt,"The passages come from 24 broad topics , each providing basic information about the corresponding concept in the style of Wikipedia.",
6995.txt,"In experiment 272 passages are used, each consisting of three or four sentences about a particular concept.",
6996.txt,The passages also span a broad range of content areas that are unrelated to the topics in experiment 1.,
6997.txt,The materials include 48 Wikipedia-style passages and 24 first-/third-person narratives.,
6998.txt,The two experiments are comparable in their within and between-passage/topic semantic similarities.,
6999.txt,All passages are presented sentence by sentence.,
7000.txt,Each sentence is presented for 4 s followed by a 4-s fixation gap.,
7001.txt,The entire set of sentences is presented three times.,
7002.txt,The participants are asked to read the sentences that they are presented to ensure attentive scanning.,
7003.txt,All subjects are scanned three times for every sentence stimuli.,
7004.txt,The scan is running consistently during the presence of sentence stimuli.,
7005.txt,"Next, the acquired data series is corrected by slice timing and motion correction and then concatenated to align the sentence.",
7006.txt,The fixation gap is used to separate the sentences and distinguish brain activities of language processing from other brain activities.,
7007.txt,"Details of the experimental setup, materials, and presentation scripts are available online.1 To fully use the data set and comprehensively display the experimental findings, we discuss the encoding results on experiment 1's 384-sentence data and the decoding results on experiment 2's 243-sentence data.The encoder is trained within the fivefold cross-validation procedure.",
7008.txt,"In each fold, the regression parameters for each dimension are learned by predicting the brain images for 307 sentences from distributed representations and tested by predicting activation patterns for the 77 left-out sentences.",
7009.txt,"The voxelwise normalization is carried out using a mean image derived from the training set, which is also subtracted from the test set.",
7010.txt,"The cross-validation procedure is carried out on data from all five subjects with each of the DSMs, respectively.",
7011.txt,"After fivefolds, this would result in 384 encoded brain activation vectors for each combination of subjects and DSMs.",
7012.txt,We evaluate the encoding results by running pairwise matching on the 384 encoded brain activation vectors.,
7013.txt,Pairwise matching is detailed in Section II-D.The decoder is also trained within fivefold cross validation.,
7014.txt,The regression parameters for each dimension are learned from mapping the brain images for 194 sentences to distributed representations and tested by predicting semantic vectors from the brain images for 49 left-out sentences in each fold.,
7015.txt,"The voxelwise normalization is carried out using a mean image derived from the training set, which is also subtracted from the test set.",
7016.txt,"The cross-validation procedure is carried out on data from all five subjects with each of the DSMs, respectively.",
7017.txt,"After fivefolds, this would result in 243 decoded semantic vectors for each combination of a subject and a DSM.",
7018.txt,We evaluate the decoding results by running pairwise matching on the 243 decoded semantic vectors.,
7019.txt,"Pairwise matching is detailed in Section II-D. Each decoder is trained on a reduced image of 5000 voxels, approximately 10% of the number left after applying a cortical mask.",
7020.txt,"Following the settings of X, these voxels are selected by the degree to which they are informative about the distributed semantic vectors.",
7021.txt,"For all subject and DSM combinations, the voxel selection is done separately in each cross-validation fold within the training set.",
7022.txt,"Especially, before the training began, we learn regression models to predict each semantic dimension from the imaging data of each voxel and its 26 adjacent neighbors in 3-D.",
7023.txt,"This yielded predicted values for each semantic dimension, which are then correlated with the values in the ground-truth sentence vectors.",
7024.txt,"Finally, the informativeness score for each voxel is the average value of such correlation across dimensions.The encoding and decoding results are evaluated by the pairwise matching task, which is one of the most widely adopted metrics herein.",
7025.txt,"We explain the pairwise matching task, taking brain decoding as an example.",
7026.txt,As shown in Fig.,
7027.txt,"2, we compute the correlation between the decoded vectors and the ground-truth sentence embeddings.",
7028.txt,"If the decoded semantic vectors are more similar to their respective brain activation patterns than to the alternative, a successful matching is scored.Each possible pair of sentences will be explored.",
7029.txt,The final matching accuracy for each participant is the fraction of correctly matched pairs.,
7030.txt,"If the model chose the match at random, the expected chance-level accuracy would be 0.50.",
7031.txt,"Similar procedures are conducted for evaluating brain encoding results, while the difference lies in that we match encoded vectors to the ground-truth brain activities.",
7032.txt,"Note that, for evaluating brain decoding, we adopt X's setting where the pairwise matching task is further divided into three subtasks.",
7033.txt,"These subtasks constrain Siand Sjto be, respectively, from: different topics;  different passages from the same topic ; and  different sentences within the same passage.Moving beyond representations at the word level, multiple methods have been proposed to build distributed representations of higher level linguistic units, such as sentences.",
7034.txt,The sentence-level DSMs roughly fall into two classes: unstructured and structured models.,
7035.txt,"Unstructured models, such as averaging among word embedding sequence, do not explicitly account for structural information of a sentence, thus enjoying minimal parameters and fast training speed.",
7036.txt,They are also the most widely used methods to probe cortical sentence representations.,
7037.txt,"In contrast, structured models can capture the sentence structure and model how words or phrases affect each other at the cost of higher computational expense.",
7038.txt,"Though more powerful in expressibility, these models have not been fully explored in neural imaging studies.",
7039.txt,"Representation models that deliver state-of-the-art performance in NLP tasks are mostly structured, such as BERT and GPT2.",
7040.txt,Structured models can be further classified into unsupervised and supervised methods.,
7041.txt,Unstructured Models: A straightforward technique for representing a longer piece of text is to ignore the sequence structure and treat it as a bag of words.,
7042.txt,"For a sentence, simply averaging the vectors for the individual words can produce representations that roughly match the human similarity judgments.",
7043.txt,This approach is tantamount to an average pooling on the sequence of word vectors.,
7044.txt,Average pooling is also one of the most widely used methods to represent stimuli in sentence-level neural encoding and decoding.,
7045.txt,"Averaging offers the advantage of aggregating the semantic information of every single word, but it also dilutes the most salient features of the sentence.",
7046.txt,"Since only a small number of words in a sentence contribute most to its meaning,max-pooling has also been adopted.",
7047.txt,"It extracts the maximum value along each dimension of the word embeddings, selecting the most salient features of all dimensions in the sentence representation.",
7048.txt,"Intuitively, features extracted by averaging and max-pooling capture complementary semantic information of a sentence as shown by Shen.",
7049.txt,"The two extracted features can, thus, be concatenated as the third representation.",
7050.txt,"Besides, Arora introduced SIF,2an improved average pooling weighted by word frequency that beats more complicated methods in standard natural language tasks.",
7051.txt,"Unsupervised Structured Models: Unsupervised structured models generally adopt the idea of language modeling, learning to simultaneously predict the next and previous sentences from the encoding of the current sentence.",
7052.txt,"Recurrent neural networks, convolutional networks , and the transformer are currently the most mainstream building blocks of language modeling in the NLP community.",
7053.txt,"Benefiting from their network architectures, the trained sentence encoders catch the syntactic information, such as word order and tree structure of a sentence.",
7054.txt,Sentences similar in distribution pattern can then be mapped to closer vectors in the produced representation space.,
7055.txt,"For skipthought, we choose the encoder's last layer and average its hidden states to produce sentence representation.",
7056.txt,"In addition to the RNN, both the CNN and transformer networks have been applied in language modeling.",
7057.txt,These networks generally share the idea of skip-thought as X and differ in the underlying structures.,
7058.txt,We choose FairSeq4to represent CNN-based models.,
7059.txt,The large-scale transformer-based language models have driven much recent progress in natural language understanding tasks.,
7060.txt,They currently dominate the family of unsupervised structured DSMs.,
7061.txt,"We choose BERT, GPT2, and RoBerTa as typical transformer-based models.",
7062.txt,It is worth noting that BERT is more frequently adopted than the other two transformer-based models in some recent work of probing brain activities with distributed representations.,
7063.txt,"For example, Gauthier and Levy discussed whether syntactic light BERT representations lead to better decoding performance, with the same brain imaging data as we use.",
7064.txt,Abnar proposed a variant of RSA to analyze the relationship between the layerwise representation of BERT with brain activation patterns.,
7065.txt,3) Supervised Structured Models: InferSent proposed in X is a supervised model trained on the Stanford Natural Language Inference data sets.,
7066.txt,"In this model, sentences are encoded by a bidirectional long short-term memory  network and fed into a three-class classifier to conduct NLI.",
7067.txt,"For a sequence of n words,and each vector is a concatenation of a forward LSTM and a backward LSTM that reads the sentence in opposite directions.",
7068.txt,"Similar to previous methods, hidden states of the last encoder layer are transduced as the sentence representation.",
7069.txt,Two strategies are compared by the author: selecting the maximum value over each dimension of the hidden units or by considering the average of each dimension.,
7070.txt,"In their experiments, the max-pooling strategy gives the best results in terms of accuracy on several downstream tasks, and such a setting is followed in this article's evaluation.",
7071.txt,"InferSent is trained on a single supervised task, NLI, while sentence encoders trained with multitask strategy are also available, such as GenSen.",
7072.txt,"GenSen shares a single recurrent sentence encoder across multiple tasks, combining the inductive biases of diverse training objectives in a single model.To have a clear understanding of what difference in the features captured by DSMs lead to their diverse performances in modeling the brain activation patterns, we probe the DSM's ability to encode surface, syntactic, and semantic features in sentence embeddings, and correlate them to the encoding or decoding performance.",
7073.txt,We first introduce the three probing tasks.,
7074.txt,Surface Probing: We evaluate the extent to which the sentence length can be predicted from a DSM's representation.,
7075.txt,Length is considered as a surface feature of a sentence because it can be acquired without linguistic knowledge.,
7076.txt,We follow the task setting proposed by Conneau.,
7077.txt,100k sentences as training sets and 10k sentences as validation and test sets are provided.,
7078.txt,These sentences are extracted from Toronto Book Corpus and in the 5-to-28 word range.,
7079.txt,They have been grouped into six equal-width bins by the number of words.,
7080.txt,"In the probing task, a single hidden-layer MLP will be trained on the six-way classification of sentence length, taking only sentence embeddings as input.",
7081.txt,All the DSMs that we evaluate in this article will encode the sentences to finish this length classification task.,
7082.txt,The test accuracy is reported as the corresponding DSM's probing score for modeling sentence length.,
7083.txt,"There might be other surface probing tasks available, but they have the risk of intrinsically correlating with the following syntactic and semantic probing that we implement.",
7084.txt,"Thus, we only adopt sentence length probing.",
7085.txt,"Syntactic Probing: We probe a DSM's ability to encode syntactic information with the approach from, inspired by Gauthier and Levy.",
7086.txt,This probing approach measures the degree to which syntactic analyses of a sentence can be reconstructed from its word embeddings.,
7087.txt,"It operates on a parsed corpus, and we use sentences sampled from the Universal Dependencies English Web Treebank  corpus.Once B is estimated on the train set, it can be applied to the test set to predict the distance between any two words in a sentence.",
7088.txt,"This yields a n n distance matrix for an n-word sentence, from which an undirected parsing tree can be derived with minimum spanning tree algorithm.",
7089.txt,The accuracy of such tree reconstruction is measured by calculating the unlabeled attachment score  to the ground-truth parsing of the sentence.,
7090.txt,"Semantic Probing: In this task, we probe a DSM's ability to account for the semantic information of sentences.",
7091.txt,We include the SICK data set and the STS Benchmark  to evaluate the DSMs in predicting semantic relatedness between sentences.,
7092.txt,Sentence pairs in these data sets have been annotated with a relatedness score between 0 and 5.,
7093.txt,"Similar to the surface probing task, a single hidden-layer MLP learns on top of DSM encoded embeddings to predict the relatedness score of two input sentences.",
7094.txt,The Pearson correlation between the predicted distribution and ground-truth score on the test set is reported.,
7095.txt,We average the performance on SICK and STS tasks as the semantic probing score of a DSM.There are three probing scores for each of the evaluated DSMs.,
7096.txt,"They will be, respectively, correlated with encoding and decoding accuracy among all the subjects.",
7097.txt,"Such a setting allows us to pin-point catching what difference in the linguistic features leads to the different encoding and decoding performance of the DSMs.We produce two ablation tasks to support the findings in the probing tasks, evaluating why a DSM might fail or succeed in modeling activities in a cause-effect manner.",
7098.txt,"If a certain feature captured by the DSM did not matter in modeling the brain activities, the corresponding ablation would not decrease its encoding or decoding performance, and vice versa.",
7099.txt,Each ablation task is a modified form of the standard language modeling task.,
7100.txt,"The training corpora of the task is manipulated to select against some particular features of linguistic representation, such as sentence meaning or grammatical structure.",
7101.txt,"As a control, the model will also be tuned on original correct sentences in normal language modeling, denoted as control.",
7102.txt,"All the sentences in the ablation data sets are extracted from the Toronto Book Corpus, which is widely used in pretraining language models, such as BERT and RoBerTa.",
7103.txt,"Language Modeling With Scrambled W ord Order: An ablated language modeling task is designed to select against the fine-grained syntactic representation of models, as inspired by Gauthier and Levy.",
7104.txt,"This task is denoted as scramble, where the word order of every input sentence is randomly shuffled to remove all first-order cues to its syntactic structure.",
7105.txt,Note that only the word order is scrambled.,
7106.txt,"No word is added, removed, replaced, or morphologically changed in the sentence.",
7107.txt,"Tuning the language models on this data set means to predict a missing word from a bag of its content words, without structural hints.",
7108.txt,"Language Modeling With Content W ords Modified: We next design a task select against fine-grained semantic representations of a DSM, compromising its ability in encoding the semantic relation between words in a sentence.",
7109.txt,This is achieved by feeding anomalous sentences that contained semantically implausible complements to the model.,
7110.txt,We make anomaly by interfering with the verbs and nouns that are usually the main content words of a sentence.,
7111.txt,Every single verb or noun in a sentence is replaced by another random verb or noun that is incompatible in meaning with its contexts.,
7112.txt,We make sure that such a replacement only causes semantic anomaly but not a syntactic error.,
7113.txt,We abbreviate this task as remword.,
7114.txt,"In this section, we discuss the relationship between cortical sentence representations against DSM by using them as predictive models of the brain responses given sentence stimuli.",
7115.txt,"In the encoding experiments, we first study how the tested DSMs predict the activities of regions of interest, from several large-scale brain networks specifically linked to high-level cognition and/or semantic processing.",
7116.txt,The selected networks are as follows:  the fronto-temporal language selective network ;  the ensemble semantic system ; and  the visual network .,
7117.txt,"We compare the predicting accuracy delivered by different DSMs with a pairwise matching task, evaluating which kind of model consistently outperforms other baselines.",
7118.txt,"Knowing the encoding performance, we further study which of the linguistic features that DSMs captured better explained the accuracy of predicting brain activities.",
7119.txt,"With a set of probing and ablation tasks, we offer a hint regarding how the selectivity of different linguistic features may influence the DSMs' encoding performance.",
7120.txt,"In addition to catching linguistic features, DSMs can reflect the semantic category of a sentence in the embeddings.",
7121.txt,"We show the topic encoding accuracy on different ROIs in language and visual networks by averaging across all the DSMs and subjects, which helps to reveal the topic selectivity of different brain areas.",
7122.txt,The findings from analyzing the encoding performance are validated by paired t-test with the Bonferroni correction.,
7123.txt,"The results are reported throughout with a significance level of  = 0.01.Prediction Within Regions of Interest: We use encoders, respectively, trained with different DSMs to predict activation patterns of the brain language and visual networks.",
7124.txt,"A DSM's encoding accuracies on eight subjects are averaged for each ROI, as shown in Fig.",
7125.txt,3,
7126.txt,"We also estimate a null distribution of the encoding accuracy for each ROI, achieved by training encoders to predict the activities of those ROIs with random sentence vectors and evaluating by pairwise matching.",
7127.txt,The null encoding accuracy is consistent among the ROIs and falls within 0.502  0.039 with 95% confidence intervals.,
7128.txt,Pairwise comparison of the ROI scores of different DSMs reveals a DSM's overall correlation with the brain activation patterns in a functional network.,
7129.txt,"In predicting the ROIs of the language and semantic networks, the three transformer-based models significantly outperform the other unsupervised structured models and all the unstructured baselines .",
7130.txt,The structured models do not consistently outperform the unstructured models.,
7131.txt,"For example, A VMA embedding is comparable with skip-thought in predicting the language networks.",
7132.txt,"In predicting the ROIs of the visual networks, the three transformer-based models also significantly outperform the other unsupervised structured models and all of the unstructured baselines.",
7133.txt,"The exception is InferSent, a supervised structured model whose encoding performance is not significantly different from that of RoBerTa in predicting the visual networks.",
7134.txt,"Among all the tested models, max-pooling  delivers the lowest matching accuracy in predicting both the language and visual networks .",
7135.txt,"Every single ROI is predicted by 12 DSMs, so it is featured by a list of 12 matching scores.",
7136.txt,Pairwise comparison of the 12-DSM score of different ROIs can give a hint on an ROI's selectivity to sentence-level linguistic features.,
7137.txt,"We find that LMTG is more accurately predicted than the other ROIs in the language networks , including the left anterior and posterior temporal gyrus.",
7138.txt,Matching accuracy on LmMFG  is significantly lower than other ROIs in the language networks.,
7139.txt,"In the visual networks, the LLOC is significantly more predictable by the DSMs than other ROIs, including left occipital complex on the right hemisphere RLOC .",
7140.txt,"Explanation With Probing and Ablation T ask: To explain what difference in the feature they capture lead to their accuracy gap in predicting the brain, we conduct three probing tasks, correlate the probing score to the encoding performance, and depict the results in Fig.",
7141.txt,4,
7142.txt,"As shown in Fig.4, surface probing scores do not significantly correlate with the matching accuracy on all the ROIs in the language networks.",
7143.txt,This means that difference in encoding sentence length in the embeddings does not reliably explain DSMs' different encoding performance in the language networks.,
7144.txt,"Syntactic probing scores correlate with matching accuracies on lateral parietal regions, LPTG, and left inferior frontal gyrus-pars orbitalis , with p < 0.01 for these three ROIs.",
7145.txt,"This means that, in the three ROIs, the UAS of reconstructing dependence-parsing tree from different DSM's sentence embeddings accounts for a significant large portion of their differences in encoding accuracy.",
7146.txt,Semantic probing scores significantly correlate with matching accuracies on all ROIs  except LaMFG  in the language networks.,
7147.txt,"From the abovementioned experiments, we find that different DSM's semantic probing scores significantly correlate with the encoding accuracy on most of the ROIs in the language atlas.",
7148.txt,"To further verify this finding, we pick BERT that reliably encodes the brain activities of the language network and conduct an ablation test.",
7149.txt,We systematically select against a model's syntactic or semantic representation by tuning them on the corresponding ablation data set and see what interference significantly influences DSM's encoding accuracy for ROIs in the language networks.,
7150.txt,"As shown in Fig.4, the interference of an ablation task leads to different results in different ROIs.For BERT, tuning on the remword task yields decreased matching accuracy relative to its untuned baseline on 8 of the 11 ROIs, except left post-potion of middle frontal gyrus , left inferior frontal gyrus , and LPar.",
7151.txt,"On these eight ROIs, tuning on the remword task also leads to significantly lower matching accuracy than the control task.",
7152.txt,This corroborates with our findings that DSMs' different levels of semantic selectivity influence their performance in predicting the brain activities aroused by sentence stimulus.,
7153.txt,Tuning on the scramble task yields decreased matching accuracy on two ROIs: LIFGorb and LMTG.,
7154.txt,"On the other ROIs, the differences in accuracy between tuning on the scramble task and the pretrained BERT baseline do not stand up to the statistical significance test.",
7155.txt,"Cortical Representation of Different Topics: The linguistic stimuli in the experiments are organized in the hierarchy of topicpassagesentence, as shown in Fig.1.",
7156.txt,"Each time a sentence is correctly matched to its corresponding brain activation patterns, we record a value of 1 and otherwise 0.",
7157.txt,"When all folds of cross validations are done, each sentence has a list of historical scores that are then averaged as this sentence's matching accuracy.",
7158.txt,The matching accuracies of all sentences from the same topic are further averaged to obtain the final matching score of that topic.,
7159.txt,All 384 sentences come from 24 topics.,
7160.txt,"After pooling such metrics across all subjects and DSMs, each ROI receives a list of 24 scores that comprehensively reflect how well brain activities aroused by different topics can be predicted from that ROI.",
7161.txt,These results are depicted as a heat map in Fig.,
7162.txt,5,
7163.txt,Only half of the 24 topics are depicted due to space limitations; the full results are shown in the Supplementary Material.,
7164.txt,"After pairwise comparison of different ROI's 24-topic scores, we find that LMTG is better predicted than other ROIs in the language and semantic networks among the topics.",
7165.txt,LLOC is better predicted than other ROIs in the visual networks among all the topics.,
7166.txt,The difference between LLOC and LMTG is not significant.,
7167.txt,These findings are consistent with the results in Fig.,
7168.txt,3,
7169.txt,Brain activities aroused by different topics tend to be more accurately predicted on LMTG and LLOC.,
7170.txt,"However, this fact does not indicate that the topics are exclusively represented by a certain ROI.",
7171.txt,"Oppositely, the heat map in Fig.",
7172.txt,"5 shows visibly that one topic can be predictable on multiple ROIs; also, in one ROI, there are multiple topics that can be predicted.",
7173.txt,"Simply speaking, the results seek to indicate that many topics are represented by many ROIs.",
7174.txt,We found a topic is not exclusively selective to a certain ROIs but represented by spatially overlapping and distributed cortical patterns.,
7175.txt,"For instance, the topic ""crime"" can be encoded on the posterior MTG , fusiform gyrus, and inferior frontal gyrus .",
7176.txt,"In this section, we discuss the relationship between cortical sentence representations against DSMs by using them to decode sentence stimuli from brain responses.",
7177.txt,The regression model is trained and tested on different subsets of the 243 sentences in the fivefold cross validation for each participant.,
7178.txt,We first show the decoding performance with the informative voxels selected by the 12 DSMs.,
7179.txt,"To determine which feature difference the DSMs capture may explain their different decoding performances, we probe the DSMs and correlate the probing score with the decoding accuracy.",
7180.txt,"We also depict the DSM's decoding accuracy on different topics, revealing their possible semantic selectivity in Section III-B2.",
7181.txt,"Since decoding is carried out with selected informative voxels, we illustrate the cortical distribution of the selected voxels among three functional networks.",
7182.txt,"For a fair comparison, we conduct the pairwise matching test with voxels constrained in three functional networks in Section III-B3.",
7183.txt,Findings from analyzing the decoding performance are validated by paired t-test with the Bonferroni correction.,
7184.txt,The results are reported throughout with a significance level  = 0.01.,
7185.txt,"1) Decoding With Informative V oxels: In this section, we conduct neural decoding with selected informative voxels and test with the pairwise matching task.",
7186.txt,"Three subtasks in progressively finer granularity are included, matching sentences coming from: 1) different topics ;different passages from the same topic ; and  different sentences within the same passage , for all possible pairs in every subtask.",
7187.txt,Matching sentences from the same passage is expected to be the most difficult subtask because sentences in one passage all describe the same object in the stimulus data set that we use.,
7188.txt,"For two sentences of the same passage, it is possible for words to overlap and sentence meanings tend to be close.",
7189.txt,"To test the significance of results, we estimate null performance by training decoders with random sentence embeddings and evaluating the decoded semantic vectors with pairwise matching.",
7190.txt,We run the null experiment five times and obtain the average accuracy for each subject on the subtasks.,
7191.txt,"Among the subjects, the null matching accuracy of the first subtask falls within 0.5006  0.022, and the second falls within 0.5014  0.035, while the third falls within 0.5061  0.028, all with 95% confidence intervals.",
7192.txt,The null performance is consistent with the expected chance level accuracy 0.4 for pairwise matching.Fig.,
7193.txt,6 shows the matching accuracy of different sentence representations.,
7194.txt,"In decoding the sentence stimuli from different topics, all the tested representations perform significantly above the null level.",
7195.txt,The three transformer-based models deliver matching accuracy higher than 0.9.,
7196.txt,InferSent also yields an impressive performance that is not significantly different from that of RoBerTa.,
7197.txt,"Averaging achieves satisfactory performance but does not rank the top, even in the unstructured-based methods.",
7198.txt,We do not observe that structured models consistently outperform the unstructured models.,
7199.txt,"In decoding the sentence stimuli from different topics, the performance pattern is also consistent across subjects.",
7200.txt,"Except for SIF and skip-thought, the matching accuracy of each DSM among the subjects has a standard deviation lower than 0.015.",
7201.txt,"As the task becomes finer in granularity, the performance patterns change.",
7202.txt,"In the third task of decoding sentences from the same passage, MAX does not significantly outperform the null level.",
7203.txt,"Skip-thought was inferior to A VMA in the first subtask , but, in the third subtask, their performance difference is no longer significant.",
7204.txt,"In the third subtask, sentences from the same passage might use semantically related words to describe one single concept, as shown in Fig.1.",
7205.txt,"This means that, by merely pooling on the word embeddings, it is largely possible to produce similar sentence representations.",
7206.txt,We think that is where the structured and other auxiliary linguistic information becomes important.,
7207.txt,"For sentences from different topics or different passages, words exhibit reduced overlap.",
7208.txt,The word embeddings alone may provide enough semantic information for a distinguishable sentence representation.,
7209.txt,"Moreover, on the third subtask, the performance fluctuations caused by the subject gap are more obvious than for the first subtask when comparing the standard deviation of matching accuracy across the subjects.We validate the abovementioned results by correlating the decoding performance with the DSMs' probing score.",
7210.txt,As shown in Fig.,
7211.txt,"7, the scores of surface and syntactic probing do not correlate with decoding accuracy on the first and second subtasks, under the significance level of  = 0.01.",
7212.txt,"On the third subtask, the surface and syntactic probing scores significantly correlate with the decoding performance .",
7213.txt,"The semantic probing score correlates with the decoding performance in all the three subtasks, but the correlation value tends to decrease as the subtask becomes finer in granularity.",
7214.txt,"The results support our hypothesis that as the decoding becomes more fine-grained, syntactic, and surface features encoded by the DSMs can be helpful.",
7215.txt,Decoding on Different T opics: Linguistic stimuli in the experiments are organized in the hierarchy of topicpassage?sentence.,
7216.txt,We are interested to know how the DSMs decode brain representation of sentences from different topics.,
7217.txt,"So for,in every tested DSM, we average its decoding score on all sentences from a specific topic.",
7218.txt,All five subjects are included in the calculation to qualify the results.,
7219.txt,As depicted in Fig.,
7220.txt,"8, the DSMs show a tendency of topic selectivity; namely, a DSM does not perform uniformly when decoding different topics.",
7221.txt,"For example, after pooling across different subjects, GPT2's highest mean matching accuracy is observed on the ""dreams"" topic while the lowest on the ""painter"" topic, with a gap of 0.094.",
7222.txt,The gap between the MAX's highest and lowest mean matching accuracy is even larger.,
7223.txt,"MAX delivers its highest accuracy on the ""ice-cream"" and lowest on the ""painter"" topic, and the gap is 0.2839.",
7224.txt,"If we compare the topicwise decoding accuracy on the five subjects but not the mean value among them, the difference between MAX's decoding accuracy on ""ice-cream"" and ""painter"" topic is significant.",
7225.txt,"In the 384-sentence data set, we find that brain responses to the crime-topic sentences are selectively more predictable than other topics.",
7226.txt,"However, in the current 243-sentences data set, we do not find a topic that is consistently easier to decode than the other ones by the DSMs.",
7227.txt,We see from Fig.,
7228.txt,"9 that, on the ""ice-cream"" topic, DSMs perform more closely, and AVG, MAX, and AVMA deliver the highest matching accuracy on this topic.",
7229.txt,"However, this does not mean that all the DSMs best decode the ""ice-cream"" topic.",
7230.txt,"For example, RoBerTa's highest matching accuracy is observed on the ""taste"" but not the ""ice-cream"" topic.",
7231.txt,Spatial Distribution of Informative V oxels: We decode with informative voxels that are selected by how well they predict the sentence representations.,
7232.txt,We map the full brain voxels to every single tested DSM in cross validation.,
7233.txt,The semantic vectors predicted from every voxel are correlated with the ground-truth sentence representations produced by a DSM.,
7234.txt,The average correlations on all 243 sentences are recorded as the informativeness score of a certain voxel.,
7235.txt,The 5000 most informative voxels are selected.,
7236.txt,"Though selected by informativeness without any spatial constraints over the brain, voxels themselves belong to different brain areas with high-level cognitive functions.",
7237.txt,How sentences are neurally represented in the human brain remains an unsolved problem.,
7238.txt,We can gain some insights through studying the correspondence between sentence representations and functional brain networks.,
7239.txt,"Following, we pick four brain networks: language networks, visual networks , default mode network, and multiple demand network.",
7240.txt,We are particularly interested in the language networks that store the mappings between linguistic forms and meanings.,
7241.txt,"We show how the informative voxels distribute among these networks, as depicted in Fig.",
7242.txt,9,
7243.txt,We also estimate a null distribution by selecting voxels with random sentence embeddings.,
7244.txt,"The null distribution is of all the voxels selected, 8.65%0.50% fall in the language networks, 6.58%0.30% fall in the visual networks, 8.88%  0.38% fall in the DMN, and 15.32%0.82% fall in the MD.",
7245.txt,The informative voxels are not evenly distributed among the function networks.,
7246.txt,Language network voxels in the informative voxels selected by each DSM take percentage significantly higher than the null level.,
7247.txt,"Visual network voxels significantly take percentage higher than the null level in voxels selected by DSMs except for AVG, ELMo, RoberTa, and GPT2.",
7248.txt,DMN voxels do not consistently take percentage higher than the null level in the informative voxels selected by DSMs.,
7249.txt,The distribution pattern of selected informative voxels is consistent among DSMs though the DSMs themselves can be largely different from each other in the underlying model structure.,
7250.txt,The rank of voxel percentage in the selected voxels is like language network > visual network > DMN > MD.,
7251.txt,"Decoding Within Functional Networks: To demonstrate how well different DSMs decode a specific brain area, we further constrain the voxels to different brain networks and retrain the decoders.",
7252.txt,"The decoding results on three subtasks are further averaged among subjects, and we show them in Fig.",
7253.txt,10,
7254.txt,"Compared with decoding with selected informative voxels, constraining voxels in a specific network does not yield improvements in decoding accuracy.",
7255.txt,"Such a trend becomes more clear in the third subtask , where the decoding accuracy decreases by a maximum of 45% in maximum.",
7256.txt,Using voxels in the language atlas yields better decoding results than other the visual network and DMN.,
7257.txt,"However, in the third subtask, we still observe an average accuracy decrease of 25%.",
7258.txt,BERT achieves 0.815 average accuracy with the selected voxels on the third subtask but only get 0.596 with the language network voxels.,
7259.txt,"Though decreasing in scale, the performance rank of different DSMs is generally consistent with that of previous experiments in the language atlas.",
7260.txt,Unstructured models perform on par with most structured models on the first two subtasks.,
7261.txt,"When decoding with the visual network and DMN voxels, we observe some patterns that differ from those of previous informative voxel-based decoding results.",
7262.txt,"With visual voxels, all the unstructured models perform even below the chance level on the third matching task.",
7263.txt,"With DMN voxels, InferSent tops in decoding accuracy on the first subtask, while BERT ranks the second.",
7264.txt,"In this article, we characterize the relationship between cortical representations and distributed sentence embeddings through the lens of neural encoding and decoding.",
7265.txt,"Though distinct in form and motivation, we obtain some common findings in encoding and decoding results.",
7266.txt,We find that structured DSMs do not consistently outperform the unstructured models.,
7267.txt,"For example, Skip-thought is not significantly different from AVMA in encoding the language and semantic networks.",
7268.txt,"The two structured models tend to perform better in fine-grained decoding tasks, such as the third subtask of decoding, classifying sentences from the same passage.",
7269.txt,"However, in the coarse-grained tasks, they perform closely to the unstructured ones.",
7270.txt,"In the structured models, we further find that supervision is not a decisive factor for a DSM's encoding or decoding performance.",
7271.txt,"The three unsupervised transformers significantly outperform GenSen, a supervised multitask model in encoding the language networks and in most subtasks of decoding.",
7272.txt,"However, InferSent, another supervised model that we test, is comparable to RoBerTa in encoding the visual networks and the third subtask of decoding.",
7273.txt,"Thus, it is worth studying the role of supervision in explaining a structured DSM's relationship with the brain.",
7274.txt,The three transformer-based models surpass other unsupervised structured models and unstructured baselines in encoding the language and semantic networks.,
7275.txt,They also perform impressively in brain decoding with both selected voxels and voxels constrained in functional networks.,
7276.txt,These results lead us to highly recommend transformer-based models to be considered in sentence-level brain encoding and decoding.,
7277.txt,"However, we should note that they do not fully resemble the neuron structure in the human brain.",
7278.txt,We observe that the differences in structure modeling and supervision do not seem to explain the DSM's relation with the brain.,
7279.txt,"Therefore, it is desired to exhaustively study the underlying structure of DSMs  and determine what leads to the high correlation between the distributed representations and the brain activation patterns aroused by the sentence stimuli.",
7280.txt,"Given the excellent encoding and decoding performance, these models should create a solid baseline to be adjusted to bionically simulate and explain the cortical sentence processing.",
7281.txt,"In this article, the transformer-based DSMs fine-tuned in downstream NLP tasks are not included in the encoding and decoding experiments except in the ablation test.",
7282.txt,It is promising to further explore how well these models trained in supervised tasks  predict and decipher the human brain activities aroused by linguistic stimuli.,
7283.txt,"Furthermore, the DSMs that we evaluate in this article are trained exclusively in linguistic modality.",
7284.txt,"How the DSMs learned in a multimodal way probe the brain representations is also worth studying in the future work.The tested DSMs exhibit different performance patterns, and it is necessary to explain what difference in the feature captured contributes most to the encoding and decoding accuracy gap.",
7285.txt,"Thus, we probe the DSMs' abilities to account for the surface, syntactic, and semantic features of a sentence.",
7286.txt,The probing scores are then correlated with the encoding and decoding accuracies to interpret by which feature they are most explained.,
7287.txt,This not only leads to a more clear empirical explanation of the experimental results but also it sheds light on the linguistic features critical in cortical language processing.,
7288.txt,"If models better accounting for a certain linguistic feature also achieved higher performance in predicting and deciphering the brain activities among different subjects, such a feature should play a role in forming the cortical sentence representation.",
7289.txt,"Through the analysis, we find common patterns in the encoding and decoding results even though different data sets are used.",
7290.txt,DSM's performances on the semantic probing task best correlate with their encoding accuracy in the semantic and language networks and also highly correlate with the decoding accuracies in three subtasks.,
7291.txt,The semantic probing task evaluates how well the DSMs predict the semantic similarity and relatedness between sentences.,
7292.txt,"Since the sentence-level DSMs exert different transformations on word vectors, the extent to which the semantic of original words can be conserved varies across the methods.",
7293.txt,"For example, AVG treats every word equally, while the transformer-based models, such as BERT, explicitly weight the importance of every word to form a sentence representation.",
7294.txt,Information on important content words is more possible to take a higher proportion in the sentence representations produced by transformers.,
7295.txt,"They do exceed other unsupervised models in encoding and most subtasks in decoding, indicating that its learned word importance weighting policy may share some patterns with the underlying sentence processing mechanism in the human brain.",
7296.txt,Syntactic probing scores significantly correlate with the encoding accuracy of two ROIs of language networks.The ablation task on BERT also shows that tuning on word-order scrambled sentences only yields decreased matching accuracy in two ROIs of the language network.,
7297.txt,"In decoding experiments, syntactic probing scores significantly correlate with the accuracy of the third subtask.",
7298.txt,A finding shared in encoding and decoding results is that the structured models do not consistently outperform the unstructured ones.,
7299.txt,"Taking together, these results may indicate that modeling syntactic structure plays a role in forming cortical sentence representations but not the decisive role.",
7300.txt,"In both the encoding and decoding studies, the brain functional networks and ROIs have been probed by the distributed representations.",
7301.txt,"Though the DSMs themselves might be built in very different ways, ROIs that can be predicted with high accuracy are virtually the same.",
7302.txt,The informative voxels selected in decoding also show consistent distribution patterns.,
7303.txt,"We find, in the encoding results, that LMTG and LLOC are consistently better predicted among subjects and with different DSMs.",
7304.txt,"Similarly, informative voxels in neural decoding also densely distribute in these areas.",
7305.txt,"Without any a priori location constraints, nearly half of the voxels selected by the transformer-based models fall into the language networks.",
7306.txt,"Based on the abovementioned results, we further discuss the semantic selectivity of different ROIs and DSMs.",
7307.txt,We find a topic is not exclusive to certain ROIs but represented by spatially overlapping and distributed cortical patterns.,
7308.txt,We also find that the topic selectivity pattern is not uniform across different DSMs.,
7309.txt,"For the brain, one topic can be represented by multiple ROIs, and a single ROI can represent multiple topics.",
7310.txt,"For DSMs, it is also difficult to find a topic that is exclusively decipherable by a certain model.",
7311.txt,"Also, we note that the current pairwise matching-based encoding and decoding methodology emphasizes the distinction of a specific topic.",
7312.txt,High encoding and decoding accuracy of a specific topic in a way reflects that its evoked cortical activation patterns are more discriminant than other topics.,
7313.txt,Humans beings have the unique capacity to communicate with language.,
7314.txt,"Such ability is based on mental representations of meaning that can be mapped to linguistic items, but to which we have no direct access.",
7315.txt,"Fortunately, the computational meaning representation of language is a well-developed field in the NLP community.",
7316.txt,"Thus, we draw upon these representation models to probe and explain the human brain's language processing through the lens of neural encoding and decoding.",
7317.txt,"In this article, encoders and decoders have been built and evaluated with a wide range of DSMs, including both classical unstructured models and state-of-the-art structured ones.",
7318.txt,"Empirically, we show the cases where unstructured models can handle and where they fail to structured models in predicting and deciphering the brain activities.",
7319.txt,"Based on the empirical results, we clarify what features contribute most to predicting and deciphering the cortical activities.",
7320.txt,We also confirm different ROIs and DSM's selectivity to topics.,
7321.txt,"Our results not only corroborate and extend previous findings, highlight the value, and identify the potential of using DSMs to explain and decipher neural linguistic representations but also offer a deeper insight into the connection between the two manifestations of mental meanings: the neural activation patterns and the extrinsic linguistic representations.",
7322.txt,We hope that these could contribute to understanding cortical linguistic representations and developing machine-learning representation models in a mutual-promotion manner.,
7323.txt,"Recently, the use of portable equipment has attracted much attention in the medical ultrasound field.",
7324.txt,"Handheld ultrasound devices have great potential for improving the convenience of diagnosis, but noise-induced artifacts and low resolution limit their application.",
7325.txt,"To enhance the video quality of handheld ultrasound devices, we propose a low-rank representation multipathway generative adversarial network  with a cascade training strategy.",
7326.txt,"This method can directly generate sequential, high-quality ultrasound video with clear tissue structures and details.",
7327.txt,"In the cascade training process, the network is first trained with plane wave single-/multiangle video pairs to capture dynamic information and then fine-tuned with handheld/high-end image pairs to extract high-quality single-frame information.",
7328.txt,"In the proposed GAN structure, a multipathway generator is applied to implement the cascade training strategy, which can simultaneously extract dynamic information and synthesize multiframe features.",
7329.txt,The LRR decomposition channel approach guarantees the fine reconstruction of both global features and local details.,
7330.txt,"In addition, a novel ultrasound loss is added to the conventional mean square error  loss to acquire ultrasound-specific perceptual features.",
7331.txt,"A comprehensive evaluation is conducted in the experiments, and the results confirm that the proposed method can effectively reconstruct high-quality ultrasound videos for handheld devices.",
7332.txt,"With the aid of the proposed method, handheld ultrasound devices can be used to obtain convincing and convenient diagnoses.Index Terms?Generative adversarial networks , handheld ultrasound device, low-rank representation decomposition, multipathway dynamic information learning system, video high-quality reconstruction.",
7333.txt,"Handheld ultrasound devices can efficiently and conveniently acquire medical images and videos without radiation , which makes them burgeoning medical instruments.",
7334.txt,"In comparison to the high-end ultrasound equipment used in hospitals, handheld devices can reduce costs and are suitable for many specific situations, such as in telemedicine,community medicine, and rural medicine.",
7335.txt,These devices provide a cost-effective solution for the early screening of often-overlooked cancers.,
7336.txt,"In addition, with portable handheld ultrasounds, it is possible to perform on-site diagnoses under emergency circumstances.",
7337.txt,"Unlike the traditional computed tomography/magnetic resonance imaging modalities, clinical ultrasound diagnosis is usually based on videos but not static images; thus, abundant information and details can be captured that cannot be seen in a singleframe image.",
7338.txt,Handheld devices can provide an informative and dynamic diagnosis reference in many applications.,
7339.txt,"However, ultrasound examination with a handheld device has the drawback of low imaging quality due to hardware limitations.",
7340.txt,"To obtain high-quality ultrasound videos, many improvements to hardware, such as modulation and demodulation, and ultrasound transmission, receiving, and beamforming modules, have been proposed.",
7341.txt,"Although these methods have displayed some effectiveness, they involve tradeoffs between the imaging quality and equipment cost/portability.",
7342.txt,"Therefore, a new low-cost method that can preserve the small size of the device and improve the ultrasound video quality is in high demand.",
7343.txt,A video postprocessing approach is an alternative way to achieve this goal.,
7344.txt,The traditional video quality improvement solutions can be divided into two types.,
7345.txt,The first type is the image-based method.,
7346.txt,"It usually involves adjusting the gray-level distribution of a single-frame image or selecting a threshold to distinguish the useful information from noise, such as by the histogram equalization-based enhancement method  or the ultrasound speckle-noise reduction method, respectively.",
7347.txt,"However, the speckle in ultrasound images is multiplicative noise, and traditional image-based methods cannot determine a suitable threshold for denoising and may destroy useful information.",
7348.txt,"In addition, the lack of dynamic information may cause intensity discontinuity in the video.",
7349.txt,"The second type takes the adjacent frames into account so that more information can be applied to generate comprehensive details of the center frame, such as in the multiframe-based fusion method.",
7350.txt,"The multiframe-based fusion method avoids the over smoothing problem of single-frame-based methods and captures dynamic information, but it is difficult to reduce artifacts in ultrasound videos.Deep learning methods have displayed superiority in many fields.",
7351.txt,They are able to automatically and comprehensively learn the gray-level distribution differences between high- and low-quality images based on big data.,
7352.txt,"In previous studies, Dong proposed a deep superresolution convolutional neural network  that improved the natural image quality and verified the ability of the deep learning method to establish mapping relations between different types of data sets.",
7353.txt,"More recently, an image superresolution feedback network also showed good reconstructed performance by refining low-level representations with high-level information.",
7354.txt,"Beyond CNN methods, GAN-based structures were also introduced to solve image reconstruction problems.",
7355.txt,"Subsequently, many improved GAN variant methods were proposed.",
7356.txt,"For instance, an enhanced superresolution GAN was presented, which combines the advantages of both residual blocks and dense blocks to fully utilize the available hierarchical features.",
7357.txt,"In addition, an ultrasound single-frame-based GAN was proposed by our group to improve the quality of singleframe ultrasound images, and the results support the feasibility of extending the learning-based method to the ultrasound image reconstruction field.",
7358.txt,"However, these previous studies addressed only static images, and the methods cannot fully solve most video-related problems.",
7359.txt,"In X, a CNN trained with single-frame images was directly used to reconstruct video, but discontinuous problems may occur because the adjacent frame information was not considered.",
7360.txt,"To solve this problem, many deep networks take dynamic information into account .",
7361.txt,"For example, Li and Wang proposed a motion compensation and residual net that compensates for motion and improves the image resolution by using the adjacent frame information.",
7362.txt,This method highlights the auxiliary role of multiframe information in video reconstruction.,
7363.txt,"Inspired by these studies, we believe that a multiframe-based deep learning method can be adopted to improve the video quality of handheld ultrasound devices.",
7364.txt,"The learning-based video reconstruction method encounters the following challenges when addressing the current task: for video reconstruction, conventional image-based deep networks cannot capture dynamic information.",
7365.txt,"In contrast to other reconstruction problems with paired learning strategies, the high-/low-quality ultrasound videos of handheld devices and high-end equipment cannot be simultaneously scanned.",
7366.txt,"The different time series, different scanning positions and different probe movement speeds do not allow the handheld video to be coupled with a training reference.",
7367.txt,"A lack of dynamic information in the learning process will result in blur and discontinuities in the reconstructed video, especially for some moving organs, such as the heart and vessels.",
7368.txt,"In addition, changes in equipment and probes when scanning training pairs may lead to movement and misalignment problems, which negatively affect the reconstruction effect.",
7369.txt,"In singleframe reconstruction, an ultrasound image usually contains considerable noise and little anatomical information, making the data difficult to train.",
7370.txt,"In addition, since the ultrasound speckles have not only negative effects on image quality but also offer useful clinical information, we cannot destroy the speckle pattern.",
7371.txt,"However, the randomness of speckles also increases the convergence difficulty of deep networks.The conventional mean square error  loss in the reconstruction task usually leads to smoothing and distortion because of the lack of perceptual information.",
7372.txt,"However, all existing perceptual loss functions were proposed for natural images in which ultrasound-specific features are absent.",
7373.txt,"In this article, we propose a low-rank representation multipathway generative adversarial network  to improve the video quality of handheld ultrasound devices.",
7374.txt,"To overcome these problems, we introduce the following innovations: first, we introduce a cascade training strategy that consists of a dynamic learning phase and a refinement phase.",
7375.txt,The plane wave single-/multiangle video pairs are sent to a multipathway generator to learn the correlations among the multiple frames of the video.,
7376.txt,"In the dynamic learning phase, the handheld/high-end image pairs are further trained in a coarse-to-fine process to obtain a high-quality single-frame reference.",
7377.txt,"Second, LRR is adopted in the proposed GAN so that the network can learn the structural information and details.",
7378.txt,"In addition, the LRR provides a guide to the GAN training to remove the random noise while protecting the ultrasound speckle pattern.",
7379.txt,"Third, many unpaired high-end/handheld ultrasound images are adopted to train an ultrasound loss function so that the ultrasound-specific features can be acquired.",
7380.txt,This article is organized as follows.,
7381.txt,"In Section II, the methodology is provided.",
7382.txt,The materials and experimental procedureare presented in Section III.,
7383.txt,"In Section IV, an explanation for the experimental results is described.",
7384.txt,"The discussion is given in Section V. Finally, Section VI provides a brief conclusion of this article.",
7385.txt,An overview of the proposed LRR MPGAN is shown in Fig.,
7386.txt,1,
7387.txt,"The LRR MPGAN model consists of three MPGANs, each of which addresses an LRR channel.",
7388.txt,"The model is trained by a cascade training strategy, which adopts two types of training data sets, including the single-/multiangle PW video pairs and the handheld/high-end image pairs.",
7389.txt,"After the training process, the handheld ultrasound video can be directly obtained by merging the output of three LRR channels.The ultrasound video reconstruction task should enhance the quality of every single frame and take dynamic information into account.",
7390.txt,"In general, in conventional learningbased natural video reconstruction tasks, the mapping of both high-quality information and dynamic features can be directly obtained within a single training stage given the ideal aligned training pairs.",
7391.txt,"In the ultrasound video quality enhancement task, the high-quality training references scanned by the high-end ultrasound equipment are indispensable for achieving satisfactory quality enhancement.",
7392.txt,"However, because handheld devices and high-end equipment cannot simultaneously scan the same location, the video-based training pairs are unavailable.",
7393.txt,"The lack of dynamic features may lead to discontinuities in the reconstructed video, indicating that a single-training phase is insufficient.",
7394.txt,"Therefore, we propose a cascade training strategy that addresses single-/multiangle PW video pairs and handheld/high-end ultrasound image pairs to learn both dynamic information and high-quality reference information, as shown in Fig.",
7395.txt,2,
7396.txt,"In the dynamic learning phase, the single-/multiangle PW video pairs are adopted so that the LRR MPGAN can learn the relevant dynamic information and the connections between consecutive frames in the ultrasound video.",
7397.txt,"Different from the handheld/high-end ultrasound devices that adopt the linescan transmission mode, the PW ultrasound is an ultrafast transmission mode.",
7398.txt,"For the PW mode, radio frequency signals of single-/multiangle data can be acquired in the same time series.",
7399.txt,"The multiangle images are obtained using several PWs emitted by the transducer array in different directions, while the single-angle images can be generated by one of these successive steered emissions.",
7400.txt,"To obtain the compounded multiangle images, the coherent compounding proposed in X is adopted.",
7401.txt,"As shown in Fig.3, the single-/multiangle PW video pairs are similar to the handheld/high-end image pairs; specifically, the single-angle PW images are of low quality with abundant artifacts, and the multiangle PW images are of high quality with clear tissue structure and detail.",
7402.txt,"Based on these characteristics, the single-/multiangle PW video pairs can be regarded as ideal data for learning dynamic information and preliminary quality enhancement information.After registration, the aligned multiangle images in t ?1, t, a n d t +1 are fused by a conventional wavelet image fusion method proposed in X, which conducts an average operation for the underfused images in the wavelet field.",
7403.txt,"In the refinement phase, the handheld/high-end image pairs that can offer higher image-based quality enhancement information than the single-/multiangle PW video pairs are selected to fine-tune the generator in the dynamic learning phase.",
7404.txt,The handheld/high-end image pairs are overlapped to simulate static videos so that the two cascaded training phases can share weights.,
7405.txt,This process provides complementary information for GAN training.The ultrasound images usually show a granular appearance called speckle.,
7406.txt,"As a multiplicative signal, the noise-like speckles have not only negative effects on image quality but also offer useful clinical information for diagnostic ultrasound imaging.",
7407.txt,"Therefore, in our research, the proposed method is designed to enhance video quality while preserving speckle information.",
7408.txt,"To guarantee that GAN training has a fine reconstruction effect for both local and global features, we introduce the LRR decomposition process into the proposed GAN.",
7409.txt,"In the LRR decomposition, the original ultrasound images are decomposed to a low-rank part and a sparse part.",
7410.txt,The LRR decomposition assumes that data samples D are approximately comprised of several low-dimensional subspaces  and aims to find the lowest-ranking representation among all candidates that can represent data samples as linear combinations.As shown in Fig.,
7411.txt,"4, the low-rank part contains a fine basic structure of tissues, but the details and the speckle texture are filtered out.",
7412.txt,"The sparse part includes much of the speckle appearance and sharpness details, which are masked by noise.",
7413.txt,"Comparing the decomposed parts of handheld and high-end ultrasound images, the low-rank parts between the two data sets are mainly the contrast gap, while the difference in the sparse parts is principally the speckle quality and noise level.",
7414.txt,"Hence, except for the original data, the low-rank and sparse parts are also input to the MPGAN in parallel to specifically reconstruct the structure and detail in ultrasound images.",
7415.txt,"In total, the proposed LRR MPGAN contains three parallel training channels.",
7416.txt,The three channels are adopted to address three complementary tasks.,
7417.txt,The low-rank part learns the contrast difference between high-/low-quality images to highlight tissue structures.,
7418.txt,The sparse part learns to generate the speckle appearance in high-quality images and remove harmful noise from low-quality images.,
7419.txt,The original part is used to provide a comprehensive reconstruction rule.,
7420.txt,"The multipathway generator of each channel has the same structure but different weights, which are trained with the original input, the low-rank part and the sparse part of the input image pairs.",
7421.txt,"The reconstructed result is generated by averaging the outputs of the three different generator branches in the merged layer in the testing stage.Multipathway Generator: In the proposed MPGAN, a multipathway generator is designed to learn the relationship between adjacent frames in an ultrasound video through the deep feature-level fusion and attention system.",
7422.txt,The detailed structure of the multipathway generator is shown in the upper part of Fig.,
7423.txt,5,
7424.txt,"Three sequential frames are first sent to three different pathways, each of which contains a convolutional layer with a rectified linear unit  to extract shallow features, such as oriented edges, followed by three residual blocks to improve the representativeness of the generator.",
7425.txt,"Each residual block contains a shortcut connection to solve the vanishing gradient problem, which connects the previous layer with the current layer by an elementwise sum operation.",
7426.txt,"Then, the adjacent frame attention  and selfattention  layer is applied, which is shown in Fig.",
7427.txt,6,
7428.txt,"In the dynamic learning phase, three pathway inputs are single-frame images at three consecutive time steps t?, t, and t+1.",
7429.txt,"Three pathways are joined by the AFA layer, which correlates the dynamic feature.",
7430.txt,"In the refinement phase, although training pairs do not contain dynamic information, we overlap three training images as three pathway inputs to simulate static videos so that all weights can be shared in the cascade training strategy.",
7431.txt,"In addition, the AFA layer is turned to an SA layer in the refinement phase.",
7432.txt,"The SA layer has the same structure but a different function, which is used to establish the longrange dependencies of the global features in each single-frame image.The matrix multiplication and elementwise sum operation of the AFA layer in the dynamic learning phase ensure that the MPGAN learns the dynamic information, and the SA layer in the refinement phase facilitates capturing the global features so that satisfactory reconstruction results can be obtained.",
7433.txt,"After the AFA/SA layer, the feature maps of the three pathways collected, and four additional residual blocks are adopted to further adjust the representativeness of the generator and perform the deep feature fusion.",
7434.txt,"Finally, three convolutional layers with the ReLUs are adopted to generate the final reconstructed image at time t.  Discriminator: The proposed discriminator consists of multiple convolutional layers, each of which is followed by a ReLU activation function and batch normalization.",
7435.txt,"Subsequently, an elementwise sum operation is processed to connect the previous layer with the current layer.",
7436.txt,"Next, a flattened layer and a dense layer with a sigmoid function are applied to distinguish the input and contribute to the adversarial loss.",
7437.txt,The structure of the discriminator is shown in the lower part of Fig.,
7438.txt,"5.Wasserstein Loss: In the conventional GAN, the adversarial loss function adopts JensenShannon divergence to evaluate the training status.",
7439.txt,"However, the JS divergence may result in drawbacks of the vanishing/exploding gradient issues and an imbalance between generators and discriminators.",
7440.txt,"The Wasserstein loss is presented in X to solve this problem, which introduces the Wasserstein distance instead of JS divergence to successfully avoid the problem.Content Loss With Ultrasound-Specific Features: The content loss is composed of MSE loss and ultrasound-specific perceptual loss.",
7441.txt,The MSE loss is selected as a component of the proposed content loss.,
7442.txt,"This loss function is widely used to solve regression problems and can provide a learning direction for the proposed GAN to minimize the pixelwise error between the generated image and the corresponding reference image.The MSE loss usually leads to distortion and over smoothing due to its lack of perceptual information; therefore, many studies have introduced the perceptual loss.",
7443.txt,"However, the existing CNN-based perceptual losses are mainly pretrained from relatively accessible natural images, which are not quite suitable for medical image processing tasks.",
7444.txt,An ultrasound-specific perceptual loss function can provide more accurate guidance for the handheld ultrasound reconstruction task.,
7445.txt,As shown in Fig.,
7446.txt,"7, the ultrasound-specific perceptual loss is obtained with an ultrasound loss network, which is a multilayer classification CNN trained using a large unpaired data set.",
7447.txt,The conventional softmax loss function of the classification network is replaced by an MSE loss to evaluate whether the quality of the input ultrasound image is high.,
7448.txt,"The labels of high-end images and handheld images are set as 1 and 0, respectively.",
7449.txt,The output of the second dense layer of the ultrasound loss network is a one-channel value that can be regarded as the ultrasound image quality score.,
7450.txt,"In the training process, the input will be categorized as a high-quality image when the quality score is higher than 0.5; otherwise, the input will be categorized as a low-quality image.",
7451.txt,"With this rule, the quality score is close to 1 when testing a high-quality image, and the score is close to 0 when testing a low-quality image.",
7452.txt,"The final ultrasound perceptual loss can be expressed as follows.In the dynamic learning phase of the experiment, 80 pairs of PW single-/multiangle videos were used.",
7453.txt,"The data were obtained by a 6.25-MHz, 128-element transducer array with a pitch of 0.3 mm.",
7454.txt,The array was used to scan different body parts on 20 healthy volunteers with 75 different scan angles uniformly distributed from ?6to 16?,
7455.txt,We selected three continuous images in each single-angle video as the input samples; the corresponding compounded images synthesized at 75 different angles were obtained as the reference data.,
7456.txt,"The beamforming and compounding methods were the standard delay-and-sum and coherent methods , respectively, in this experiment.",
7457.txt,"In the refinement phase of the experiment, 188 pairs of clinical data were used.",
7458.txt,"The high-end Toshiba Aplio 500 device  and the android-based portable mSonics MU1 apparatus  with an L10-5 transducer were applied to obtain high-quality references and low-quality samples, respectively.",
7459.txt,"The data pairs were obtained by scanning 47 healthy volunteers, and scanning was performed by an experienced sonographer.",
7460.txt,"To minimize the movement between each training pair, a cross-shaped landmark point was utilized to ensure that the two probes of the devices scanned at the same location.",
7461.txt,"In the testing stage, 40 ultrasound videos from the handheld devices were evaluated.",
7462.txt,"The videos were obtained by scanning different body parts of eight healthy volunteers, including the thyroid, carotid artery and thigh muscle.",
7463.txt,Each video contained 60 frames with a frame rate = 15.,
7464.txt,"To obtain a robust ultrasound loss network, 500 unpaired low- and high-quality images scanned by the mSonics MU1 apparatus and Toshiba Aplio 500 device were utilized.",
7465.txt,"The unpaired data were easier to acquire than the paired data and included 500 images of high-/low-quality data scanned by high-end/handheld devices to maintain a balance among samples.A series of data preprocessing steps, including data augmentation, registration, normalization, and LRR decomposition, was implemented.",
7466.txt,"First, to prevent the overfitting problem, data augmentation was performed for all data, which increased the amount of data by eightfold through cropping, rotation, scaling and vertical/horizontal flipping.",
7467.txt,"Second, because the handheld/high-endultrasound data cannot avoid the movement issue caused by human interference, the same registration method that was used in X was applied with a multiangle data registration module in the dynamic learning phase to further reduce the misalignment of the training pairs scanned by the two devices.",
7468.txt,"Third, to accelerate network training, a zero-mean normalization method was adopted.",
7469.txt,The ultrasound loss network was trained before GAN training.,
7470.txt,We used fivefold cross-validation to evaluate the training state during each iteration so that the underfitting/overfitting could be detected and adjustments could be made during the training process.,
7471.txt,The Adam optimizer was applied with an initial learning rate of 0.001.,
7472.txt,A threshold of 1000 epochs is set for the training process to converge.,
7473.txt,The batch size is 8.,
7474.txt,"During GAN training, fivefold cross-validation and the RMSProp optimizer were applied.",
7475.txt,"The updated hyperparameters of the discriminator were clipped to [?.01, 0.01] to enforce the Lipschitz constraint on the discriminator.",
7476.txt,"In the dynamic learning phase, we set the learning rate = 10?, batch size = 4, and the total number of epochs = 600.",
7477.txt,The content loss considered in this stage was MSE loss and VGG loss.,
7478.txt,"In the refinement phase, the parameters in layers before the SA layer were fine-tuned with a learning rate = 10?, and the other parameters were fine-tuned with the learning rate = 10?.",
7479.txt,"In addition, we set the weight decay = 0.01, the batch size = 4, and the total number of epochs = 500.",
7480.txt,The data preprocessing and result in evaluation steps were performed with MA TLAB.,
7481.txt,"The GAN training process was conducted in the TensorFlow library on a Dell 7910 workstation, and an NVIDIA Titan X graphic processing unit  was adopted to increase the training speed.",
7482.txt,The comparison methods can be divided into nonlearningbased methods and learning-based methods.,
7483.txt,"The nonlearningbased methods include the dynamic HE  method , ultrasound speckle-noise reduction method , and advanced discrete wavelet transform fusion method.",
7484.txt,"The learning-based methods include the SRCNN , and ultrasound single-frame-based GAN.",
7485.txt,"The DHE method proposed in X divides the image histogram into three partitions by the local minima, and then the gray-level ranges of each partition are separately assigned to equalize them.",
7486.txt,The amount of emphasis given to frequency x was set to 0.,
7487.txt,"The ultrasound speckle-noise reduction method proposed in X uses a Fourier filter, whose cutoff frequency was set to 20% to reduce the multiplicative speckle noise in ultrasound images scanned by handheld devices.",
7488.txt,The aDWT fusion method selects the nearest four frames to the center frame to synthesize a high-quality image with abundant information.,
7489.txt,We decomposed all inputs using the wavelet transform and adopted principal component analysis as the fusion method.,
7490.txt,The minimal length of the transformed image by the DWT was set to 2.,
7491.txt,The SRCNN comparison method proposed in X adopts the sparse coding-based superresolution approach; the resolution expanding rate was set to 1 in this study to learn the quality differences only between high/low image pairs.,
7492.txt,"The learning rate was set to 10?in the first two layers and 10? in the other layers, and the number of training epochs was 500.",
7493.txt,"In the reimplementation of the ESRGAN method, the learning rate was set to 10?, and the weight decay factor was 10?.",
7494.txt,"Moreover, the training process roughly converged after 800 epochs.",
7495.txt,The SRFBN method was implemented in the highquality reconstruction task by setting the expanding scale to 1.,
7496.txt,"The learning rate was set to 10?, and the number of training epochs was 500.",
7497.txt,The ultrasound single-frame-based GAN employs the same setting as that used in X.,
7498.txt,"The learning rate of the transferred and nontransferred portion was set to 10?and 10?, respectively, while the training epochs of the dynamic learning phase and the refinement phase were set to 500 and 650, respectively.Because an ultrasound video scanned by a handheld device cannot have a corresponding high-quality video reference because of the difference in the time series, we used a single frame in each handheld video and selected the most similar frame in the high-end video as the evaluation reference to obtain an accurate quality evaluation with full reference indices.",
7499.txt,"In addition, to evaluate the entire period of the video, nonreference evaluators were adopted, and the average measurement values for each video were calculated.",
7500.txt,"In the experiment, three full-reference measurement indices, including the peak signal-to-noise ratio, structural similarity index , and MI, were used to evaluate the quality of the single-frame image in the ultrasound video.",
7501.txt,"The PSNR is a widely used measurement to evaluate the quality of a reconstructed image, and it reflects the pixelbased similarity between the reconstructed image and the corresponding reference.",
7502.txt,The SSIM can predict the perceived quality and assess the perceptual-based similarity between paired images scanned by handheld devices and high-end equipment.,
7503.txt,"The MI measures the mutual dependence between the reconstructed image and the high-quality reference, and it reflects their information-based similarity.",
7504.txt,"Two no-reference measurements, including the naturalness image quality evaluator and ultrasound quality score, were adopted to evaluate the quality of the generated video.",
7505.txt,"The NIQE is an advanced no-reference image quality measurement for natural images that reflects the quality of medical images, as verified in X.",
7506.txt,The NIQE fits a reference model by extracting features from the images obtained by high-end devices.,
7507.txt,A small NIQE score indicates high perceptual quality.,
7508.txt,"The ultrasound quality score is generated by the proposed ultrasound loss network, and this approach has a robust ability to distinguish image quality differences between handheld and high-end ultrasound images.",
7509.txt,The ultrasound measurements can specifically monitor the ultrasound features and provide perceptual-based evaluation information.,
7510.txt,"To further evaluate the stability and continuity of the reconstructed video of different methods, the vessel area variation curves in all thyroid images in the test data set were drawn.",
7511.txt,"To obtain accurate and convincing comparison results, each thyroid vessel frame was manually segmented five times by different people.",
7512.txt,The vessel area variations were recorded by calculating the average number of pixels in the vessel in each single-frame image throughout the entire video.,
7513.txt,"A clear curve of blood vessel expansion and contraction is expected.In this section, we first evaluate the contribution of each component of the proposed GAN structure.",
7514.txt,"Then, the performance of different loss functions is assessed, and finally, we compare the video continuity and quality of the proposed method with other approaches.",
7515.txt,The performance of each component of the LRR MPGAN was evaluated.,
7516.txt,"The ablation experiments include a singlepathway GAN with only dynamic learning phase, a singlepathway GAN with only a refinement phase, a single-pathway GAN with cascade training, MPGAN with cascade training, and LRR MPGAN with cascade training.",
7517.txt,The comparison results are presented in Fig.,
7518.txt,8 and Table I.,
7519.txt,"As shown in Fig.8, the reconstructed images generated by single-pathway GAN with only a dynamic learning phase show a highlighted tissue boundary but poor denoising performance.",
7520.txt,"The PSNR, SSIM, MI, and ultrasound quality scores are increased by 42.98%, 41.67%, 16.90%, and tenfold, respectively, and the NIQE are decreased by 31.67%.",
7521.txt,As shown in Fig.,
7522.txt,"8, the artifacts are reduced due to the reconstruction of single-pathway GAN with only the refinement phase.",
7523.txt,"Although the similarity measurements are improved, the visualization performance is not good.",
7524.txt,This is because the references of these similarity measurements and the GAN training targets of the refinement phase are both high-end ultrasound image data sets.,
7525.txt,"The handheld/high-end training pairs of this phase are semialigned, which negatively influence the GAN training and cause distortion.",
7526.txt,The single-pathway GAN with cascade training combines the merits of the dynamic learning phase and the refinement phase.,
7527.txt,"Although the similarity measurements are even, the nonreferenced measurements  have considerable improvements.",
7528.txt,"The visualization performance also verifies the effectiveness of the cascade training strategy, which can generate an output with fewer artifacts and less distortion.",
7529.txt,"However, the reconstructed results are still blurred with poor contrast.",
7530.txt,By comparing Fig.,
7531.txt,"8 with X, it can be seen that the MPGAN with cascade training generates better image contrast and maintains considerable speckle information.",
7532.txt,"Compared with the singlepathway GAN, the multipathway GAN achieves increases of 3.08%, 7.32%, 3.16%, and 10% for the PSNR, SSIM, MI, and ultrasound quality score, respectively, and a decrease of 12.54% for the NIQE.",
7533.txt,As shown in Fig.,
7534.txt,"8, the reconstructed images generated by the LRR MPGAN with cascade training have the highest quality, showing clear blood vessel boundaries and tissue details.",
7535.txt,"The performances of the proposed content loss functions are evaluated by comparing the results of LRR MPGAN with the cascade training strategy generated by difference content loss components, including MSE loss, MSE loss and the proposed MSE ultrasound loss.",
7536.txt,The results of the ablation study are shown in Fig.,
7537.txt,9 and Table II.,
7538.txt,"The reconstructed results of the MSE loss have less noise and better contrast than the original handheld input, but the textural features and details are fuzzy.",
7539.txt,"The PSNR, SSIM, MI, and ultrasound quality score obtained by the proposed GAN with only MSE loss are 45.27%, 70.83%, 43.66%, and are 13-fold higher, respectively, than those of the low-quality ultrasound input scanned by the handheld device, and a 51.08% decrease in the NIQE is achieved.",
7540.txt,"The reconstructed results of the MSE + VGG loss are sharpened, but the distortion in both the tissue structure and speckle information becomes an issue.",
7541.txt,"Overall, the proposed MSE + ultrasound loss generates the highest image quality, demonstrating satisfactory contrast, clear details, and fine speckle information.",
7542.txt,"The measurement values obtained by the proposed MSE + ultrasound loss are superior to those of the other functions, with increases as high as 5.89%, 4.65%, and 7.23% for the PSNR, SSIM, and ultrasound quality score and a decrease of 16.57% for the NIQE.A comparison between the proposed method with other comparison methods is shown in Fig.",
7543.txt,10 and Table III.,
7544.txt,"To obtain a convincing evaluation, comprehensive methods, including the natural-based DHE method, ultrasound imagebased speckle-noise reduction method, aDWT fusion method, SRCNN, ESRGAN, SRFBN, and ultrasound single-framebased GAN, are adopted for comparison.",
7545.txt,"As shown, the reconstructed result of the DHE method improves the contrast significantly but oversharpening occurs, leading to decreases in PSNR, SSIM, and MI values and an increase in NIQE.",
7546.txt,Only the ultrasound quality score displayed improvement .,
7547.txt,"Inversely, the reconstruction result of the ultrasound speckle reduction method was over smoothed with poor contrast.",
7548.txt,"The PSNR, SSIM, and MI displayed small increases of 3.08%, 4.17%, and 4.23%, respectively, compared with those of the handheld ultrasound image, but the ultrasound quality score was lower than those of the DHE method.",
7549.txt,"The aDWT fusion method yields moderate contrast without losing much detail, but the artifacts in the handheld ultrasound video are not removed.",
7550.txt,"The PSNR, SSIM, and MI obtained by the aDWT fusion method are higher than those of the DHE method but lower than those of the ultrasound speckle reduction method.",
7551.txt,"Compared with these non-learning-based methods, the learning-based method obtains a better artifact reduction effect, as shown in Fig.",
7552.txt,"10, and all measurement values show significant improvements.",
7553.txt,"The reconstruction results of the SRCNN include highlighted structural contours, but some detailed information disappears.The ESRGAN method can avoid over smoothing, but the masked artifacts were not removed well.",
7554.txt,The evaluation measurements obtained by the ESRGAN method reflect worse quality than those obtained by the SRCNN.,
7555.txt,"The SRFBN achieved a better visualization effect than the SRCNN and ESRGAN methods, but the speckle texture and details display slight distortion, as shown in the lower magnified red box.",
7556.txt,"The NIQE has a 53.47% decrease, indicating a great improvement in global perceptual quality.",
7557.txt,The ultrasound single-frame-based GAN ameliorates the distortion of speckle texture and details in SRFBN.,
7558.txt,"However, some local artifacts still occur, and the tissue structure still needs to be strengthened.",
7559.txt,"The PSNR, SSIM and MI are similar to those of SRFBN, while the NIQE and ultrasound quality score exhibit a 9.64% decrease and 12% increase, respectively.",
7560.txt,"Overall, the reconstruction results obtained by the proposed method exhibit the best perceptual quality, with clear tissue edges and rich details.",
7561.txt,"In addition, 57.33%, 87.50%, 47.89%, and 15-fold increases are observed in the PSNR, SSIM, MI, and ultrasound quality score, respectively, compared with those of the original video, and a 64.32% decrease in NIQE is achieved.",
7562.txt,"To evaluate the stability of the reconstructed video, we recorded the thyroid vessel area variation curve by calculating the average number of pixels in the segmented area throughout the entire video.",
7563.txt,V essel area in every single frame was manually segmented five times by different doctors to obtain accurate and convincing comparison results.,
7564.txt,"Each vasodilatation and vasoconstriction is labeled by squares and circles, respectively.",
7565.txt,As shown in Fig.,
7566.txt,"11, the vessels expand three times in the illustrated period.",
7567.txt,"In Fig.11, the curve is not smooth because the artifacts of the original handheld video negatively affect the observation and lead to incomplete segmentation of the unclear edge masked by noise.",
7568.txt,"In Fig.11, we compare the proposed method with the nonlearning-based fusion method; the vessel area of vasodilatation and vasoconstriction of the red curve is more consistent, indicating better stability of the reconstructed video obtained by the proposed method.",
7569.txt,"In Fig.11, we compare the proposed method with the ultrasound single-frame-based GAN method.",
7570.txt,The purple curve is more stable than the green curve of Fig.,
7571.txt,"11 but not as smooth as the red curve, and the vessel area of the third vasodilatation exhibits a sharp increase, indicating that the comparative single-frame-based GAN method alleviates the obstacle produced by artifacts of the handheld video, but its reconstructed video shows less continuity than that of the proposed method.",
7572.txt,"The proposed LRR MPGAN is elaborately designed to enhance the quality of ultrasound video scanned by ultrasound handheld devices, which can effectively generate high-quality ultrasound videos.",
7573.txt,"In this section, our research is adequately discussed from different perspectives.",
7574.txt,"First, as mentioned in Section IV-A and IV-B, each component of the proposed method contributes to reconstructing a high-quality ultrasound: 1) To learn the dynamic information in an ultrasound video, the cascade training strategy is presented.",
7575.txt,The results obtained by only the dynamic learning phase training process encounter problems associated with grainy noise because of the discrepancy between single-/multiangle PW training pairs and the target task .,
7576.txt,The results obtained by only the refinement phase training process are distorted because of the semialigned high-end/handheld training pairs.,
7577.txt,Multipathway generator and the AFA/SA layer are applied to simultaneously extract multiframe features and synthesize them.,
7578.txt,"The reconstructed image of the proposed method has more abundant details than that of the single-pathway generator, which indicates that the neighboring frames can provide supplementary information.",
7579.txt,"To facilitate the GAN training and achieve a balance between the structure and detail reconstruction, LRR decomposition is employed.",
7580.txt,As verified in Fig.,
7581.txt,"7, the reconstruction results of the LRR MPGAN have less noise and realistic speckle information.",
7582.txt,The parallel training of low-rank and sparse parts provides balanced guidance for GAN training.,
7583.txt,The combination of MSE loss and ultrasound loss ensures that LRR MPGAN can extract both pixel-based information and ultrasound-specific perceptual features.,
7584.txt,As shown in Fig.,
7585.txt,"8 and Table II, the MSE + ultrasound loss performed better than the MSE + VGG loss function because VGG loss can only provide the perceptual features of natural images.",
7586.txt,"Second, we note some specific findings by comparing the proposed method with other methods.",
7587.txt,"Nonlearning-based methods contribute to limited quality enhancementand provide problems, such as over smoothing and over contrast.",
7588.txt,The lack of referenced information results in poor similaritybased measurements.,
7589.txt,The DHE method stretches the graylevel distribution to reestablish a similar histogram to the referenced high-quality ultrasound image scanned by a highend device.,
7590.txt,"However, the transformation does not consider ultrasound features and improperly highlights noise.",
7591.txt,"The ultrasound speckle denoising method reduces the speckle noise in images from a handheld device, but the speckle pattern reflects some physiological information that should not be completely removed.",
7592.txt,"In addition, handheld images contain more artifacts than conventional B-mode ultrasound ones, which leads to worse performance in addressing the target handheld task.",
7593.txt,"The aDWT fusion method enhances the image quality by synthesizing the neighboring frames, which can indeed provide increased information, but the poor quality of
handheld video leads to limited valid information and noise that cannot be effectively distinguished by the fusion rule.",
7594.txt,"In terms of learning-based methods, the reconstruction results are superior to the nonlearning-based method contributed to the prior information provided by the high-end image data set.",
7595.txt,The SRCNN method has better full referenced measurements.,
7596.txt,"However, the perceptual effect obtained by SRCNN is fuzzy, as has been noted in many other studies , which illustrate the limitation of reconstructing the details of the CNN structure.",
7597.txt,The ESRGAN can extract hierarchical features and take full advantage of them in the training stage.,
7598.txt,"However, the distortion problem that occurred in the ESRGAN results suggests that ignoring some hierarchical features may be a potential choice when training with semialigned data pairs.",
7599.txt,"The SRFBN methods obtain better denoising effects than ESRGAN, which may be caused by the curriculum learning strategy.",
7600.txt,"The reconstructed step-by-step strategy of SRFBN makes it more suitable for addressing a semialigned data set, but the lack of an ultrasound-specific reference reduces its effectiveness in this task.",
7601.txt,"The ultrasound single-framebased method takes the ultrasound feature into account and can obtain considerable results; however, the video-based information is not used in this method.",
7602.txt,The proposed LRR MPGAN method effectively solves the problems of the above learning-based methods.,
7603.txt,"Third, the proposed method is now suitable for retrospective processing of the achieved handheld video.",
7604.txt,"Among all learning-based comparison methods, the SRCNN method is a lightweight structure with only three convolutional layers and the fewest parameters .",
7605.txt,Other learningbased comparison methods have a more complicated structure and more parameters.,
7606.txt,"The parameter number of the proposed method is 7.0  107, which is approximately twofold and 43% compared with that of the SRFBN method and ESRGAN method, respectively, and is similar to that of the ultrasound singleframe-based GAN method.",
7607.txt,"With the aim of reducing memory usage, mixed precision was adopted.",
7608.txt,This approach helps our method save 30% of GPU memory.,
7609.txt,"In future work, it is anticipated that high-quality video will be directly generated as a postprocessing algorithm embedded in the handheld device.",
7610.txt,"Therefore, future work will focus on improving the time consumption and memory usage while maintaining the original quality enhancement effectiveness.",
7611.txt,"A lightweight and rapid algorithm will enable handheld ultrasound devices to generate real-time, high-quality videos in diagnostic scenarios.",
7612.txt,"In this article, an LRR MPGAN method was proposed to enhance the ultrasound video quality scanned by handheld devices.",
7613.txt,The proposed framework can effectively reconstruct both global features and local details with LRR decomposition channels.,
7614.txt,"To utilize the multiframe information in ultrasound video, a cascade training strategy is introduced.",
7615.txt,"The cascade training includes the dynamic learning stage, which is pretrained by the PW single-/multiangle video pairs, and the refinement stage, which captures high-quality reference information via fine tuning with handheld/high-end image pairs.",
7616.txt,"To integrate the video-based information, a multipathway generator is adopted.",
7617.txt,"In addition, we combined conventional MSE loss with a novel ultrasound loss to acquire ultrasoundspecific perceptual loss information.",
7618.txt,The experimental results confirmed that the proposed method could reconstruct handheld ultrasound videos with high quality and continuity.,
7619.txt,"Using this approach, handheld devices can be more widely used in many clinical applications.",
7620.txt,We investigate feature stability in the context of clinical prognosis derived from high-dimensional electronic medical records.,
7621.txt,"To reduce variance in the selected features that are predictive, we introduce Laplacian-based regularization into a regression model.",
7622.txt,"The Laplacian is derived on a feature graph that captures both the temporal and hierarchic relations between hospital events, diseases, and interventions.",
7623.txt,"Using a cohort of patients with heart failure, we demonstrate better feature stability and goodness-of-fit through feature graph stabilization.",
7624.txt,"Stability promotes reliabilityin performance, estimation, or interpretability.",
7625.txt,"Commonly, stability relates to robust performance against reasonable perturbations in data, achieved through diverse methods such as Jackknife, bootstrap, or cross validation.",
7626.txt,"The stability of selected features is often overlooked in prediction modelsparticularly, if consistent performance alone is the goal.",
7627.txt,But feature stability matters.,
7628.txt,Even when the prognosis performance is robust.,
7629.txt,"When building models from high-dimensional data, feature selection algorithms choose a small subset of features that maximizes the model performance.",
7630.txt,"These features, predictive of the prognosis, are important because they could be hypothesis generating thus meriting further investigation.",
7631.txt,"In clinical situations, explaining the prognosis is as important as the prognosis itself.",
7632.txt,"Consequently, consistent predictors in spite of data resampling are critical for the clinical adoption.",
7633.txt,"Feature stability is crucial not only in clinical prognosisas example, stable biomarkers aid model reproducibility in bioinformatics.",
7634.txt,Building clinical prediction models from electronic medical records faces serious challenges for stable feature selection.,
7635.txt,"EMR data are temporal, strongly correlated, and high dimensional.",
7636.txt,Each of these aspects makes this task challenging.,
7637.txt,High-dimensional data calls for sparsity inducing feature selection .,
7638.txt,"However, automatic feature selection, particularly in clinical data, has been known to cause instability in features resulting in nonreproducible models .",
7639.txt,This problem is further aggravated by strong correlations in EMR data.,
7640.txt,Sparse modelsoften pick the strongest features from the chosen sample set.,
7641.txt,"Under data resampling, an alternate feature from the correlated pair could be selected causing significant variations to the feature weights during each training run .",
7642.txt,This problem is illustrated in Fig.,
7643.txt,"1,the mean weights of the top 50 predictors from routine EMR data for six months readmission for heart failure is shown.",
7644.txt,"The top predictors selected by the lassoregularized model  have large variance in feature weights under bootstrapsthus, rendering them unusable in a clinical setting.",
7645.txt,Addressing the open problem of stable feature selection in clinical settings we askCan we ensure the stability of predictors in a linear model for prognosis using EMR data?,
7646.txt,"To measure the performance of this stability, we adopt variance in selected model parameters across data resamplings.",
7647.txt,"For prognosis, we use a logistic regression model for six months readmission after heart failurea deadly and costly disease with a majority of patients returning within a year after discharge.",
7648.txt,Automatic feature selection was achieved by the sparsity-promoting shrinkage method of lasso.,
7649.txt,"To address our problem, we hypothesize that exploiting the inherent structures of EMR data to enforce statistical sharing may stabilize the prediction model.",
7650.txt,We consider temporal and hierarchical structures.,
7651.txt,"Since features are accumulated over multiple time granularities , features that lie in consecutive time periods are considered to be related.",
7652.txt,The hierarchies are exploited through the semantics in the ICD-10 tree1and the procedure cubecodesthat share similar prefix are considered to be related.,
7653.txt,We embed these relations in a feature graph.,
7654.txt,"When the feature graph regularization term is added into the lasso model, weights assigned to related features will tend to be similar.",
7655.txt,"The model was derived from feature rich EMR records of 1 405 patients from Barwon health, a regional hospital in Australia.",
7656.txt,The model estimation was stabilized by utilizing a 3338  3338 feature graph constructed from hierarchical relations in ICD-10 disease tree and temporal abstraction of clinical events.,
7657.txt,"We used the Jaccard Index and Consistency Index to measure feature stability of the top features selected, with and without graph stabilization.",
7658.txt,We further compared the robustness of the features from our graph stabilized model with state-of-the-art elastic net regularized model .,
7659.txt,Both Jaccard Index and Consistency Index confirmed better feature stability for the feature graph-regularized model.,
7660.txt,"The graph stabilized model also resulted in better goodness-of-fit as confirmed by the HosmerLemeshow test., which is competitive against existing models that predict heart failure readmission.",
7661.txt,Our novelty is to identify the importance of the stable feature selection problem in clinical settings and to propose a solution based on additional regularization of a lasso model exploiting knowledge about hierarchical structures in disease and interventions and temporal relationships between events.,
7662.txt,"Specifically, embedding these relations reduces the fragmentation of selection in the lasso model, delivering our goal of feature stability.",
7663.txt,"The significance of our contribution is to reset the thinking of prognosis from ""model performance only"" to ""model performance and feature stable models""without these two components, many of our advanced models will be rendered futile in a clinical setting.Despite advances in learning models for high-dimensional data, stability in feature selection has received limited attention.",
7664.txt,Initial studies focused on comparing different feature selection algorithms based on stability of feature preferences.,
7665.txt,Kalousis compared the stability of fivepopularfeature selection algorithms on 11 datasets taken from three different application domains.,
7666.txt,"Feature stability was investigated based on weight-scores, rank, and selected feature subsets.",
7667.txt,No algorithm was found to be superior and it was concluded that feature stability depends significantlyonthedatasetused.Anotherfocus in stability studies is the development of various measures of stability.,
7668.txt,A recent survey  consolidated seven metrics for computing similarity measure of feature subsets.,
7669.txt,"Feature instability has been a serious concern to the bioinformatics domain, largely due to the nature of data.",
7670.txt,"Early work on this topic proposed ensemble ranking, feature bias from prior knowledge, and grouping redundant data.",
7671.txt,Recent studies utilize prior biological knowledge and pathway information to enhance the stability of biomarkers.,
7672.txt,"These information, compiled from many years of research, is made available through online databases like KEGG, HPRD, Pathway Commons,Reactome, BioCarta, and BioCyc.",
7673.txt,Context specific data extracted from such databases can be used to create a graph network with nodes as genes or gene products and edges as interactions or relationships.,
7674.txt,Such networks can be used to stabilize learning models by either a filter-based approach or using an embedded feature selection techniques.,
7675.txt,A natural solution to this problem is to select a subset of features from prior clinical knowledge.,
7676.txt,A recent study used only a subset of EMR features for predicting heart failure readmission .,
7677.txt,Our work is inspired from the bioinformatics domain of using network information to stabilize high-dimensional models.,
7678.txt,We differ from the traditional approach in feature stability by constructing the feature network graph from an inherent structure and relations in the training data.,
7679.txt,The feature graph is used to stabilize a lasso-regularized linear model for predicting heart failure readmission in six months.,
7680.txt,We wish to emphasize that the feature extraction process and construction of feature graphs depend solely on the hierarchical and temporal nature of EMR data and is not based on prior studies or predefined clinical knowledge.We present a stabilizing method for building prediction models from EMRs.,
7681.txt,A typical EMR is very high dimensional.,
7682.txt,It consists of demographic information  and time-stamped events.,
7683.txt,High-dimensional data necessitate automatic feature selection.,
7684.txt,We choose the sparsity-promoting shrinkage method of lasso  as it is effective in handling very highdimensional variables.,
7685.txt,"The methods are applicable to any member in the family of generalized linear models.Unfortunately, sparsity-inducing models are susceptible to data variations resulting in loss of stability .",
7686.txt,"For strong but highly correlated features, lasso often chooses one of the two , resulting in only a 0.5 chance for strongly predictive feature pairs.",
7687.txt,"EMR-derived features amplify this selection instability because of  the high degree of redundancy in hospital-recorded events and a large portion of features could be weakly predictive for some tasks, leading to low selection probabilities .",
7688.txt,"One popular solution to the correlated features is elastic net , which modifies the lasso regularization in X as follows:We propose an alternative solution by encouraging shared statistical strength among correlated features.",
7689.txt,This is achieved by exploiting two relational structures in the EMR data.,
7690.txt,The first is the temporal relations that accumulates events at different time granularities .,
7691.txt,The second is the hierarchical structures captured through the disease classification semantics in the ICD-10 diagnosis tree and procedures codes.,
7692.txt,An undirected feature graph is then built with its edges representing the relations between two features.,
7693.txt,"Sharing statistical strength between any two related features is realized by enforcing the similarity in their weights, a graph-regularizing term is added to X.The Laplacian regularizer combats the instability in several ways.",
7694.txt,"First, features of the same type tend to cluster, and thus, their weights are more difficult to vary as a whole.",
7695.txt,Weaker features can thus borrow the statistical strength from the stronger ones.,
7696.txt,"Second, two strongly correlated features must either be selected or jointly suppressed by the lasso.",
7697.txt,Fig.,
7698.txt,2,
7699.txt,Workflow diagram of the framework for deriving graph-stabilized prediction models from EMRs.,
7700.txt,Temporal feature relations and coding hierarchies were used to construct the feature graph.,
7701.txt,Model Development We present a framework for realizing the stabilization strategy described earlier.,
7702.txt,The framework consists of a training phase using data from the past and a validation phase using new admission data from the future.,
7703.txt,"Our model development consists of three subphases:  multigranular temporal feature extraction,  feature graph construction based on the temporal relations and coding hierarchies, and  model training with feature selection and feature graph regularization.",
7704.txt,Multigranular Temporal Feature Extraction: Feature extraction from EMR transforms inpatient time-stamped events  into a high-dimensional feature vector at the index discharge.,
7705.txt,The challenges are that recorded events are sparse and irregular.,
7706.txt,"As diseases progress in different paces, it is important to take multiple time scales into account.",
7707.txt,"In addition, recent critical events carry more weight than mild conditions observed far back in the history.",
7708.txt,"To this end, we employ the one-sided convolutional filter bank recently introduced in X.",
7709.txt,Feature Graph Construction: The feature graph is built by identifying connections between features that observe temporal and structural relations.,
7710.txt,Two features are connected if they satisfy one of the following two conditions.,
7711.txt,The first condition is the codes are identical and the periods are consecutive.,
7712.txt,"This represents the disease progression over the time, for example, from the period of 3? months to the period of 0? months before the discharge.",
7713.txt,"Alternatively, the periods are identical and the codes share the first two characters.",
7714.txt,This captures the diagnostic or therapeutic relations.,
7715.txt,"For instance, two related features are the ICD-10 code I25 and I21 .We validated the stabilization strategy on six-month unplanned readmission prediction among patients suffering heart failure.",
7716.txt,"As it is a binary outcome, logistic regression was used as the predictive model P.  Data: The data were collected from Barwon Health, a regional health service provider in Victoria, Australia.",
7717.txt,Ethics approval was obtained from the Hospital and Research Ethics Committee at Barwon Health  and Deakin University.,
7718.txt,Patient details are stored in EMR databases.,
7719.txt,The cohort of inpatients with heart failure contains 1 405 unique patients with 1 885 index admissions between January 2007 and December 2011.,
7720.txt,We identified patients as having heart failure if they had ICD-10 diagnosis code I50.,
7721.txt,Patients of all age groups were included.,
7722.txt,Inpatient deaths were excluded.,
7723.txt,We focused our study on emergency attendances or unplanned admissions of patients.,
7724.txt,Temporal V alidation: The model was externally validated in time .,
7725.txt,"That is, patients discharged prior to 1st September 2010 were used for training, and a separate set of those discharged afterward for testing .",
7726.txt,This validation strategy was chosen because it better reflects the common practice of training the model in the past and using it in the future.,
7727.txt,"Model performance was evaluated using measures of sensitivity , specificity, precision, F-measure, and area under the ROC curve  with confidence intervals based on MannWhitney statistic .",
7728.txt,We used a predefined threshold to predict readmissions.,
7729.txt,The value of the threshold was chosen to maximize the F-measure computed from the training data.,
7730.txt,Measuring Goodness-of-Fit: We used the Hosmer?Lemeshow test to measure the goodness-of-fit for our logistic regression models.,
7731.txt,The HosmerLemeshow test  assesses the degree of fit by matching the observed probabilities with the estimated probabilities.,
7732.txt,The validation set is divided into G ordered groups based on estimated probability of outcome events.,
7733.txt,The Chi-squared test statistic is calculated by comparing the expected and observed number of outcome events in each group as The characteristics of the training and validation cohort are summarized in Table I.,
7734.txt,The feature extraction process  resulted 3 338 features.,
7735.txt,"The lasso-regularized regression model  resulted in 142 risk factors, which are positively predictive of unplanned rehospitalization following heart failure discharges.",
7736.txt,"The graph-based regularization results in subgraphs being selected as a whole, as shown in Fig.",
7737.txt,4,
7738.txt,The question is how does it affect model performance and feature stability against data resampling?,
7739.txt,The model performance was measured for different values of the lasso-regularization termand the Laplacian-regularization term .,
7740.txt,Table II reports other measures.,
7741.txt,"Overall, the discriminative measures were not sensitive of the Laplacian factor  but depended critically on the lasso factor .",
7742.txt,Fig.,
7743.txt,5 displays the AUC in finer details for .,
7744.txt,"A good discrimination was achieved at  = 0.001 and  = 0.01, where external validation resulted in an AUC of 0.66 .",
7745.txt,"For the validation cohort, the Laplacian stabilized model was able to detect more true readmissions than lasso-regularized model .",
7746.txt,The overall classification accuracy for the Laplacian stabilized model was 59.6% as opposed to 57.9 % for the lasso-regularized model.,
7747.txt,ROC Curve Analysis: The AUC can be used to compare different models fitted to the same data.,
7748.txt,As shown in Fig.,
7749.txt,"6, the application of Laplacian stabilization marginally improved the AUC over the lasso model.",
7750.txt,"However, a combination of elastic net and Laplacian was not able to improve the model discrimination.",
7751.txt,Goodness-of-Fit Statistics: We now compare the goodness-of-fit of models using HosmerLemeshow  test statistic.,
7752.txt,We divided our validation cohort into ten groups defined by an increasing order of the estimated risk.,
7753.txt,"Nine groups contained 37 observations, while one group contained 36.",
7754.txt,The expected frequencies in each group was more than five.,
7755.txt,"Hence, all conditions for reporting the HL test statistic was met .",
7756.txt,"Both Laplacian and combination of elastic net and Laplacian regularization resulted in small values of HL test statistic with p > .05 suggesting that these models fit the data quite well.During this experiment, the lasso regularization term was fixed at  =0.001, corresponding to the value for maximum AUC of the model.",
7757.txt,"Thus, feature stability through graph regu-larization is entirely controlled by the hyperparameter  in X.",
7758.txt,The effect of  on feature stability is demonstrated in Fig.,
7759.txt,7,
7760.txt,Both Consistency Index and Jaccard Index confirmed improvements in feature stability with increasing graph penalty.,
7761.txt,"Next, we compared the stabilizing effect of regularization schemes.",
7762.txt,"The feature graphs were applied not only for the lasso but also for the elastic net, thus creating four alternativeslasso  Elastic net and Laplacian regularization both reduce weight variance significantly over the baseline lasso, and the Laplacian performs slightly better.Fig.",
7763.txt,"8 show a finer visual representation of the effect, clearly demonstrating the reduction in weight variance using the graph regularization.",
7764.txt,"For Feature Selection Stability, Consistency Index and Jaccard Index are reported in Fig.",
7765.txt,9,
7766.txt,Feature graph regularization consistently outperformed elastic net regularization for the top ranked features.,
7767.txt,"Again, the combination of feature graph and elastic net resulted in the most stable set of features for all subset sizes.",
7768.txt,"Although stability in feature selection is gaining importance, measuring the robustness of selected features in clinical prediction models has not been studied extensively.",
7769.txt,Feature stability facilitates reproducibility between model updates and generalization across medical studies.,
7770.txt,"This is especially important in EMR-derived models due to its high-dimensional, dynamic, and implementation-dependent nature.",
7771.txt,"In practice, a stable model will allow the clinician to have more confidence on the selected features and their predictive importance.In this paper, we have introduced feature graphs and Laplacian regularization to regression models to enhance the stability in feature selection.",
7772.txt,"Laplacian feature graphs have been used in bioinformatics to improve the feature stability, but with important differences.",
7773.txt,"First, lasso was not used as an embedded feature selection method.",
7774.txt,"Cun and Frohlich, for example, employed a filter-based method, where the feature selection does not occur during learning of model parameters.",
7775.txt,"Second, feature graphs were often constructed based on prior knowledge of interaction between features .",
7776.txt,"In our method, the model estimation is stabilized using a feature graph constructed from latent clinical structures in the training data.",
7777.txt,Our work stands unique in the following aspects: generic construction of feature graphs from commonly available attributes in the medical database and extensive numerical validation of the model stability in both model estimation and feature selection.,
7778.txt,Our experiments confirm that the stability of a highdimensional linear clinical prediction model can be improved by using temporal and structural relations in EMR database.,
7779.txt,The combination of Laplacian regularization with existing state-ofthe-art binary elastic net resulted in most stable features without hurting the model discrimination.,
7780.txt,"Thus, with Laplacian regularization, more features can be confidently selected for prediction .",
7781.txt,This is useful in the EMR setting because each patient typically has limited number of active features despite the huge number of features across the database.,
7782.txt,Having more confident features would make explanation for individual prediction easier.,
7783.txt,"With regards to performance, Laplacian regularization along with binary elastic net resulted in a model with a better fitagainst the validation cohort .",
7784.txt,The marginal increase in sensitivity and classification accuracy in Laplacian regularization can be attributed to grouping of correlated features.,
7785.txt,"With regards to the feature stability, the improvement upon the elastic net demonstrates that the feature graph is complementary to ridge regression.",
7786.txt,"This could be explained by the fact that while ridge regression tends to encourage all weights to be similar and regressed toward zero, graph regularization only requires pairwise smoothness.",
7787.txt,Our EMR-derived model achieved a discriminatory capacity comparable with or better than existing prediction models for rehospitalization following heart failure discharges.,
7788.txt,"The model is derived from free available administrative and medical data, making it readily implementable into existing EMR systems.",
7789.txt,"Interestingly, the top predictors discovered by our model are consistent with the existing clinical studies.",
7790.txt,Our model ranked male gender highest on the importance scale.,
7791.txt,"Looking at the medical factors, the strong predictors include prior history of hospitalization, which are consistent with those in X.",
7792.txt,The comorbidities observed were occurrence of coagulopathy in the past year and occurrence of complicated diabetes in the past three months.,
7793.txt,"Other major predictors for the heart failure rehospitalization are heart failure, lipoprotein metabolism disorders, angina pectoris, cataract, and chronic ischaemic heart diseases.",
7794.txt,Past number of procedures in a period of three months to two years was also ranked high.,
7795.txt,"The discrimination power, the automatic feature selection, and stability control capacity suggest that the model can be used as a fast and inexpensive screening tool to select patients and risk factors for more in-depth clinical investigation.",
7796.txt,"For example, through selected feature subgraphs, related risk factors can be collapsed to achieve more generality.",
7797.txt,It could serve as a first step in bridging the translational gap between bench and bedside .,
7798.txt,We wish to emphasize that the entire prediction process is transparent as the model is capable of explaining what risk factors are involved in a risk estimate.We acknowledge the following limitations in our study.,
7799.txt,"First, since our main focus was on stabilizing a high-dimensional model, we did not concentrate on improving the accuracy.",
7800.txt,"In our experiments, graph regularization contributed very little to improving model discrimination.",
7801.txt,"Second, we did not investigate more complex relationship between variables in EMR data when building feature graphs.",
7802.txt,It is possible that exploiting structures like billing codes and lab tests may further enhance sharing of statistical strength between correlated features.,
7803.txt,"Third, the model evaluation was not tested independently by other researchers.",
7804.txt,"However, we have used temporal validation on unique patients, and it matches the common practice of learning models using past patients and predicting outcomes for future patient.",
7805.txt,"Fourth, clinical measurements had a high degree of missingness, and hence, were discarded.",
7806.txt,"In review of the these limitations, we believe our derived model is conservative and may have underestimated the AUC of the validation cohort.In this study, we tackle the seldom studied but notorious problem of the feature instability in clinical prediction models.",
7807.txt,"Stable model features translate to proper understanding of risk factors, and hence, better confidenceinprognosis.Ourapproach consists of a novel technique to mitigate the problem by utilizing feature graphs that link similar conditions/interventions and the same condition/intervention over multiple time periods.",
7808.txt,Our extensive experiments in predicting six-month readmission in a heart failure cohort confirm that the application of feature graphs increases the stability of the selected feature subset and reduces the variation in feature weights.,
7809.txt,The performance of the readmission models derived from administrative hospital data is competitive against existing models developed on clinical data.,
7810.txt,"Further, since our approach is based on commonly available administrative attributes, models can be readily implemented on top of existing EMR systems and portable across cohorts and institutions using similar EMR databases.",
7811.txt,We believe our stabilizing framework provides the first proof of concept in utilizing feature graphs in clinical setting and numerically validating the stability for a clinical prediction model.,
7812.txt,Future work includes applying the same technique for a variety of cohorts and sites and prospective evaluation in practice.,
7813.txt,"Integrating human-provided location priors into video object segmentation has been shown to be an effective strategy to enhance performance, but their application at large scale is unfeasible.",
7814.txt,"Gamification can help reduce the annotation burden, but it still requires user involvement.",
7815.txt,We propose a video object segmentation framework that leverages the combined advantages of user feedback for segmentation and gamification strategy by simulating multiple game players through a reinforcement learningmodel that reproduces human ability to pinpoint moving objects and using the simulated feedback to drive the decisions of a fully convolutional deep segmentation network.,
7816.txt,"Experimental results on the DAVIS-17 benchmark show that:  including user-provided prior, even if not precise, yields high performance;  our RL agent replicates satisfactorily the same variability of humans in identifying spatiotemporal salient objects; and  employing artificially generated priors in an unsupervised video object segmentation model reaches state-ofthe-art performance.",
7817.txt,"In spite of the large research efforts spent on video object segmentation, a general solution is yet to be found due to the difficulty in dealing with several sources of variability, including scene and object appearance and conditions.",
7818.txt,"The approaches proposed so far can be categorized as follows: unsupervised methods compute background/foregroundbinary masks based on the input video frames alone; semisupervised methods need some ""clues"" on the location of moving objects ; supervised methods require a certain degree of user interaction, often provided by means of clicks or strokes inside or around the objects of interest in the video.",
7819.txt,"Semisupervised and supervised methods, while being, in general, more accurate, become impractical when large amounts of data need to be processed because of the requirement of human intervention.",
7820.txt,"On the other hand, unsupervised segmentation requires large data sets with per-frame manual annotations on background and foreground pixels, whose creation is a costly and time-consuming task.",
7821.txt,"An effective human-in-the-loop strategy is gamification as in X, where the annotation task is posed as a game in order to make it more enjoyable to potential users and to leverage competition as a motivational factor.",
7822.txt,"The collected annotations may not be very precise, but they provide important clues on moving object locations that can be used to enhance the performance of automated video object segmentation.",
7823.txt,"Given the noisy quality of the data generally collected through gamification, video object segmentation exploiting that kind of user feedback can be considered as a particular case of the weakly supervised problem.",
7824.txt,"In this article, we build on the same strategy for collecting user clicks and replace humans with reinforcement learning agents for unsupervised video object segmentation.",
7825.txt,"In particular, the idea is to train a video segmentation network with user-provided motion clues and then to replace humans as a source for those clues with an artificial agent that approximately estimates object locations in order to turn our segmentation approach into a fully unsupervised one.",
7826.txt,"The RL paradigm, recently risen as a valid alternative to traditional learning methods in several tasks  has shown promising performance in approximating agents constrained by a small set of actions, while pixellevel labeling in videos is a very high-dimensional problem.",
7827.txt,"To cope with this, we constrain the set of possible actions of our RL approach to simple movements and placement of a single ""click"" for each video frame.",
7828.txt,Multiple agents operating simultaneously on the same frame provide a set of distributed priors over the objects of interest for the subsequent segmentation model.,
7829.txt,"The motivation for using human prior emulated by RL, rather than employing a CNN predicting whether or not a user will click on image patches, stands mainly in the different learning paradigm: in the latter case, the model will learn, in a supervised way, a mapping between spatiotemporal cues and patches, and thus it will strongly depend on the quality of the training data; in the former case, the model will learn to follow spatiotemporal salient objects, regardless the specific training data, as well as model the variability introduced by different human players.",
7830.txt,"More simply, increasing the accuracy of a CNN-based model will necessarily pass through increasing the size of the training data and retraining the model, while the RL-model will not require any additional training, but the execution of multiple instances with different initialization.To summarize, the contributions of this article are as follows.",
7831.txt,We propose a weakly supervised deep network for video object segmentation that exploits object location priors for accurate segmentation.,
7832.txt,"We transform the previous model into a fully unsupervised one by emulating, through RL, human behavior in games.",
7833.txt,Both our weakly supervised and fully automated method outperform state-of-the-art methods on the DA VIS 2017 benchmark .,
7834.txt,This article tackles the problem of unsupervised video object segmentation by using an RL agent able to accurately reproduce user-provided priors on moving objects.,
7835.txt,"Thus, we first review the video object segmentation methods and, afterward, recent RL methods.",
7836.txt,A.,
7837.txt,"Video Object Segmentation As mentioned in Section I, video object segmentation methods can be categorized as follows.",
7838.txt,Unsupervised: The methods that perform segmentation in inference without additional input on object location other than the video frames.,
7839.txt,"Semisupervised: The methods that, instead, employ annotations in the first frame for inference.",
7840.txt,The methods that require user interaction.,
7841.txt,"Note that while in other machine learning contexts, the concept of ""supervision"" refers to the availability of manual annotations at training time, in video object segmentation, it refers to the availability of interactive user support at inference time.",
7842.txt,"Of course, the three classes of approaches define a tradeoff between accuracy and need for user interaction.",
7843.txt,Unsupervised video object segmentation methods typically pose the problem as the identification of spatiotemporal "tubes" by tracking points or patches over consecutive frames in order to localize areas where coherent object motion and appearance are found.,
7844.txt,Semisupervised approaches simplify the problem by receiving the correct annotations on a subset of frames and then propagate them to the rest of the video frames.,
7845.txt,"In general, semisupervised approaches are able to achieve higher accuracy than their unsupervised counterparts since the additional input hints at the location of both objects of interest and background regions.",
7846.txt,"Supervised or interactive video object segmentation, instead, requires humans in the whole loop to provide annotations or correct errors However, interactive segmentation, being constrained by the requirement of human intervention, is probablythe least generally applicable paradigm, and it finds application primarily in video postproduction and computer graphics, where high accuracy is required.",
7847.txt,"To reduce the needed interaction level, there have been only a few attempts to employ weaker supervision, in the form of frame-level labels or bounding boxes, during training.",
7848.txt,"We argue that our approach leveraging user clicks falls in the category of weakly supervised video object segmentation, as we employ noisy feedback not necessarily available on all frames.",
7849.txt,"However, when replacing player clicks with RL agents, it actually becomes an unsupervised method.",
7850.txt,"B. Reinforcement Learning RL is a paradigm where an artificial agent interacts with a simulated environment, by taking actions that result in a change in the environment's state and a reward .",
7851.txt,"The agent, thus, attempts to maximize the total reward in its sequence of actions; in this context, the only kind of supervision that the agent receives is provided through rewards, which may be sparse and temporally distant from the relevant actions that affected it, making the resulting learning paradigm more flexible but typically harder.",
7852.txt,"For these reasons, RL has recently attracted a lot of attention for emulating human behavior in several contexts, such as games  and autonomous driving , but also for computer vision tasks, including video object segmentation .",
7853.txt,"Goel , specifically, propose a deep segmentation model to identify multiple masks on video frames, with an RL agent learning policy to focus on the ones likely containing objects of interest for Atari games; presents a simple RL approach to identify color thresholds for object segmentation.",
7854.txt,"These methods are significantly different from ours in that:  they do not exploit any spatiotemporal information and are used in very simple settings, while we face real-world problems; they attempt to identify either the most suitable bounding boxes from a set of precomputed masks or the most suitable thresholds for segmentation, while we attempt to emulate human behavior.",
7855.txt,"Our formulation fits better with the video object segmentation problem; indeed, it is really complex to solve highdimensional problems with RL, such as learning spatiotemporal visual features for prediction, while we attempt to learn a reduced set of interaction patterns that are then used to drive a segmentation problem.",
7856.txt,"Our intuition is more similar in the spirit to X, where a semisupervised video object segmentation is proposed by combining an RL agent that identifies bounding boxes of moving objects and their context, with a network that performs accurate segmentation on the bounding boxes.",
7857.txt,"This approach and ours have in common the fact that the segmentation framework is divided into a first step that uses RL to roughly estimate motion location, and a second step that performs accurate segmentation.",
7858.txt,"However, while X uses annotations on the first frame , our method performs unsupervised segmentation, i.e., it does not employ any annotation at inference time, by training initially an interactive segmentation approach and then employing RL to remove the user interaction constraint.",
7859.txt,"The proposed framework is based on a deep neural network  for video object segmentation, which employs location priors for supporting the segmentation process.",
7860.txt,The approach then becomes the following.,
7861.txt,W eakly Supervised: When location priors are provided by users in the form of clicks collected through gamification.,
7862.txt,When an RL model emulates human behavior in click generation.,
7863.txt,"Our RL model interacts with an environment with actions defined to move the agent over a frame and place simulated clicks, with a reward function replicating the one employed to compute scores in a game setting .",
7864.txt,The overall framework is shown in Fig.,
7865.txt,2,
7866.txt,"The unsupervised approach leverages the advantages of an annotation-guided segmentation, which allows the model to approximately identify the location of moving objects from the provided annotation, and the flexibility of an RL-based approach for annotation generation, which relieves the need of the human-in-the-loop component.",
7867.txt,A.,
7868.txt,Segmentation Model With User-Provided Prior The proposed deep convolutional network processes video frames along with priors provided as a mask of click locations and outputs segmentation maps.,
7869.txt,"We do not make any assumption on the nature of location priors, as the approach is general.",
7870.txt,"Section III-B describes our gamification approach for collecting multiple user clicks, while Section III-C shows instead how to automate the click generation process with RL.",
7871.txt,The input to our deep network is a set of three consecutive video frames with the corresponding object location prior .,
7872.txt,"Each prior map is computed starting from a binary image where the click locations correspond to white pixels on a black background; this binary map is then processed by a Gaussian filter in order to emphasize these locations and their topology, which may be harder for the network to understand if left as a set of isolated pixels.",
7873.txt,"It is important to notice that priors provided by these maps are not perfectly aligned to object boundaries, which forces the model not to rely too much on them but to learn to segment objects using appearance and motion cues from the input frames.",
7874.txt,Each input to the model is a 12-channel tensor containing a sequence of video frames and the associated location prior maps and is fed to a deep convolutional neural network that carries out actual segmentation.,
7875.txt,"The architecture of our network, shown in Fig.",
7876.txt,"4 and the exact sequence of layers given in Table I, is inspired by X, a fully convolutional DenseNet  consisting of a downsampling and an upsampling path, and skip connections typical of U-net architectures.",
7877.txt,"The first and last layers in the network, InitConv and FinalConv, are 3  3 convolutions with 1-pixel padding and 1pixel stride, meant to increase  or decrease  the number of feature maps, without the computational burden of a full dense block layer.",
7878.txt,The downsampling path processes the input data through an initial convolutional layer and a cascade of dense blocks and transition-down blocks; the latter is responsible for applying max-pooling in order to reduce the spatial size of feature maps.,
7879.txt,"Similarly, the upsampling path interleaves dense blocks with transitionup blocks, implemented through transposed convolutions with the objective of increasing feature map size.",
7880.txt,"In particular, each dense block consists of a cascade of five dense layers.",
7881.txt,The input to each dense layer is the concatenation of the outputs of all previous dense layers in the block.,
7882.txt,"The layers inside a dense block employ 3  3 convolutions with 1-pixel padding, thus keeping the size of the feature maps constant.",
7883.txt,The number of feature maps generally increases in the downsampling path and decreases in the upsampling path.,
7884.txt,The transition-down layers follow dense blocks in the downsampling path and act on input feature maps by reducing their spatial size.,
7885.txt,"In fact, they are structurally similar to dense layers, with the addition of a 22 max pooling layer that halves the width and height of the input.",
7886.txt,"The transition-up layers, in the upsampling path, aim instead of increasing the size of the input feature maps.",
7887.txt,"They are implemented as a transposed convolution with 33 kernels , stride of 2, and no padding.",
7888.txt,"They also receive as input, through skip connections, the feature maps from the corresponding transition-down layer from the downsampling path.",
7889.txt,"However, while traditional U-net models are devised for single-image pixel-level dense prediction, video object segmentation is a strongly time-driven process, and the analysis of temporal dynamics between consecutive frames is necessary.",
7890.txt,"Hence,ReLU activations, batch normalization, and dropout are employed in the model.",
7891.txt,"Finally, the output of the model at the end of the upsampling path is a spatial softmax distribution of pixel-level background/foreground probabilities.",
7892.txt,"During training, we employ a loss function that measures the errors at the mask level and at the contour level B. Weakly Supervision Through Gamification User click collection is performed by means of a web game, inspired by X, where videos are played on the user's browser and the task is to click on moving object locations.",
7893.txt,"Each correct click awards points to the player, while off-target clicks penalize the score.",
7894.txt,"In addition, consecutive valid clicks on the same location award fewer and fewer points, motivating users to distribute clicks over different objects and object parts in a scene.",
7895.txt,"In particular, click reward on a specific frame is given by measuring the average distance between the click and previous clicks by all players on the same frame.",
7896.txt,"This suppresses the need of ground-truth annotations during click collection although scores may not be precise in the first games when only few data are available; however, score precision does not have to be perfectly accurate, as it only serves as a way to drive user behavior toward correctly performing the task and to encourage competition, in order to collect as many data as possible.",
7897.txt,"Level difficulty increases by rising the frame rate in the game, forcing users to be faster in clicking, which sometimes reflects on imprecise clicks.",
7898.txt,"Despite the noisy source, embedding the user interaction task as a game makes data collection efficient and makes it possible to gather a large amount of information that can be used to provide the segmentation model with a weak prior on regions of interest for segmentation purposes .The second component of our framework is an artificial agent that learns appearance and motion cues in video sequences in order to emulate game players, thus replacing user interaction as a means to generate the prior maps required by the segmentation model.",
7899.txt,"We pose the training of the agent as an RL problem, where each episode consists of the processing of a single frame.",
7900.txt,here k is the iteration number in frame ft.,
7901.txt,This component defines penalties for the agent in two cases:  when a movement action would move the agent's location outside of the frame boundaries and when the agent performs the same movement action on a patch that it visited before.,
7902.txt,"The last condition aims at pushing the object to move as directly as possible toward motion areas, without indulging to collect rewards by movement alone.This strategy, including dividing the reward by the number of performed iterations k, prevents the agent from preferring useless movement actions over set actions on locations clicked by the game players.",
7903.txt,"The conditions on the distances between the selected patch and, respectively, the frame center or the user's click mass center enforce the agent to find a tradeoff between settling Fig.",
7904.txt,5,
7905.txt,Architecture of our Q-network.,
7906.txt,"For each iteration of our RL approach, we provide as an input to the model a frame, the optical flow between current and past frame, the last selected patch, and the history of the previously selected patches for the analyzed frame.",
7907.txt,for a small reward by moving toward users' clicks or frame center or placing clicks on a frame and stopping when no good locations are present.,
7908.txt,The goal of our RL agent is to interact with the environment by choosing the actions that maximize the rewards it receives.,
7909.txt,"To do so, we use the Q-learning algorithm to train a deep Q-network  that approximates the optimal action-value function; this function estimates the quality of action a at state s as the sum of future rewards, discounted by a factor  at each time step.",
7910.txt,The network receives as input a state tensor with dimension 298  168 7 and returns the estimated  values over possible actions.,
7911.txt,"The architecture of the network, shown in Table IV, is equivalent to the downsampling path of the segmentation network.",
7912.txt,Updates to the model parameters are computed by exploiting the Bellman equation and minimizing the difference between the two sides using the Huber loss.,
7913.txt,Examples of how our RL agent works are given in Fig.,
7914.txt,6,
7915.txt,"We evaluate the performance of our models on the DA VIS17 data set, an extension of X, the most extensive public benchmark for video object segmentation.",
7916.txt,"The DA VIS-17 data set contains 150 videos, split in training, validation, and test sets, with pixel-level multiobject annotations for all frames, with several challenging examples with occlusion, motion blur, and appearance changes.The validation set of DA VIS-17 is used for model selection, while the reported results are computed on the test set.",
7917.txt,We test the effectiveness of our RL model by measuring the performance difference in video object segmentation when employing clicks of game players and when simulating clicks.,
7918.txt,"Clicks for training our RL-based video object segmentation method were collected on video shots from the DA VIS-17 training set, using the web game presented in Section III-B.",
7919.txt,"We ran a contest among BS students in computer science and collected 100 700 clicks, with an average of 24 clicks per video frame.",
7920.txt,"Then, for training the segmentation network, we used the DA VIS-17 training videos with the clicks collected on them.",
7921.txt,B.,
7922.txt,"Model Training To train the video object segmentation network, we use minibatch stochastic gradient descent with RMSprop optimizer: learning rate 10-4, weight decay 10-4, and minibatch size 4.",
7923.txt,The standard deviation mof the Gaussian filter used to preprocess click maps is set to 30.,
7924.txt,"Training is run for 100 epochs, with model selection carried on the best mean J score achieved on the validation set.",
7925.txt,"The RL model is trained using the same optimizer, learning rate, and weight decay as earlier, while the minibatch size is set to 10; the  parameter for reward discounting is set to 0.99.",
7926.txt,"During training, we run episodes of our RL environment and store state transitions with corresponding actions and rewards into a replay memory; at each step in the episode, we sample a minibatch of transitions from the replay memory to perform gradient descent on the Q-network.",
7927.txt,The constants employed in X were found empirically by testing on the validation set.,
7928.txt,"C. Segmentation Performance The first evaluation aims at assessing the contribution that the noisy annotations, provided by users, give to the segmentation approach described in Section III-A.",
7929.txt,The main baseline we compare to is the approach proposed in X.,
7930.txt,"This method provides user clicks collected through a web game as input to the segmentation algorithm, which is formulated as a two-step optimization problem on a spatiotemporal Markov random field.",
7931.txt,Two additional baselines are provided by employing different types of location priors.,
7932.txt,"In the first, instead of smoothing click locations with a Gaussian kernel, we perform superpixel segmentation using SLIC and set the prior mask to 1 at locations corresponding to superpixels that contain clicks.",
7933.txt,The second baseline is completely unsupervised and identifies location priors by combining objectness and motion features.,
7934.txt,"In detail, we first initialize an objectness map by setting locations corresponding to the top three object proposals returned by BING to 1 and the rest to 0.5; then, we initialize a motion map as the normalized optical flow magnitude.",
7935.txt,"The final prior location map is obtained by multiplying the two maps, smoothing the image using a 25  25 Gaussian kernel, and extracting local maxima.",
7936.txt,"In order to expand the single maxima locations into larger regions, we employ the same 30  30 Gaussian kernels employed to expand user clicks in our method.",
7937.txt,"Furthermore, we perform ablation studies to assess the contribution that our design choices provide to the segmentation accuracy.",
7938.txt,"In particular, we test two variants of our segmentation network with and without the location priors provided by the game players.",
7939.txt,"Results are given in Table V and indicate that:  adding location priors leads to a significant performance increase;  when used in conjunction with location priors, the bidirectional LSTM in the bottleneck enhances accuracy by about 2%?%; and  our model is able to perform segmentationeven without location priors.",
7940.txt,"In this last case, it is interesting to note that removing the LSTM actually enhances accuracy.",
7941.txt,We analyzed this behavior through the visualization of activation maps returned by the LSTM layer and compared its outputs with and without location prior maps.,
7942.txt,"In the latter case, larger activations were found in presence of background motion than in correspondence to objects; our conclusion is that the lack of object location priors makes it harder for the model to identify target-related temporal dynamics than largescalebut not meaningful for segmentationvariations.",
7943.txt,"We also note that the superpixel prior baseline performs fairly well though it achieves lower performance, which may be due to the fact that our method's Gaussian smoothing allows to preserve information on click density .",
7944.txt,"On the contrary, the objectness/motion prior is unable to provide meaningful information to the segmentation model; in our analysis, we found that camera motion causes background areas to have high-magnitude motion vectors, which introduces noise in the resulting prior maps.",
7945.txt,"In order to investigate the best architectural settings, we also compute performance of the segmentation model with location prior  when replacing the dice loss with the traditional pixelwise cross entropy and  increasing the number of consecutive input frames to the model .",
7946.txt,"Results are given in Table VI, showing that the dice loss leads to better performance than cross-entropy loss  and that increasing the number of input frames does not affect performance significantlyat least, not enough to justify the larger computational overload.",
7947.txt,"This is because the segmentation accuracy is mainly driven by the presence of location priors , which already encoded the information needed for identifying accurately the objects of interest without the need to extract it from multiple video frames.",
7948.txt,"We then compare our model with user clicks against both semisupervised state-of-the-art approaches, namely, and weakly supervised ones.The results are given in Table VII; our approach significantly outperforms existing weakly supervised methods that provide weak supervisionat inference timeon multiple video frames.",
7949.txt,"It is, instead, on par with semisupervised methods that use accurate segmentation only on the first frame, while our method uses weak annotation on all frames.",
7950.txt,"We, thus, evaluate the accuracy of our method while varying both the percentage of video frames with available clicks and the number of clicks for the annotated frames.",
7951.txt,"Results in terms of the mean Jaccard similarity, given in Fig.",
7952.txt,"7, show that the number of required annotated frames for training can be reduced, as long as enough clicks are available.",
7953.txt,"Afterward, before evaluating the RL model, we assess how the segmentation performance changes with respect to the ratio of accurate versus inaccurate clicks and the degree of inaccurateness.",
7954.txt,"For the former experiment, we synthetically sample different proportions of accurate clicks.",
7955.txt,Results are shown in Table VIII for different ratios (A%) of accurate pixels over the total number of clicks available per frame.,
7956.txt,"While performance naturally decreases with lower number of accurate clicks, we can observe by comparing the results when using synthesized clicks and real clicks that using 100% accurate clicks does not give significant performance improvements with respect to using user clicks and our method is fairly robust to noisy clicks; when using up to 20% of noisy clicks, performance is similar to using 100% correct clicks .",
7957.txt,The final evaluation still focuses on click accuracy but measures how segmentation accuracy varies with different degrees of click inaccurateness.,
7958.txt,"To do so, for a fixed set of inaccurate pixels, set to 20% in order to mimic real players' behavior , we sample inaccurate clicks within a certain distance d from a ground-truth object in a frame and measure how segmentation accuracy varies with d. Results, given in Table IX, show that the distance of inaccurate pixels from ground-truth objects influences the results; indeed, as d increases, performance degrades significantly, indicating that inaccurate pixels should be relatively close to object boundaries.",
7959.txt,The next evaluation phase assesses the performance of our RL model in emulating user clicks by measuring the contribution that the RL-generated clicks provide for unsupervised video object segmentation.,
7960.txt,"Indeed, replacing user clicks with RL-generated ones turns our approach from weakly supervised o fully unsupervised.",
7961.txt,"Thus, at inference time, we run multiple RL agents to simulate user clicks and evaluate the segmentation accuracy using such generated clicks .",
7962.txt,"The obtained performance is compared to state-of-theart unsupervised video object segmentation methods, namely, whose results are reported from X.",
7963.txt,"The achieved results are given in Table X and show that our RL-based segmentation approach, when using about 100 000 simulated clicks ,performs slightly worse than state-of-theart methods.",
7964.txt,Increasing the number of simulated clicks  significantly enhances the segmentation accuracy.,
7965.txt,"This confirms that our RL method has indeed learned to replicate human behavior when playing the game, to place clicks on salient moving objects that represent a valuable prior for video object segmentation.",
7966.txt,"In this article, we propose a video object segmentation approach that combinesfor the first time, to the best of our knowledgethe advantages of weak supervision, gamification, and RL paradigms.",
7967.txt,"The resulting model is used to drive the development of both a semisupervised video object segmentation approach through priors provided in the form of clicks by users and of an unsupervised method that, instead, uses synthetic clicks generated by an RL agent.",
7968.txt,"Experimental results demonstrate that our segmentation network, employing user clicks, outperforms state-of-the-art semisupervised methods and our RL network is able to accurately model game player behavior and generate clicks, resulting in an unsupervised video object segmentation framework that achieves stateof-the-art performance.",
7969.txt,"A community question answering  site is a well-known online community, where user interacts on a wide variety of topics.",
7970.txt,"To the best of our knowledge, the selection of a best answer for the question asked on the CQA site is done manually, which is traditional and tedious.",
7971.txt,"In this paper, a model is developed for selecting best answer for the question asked on the CQA site.",
7972.txt,"Instead of taking data related to questionanswer only into account as done in manual process, this model takes both questionanswer and answerers' data into account, which gives an insight view into the answers given by the experts that is more likely to be selected as the best answer.",
7973.txt,The presented approach analyzes StackOverflow Q&A posts with at least five answers to extract features for pattern identification using which the best answer is selected for the asked questions based on topic modeling and classifier.,
7974.txt,"To evaluate correctness of the proposed model, a set of parameters are used, such as Receiver Operating Characteristics Area Under Curve, Precision Recall Area Under Curve, Gmean, and Accuracy.",
7975.txt,Results show that the proposed model is effective in predicting the best answer.,
7976.txt,"Community question answering  sites have become an important source of content creation over the years, as these CQA sites have exceeded the rate of content consumption.",
7977.txt,"Users ranging from naive to outshiners, visit CQAs to gain knowledge and seek answers to various type of questions.",
7978.txt,StackOverflow is an interactive CQA site for software knowledge by hosting collaborative network of millions of users.,
7979.txt,"The users can create free account to: ask/answer questions, upvote/downvote questions/answers, gain reputation etc.",
7980.txt,to become an expert in the domain of software engineering.,
7981.txt,"In today's age, every day users are engaged on CQA sites with myriads of questions and their corresponding answers,which in turn, lead to continuous growing size of contents on this site.",
7982.txt,Such growing contents are posing several challenges which open up new opportunities for researchers to comprehend and establish meaningful patterns from the large size of contents that are available on such CQA sites.,
7983.txt,"Analyzing and understanding the StackOverflow knowledge repository could provide key insights about domain knowledge, activeness, expertise etc.",
7984.txt,"However,itistedioustoanalyzesuchhugeand semi-structured textual contents along with associated post scores manually .",
7985.txt,There are two types of users involved on StackOverflow.,
7986.txt,StackOverflow allows askers to pose their queries as questions and receives multiple answers from their fellow users.,
7987.txt,Posts on StackOverflow suggest that the first answer on a question arrives in about 9 minutes.,
7988.txt,"The best answer to be accepted is the answer that satisfies the asker's question, usually arrives in a span of minutes.",
7989.txt,"In this work, we study the answers received for the question and their related metrics for patternidentification of answers to decide which answer will get accepted.",
7990.txt,The rest of the paper is organized as follows.,
7991.txt,We present study on related work in Section II.,
7992.txt,Section III describes our research questions with research data.,
7993.txt,The research methodology used is presented in Section IV.,
7994.txt,The classifier modelling with experimental results has been presented in Section V. Section VI comprises of the extensive feature impact analysis related to our work.,
7995.txt,The potential threats to validityarediscussedinSectionVII.,
7996.txt,"In X, the activeness of users'has been explored in CQA.",
7997.txt,They have shown how badges and reputation scores are related to find activeness in different forums based on statistical analysis.,
7998.txt,"In X, the StackOverflow posts has been analyzed through quantitative and qualitative approaches in order to visualize the activity signatures for the success of CQA.",
7999.txt,"In X, Anusha et al.",
8000.txt,"discussed on clustering the users of StackOverflow into four clusters namely naive, surpassing, experts and out shiners based on characteristics accounting various metrics by using machine learning algorithm in order to predict the users'activities.",
8001.txt,But they mainly focused on: who dominate the community and how their expertise levels make impact on reputation in the community.,
8002.txt,"In X, Barua et al.",
8003.txt,"has worked on the goal of uncovering topic interest, main discussion topics and technology trends over time with the help of statistical topic modelling.",
8004.txt,"Finding the best answer from a list of answers can be seen as the problem of ranking the answers, where the best answer gets the maximum rank.",
8005.txt,Ranking technique can also be utilized effectively for selecting the best answer.,
8006.txt,Some of the popular state-of-the-art ranking techniques are discussed here.,
8007.txt,The PageRank  and HITS algorithm  are graphbased approach to rank the web pages.,
8008.txt,These algorithms consider a web page as a node of the graph and a directlink from one web page to another as an edge of the graph.,
8009.txt,The PageRank algorithm computes a random surfer landing probability based on Markov chains of a given web page and accordingly ranks them.,
8010.txt,The HITS algorithm computes authority and hub value of the web page.,
8011.txt,Authority value is used to estimate the content of the web page whereas the hub value is used to estimate the links of the web page with other web pages.,
8012.txt,"In addition to the graphical features, this algorithm also includes a metric Z-score based on  the number of answers given by a user and  the number of questions asked by that user.",
8013.txt,Their results suggest that a simple metric like Z-score outperforms complex graph based algorithm such as PageRank.,
8014.txt,"In X, the similar work has been proposed for expert identification in Yahoo!",
8015.txt,"Answers, however they used the number of best answers given by the user as a metric to compute the expertise level of the user based on clustering algorithms.",
8016.txt,"The CQARank algorithm has been proposed to measure user interests and expertise score under different topic using Topic Expertise Model, whichisanovelprobabilisticgenerativemodelwithGaussian Mixture Model  hybrid.",
8017.txt,Zhou proposed the topic sensitive random surfer model  by considering the topical similarity among users when setting the affinity weight ignored in TEM  for expert finding.,
8018.txt,"Yang and Manandhar  learnt the latent feature space of both user and tag to build user-tag matrix and proposed tag based expert recommendation model with the help of probabilisticmatrixfactorization,andtheyshowedthat theresultsaswellasthecomputationaltimeobtainedbyusertag matrix using PMF outperform those of TEM in the domain of expert recommendation.",
8019.txt,Pal  explored users' question selection preferences through probabilistic model to run machine learning algorithms in order to identify experts and potential experts in CQA.,
8020.txt,Treude analyzed StackOverow and categorized the questions using tag and question coding.,
8021.txt,They used five tag and ten question categories statistically to identify the kind of questions asked and answered.,
8022.txt,"In X, Wang et al.",
8023.txt,have extended the work presented in X by investigating the distribution of questioners and answerers.,
8024.txt,"They used Latent Dirichlet Allocation , a well known topic modelling technique, to identify topics from questions for learning and assigned a question to several topics with some probabilities.",
8025.txt,"In X, the User Topical Ability Model  has beenproposedthatexploitsbothusers'expertiseanddescriptive abilities in CQA sites.",
8026.txt,"UTAM is a probabilistic model, to depict the topic-specific user ability based on textual content  and voting scores of questions.",
8027.txt,"In addition to textual and voting information, they also explore social links within a Q&A community by integrating the results of UTAM to describe User Social Topic Ability .",
8028.txt,"In X, a topic-sensitive probabilistic model has been proposed that extends the PageRank algorithm .",
8029.txt,"They combined the link information with user information to overcome the drawback of existing link analysis techniques.They used LDA to identify topical interest from previous answers given by the user, while expertise level is computed using collaborative voting mechanism.",
8030.txt,"In X, Riahi et al.",
8031.txt,compared the statistical topic modelling techniques namely LDA and Segmented Topic Model  with the help of traditional information retrieval approaches namely Language Model  and TF-IDF .,
8032.txt,"They found that STM outperforms LDA, LM and TF-IDF.Tian  uses learning from labeled data of questionanswer features using classification and predicted the best answer for the question for which the answer is not accepted yet.",
8033.txt,"Similarly, Shah and Pomerantz  evaluated and predicted the best answer using classifier learned from the features of question, answer and user in order to meet the satisfaction level given by human under 13 different criteria.",
8034.txt,"In X, the high quality answers has been identified by running hybrid hierarchy of classifiers trained on the features identified in order to predict the quality score of the answer.",
8035.txt,"Motivated from the work presented by Treude, this paper addresses the answer to unanswered research question 3 - how are the best answers selected?.",
8036.txt,"First, we use activity signatures, domain knowledge  and topical similarity of the user to identify active answerers in the domain of the questions asked.",
8037.txt,"Second, we use topical interest, topical expertise for expertise computation as used in X using topic modelling and voting scores.",
8038.txt,"Third, we find topic relevancy to find the relationship between Q&A pairs as in X.",
8039.txt,"Next, we focus on features involved in posts as in X and  for predicting whether the answer to the question will be accepted or not based on different classifiers.",
8040.txt,The empirical study of the work is performed based on extensive literature survey in terms of research questions.,
8041.txt,"As of now, we didn't findanymodelfromtheliteraturewhich automatically accepts the best answer.",
8042.txt,The first question that comes in our mind is that if every question receives multiple answers then how and what basis the best answer is accepted for the question.,
8043.txt,"In order to answer this question, we study StackOverflow CQA site and develop a model to accept the best answer automatically for the asked question which allows us to formulate the following four research questions.",
8044.txt,"Who provide answers to the question on stack overflow?The answerer works on multiple domains and has knowledge in a wide array of topics, tools, technologies and programming languages.",
8045.txt,StackOverflow CQA site is designed to resolve the challenges faced by the users in computer programming by knowledge sharing in the form of question answering.,
8046.txt,"Clearly, you can find that the question asked by the user must belong to a particular domain of the programming.",
8047.txt,"So, how to find the domain of the question that can help us to identify the answererinthatdomainwhoanswersthequestion.",
8048.txt,"Moreover,thedomainknowledgeoftheanswereristhe possible research area that has high impact in expert identification.",
8049.txt,How much expertise does the answerer has in same domain  different domain?,
8050.txt,Expertise computation  in CQA has been gaining popularity amongst researcher over recent years.,
8051.txt,Answerer of the question may have expertise on the same domain as well as on different domain of the question.,
8052.txt,"In general, the answer given by the answerer of the same domain has high quality and more likely to be accepted.",
8053.txt,"In addition to the domain knowledge, the number of question asked and the number of answer given in various domains play important roles for computing the expertise level.",
8054.txt,To what extent the answer is relevant to the question?,
8055.txt,"The asker or community, review the received answers so as to meet the requirement of the asker described by the question.",
8056.txt,We found that the requirement of the question is explained through textual information.,
8057.txt,We use the textual information of both question and answer to find the closeness between them.,
8058.txt,The more similarity between textual information of question and answer represents the more relationship.,
8059.txt,Text mining is the area to deal the textual content of the document to learn the properties for further inference.,
8060.txt,How the best answer is selected amongst a set of answers?,
8061.txt,There is no limitation in posting the number of answers to the question.,
8062.txt,The asker or community then review the answers manually to accept the answer that explains the requirement of the question.,
8063.txt,It takes a lot of time to review these answers as the size of StackOverflow growing rapidly.,
8064.txt,This would encourage us to work on this field.,
8065.txt,StackOverflow is an interactive CQA site for exchanging the knowledge in the software engineering field.,
8066.txt,It provides the wide variety of functionality for users to gain the knowledge.,
8067.txt,The basic function is asking and answering the questions by the registered user.,
8068.txt,The users are free to give their opinion about questions/answers either in terms of up-voting/ down-voting or posting comments on them.,
8069.txt,"The users gain the reputation through different activities like answering the question, their answer is accepted etc.",
8070.txt,"The access privileges on the site are decided by the reputation score of the users, which indicates how useful the user is for the community.",
8071.txt,"Similarly, the importance of the post is determined using the score obtained by the number of up-votes minus the number of down-votes for the post.",
8072.txt,StackOverflow offers its data publicly available through Stack Exchange Data Explorer and XML format data dump under creative common licence.The statistics about the dataset relevant to our study has been presented in Table 2.,
8073.txt,"However, we have not included the data of posts  which have less than five answers  for which answer is not accepted yet so as to analyze how the answers will get accepted.In StackOverflow,therearemanyquestionsfromvarioustopics related to programming.",
8074.txt,"So, it's a challenge to detect who answers the questions of the StackOverflow.",
8075.txt,"In our analysis, we found that the user who belongs to the domain of the question and have prior knowledge in that domain can answer the question on StackOverflow.",
8076.txt,Our criteria for evaluating the user's knowledge of the domain are based on user's tags and topics on which the user has been previously involved.The detailed research methodology for RQ 1 is presented in Figure 1.,
8077.txt,"Based on our study, we try to identify answerer based on three key features:It is defined as the association amongst tags of the question with the tags of the user on which s/he has answered previously across StackOverflow and given by the following formula.",
8078.txt,It is defined as a cosine similarity between the topic terms of the question and previous answers given by the answerer and given by the following formula.,
8079.txt,"where, Tt (q) and Tt (ai) are the set of topic terms of question (q) and prior answers (ai) given by the answerer respectively.",
8080.txt,The average number of answers given by the answerer per day and it is given by the following formula.,
8081.txt,"where, |ai| is the number of answers given by the answerer in N days.",
8082.txt,"From Table 3, we can draw the inference that the active user, who has knowledge on domain of the question, can answer the question.",
8083.txt,We use Pearson's Correlations between the number of answer given by the user and features of RQ 1 to see the effect in identifying the answerer of the question.,
8084.txt,Pearson's correlation coefficient (r) ranges from ?1 to +1 and p represents the significant level.,
8085.txt,The positive valueof(r)indicates both variables are increases or decreases together i.e.,
8086.txt,"positive correlation, whereas negative value of (r) indicates that as one variable increases, so the other decreases, and vice versa i.e.",
8087.txt,negative correlation.,
8088.txt,"For the strength of correlation, |r| < 0.3 indicates small correlation, 0.3 ?|r| < 0.5 indicates medium correlation, and |r| > 0.5 indicates strong correlation.",
8089.txt,"First, the Tag Membership  and the Topical Similarity  are positively correlated with the number of answer given by the users, indicating that the higher value of Tag Membership and Topical Similarity increases the number of answer given by the users.",
8090.txt,"Second, Activeness is by default positively correlated as per the definition.",
8091.txt,We observed that the number of answerer gives the answer to the question; these answerers have certain level of knowledge in the question domain.,
8092.txt,"The knowledge of the answerer can be derived from the metrics such as number of up-votes, reputation and percentage of accepted answer as in Figure 2.",
8093.txt,"As the knowledge of the answerer increases the expertise level also increases, consequently the respective answers are likely to be accepted.",
8094.txt,"Now, we focus on the expertise of the answerer by using the knowledge level metrics in two categories as follows.",
8095.txt,The number of up-votes the answerer has on the tags to which s/he has given the prior answer and is given by the following formula.,
8096.txt,We observed that the number of answerer gives the answer to the question; these answerers have certain level of knowledge in the question domain.,
8097.txt,"The knowledge of the answerer can be derived from the metrics such as number of up-votes, reputation and percentage of accepted answer as in Figure 2.",
8098.txt,"As the knowledge of the answerer increases the expertise level also increases, consequently the respective answers are likely to be accepted.",
8099.txt,"Now, we focus on the expertise of the answerer by using the knowledge level metrics in two categories as follows.",
8100.txt,The number of up-votes the answerer has on the tags to which s/he has given the prior answer and is given by the following formula.,
8101.txt,It is defined as the relationship between topics found in questions  and topics found in the corresponding answers and is given by the following formula.,
8102.txt,"To limit the number of topics, we set threshold value  = 0.1 for both question and answer.",
8103.txt,Table 5 represents the relationship between question and answer.,
8104.txt,The higher the value of TRqarepresents the higher relevancy between question and their corresponding answer.,
8105.txt,The relevancy between question  and answer  is higher than other QA pairs.,
8106.txt,"Pearson's Correlations is used between theanswer scoreand metric of RQ 3 to see the effect and found, which represents topic relevancyis positively correlated with theanswer scoreof the answer, indicating that the higher value of metric represents high relevancy between question and answer.",
8107.txt,"Currently, the evaluation of the answers is carried out manually for accepting the answer that meet the requirement of the asker, which is explained through the question.",
8108.txt,"Generally, the answer is evaluated using evaluation parameters, these evaluation parameters are hidden in the current scenario.",
8109.txt,"We compile the answer of above three research questions, which acts as the baseline in order to answer the research question RQ 4 along with one more metric i.e.",
8110.txt,time span of the answer using classifier.,
8111.txt,The detailed research methodology is shown in Figure 4.,
8112.txt,It is defined as the time difference between question posting and corresponding answer posting and can be expressed as:Table 6 gives elapsed time of the answers after posting the corresponding question of PostID 27729802.,
8113.txt,The asker is expecting the answer as early as possible so as to meet the requirement.,
8114.txt,"Therefore, the time span of the answer is very important metric in accepting the answer.",
8115.txt,"Again, we use Pearson's Correlations between the time span and the class whether the answer is accepted or not to see the effect and found , which represents time span is negatively correlated with the class of the answer, indicating that the higher value of metric represents less chance of acceptance of the answer.",
8116.txt,"Based on a posts feature vector that we have extracted, the answer is classified whether accepted or not.",
8117.txt,"We used BayesNet and NaiveBayes for the task of binary classification, in which the generative model is utilized for modelling question and answer based on Gaussian distribution.",
8118.txt,The scatter plot of features for the dataset can be drawn and the contours of the Gaussian distribution fitted based on the MLE estimates.,
8119.txt,The smaller contours will capture majority of the accepted answer and some of the non-accepted answers as well.,
8120.txt,"where, P(YES) is prior probability of an answer being accepted.",
8121.txt,Prior probability is the ratio of accepted answers to total answer in the training data.,
8122.txt,"We also compute posterior probability of an answer belonging to the other class, whichever class has a higher probability.",
8123.txt,We model the features of a post in Bayes rule framework for evaluating the performance of binary classification.BayesNet and NaiveBayes classifiers are used in the prediction task and results are presented in Table 7.,
8124.txt,The well known 10 fold cross validation is used for training and testing of the dataset.,
8125.txt,We run the Weka implementation of the classifiers with default settings.,
8126.txt,"To assess the prediction quality of the classifier, we use four evaluation measures namely Receiver Operating Characteristics Area Under Curve, Precision Recall Area Under Curve , G-mean and accuracy.",
8127.txt,First three evaluation measures are generally used to assess the performance of the classification where the dataset is imbalanced as we have.,
8128.txt,Table 7 presents the experimental results and indicating that BayesNet classifier outperforms over NaiveBayes classifier.,
8129.txt,The characteristics of Accepted and Non-Accepted are investigated through the various measures like central tendencies  and standard deviations of the extracted features.,
8130.txt,Table 8 and Table 9 shows that the characteristics of the actual and normalized dataset respectively.,
8131.txt,The range value of the features doesn't give any idea about acceptance of the answer.,
8132.txt,It happens because of the large proportions of Non-Accepted answer compared to Accepted answer.,
8133.txt,"However, It is observed that the median and mean value of the features for Accepted answer are clearly greater than that of Non-Accepted answer, which reveals that the answers having greater value for the features from S. No.1 to 11 and less value for the feature of S. No.12 are more likely to be accepted.",
8134.txt,"In order to see the distribution of the features amongst both the classes Accepted and Non-Accepted, the overlaying bar graph has been presented for these features of normalized dataset in Figure 5.",
8135.txt,The statistical measures and statistical distribution of the features are different for both Accepted and Non-Accepted class presented in previous section.,
8136.txt,This findingindicatesthat the features are key in predicting whether a question will get accepted or not.,
8137.txt,"However, the previous section doesn't deal with the relative importance of the features for differentiating Accepted and Non-Accepted answers.",
8138.txt,"Therefore, we use three well known ranking algorithms for feature evaluation based on information gain.",
8139.txt,"In information theory, the information gain of a random variable is defined as the change in information entropy from a prior state to a state that takes the variable as given.",
8140.txt,"Although information gain is usually a good measure for deciding the relevance of a feature, it favours the features that can take on a large number of distinct values.",
8141.txt,"Therefore, we have used gain ratio to rank our features, which overcomes the previous problem.",
8142.txt,"Gain ratio is defined as: However, gain ratio gives an extra benefit to the features with very low information gain.",
8143.txt,"Therefore, we use above three rankings to select the prominent features.",
8144.txt,"We use the Weka implementation of Information Gain, Gain Ratio and Chi-squared Ranking algorithm with default settings to rank the features defined as above.",
8145.txt,The detailed ranking result with their corresponding values is presented in Table 10.,
8146.txt,The rankings are same for information gain and chisquared whereas there are some differences in ranking using Gain Ratio.,
8147.txt,"But in total, the three ranking algorithms agreed on selecting the 12 features listed in the table for the proposed problem.",
8148.txt,"From all the rankings, we found that the first 7 features which represent the expertise of the answerer are the most dominant features in predicting whether an answer for the particular question will get Accepted or Non-Accepted.Although the extensive empirical analysis and experiments has been performed in the evaluation and selection of the features for accepting the answer for the asked question.",
8149.txt,There are some threats which can affect the results:  posts selected for experiments can affect the parameters of studies.,
8150.txt,"Other CQA sites can arrange the metadata in different format, so preprocessing can affect the performance parameters our model fails to calculate the expertise level for potential experts .In this paper, we study and analyse the StackOverflow answers with their question to predict whether the answer will get accepted or not.",
8151.txt,We perform an extensive empirical analysis on StackOverflow data set to answer the four research questions.,
8152.txt,"To answer the research questions, we extracted the corresponding features to answer the framed research questions.Our findings will suggest that :prior involvement of the answerer on question tags and topics increases the chance to give the answer for that question  expertise will increases the chance in acceptance of the answer  topical compatibility between the question and answer increases the satisfaction of asker or community with that answer.",
8153.txt,We use various statistical methods in order to answer the first three research questions whereas classifier model is used in order to answer the fourth research question based on the previous research questions.,
8154.txt,"With this, we conduct the experiments and found that the extracted features have the great importance for the proposed problem using various feature evaluation metrics.The evaluation parameter of the classifier reveals that the results are remarkable in predicting the answer acceptability.",
8155.txt,"As of now, we are the first to analyze and conduct the experiments to predict the acceptance of the answer whatsoever.",
8156.txt,"We have achieved the maximum accuracy of 46% for minority class ,74% for majority class and overall accuracy 69% with 0.645 PRC area using BayesNet Classifier.",
8157.txt,The accuracy may be improved in future for both the classes with increased PRC area in several ways.,
8158.txt,"First, classifier model must be designed in such a way that the class imbalance problem doesn't influence the accuracy of both the classes and so overall accuracy keeping in view PRC area.",
8159.txt,"Second, Feature extraction plays a vital role in classification problem.Third, Ensemble learning can be devised to model the suggested problem in order to improve the accuracy.",
8160.txt,"A systematic experimental and theoretical evaluation of stiction between intermittently contacting silicon surfaces in an ultra-clean encapsulation process is presented, evaluating magnitude of stiction forces, the reversible nature of sidewall contact, and repeatability of results.",
8161.txt,"The uniquely stable environment and the lack of native oxide are leveraged to enable reliable collision and contact models, which confirm the nature of the asperity contact.",
8162.txt,"In addition, we demonstrate a series of dynamic mechanical anti-stiction solutions and the mechanisms by which they mitigate stiction.",
8163.txt,These devices are shown to reduce susceptibility to stiction-related failure by 50%.,
8164.txt,"These types of contact may occur either by design, as in a micro/nano mechanical relay, or by accident during fabrication or device operation.",
8165.txt,Stiction and surface adhesion are especially problematic in microscale and smaller devices because of the high surface area to volume ratio.,
8166.txt,"As a result of this scaling, surface forces that are typically too weak to consider at macroscale dimensions, come to play a significant role, or even dominate at the microscale.",
8167.txt,"The problem is further exacerbated by typical design goals or restrictions requiring narrow transduction gaps, high displacements for increased sensitivity, or high shock survivability.",
8168.txt,A vast array of forces may contribute to stiction in MEMS devices.,
8169.txt,"Practically, however, a small number of forces are responsible for most stiction forces: capillary attraction, electrostatic force, hydrogen bonding, and van der Waals forces.",
8170.txt,"V an der Waals forces, in particular, are unavoidable, as they exist between any pair of surfaces in close proximity, but all of these forces are common in MEMS devices during fabrication or use.",
8171.txt,"There have been numerous attempts to characterize and model stiction forces in the past, such as those arising from capillary forces on cantilevers, organic materials on silicon , or due to repeated impacts in a single device .",
8172.txt,Atomic force microscopy has been used as a tool to measure the attractive force of various materials used in MEMS devices .,
8173.txt,"Additionally, MEMS test devices have been fabricated specifically to investigate stiction.",
8174.txt,"For instance, a thorough investigation of adhesion in polysilicon devices found stiction to depend upon impact energy and contact area.",
8175.txt,"Experimental results have also been matched with numerical models for forces such as Van der Waals, or capillary attraction.",
8176.txt,"Broadly applicable results, however, continue to be elusive due to the wide variety of devices, materials, fabrication techniques and test conditions.",
8177.txt,"Previous work has shown that stiction may or may not exhibit dependence on many factors, such as area, humidity, contact force, surface treatment, process and cycling .",
8178.txt,"As a result of the significant problem posed by stiction, considerable efforts have gone into development of effective anti-stiction strategies .",
8179.txt,"These efforts may broadly be categorized into three groupschemical surface treatments, physical surface treatments and mechanical anti-stiction designs.",
8180.txt,"Chemical surface treatments, typically organic selfassembled monolayers or vapors, have been shown to improve resistance to capillary attraction and chemical bonding by several orders of magnitude.",
8181.txt,Hard surface coatings also can improve resistance to stiction and wear.,
8182.txt,"Physical surface treatments concentrate on reducing effective contact area, often by increasing surface roughness .",
8183.txt,"This can also be very effective in reducing stiction, and can additionally reduce van der Waals forces to a much greater degree than chemical methods .",
8184.txt,"The mechanical anti-stiction methods span a wide array of device-specific designs to eliminate, reduce or modify contact.",
8185.txt,"Some devices are designed to be sufficiently stiff, or have large enough gaps to prevent any contact from occurring during acceptable operating conditions.",
8186.txt,"Although this necessarily circumvents the problems created by stiction, it imposes strict conditions upon the device design, often requiring specialized fabrication, or lower device sensitivity.",
8187.txt,"Bump stops, or over-travel stops, are a nearly universal feature of MEMS devices, serving to limit contact area and prevent electrical shorts .",
8188.txt,An innovative extension of the basic bump stop is the spring stop .,
8189.txt,"These stops allow sliding contact, reduced contact forces and storage of impact energy .",
8190.txt,Systematic study of dynamic bump stops has not been conducted due to the wide variety of materials and device configurations that dominate the design and application.,
8191.txt,"High temperature, wafer scale, epitaxial encapsulation is a unique MEMS packaging technique that can enable hermetically sealed, ultra clean pure silicon devices with a silicon cap .",
8192.txt,"As compared to traditional packaging techniques such as cap bonding, this process results in devices with oxidefree surfaces in a near vacuum, pure hydrogen environment.",
8193.txt,"These features are a direct result of the epitaxial sealing cap, which is grown in an ultra-clean silicon growth environment at 1100C.",
8194.txt,"Benefits include the ability to fabricate high performance MEMS devices with high stability, high quality factor , no detectable fatigue, and the possibility of integrated or ""combo"" sensors .",
8195.txt,The encapsulation process has significant implications regarding stiction.,
8196.txt,Most typical sources of adhesion force are not relevant in this hermetic environment.,
8197.txt,"For instance, capillary attraction and hydrogen bonding are impossible without humidity and hydroxyl groups, respectively.",
8198.txt,"Similarly, in the absence of oxide or any other dielectric coatings, electrostatic forces due to trapped charges are eliminated.",
8199.txt,"Van der Waals forces, however, could be maximized due to extremely smooth sidewalls .",
8200.txt,"In addition, the high temperature sealing step precludes the use of anti-stiction surface treatments.",
8201.txt,"The encapsulated environment provides unique challenges with regards to stiction, but also the opportunity to realize high performance designs.",
8202.txt,"Preliminary investigation of stiction in this process has shown the reversible nature of sidewall contact, with stiction forces less than 45 N.",
8203.txt,"In addition, previous work has suggested the possibility of reducing the effect of stiction through mechanical anti-stiction measures .",
8204.txt,"The highly consistent nature of the process also allows for unique investigation of the nature of the stiction forces on native oxide-free single crystal silicon in an extremely well controlled environment, and subsequently, the most effective mechanical means of overcoming these stiction forces.",
8205.txt,"In order to study the nature of the stiction forces in encapsulated MEMS devices, a series of test structures were designed.",
8206.txt,"The test devices incorporate several key features: actuation to force a surface contact, defined contact geometry, measurement capability, and design within standard process rules.",
8207.txt,"In addition, the test structures were designed to resemble a generic inertial sensor to maintain relevance to real devices.",
8208.txt,A schematic of the device is shown in Fig.,
8209.txt,1,
8210.txt,"The device is fabricated on 40 m thick single-crystal silicon, in the wafer-scale encapsulation process, resulting in a near vacuum environment with pure silicon surfaces.",
8211.txt,"B. Electrostatic Actuation The device is actuated by applying a voltage between the proof mass and pull-in electrode, as shown in figure 1.",
8212.txt,This creates an electrostatic force which pulls in the proof mass.,
8213.txt,"The force is non-linear, and the proof mass snaps in towards the bump stop at an expected voltage and displacement.The relations in equation X allow us to calculate the expected pull-in voltage, where k is the suspension spring constant, gois the resting electrostatic gap, Aelis the electrode area and  is the permittivity of free space.",
8214.txt,"Beyond this point, the electrostatic force grows more quickly than the spring restoring force, until the proof mass contacts the bump stop.",
8215.txt,"As the electrostatic voltage is then reduced , the pull-out voltage is expected to be governed by equation X, in the absence of stiction, where b is the height of the bump stop  Several transduction techniques were used throughout the course of this study to fully understand the behavior of the devices.",
8216.txt,"A semiconductor parameter analyzer was used to detect electrical contact and measure resistance between the proof mass and bump stop, with a precisely limited current to minimize localized heating and electro-welding.",
8217.txt,"To detect the position of the proof mass, a high-frequency AC impedance measurement was carried out with an LCR meter.",
8218.txt,"Treating the proof mass and pull in electrode as a parallel plate capacitor, we can easily determine the relative position of the proof mass from the change in capacitance.",
8219.txt,"The basic current-voltage and AC impedance measurements both generate high precision information, but are limited in bandwidth.",
8220.txt,"Each of these techniques has a maximum measurement bandwidth in the subkHz regime, and therefore are unable to reflect the real-time dynamics of typical MEMS devices.",
8221.txt,"In order to gain insight into the higher speed dynamics, we measure the motional current generated as the capacitance of the parallel plate arrangement changes, as shown in figure 2.",
8222.txt,"The current, I, developed by moving charge, Q, is shown in equation X.",
8223.txt,"It is proportional to the velocity of the proof mass, v, and can be measured at very high rates with a GHz analog-to-digital converter, revealing the fast movements and oscillations of the proof mass.",
8224.txt,"The basic behavior of this device may be modeled as a mass-spring-damper system with intermittent contact, using equations X.",
8225.txt,"The forces are defined as follows: FSis the main suspension force, Felis the electrostatic force, Fcois the contact force between the proof mass and bump stop.",
8226.txt,The intermittent contact of the proof mass with the bump stop is modeled by a simple elastic collision model.,
8227.txt,"This was implemented by simulating the dynamics of the bump stop as a spring with mass and the following constraints: the position of the proof mass edge may never be greater than the position of the bump stop, and the maximum tensile force at the contact point is limited to the estimated adhesion force before the contact is disrupted.",
8228.txt,"The equivalent spring stiffness is calculated by applying Hooke's Law to the geometry of the bump stop, where E is the Y oung's modulus of silicon in the appropriate orientation, Absis the bump stop cross-sectional area, and Lbsis the bump stop released length.",
8229.txt,"The essential questions regarding the basic nature of stiction in encapsulated MEMS devices, such as magnitude of the force, consistency of this result, and geometric dependence, were investigated with the electrostatically-actuated test structures.",
8230.txt,The basic pull-in and release measurement allowed us to determine the stiction force after such an impact from the difference in pull-in and pull-out voltages.,
8231.txt,The basic measurement from the Agilent/HP 4156B Semiconductor Parameter Analyzer is shown in Fig.,
8232.txt,3,
8233.txt,We can see from figure 3 that the adhesive or stiction forces retard the release of the proof mass.,
8234.txt,"Using equations X,, the forces were calculated for over 20 devices and the summarized results are presented in Table I.",
8235.txt,"It is interesting to note that the forces are not overwhelming compared to the typical forces in a MEMS device, and therefore that pure silicon-silicon contact does not result in irreversible attraction.",
8236.txt,The significant distribution of measured stiction forces within the measured range has two contributing factors.,
8237.txt,"Firstly, high-impact surface contacts are fundamentally stochastic in nature, and therefore some variance is to be expected.",
8238.txt,"This is exaggerated, however, by the hot-switching contact measurement technique.",
8239.txt,Differences in the current flow through the contact due to varied contact resistance and parasitic capacitance additionally contribute to the variance.,
8240.txt,"Despite this, the complete range of observed forces is within reason for a MEMS device, and may not dominate the dynamics.",
8241.txt,"For instance, the inertial force on an accelerometer or driving force on a resonator is typically in the range of ?0uN.",
8242.txt,Even devices with relatively weak suspension springs will often have more restoring force than the measured stiction forces.,
8243.txt,"B. Asperity Dominated Contact Since stiction typically arises from forces that are proportional to area, we would expect the stiction force to be proportional to the area of the contact, defined by the width of the bump stop.",
8244.txt,"To explore this expectation, the test structures were designed with different contact configurations, as shown in figure 4.",
8245.txt,"The results, however, demonstrate no correlation between stiction force and the designed contact area.",
8246.txt,None of the variation in stiction forces between different devices can be explained by difference in contact area.,
8247.txt,This result suggests that local asperities dominate contact behavior.,
8248.txt,"The actual contact area is not defined by the area of the bump stop, but rather by asperities on the opposing surfaces.",
8249.txt,"Though at the nano-scale, the silicon surfaces have root mean square roughness less than 0.2nm, the high temperature encapsulation consistently forms micro-scale protrusions on the sidewalls, which substantially affect the contact.",
8250.txt,"The asperities are formed by properties fundamental to the pure silicon encapsulation process, such as the fracture strength and Young's modulus of silicon, and the high temperature encapsulation of deep-reactive ion etch surfaces.",
8251.txt,"Silicon migration during high temperature annealing is controllable, and has been studied elsewhere.",
8252.txt,"This result is of considerable significance, as it allows for some degree of design freedom in geometry, device and bump stop configuration, while maintaining roughly the same stiction performance.",
8253.txt,"This is in contrast to many other results, which are highly dependent upon device configuration or specific anti-stiction treatments and thus cannot easily be applied to arbitrary devices.",
8254.txt,"As a consequence of the extremely clean environment, and fundamental nature of the relevant adhesive forces, this asperity contact should fall within the regime that is well represented by Hertzian contact models.",
8255.txt,"Specifically, the Derjaguin-Muller-Toporov extension of the basic Hertzian contact model is well suited to adhesive contact between stiff materials, and surface with relatively small radii of curvature .",
8256.txt,"The DMT model allows us to estimate the true contact area, and pull-off force with the relations shown in equations.",
8257.txt,"The radius of curvature may be determined from SEM images of the device and sidewall profiles, and the Young's Modulus  is well defined for single crystal silicon.",
8258.txt,The applied force is easily calculated from the electrostatic and spring forces acting on the proof mass.,
8259.txt,The surface energy () can be estimated from values reported in literature.,
8260.txt,"These parameters, summarized in table II, can be used to estimate the stiction force.",
8261.txt,"The DMT model indicates that the surface adhesion in these test structures spans from that expected for a rough polysilicon surface, all the way to perfectly-aligned single crystal silicon surfaces, as shown in table III.",
8262.txt,The Hertzian contact models assume elastic contact between asperities with no plastic deformation.,
8263.txt,"However, during the initial high-impact collision the contact area predicted by this model  is less than the minimum area required to avoid exceeding the fracture stress of silicon.",
8264.txt,"This implies that while the model accurately describes the steadystate results, during the initial impact, some small amount of plastic deformation may occur.",
8265.txt,"This deformation serves to distribute the stress over a larger area, eliminating some of the mismatched asperities between the contacting surfaces, and driving the surface energy towards the perfect single crystal silicon case.",
8266.txt,"Depending upon the random distribution of asperities and local stress profile during the initial impact on each test device, the deformedsurface will maintain some fraction of the original asperities.",
8267.txt,"This post-deformation surface determines the stiction force, as measured by the pull-in testing, and evolves relatively slowly during subsequent tests.",
8268.txt,"To confirm this analysis, we compare an additional measurement to results from this same model.",
8269.txt,"The measured contact resistance should be inversely proportional to contact area, and if the model is an accurate representation, it should demonstrate the same dependence.",
8270.txt,In fig.,
8271.txt,"6, we see that the modeled and measured data show a similar trend between stiction force and contact resistance.",
8272.txt,The nature of the asperity-dominated contact revealed by these measurements and modeled results allows us to bound the expected stiction force to within a limited range.,
8273.txt,"In addition, it suggests that limiting contact forces may preserve asperities and reduce the probability of stiction occurring.",
8274.txt,Repeating the contact cycle measurement allows us to examine the evolution of the surface adhesion as a result of multiple impacts.,
8275.txt,An example measurement is shown in figure 7.,
8276.txt,This result demonstrates that the device contact can be relatively robust.,
8277.txt,"Despite being reliant upon asperities, the contact may survive thousands of cycles with relatively small changes in stiction force.",
8278.txt,"In addition, if we examine the data for a larger set of devices, we confirm that there is little correlation between designed bump stop area and stictionrelated performance.",
8279.txt,Figure 8 shows the number of cycles withstood by each device before the breakdown of normal switching behavior.,
8280.txt,"Once again, there appears to be no correlation between contact area and stiction-related failure, affirming the conclusion that actual contact is dominated by asperities.",
8281.txt,"D. Batch-to-Batch Repeatability In order to investigate the effect of small fabrication process variations on the magnitude of stiction forces, a series of low-profile test structures were included in six fabrication runs.",
8282.txt,"These runs encompassed variants of the basic process such as different device layer thicknesses, the inclusion of top electrodes in the cap, silicon nitride etch stops through the device and a wide variety of etch and growth recipes.",
8283.txt,The test structures used in this part of the investigation were in-plane cantilevers.,
8284.txt,"These cantilevers provide a simple method of checking for surface adhesion, while consuming little valuable die space.",
8285.txt,"The cantilevers were designed with different length, effective mass and contact configuration.",
8286.txt,"These parameters allow us to confirm the role of various factors such as stiffness, resonant frequency and contact geometry in stiction failure.",
8287.txt,"During the final steps of fabrication and wafer handling, after the devices are released, inertial forces cause the cantilevers to contact the sidewalls.",
8288.txt,"The stiffer cantilevers, with restoring force greater than the stiction force, break from contact, while those with insufficient restoring force remain stuck.",
8289.txt,Figure 10 shows the fraction of cantilevers of each stiffness that did not remain adhered due to stiction.,
8290.txt,"This result demonstrates several interesting features; firstly, as expected, spring stiffness has an extremely strong correlation with likelihood of overcoming stiction.",
8291.txt,"Stiffness, and consequently restoring force, was much more closely correlated with cantilever survival than resonant frequency or released length ?parameters that are often used as design guidelines.",
8292.txt,"Secondly, despite the non-trivial modifications to the process and fabrication tools, the test results are extremely similar for each fabrication run.",
8293.txt,"This insensitivity to fabrication variations again suggests that the stiction forces are determined by fundamental material properties, such as surface energy, Young's modulus and fracture stress.",
8294.txt,"In addition, it is clear that the test structures with spring stiffness greater than 18 N/m have a very high likelihood of successful release from surface contact.",
8295.txt,This allows for the formation of design rules that help ensure future designs will be able to overcome stiction.,
8296.txt,"As a result of the consistent nature of past results, and evidence suggesting that stiction in this process is determined by fairly fundamental bases, these design rules are well founded, and should have broad applicability to encapsulated, pure silicon devices.",
8297.txt,"The stiction performance of encapsulated, pure silicon MEMS devices is both extremely consistent and constrained by the unavailability of many typical anti-stiction methods.",
8298.txt,"As a result, innovative mechanical methods of overcoming stiction within a constrained, single material process are required.",
8299.txt,A.,
8300.txt,"Spring Bump Stops In order to evaluate the effectiveness of mechanical anti-stiction measures, another set of test structures was used.",
8301.txt,"Like the structures used for the static tests, these structures are also electrostatically actuated pull-in devices and resemble the basic features of an inertial sensor.",
8302.txt,"The key difference in these test devices is the use of spring bump stops, in place of the standard immobile over-travel stops.",
8303.txt,"Given the constraints of the process, the spring bump stops were designed as 3 m-wide beams with a contact point protruding 200 nm above the pull in electrode.",
8304.txt,"This allows for some amount of deflection without contacting secondary structures, such as the pull-in electrode.",
8305.txt,Spring bump stops of different lengths and contact angles were fabricated to reveal the effects of spring stiffness and perpendicular motion on overcoming stiction forces.,
8306.txt,"The spring lengths ranged from 20 - 50 m, and angles from 0 - 90.",
8307.txt,"Examples of these different springs are shown in figure 11b-c, and the fabricated device is shown in figure 12.",
8308.txt,Measurements of the proof mass position during testing were conducted by measuring the capacitance between the proof mass and pull-in electrode.,
8309.txt,"These measurements enabled the position of the proof mass to be calculated for each pull-in voltage, as shown in figure 13.",
8310.txt,"It is essential to note that as a result of the measurement bandwidth, these experiments are conducted in a quasi-equilibrium condition; each measurement required ?s to collect, so the device necessarily came to equilibrium at each voltage step, and the natural high-speed dynamics are not revealed in this test.",
8311.txt,"This result in figure 13 shows the expected features of a pull-in hysteresis curve; the proof mass moves towards the pull-in electrode with increasing voltage, until it reaches the unstable point and snaps in to the bump stop.",
8312.txt,"Since the bump stop is a compliant spring, further increases in the voltage pull the proof mass closer by deflecting the bump stop spring.",
8313.txt,"As the voltage is reduced, this deflection is reversed, until the sum of the electrostatic and stiction forces is insufficient to maintain the proof mass in the pulled-in position, and it snaps back to equilibrium.",
8314.txt,"As a result of the interdependency of position and force, we cannot solve for the major uncertainties in our devices, and therefore cannot use equation X to solve for the stiction force.",
8315.txt,"As a result, we rely upon alternative metrics to evaluate the relative performance of the different designs.",
8316.txt,One such metric is simply the width of the hysteresis band between pull-in and pull-out.,
8317.txt,"This difference in voltage is a direct proxy measurement for stiction force, and the smaller the difference, the smaller the stiction force.",
8318.txt,"This result is shown in table IV, for the devices, both by bump stop spring length and spring angle.",
8319.txt,"While the data suggests that the 20 ?30 m and 45 spring bump stops may significantly improve the ability to overcome stiction, this conclusion is obscured by a large variance from device to device.",
8320.txt,"This variance may be explained by fabrication tolerance and error, and by a measurement process that is highly sensitive to disturbances.",
8321.txt,"The longer springs are insufficiently stiff to arrest the movement of the proof mass, and sometimes allow electrical shorting and therefore catastrophic failure to occur.",
8322.txt,A more robust alternative metric is simply to observe what fraction of each device configuration survives the high impact surface contacts endured during fabrication and pull-in testing.,
8323.txt,"This result is also more indicative of real-world performance, where the most important requirement is simply that the devices avoid stiction related failure in fabrication and use.",
8324.txt,"The data shown in figure 14, compiled from over 300 test devices, clearly demonstrates that the addition of spring bump stops can significantly reduce susceptibility to stiction-related failure.",
8325.txt,The results of the quasi-equilibrium measurements also enable us to verify our dynamic model of the pull-in test device with spring bump stop.,
8326.txt,"The simulated result, in figure 15, shows nearly identical behavior to the measured result.",
8327.txt,"There are a few differences, however, which are extremely important to note.",
8328.txt,The most significant difference is the considerable overshoot that occurs with pull-in and pull-out.,
8329.txt,The natural high-speed dynamics of the test devices suggest the possibility of better understanding the contributions to the adhesion force and methods of overcoming it.,
8330.txt,Measurement of the motional current generated when the proof mass is moving allowed high speed measurements of the velocity throughout the testing procedure.,
8331.txt,The results of this measurement on a pull-in device are presented in figure 16.,
8332.txt,"This result shows a close correspondence with the modeled behavior; before impact, the proof mass accelerates rapidly until it contacts the spring bump stop.",
8333.txt,"Following the initial contact, the proof mass rebounds and enters an exponentially decaying oscillation.",
8334.txt,The large amplitude of these oscillations is enabled by the spring bump stops.,
8335.txt,"Comparing the velocity profiles from a spring bump stop and hard bump stop impact, we may explain the improvement in stiction performance yielded by the spring stops.",
8336.txt,The hard bump stop converts far less of the collision energy to harmless oscillations than the spring stop.,
8337.txt,"Instead, that same energy is dissipated through much more destructive pathways, like permanent deformation of the contact surfaces.",
8338.txt,"By avoiding this destructive impact, the spring bump stops are able to maintain a much reduced effective surface energy, and thus minimize surface forces, resulting in the improved resistance to stiction-related failure seen in the section above.",
8339.txt,The importance of high-speed dynamics is not limited to the initial impact; rapidly switching off the pull-in voltage allows the energy stored in the deflected spring to be recovered to aid in breaking the surface contact.,
8340.txt,"Furthermore, this configuration is much more representative of an inertial impact in a real device, as the shock loading is typically removed suddenly, rather than ramping down slowly over several seconds.",
8341.txt,The results seen in figure 18 show clearly that removing the electrostatic pull-in force quickly significantly reduces the effect of stiction forces.,
8342.txt,Utilizing the stored energy in the spring to break the surface adhesion achieves excellent resistance to stiction failure under realistic test conditions.,
8343.txt,Repeating the pull-in and pull-out cycles indicates that these results should be quite robust and stable.,
8344.txt,"Subjecting a test device to 1440 cycles at the same pull-in and pull-out voltages shows that the behavior is very nearly identical before and after cycling, within the precision of the measurement.",
8345.txt,"Taken together, the results of the investigation on spring bump stops show that they significantly improve resistance to stiction failure.",
8346.txt,"High speed measurement and actuation both further improve this result, and illuminate the mechanisms responsible for the improvement.",
8347.txt,The spring stops serve to reduce the impact forces and utilize stored energy from the impact to assist in breaking the adhesion.,
8348.txt,The results appear to be stable and broadly applicable to devices that may encounter unexpected surface contact.,
8349.txt,"In this work, we have developed a systematic method for measuring and simulating impacts and real-world conditions leading to stiction.",
8350.txt,"We have used these techniques to thoroughly investigate stiction in pure-silicon MEMS devices, and have shown that silicon-silicon contacts are reversible, even under high loading and repeated contact.",
8351.txt,"While there are significant stiction forces, the magnitudes are modest relative to other forces in typical MEMS devices, and can be overcome.",
8352.txt,"The ultra-clean, pure-silicon environment proves to allow modeling of the contact using reliable models, and illuminates the critical parameters, which determine the magnitude of the stiction forces.",
8353.txt,"These results have been shown to be robust to variations in the process, and are thus broadly applicable to MEMS devices with pure silicon surfaces.",
8354.txt,"In addition, we successfully developed mechanical means of overcoming stiction.",
8355.txt,"These results are different from previous efforts because they are easily adapted to many processes and devices, and require no additional materials or chemical treatments.",
8356.txt,"The improved performance demonstrated by these anti-stiction methods is shown to be accounted for by a reduction in peak impact force, and by utilizing the natural dynamics of the system to provide additional energy, thereby disrupting surface contact.",
8357.txt,"Despite their simplicity, the spring bump stops reduce effective stiction force, or change of stiction failure, by over 50%, and enable the fabrication of high-displacement MEMS devices within encapsulated silicon packaging.",
8358.txt,The authors acknowledge many useful technical discussions with Gary Yama and Gary O'Brien.,
8359.txt,Micromanagement is a very important aspect of real-time strategy games.,
8360.txt,"It involves moving single units or groups of units effectively on the battle field, targeting the most threatening enemy units and use the unit's special abilities when they are the most harmful for the enemy or the most beneficial for the player.",
8361.txt,Designing good micromanagement is a challenging task for AI bot developers.,
8362.txt,"In this paper, we address the micromanagement subtask of positioning units effectively in combat situations.",
8363.txt,"Two different approaches are evaluated, one based on potential fields and the other based on flocking algorithms.",
8364.txt,"The results show thatboththepotentialfieldsversionandtheflockingversionclearly increases the win percentage of the bot, but the difference in wins between the two is minimal.",
8365.txt,The results also show that the more flexible potential fields technique requires much more hardware resources than the more simple flocking technique.,
8366.txt,Real-time strategy games provide many challenges for AI bot developers.,
8367.txt,Each player typically starts with a command center and a number of workers.,
8368.txt,The workers are used to gather one or more type of resources.,
8369.txt,"Buildings can be used to expand the base, protect the base, and produce combat units.",
8370.txt,It is also common for RTS games to have technology trees where a player can invest resources in upgrades for units and/or buildings.,
8371.txt,Each player must take numerous decisions about what to spend resources on.,
8372.txt,Resources are limited and take time to gather.,
8373.txt,"They can, for example, be spent on cheap units to be able to launch an attack on the enemy early in a game , constructing a good defence with nonmobile turrets and bunkers, or on technical advancements to produce strong units, which on the contrary can leave the player vulnerable early in the game.",
8374.txt,Decisions in RTS games or usually divided into the two categories macro- and micromanagement.,
8375.txt,"Macromanagement is decisions at a higher level of abstraction such as what buildings and units to produce, which upgrades to invest in, and when to launch an attack on enemy bases.",
8376.txt,Micromanagement is about controlling individual units.,
8377.txt,"Placing units at tactically good locations, targeting the most dangerous enemy units within fire range and smart use of special abilities can win many games.",
8378.txt,"This paper deals with micromanagement, specifically where to move individual units in combat situations.",
8379.txt,"Examples of good placement of units is to place long-range units in the back guarded by short-range units in the front, avoid taking unnecessary damage on support units, and surround the enemy at maximum shooting distance.",
8380.txt,Navigation of units in RTS games is typically handled with pathfinding algorithms such as A*.,
8381.txt,"A* always finds the best possible path between two positions in a reasonably short time, but does not handle dynamic worlds  very well.Ittakestimefor a unit to travel along apath and much can happen in the game world before the unit reaches the goal position.",
8382.txt,If the path is suddenly blocked by a mobile object it becomes obsolete and the agent has to recalculate all or parts of it.,
8383.txt,Extensive work has been done to modify A* to work better in highly dynamic worlds.Koenig and Likachev have made contributions to the field with their work on real-time A* .,
8384.txt,Pathfinding algorithms such as A* only find paths to the goal position and does not take into account how to position units in combat situations.,
8385.txt,"Additional logic has to be added to handle positioning of units.The paper proposes a hybrid approach for navigation where A* is used when no enemy units or buildings are within sight range,and potential fields when unit are engaged in combat.",
8386.txt,The hybrid approach avoids the problem of local optima when using potential fields.The purpose of this paper is to evaluate if the potential fields based part of the hybrid navigation system can be replaced with a system based on flocking algorithms.,
8387.txt,"Boids is a flocking algorithm for simulating the aggregate motion of a flock of birds, a herd of land animals or a school of fish.Itwasfirst published by Reynoldsin 1987 and has since then attracted a lot of attention in different application areas.",
8388.txt,The boids algorithm is based on a set of rules.,
8389.txt,"In the simplest version, three rules are used.",
8390.txt,?,
8391.txt,Separation: Each member of the flock moves in a direction to avoid colliding with local flock mates.,
8392.txt,?,
8393.txt,Alignment: Each member of the flock moves towards the average heading of the flock members.,
8394.txt,?,
8395.txt,Cohesion: Each member of the flock moves towards the average position of the flock members.,
8396.txt,"Additional rules can be added for, for example, moving towards a goal and avoiding obstacles.",
8397.txt,Flocking have previously been used with success in RTS games.,
8398.txt,Danielsiek et al.,
8399.txt,used boids in the open source RTS game Glest .,
8400.txt,The authors combined boids with influence maps to find safer paths for the flocks.,
8401.txt,The authors show that flocking decreased the amount of unit losses.,
8402.txt,Preuss et al.,
8403.txt,extended the work in X. Synnaeve and Bessier successfully used flocking combined with a Bayesian model for unit control in the RTS game StarCraft.,
8404.txt,The hybrid A*/boids navigation system has been implemented in the open-source StarCraft bot BTHAI.1The bot is a slightly updated version of the one used in our previous work where a hybrid A*/potential fields navigation system was used X.The hybrid navigation system has two parts.,
8405.txt,"When no enemy unit or building is within sight range, agents navigate using A*.",
8406.txt,Local influence algorithms such as flocking and potential fields have a tendency to get stuck in complex terrain since they do not "backtrack" if they get stuck in a dead end.,
8407.txt,We avoid this problem by using A* to calculate the shortest path to the goal position.,
8408.txt,A*isontheotherhandnotverysuitableforpositioningunits.,
8409.txt,Agents move towards the goal without considering how to effectively engage the enemy in a combat situation.,
8410.txt,To solve this the navigation system switches to using flocking with the boids algorithm as soon as an enemy unit or building is within sight range.,
8411.txt,"The boids algorithm is modified so agents try to keep a distance to the enemy close to the maximum shooting distance of its own weapons, while at the same time keeping the squad grouped up.",
8412.txt,Agents shouldalsoavoidcollidingwithotherownagentsandobstacles.,
8413.txt,The hybrid navigation system is outlined in Fig.,
8414.txt,1,
8415.txt,Fig.,
8416.txt,2 shows the preferred moves of two Terran Marines in a combat situation where four Marines attack a Protoss building.,
8417.txt,The Marine that is too far away shall move to a spot on the maximum shooting distance without colliding with other own units.,
8418.txt,"The same goes for the Marine that is too close, but note that shooting has higher priority than moving so he only moves when his weapon is on cooldown.",
8419.txt,Fig.,
8420.txt,3 shows how this behavior looks like in-game.,
8421.txt,A group of marines and medics group up at maximum shooting distance and form an arc surrounding the enemy buildings.,
8422.txt,The hybrid potential fields version works in a similar fashion.,
8423.txt,"Pathfinding with A* is used when no enemy units are within sight range, but potential fields is used instead of boids when an agent is close to an enemy.",
8424.txt,"In potential fields, each interesting game object generates a field surrounding the object.",
8425.txt,"Each field can vary in shape and size, but must fade to zero.",
8426.txt,"Positive potential field values are attracting for agents, negative values are repelling and zero has no influence.",
8427.txt,"All fields generated by objects are weighted and summed to a total potential field, which is used by agents for navigation.",
8428.txt,"When deciding where to move, each agent locates and moves towards the most attracting position in its near surroundings.",
8429.txt,An example of how a total potential field could look like is shown in Fig.,
8430.txt,4,
8431.txt,"The figure shows three agents that generate small repelling fields around them for obstacle avoidance, impassable terrain  that also generate repelling fields for obstacle avoidance, and an enemy unit that is attracting for the agents.",
8432.txt,The highest potential values are located at the maximum shooting distance from the enemy unit.,
8433.txt,This has the effect that the agents approach and surround the enemy units at the shooting distance of their weapons.,
8434.txt,Potential fields can also be used when retreating from dangerous enemy units.,
8435.txt,"In this case, an enemy unit generates a repelling field of negative values with a size a little larger than the maximum shooting distance of the enemy unit.",
8436.txt,An example of agents retreating from an enemy unit is shown in Fig.,
8437.txt,5,
8438.txt,The repelling field is shown in red where lighter red areas are more repelling than darker red areas.,
8439.txt,Fig.,
8440.txt,6 shows an example of the generated total potential field surrounding a Terran Marine in StarCraft.,
8441.txt,More details about the potential field implementation can be found in a previous paper.,
8442.txt,All agents are grouped in squads.,
8443.txt,A squad can contain any number of units and can have different unit types.,
8444.txt,Note that the boids rules described in this chapter only applies to group members in an agent's own squad.,
8445.txt,The rules do not take agents from other squads into consideration.,
8446.txt,"The implementation has five rules, each described in detail below.",
8447.txt,"The pseudocode for each rule, except the separation from enemy units rule, contains a constant value.",
8448.txt,"This value determines how dominant each rule is, and is in our case simply set by trial-and-error.",
8449.txt,t is important for the members of a squad to stay together.,
8450.txt,If single agents get astray they are easy prey for the enemy.,
8451.txt,This is solved with the cohesion ruleeach agent moves towards the average position of all other members in the squad.,
8452.txt,"This rule is not very dominant since other rules, such as keeping distance to enemy units, are more important.",
8453.txt,Each squad move towards a common goal and therefore individual agents shall move in approximately the same direction.,
8454.txt,Each agent therefore moves towards the average heading/direction of the other squad members.,
8455.txt,Pseudocode for the alignment rule is shown later.,
8456.txt,The influence of this rule is quite weak as in the case of the cohesion rule.,
8457.txt,The bot has a commander that decides where to move each squad.,
8458.txt,The commander controls one or more attacking squads.,
8459.txt,When all these squads are constructed an attack is launched at the enemy.,
8460.txt,The goal of the attack is the closest enemy building found during scouting.,
8461.txt,"The commander is very simple and a lot of features and improvements can be made, but that is out of scope of this paper.",
8462.txt,Each agent moves towards the goal of the squad.,
8463.txt,Note that this rule has quite weak influence as well.,
8464.txt,The navigation towards the goal is mostly handled by the A* part of the navigation system.,
8465.txt,Agents shall avoid colliding with other own agents and shall also strive to keep a short distance between each other.,
8466.txt,This is handled with the separation rule.,
8467.txt,The detection limit iscalculatedasthe radiusof the agent plus the radius of the agent to avoid plustwo.,
8468.txt,"If we want the group members to spread out more, we simply increase the detection limit.",
8469.txt,Pseudocode for the separation of own agents is shown here.,
8470.txt,The separation from enemy units is the most important rule in the boids implementation.,
8471.txt,The purpose of the rule is to keep agents at approximately the maximum shooting distance from enemy units and buildings.,
8472.txt,The detection limit is calculated differently depending on the current situation.,
8473.txt,?,
8474.txt,"If the agent can attack the enemy, detection limit is set to the maximum shooting distance of the agent's weapon.",
8475.txt,?,
8476.txt,"If the agent cannot attack the enemy but the enemy can attack the agent, detection limit is set to the maximum shooting distance of the enemy's weapon plus the radius of the agent.",
8477.txt,?,
8478.txt,"If the agent cannot attack the enemy and the enemy cannot attack the agent, detection limit is set to the radius of the agent plus 10.",
8479.txt,The pseudocode for the separation from enemy units rule is as follows.,
8480.txt,Agents shall also avoid colliding with impassable terrain.,
8481.txt,This separation rule is explained in the pseudocode below.,
8482.txt,Note that this rule does not apply to airborne units.,
8483.txt,There is no terrain in StarCraft that blocks flying units.,
8484.txt,"The main purpose of this paper is to compare two hybrid pathfinding systems, one based on boids and another based on potential fields.",
8485.txt,We will also see how effective the hybrid pathfinding systems are compared to a nonhybrid pathfinding system based on A* only.,
8486.txt,"One of the disadvantages of potential fields based solutions in games with many agents is performance, and a performance comparison between potential fields and boids would give valuable insight in which hybrid pathfinding solution to select.",
8487.txt,To answer the research questions we have conducted a series of experiments where the three pathfinding systems played against the built-in StarCraft AI on four StarCraft maps.,
8488.txt,"Both the bot and the built-in AI played Terrans, and each map was played 50 times for each bot version.",
8489.txt,"We have also compared performance between the boids hybrid pathfinder and the potential fields hybrid pathfinder using QueryPerformanceCounter , a reliable high-precision timer that can measure down to ms level.",
8490.txt,The results from the experiments are presented in Table I.,
8491.txt,"Not surprisingly, a hybrid pathfinder using either potential fields or boids outperformed the version without any hybrid pathfinding.",
8492.txt,"The difference between the two hybrid pathfinding systems was minimal, 175 wins against 178 wins.",
8493.txt,There is also a clear difference between simple two-player maps and more complex four-player maps.,
8494.txt,"The results for hybrid and nonhybrid pathfinding was almost equal for the two-player maps, while the results differ markedly for the four-player maps.",
8495.txt,Totestforstatisticalsignificancewehaveperformedpairwise two-sample T-test between proportions with significance level 0.10.,
8496.txt,The results are presented in Table II.,
8497.txt,"As expected the win percentage of A* is significantly lower than the other two versions, but no significant difference can be found between the potential fields and boids solutions.",
8498.txt,The experiments failed to find a difference in win percentage between the potential fields and the boids solutions for hybrid pathfinding.,
8499.txt,This is as we expected.,
8500.txt,The behavior of squads is quite similar when watching games being played.,
8501.txt,The results from the performance tests are presented in Table III.The potential  fields version required on average well over 100 times longer to execute!,
8502.txt,"Of coursethereareprobably several waysthe potential fields implementation can be optimized, but the results at least give a good hint that boids is a much faster solution.",
8503.txt,"To see which hybrid pathfinding system is the best in terms of win ratio, we have also run a series of experiments where the boids version played against the potential fields version.",
8504.txt,The results are presented in Table IV.,
8505.txt,"The potential fields based version has a slightly higher win ratio, but at the cost of higher computational needs.",
8506.txt,We expected that a hybrid pathfinding system would outperform a nonhybrid solution.,
8507.txt,"This was verified by the experiments, but an interesting note is that the difference in win ratio is very small for simple two-player maps and quite large for more complex four-player maps.",
8508.txt,Overall we think that hybrid pathfinders are very competent for RTS game bots.,
8509.txt,This claim is also verified in a previous paper.,
8510.txt,We also expected the win ratio of the boids solution to be equalorslightlylowerthanforthepotentialfieldssolution.This was also verified by the experiments.,
8511.txt,Even though the boids solution had slightly higher win ratio compared to the potential fields solution  the difference was not statistically significant and we conclude that the win ratios are in practice equal.,
8512.txt,The most interesting thing is the performance tests.,
8513.txt,We expected that the potential fields solution would require much more execution time than a solution based on boids.,
8514.txt,This was also verified by the experiment results.,
8515.txt,The difference in execution time between the two was well above the factor of 100.,
8516.txt,The potential fields based solution in its current form is not suitable for StarCraft since the average execution time of 7.6 ms is too long.,
8517.txt,"The AI has to take a lot of microand macrodecisions in the relatively short time available each frame, and currently the bot cannot run at highest speed when using potential fields.",
8518.txt,More research is required to optimize implementations of potential fields based solutions.,
8519.txt,An important benefit of potential fields over boids is that fields surrounding in-game objects can have a wide variety of shapes and sizes.,
8520.txt,A field can for example be attractive at one distance from the object and at the same time repelling at another distance.,
8521.txt,Boids is not as flexible.,
8522.txt,In-game objects are either attractive or repelling.,
8523.txt,"This is to some extent verified in the second experiment where the potential fields based solution outperformed the, compared to the built-in AI, more competent boids solution when playing against each other on small maps.",
8524.txt,On larger four-player maps both versions had the same win ratio.,
8525.txt,We believe this is due to more factors influencing who will win or lose on a larger map than on a smaller map.,
8526.txt,As future work both versions could be played against bots from the annual StarCraft tournaments to see if this is the case.,
8527.txt,Developers should also have in mind that it can be quite time consuming to fine tune how individual potential fields interact to form a total potential field for effective behaviors.,
8528.txt,The choice of which technique to use comes down to the complexity of the agent behaviors.,
8529.txt,"We believe that for hybrid pathfinding in RTS games where the goal of the agents is to surround the enemy, a boids solution can be at least as effective as a potential fields based solution while requiring much less hardware resources.",
8530.txt,Note that more research has to be done to see if this is also the case when facing more competent opponents than the built-in AI.,
8531.txt,An interesting idea for future work is to combine flocking with potential fields.,
8532.txt,Potential fields can be used for tactical analysis of combat situations and boids for agent movements.,
8533.txt,"Due to a battery constraint in wireless sensor networks, prolonging their lifetime is important.",
8534.txt,Energy-efficient routing techniques for WSNs play a great role in doing so.,
8535.txt,"In this paper, They are further classified into static and mobile ones.",
8536.txt,"We give an overview of these protocols in each category by summarizing their characteristics, limitations, and applications.",
8537.txt,"Finally, some open issues in energy-efficient routing protocol design for WSNs are indicated.",
8538.txt,"Advances in micro-electro-mechanical systems, wireless communication and distributed information processing technologies have enabled the rapid development and deployment of wireless sensor networks .",
8539.txt,Their applications vary from military uses to environmental monitoring .,
8540.txt,"However, their nodes are normally equipped with energyconstrained batteries to meet size and cost constraints.",
8541.txt,"Therefore, it is imperative to design energy-efficient protocols for them in order to prolong their lifetime.",
8542.txt,Energy consumption of a sensor node has a significant impact on the lifetime of WSNs.,
8543.txt,"The energy of a WSN can be saved by applying different techniques, such as dutycycle scheduling , energy-efficient MAC , energy-efficient routing , node replacement , energy harvesting , energy replenishment , and energy balance .",
8544.txt,As shown in Fig.,
8545.txt,"1 , the communication needed by a typical sensor node is the biggest power consumer.",
8546.txt,"Its wireless communication module has four states, send, receive, idle and sleep.",
8547.txt,"In other words, an efficient routing protocol can help balance the energy consumption levels among WSN nodes.",
8548.txt,"Giving the same hardware conditions, it can help prolong the lifetime of WSN, as well as improve the quality of data transmission.",
8549.txt,"However, traditional routing protocols tend to focus on how to make the data packets reach fastest their destination nodes with the shortest transmission path.",
8550.txt,TheymaynotbethebestfromtheviewpointofWSNlifetime  owing to energy-constrained sensor nodes.,
8551.txt,"Furthermore, due to the energy consumption at the sleep and idle states are minimal in comparison with the others, researchers often consider the energy consumption of the sending and receiving states only.",
8552.txt,"Generally, the energy model is adopted from X.",
8553.txt,"In this model, both free-space and multipath fading channel models are used, depending on the distance between a transmitter and receiver.",
8554.txt,"When the distance is less than a threshold value d0, the former is used; otherwise, the latter is used.",
8555.txt,"Then to transmit an l-bit message for a distance d, the energy model is given as follows: Many routing protocols for WSNs have been proposed, and many surveys and introductory papers on routing protocols,are available in the literature.",
8556.txt,Their classification in X is extended in Y which is comprehensive but not all the protocols described are energy-aware.,
8557.txt,"Furthermore, each protocol involved in X also considers only one base station.",
8558.txt,"The survey divides WSN routing protocols into four classes known as Network Structure, Communication Model, Topology Based and Reliable Routing Schemes.",
8559.txt,The Network Structure class is subdivided into flat and hierarchical protocols.,
8560.txt,"The Communication Model class has query, coherent and negotiation ones.",
8561.txt,Topology Based protocols are further classified into location and mobile agent ones.,
8562.txt,Reliable Routing Schemes refer to either multipath or QoS ones.,
8563.txt,The routing challenges and design issues in WSNs are given.,
8564.txt,The work comprehensively introduces various routing protocols for WSNs.,
8565.txt,Y et it largely misses their performance results.,
8566.txt,The work  presents a survey with its focus on the scalability of routing protocols.,
8567.txt,"It classifies them according to motivations such as control overhead reduction, energy consumption mitigation and energy balance.",
8568.txt,The work  gives an exhaustive overview of intelligent routing protocols.,
8569.txt,It first defines network lifetime in three aspects.,
8570.txt,"Then, it categorizes the protocols based on such algorithms as reinforcement learning, ant colony optimization, fuzzy logic, genetic algorithm, and neural networks.",
8571.txt,It also highlights the performance analysis results and applications of each surveyed routing protocol.,
8572.txt,"Clearly, a routing protocol that cannot cope with mobility at all affect negatively the lifetime of WSNsand a definition of network lifetime that does not explicitly account for mobility at all may likely yield false lifetime estimation.",
8573.txt,"By introducing mobility in WSNs, mobile nodes can move to the sensors near sinks or isolated parts of the network and hence energy consumption in the nodes becomes even and connectivity is better maintained .",
8574.txt,"All the sensor nodes in homogeneous WSNs in X are assumed to be of the same type, especially in their power supply, communication bandwidth, computation and storage capacity.",
8575.txt,"Homogeneous WSNs may help researchers understand and analyze WSNs at the beginning, but with the expansion and in-depth research, they cannot meet the needs for practical applications.",
8576.txt,Their network model is too ideal and simple.,
8577.txt,"In reality, heterogeneous WSNs are more common.",
8578.txt,"In intelligent building monitoring applications, for example, there exist some nodes in monitoring air humidity and indoor temperature, and others in monitoring light intensity.",
8579.txt,These nodes have function heterogeneity.,
8580.txt,"Moreover, their initial energy may be different due to different manufacturers or different batch production.",
8581.txt,Their computing power and link capacity may vary as well.,
8582.txt,Their sensing capability and transmission range may differ.,
8583.txt,Heterogeneous WSNs are those composed of different types of nodes to meet diverse application requirements .,
8584.txt,Traditional routing protocols for homogeneous WSNs are not fit for heterogeneous ones.,
8585.txt,"Hence, routing protocols for heterogeneous WSNs should be studied.",
8586.txt,Table1providesacomparativesummaryofthesepriorsurveys in terms oftheir shared and most recent citedreferences.,
8587.txt,"From Table 1, we have: The 2004 survey  presents a comprehensive survey of earlier routing protocols, but not all described are energyefficient;  addresses various aspects of energy harvesting sensor systems;  exploits routing protocols designed for large-scale WSNs;describes energy-efficient routing protocols;  classifies routing protocols based on different design criteria, and discusses the mobility including mobile sinks only, few mobile nodes act as mobile relays, all nodes mobile and few nodes are stationary; gives an overview of WSNs from an industrial perspective;  discusses routing protocols based on intelligent algorithms;  considers only the routing protocols with mobile sinks; focuses on hierarchical routing protocols for heterogeneous WSNs; and categorizes various heterogeneous routing protocols for WSNs based upon various predefined parameters.",
8588.txt,"Besides, routing characteristics of WSNs, such as energyaware, cluster-based, mobility, scalability, homogeneity and heterogeneity are given in the above surveys.",
8589.txt,"Note that, although an energy model plays an important role in the conservation of energy, it is not mentioned in the above surveys.",
8590.txt,"To the best of our knowledge, the work presented in this paper is the first attempt at such a survey with the focus on the energy-efficient routing protocols in these distinct types of WSNs.",
8591.txt,"Furthermore, this work aims to provide the stateof-the-art in the subject by including the recently developed techniques and proposals.",
8592.txt,"In addition, this work gives application scopes of each protocol which were missing in the earlier surveys.",
8593.txt,LEACH is cited and studied by almost all the survey papers.,
8594.txt,"This is because cluster-based routing is more energy-efficient, more scalable, and more secure as compared with traditional flat routing .",
8595.txt,"As the first cluster-based routing protocol, its basic idea is that all sensor nodes are grouped into several clusters.",
8596.txt,"In each cluster, a lead node called cluster head  whose duty is to gather data and transmit data to the base station is elected based on a predetermined probability.",
8597.txt,"It works in two phases, namely, setup and steady phases.",
8598.txt,"In the former, CH is elected by rotation and clusters are formed.",
8599.txt,"In the latter, nodes sense and transmit data to the CH.",
8600.txt,Then the CH aggregates and sends data to the BS directly.,
8601.txt,Thus it is not suitable for large WSNs.,
8602.txt,"The main limitation of this protocol is its random selection of CH, which may pick up a CH that has low energy and thus dies quickly.",
8603.txt,"Therefore, many routing protocols proposed thereafter aim to make improvements on it.",
8604.txt,"For example, HEED takes residual energy and communication cost into consideration when selecting a CH.",
8605.txt,"In contrast with LEACH, HEED uses multi-hop communications between CHs and the BS while LEACH uses single-hop communication.",
8606.txt,"Moreover, HEED also provides guaranteed coverage of nodes in WSNs.",
8607.txt,"However, it assumes that nodes can control their transmission power level.",
8608.txt,This is not always a realistic assumption.,
8609.txt,The rest of the paper is organized as follows: Section II categorizes current routing protocols for WSNs into different classes according to whether WSNs are homogeneous or heterogeneous and static or mobile.,
8610.txt,"Sections III and IV give a detailed analysis of currently representative routing protocols, with the objective to highlight the critical characteristics influencing routing protocol design and applications.",
8611.txt,A comparative summary of the current routing techniques is also provided.,
8612.txt,"Finally, conclusions and open issues are discussed in Section V. The network layer aims to realize the communication among sensors, and between sensors and observers, data routing and cooperative sensing.",
8613.txt,"WSN routing protocols must be designed to meet the desired performance requirements in energy efficiency, scalability, robustness, and convergence.",
8614.txt,"Their main goal is to establish a reliable and energyefficient path for WSN nodes, and achieve the longest lifetime for the entire WSN.",
8615.txt,"Energy consumption in routing is caused by neighborhood discovery, communication and computation.",
8616.txt,We discuss the state-of-the-art representative routing protocols for WSNs.,
8617.txt,We summarize the methods for improvingenergy-efficientaccordingtotheirmotivation.The classification is shown in Fig.,
8618.txt,2,
8619.txt,Routing protocols for homogeneous WSN deal with identical nodes.,
8620.txt,Its energy-efficient routing protocols are proposed from different points of view.,
8621.txt,They can be subdivided into static and mobile ones.,
8622.txt,"The former includes opportunistic, cross-layer, cooperative and biologically inspired optimal routing protocols depending on their protocol design and principles while the latter aims to deal with not only energy problems but also mobile scenarios.",
8623.txt,Mobile nodes can be sources and sinks.,
8624.txt,Routing protocols for heterogeneous WSN aim to tackle heterogeneity as well as energy issues.,
8625.txt,"According to X, heterogeneity can triple the average delivery rate and provide a fivefold increase in network lifetime when properly deployed.",
8626.txt,"The heterogeneity is reflected via energy, computation, network protocol and/or links.",
8627.txt,Note that cluster-based routing is not classified as a class in Fig.,
8628.txt,2 for the following two reasons.,
8629.txt,One is that such routing is widely used in both homogeneous and heterogeneous WSNs.,
8630.txt,The other is due to limited space.,
8631.txt,"Thus, the characteristics of cluster-based routing are well described in static heterogeneous WSNs.",
8632.txt,Opportunistic routing  is proposed to solve unreliable link problems and reduce unnecessary retransmission.,
8633.txt,"Thus it can improve not only transmission reliability, but also energy efficiency.",
8634.txt,It involves multiple forwarders to increase network communication throughput by taking advantage of the broadcast nature of wireless communication.,
8635.txt,An Extremely Opportunistic Routing  protocol in X is the first such scheme.,
8636.txt,The MAC-independent Opportunistic Routing and Encoding protocol  is its extension.,
8637.txt,MORE presents the first integration of opportunistic routing with intra-flow network coding to bypass the coordination issue previously resolved by an ExOR's highly structured scheduler.,
8638.txt,"Although ExOR and MORE are the two early and famous opportunistic routing schemes, they do not take the energy consumption issue into consideration.",
8639.txt,"Therefore, they are not further discussed in this paper.",
8640.txt,EEOR: An Energy-Efficient Opportunistic Routing protocol is proposed in X with the aims to reduce energy cost in selecting and prioritizing a forwarder list under opportunistic routing and to increase the lifetime of a network.,
8641.txt,It is multipath routing.,
8642.txt,Its Expected Energy Cost  is studied as a primary metric instead of its Expected Transmission Count in X.Then a forwarder list can be prioritized based on EEC.,
8643.txt,"Since the smaller transmission power, the smaller energy consumed to transmit one packet of data received successfully by at least one node in a forwarder list, several algorithms are introduced to calculate the forwarder list and EEC.",
8644.txt,"EEOR has two power models, nonadjustable and adjustable ones.",
8645.txt,"Simulation results prove that EEOR is more efficient in terms ofenergyconsumption,packetdelivery,throughput,lossratio and delay than ExOR.",
8646.txt,"However, one component of EEC, namely the energy consumed for communication agreement, is not accurately computed.",
8647.txt,"Furthermore, EEOR fits for unicast cases only.",
8648.txt,E2R:A simple but robust multipath routing protocol named energy efficient routing protocol  is introduced in X.,
8649.txt,"According to X, in some opportunistic routing protocols, such as ExOR  and EEOR , pre-selecting a forwarding list beforehand can be unwise, especially for a very large network.",
8650.txt,E2R introduces a forwarder self-selection scheme in a data delivery phase.,
8651.txt,Its key idea is to use a node's own route metric value to compare with that attached in its received data packets.,
8652.txt,"If the former value is smaller than the latter's and the node does not overhear one of its neighbors with a better route metric during the node's back-off time interval, the node selects itself as a relay node.",
8653.txt,"As a result, the less needed information of the node, the less decreased size of the data packet, which in turn consumes less energy during wireless transmission.",
8654.txt,"Moreover, a greedy forwarding algorithm in a route metric discovery phase is proposed to further decrease the overhead of control messages.",
8655.txt,"Simulation results show that E2R achieves superior performance in terms of packet delivery ratio, control overhead, packet delivery delay and energy consumption over AODV .",
8656.txt,Note that E2R can work in a mobile environment.,
8657.txt,It is thus well suitable for large scale WSNs.,
8658.txt,K-S: Kaliszan and Stanczak integrate opportunistic routing with network coding  by considering the energy consumed to transmit one packet of data and receive it by another node.,
8659.txt,It prolongs network lifetime by avoiding duplicate transmissions without using a coordination mechanism as used by the prior protocols .,
8660.txt,"Giving a fixed reception probability, alinearprogramisformulatedandalow-complexityheuristic algorithm is designed to solve it.",
8661.txt,Simulation results indicate that K-S reduces energy up to 20% compared with MORE.,
8662.txt,"Because of the characteristic of network coding, this protocol can be applied to delay-tolerant applications.",
8663.txt,"It is, however, not suited for the real-time application of WSNs.",
8664.txt,Table 2 provides a comparative summary of the characteristics of opportunistic routing-based protocols discussed in this section.,
8665.txt,"Because controllers at the network layers interact with each other, the parameters of each layer should be jointly decided to achieve the optimal network performance.",
8666.txt,"Apart from a stringent layered protocol, cross-layer design that violates the principle of layered protocol and permits the interaction of non-adjacent layers has received much attention.",
8667.txt,It can realize flexible and intelligent management and control of WSNs so as to achieve high energy efficiency and extend the WSN lifetime.,
8668.txt,"They have performed a joint optimal design of the physical, MAC and routing layers to maximize lifetime of a single-sink WSN with energy constraints.",
8669.txt,"Given the link access probabilities, the problem can first be formulated as a convex optimization problem.",
8670.txt,"A distributed algorithm, called Joint Routing and Power control Algorithm, is then proposed.",
8671.txt,"Its power control protocol and routing strategy protocol are regulated by a Lagrangian multiplier and work in physical and network layers, respectively.",
8672.txt,"However, the linkaccessprobabilitiesareoftennotdirectlyavailableinreal networks.Thus,theproblemisdeterioratedintoanon-convex problem.",
8673.txt,"As a heuristic algorithm, JRPRA is then developed.",
8674.txt,Both JRPA and JRPRA try to minimize energy consumption of the nodes by adopting correlated data gathering technique that uses Slepian-Wolf coding .,
8675.txt,JRPRA also increases the network lifetime by adjusting link capacity.,
8676.txt,"Furthermore, it uses multipath routing in transmission according to the total rate of data flows over a link and selects the route by employing the Bellman-Ford shortest path algorithm.",
8677.txt,Simulation results show that JRPRA significantly improves the lifetime of WSN.,
8678.txt,Note that it maximizes the lifetime with the assumption of lossless transmission.,
8679.txt,"Thus, it is suitable for the network of high stability since a network of low stability invalidates the assumption.",
8680.txt,A distributed algorithm called Lifetime Maximization Cooperative Routing with Truncated Automatic repeat request is presented in X.,
8681.txt,"It combines together cooperative diversity at the physical layer, truncated automatic repeat request at the data link layer and distributed routing strategy at the network layer.",
8682.txt,"It decreases the consumed energy and optimizes lifetime through the following ways:  integrating cooperative diversity techniques  whose significance in saving energy and improving quality of a wireless channel is proved;  exploiting power allocation based on the average packet error rate and the average symbol error rate through two modulations, BPSK and QPSK , and  choosing a cost-least routing path in terms of channel state and residual energy.",
8683.txt,"It uses the residual energy information to balance the energy among all nodes to avoid any energy hole, thereby prolonging the WSN lifetime.",
8684.txt,"Besides, it utilizes cyclic redundancy check appended behind the data information as the metric of judging the correctness of received signal instead of popularly used SNR  threshold.",
8685.txt,Simulation results show that it is highly efficient in a high-quality channel network.,
8686.txt,"However, it has some rooms for its improvement.",
8687.txt,"For example, it is desired to evaluate the energy consumption associated with this switching process, although it enables sensor nodes in differentstatestoavoidunnecessaryenergywaste.Sinceeach node is equipped with one omnidirectional antenna, which sends signals in unnecessary transmission direction as well, extra energy consumption is caused, which may be avoided by using directional or smart antenna.",
8688.txt,"The work develops a robust and efficient Cross Layer Optimal Design  that performs scheduling at the data link layer, routing at the network layer, and congestion control at the transport layer.",
8689.txt,It reduces energy mainly by congestion control.,
8690.txt,"Node-level congestion at a transport layer is reduced through a compressed sensing technique that attributes to decreasing transmitted bits, while linklevel congestion at the data link layer is reduced via proper resource allocation.",
8691.txt,Simulation results demonstrate that its computational complexity is greatly reduced and performs well under light load.,
8692.txt,Note that CLOD assumes that the link capacity is fixed.,
8693.txt,Table 3 provides a comparative summary of the characteristics of cross-layer-based routing protocols discussed above.,
8694.txt,"Cooperative communication is able to mitigate channel fading, achieve high spectral efficiency and improve transmission capacity .",
8695.txt,"Strictly speaking, it is a part of crosslayer routing.",
8696.txt,It is developed from the traditional MIMO  techniques that can reduce the transmission power and extend the transmission coverage.,
8697.txt,"Its basic idea is to allow multiple nodes to form a virtual MIMO system to share their antennas and resources, thereby gaining the advantage of space diversity in a multinode scenario instead of equipping each node with multiple antennas.",
8698.txt,"RBCR: As an energy-efficient cooperative routing scheme with space diversity, Relay selection Based Cooperative Routing is established by considering the consumed energy as well as channel quality in X.",
8699.txt,It first models the problem based on the minimum cost path problem with relays  and formulates it as a multi-objective optimization problem.,
8700.txt,"To solve it, RBCR uses a distributed algorithm based on two labeling algorithms aided by auxiliary matrixes that store labels with different metrics.",
8701.txt,It finds a single-node cooperative route by using channel state information of a node's two-hop neighborhood and consumed energy at each node.,
8702.txt,"In such a route, each relay has one node only.",
8703.txt,"In addition, nodes use a decode-and-forward strategy without cyclic redundancy check and transmit decoded information to a receiver node that combines its received signals to retrieve data.",
8704.txt,Simulation results show that energy efficiency is enhanced by not only utilizing the cooperative diversity available which can overcome rayleigh fading but also selecting the best paths in terms of channel state information and energy consumed.,
8705.txt,RBCR performs better under good-quality channels since non-cooperative transmission outperforms fixed relay cooperative transmission under poor-quality channels.,
8706.txt,EBCR: An Energy-Balanced Cooperative Routing along the underlying non-cooperative path is proposed to ensure high energy efficiency.,
8707.txt,"Instead of requiring two-hop neighborhoods in RBCR, it introduces and uses only one hop neighborhoods.",
8708.txt,It determines the optimal relaying set and utilizes a multiple-relay strategy.,
8709.txt,The selected multiple neighboring nodes act as multiple transmitting and receiving antennas.,
8710.txt,The protocol provides higher throughput and similar delay performance compared with the traditional single-relay strategy and single receiving diversity routing methods .,
8711.txt,"However, EBCR is not taking the fading problem into consideration, thereby yielding relatively high bit error rate.",
8712.txt,"It is suitable for applications in which network reliability is not essential, namely a network with low SNR.",
8713.txt,mp-MILP: The minimum energy cooperative routing problem is formulated as a Multi-Parametric Mixed-Integer Linear Program to determine the optimal relay selection and power allocation while meeting an SNR constraint .,
8714.txt,"Unlike RBCR and EBCR, instead of multiple hops, the scope of cooperative relay depends on Euclidean distance among nodes to decide next nodes.",
8715.txt,"Similar to EBCR, it involves multiple neighboring relays.",
8716.txt,Another feature in the systematic determination of the optimal relaying set is that the transmission power of each node is adjusted and cooperative nodes with the smallest possible total transmission power are selected.,
8717.txt,"Since mp-MILP aims to minimize the total transmission power, the uneven energy consumption among nodes and much shorter network lifetime than EBCR's may result.",
8718.txt,"Note that, to obtain a low complexity implementation, mp-MILP is solved off-line by using multi-parametric programming theory.",
8719.txt,A modulation scheme is used to solve the fading problem.,
8720.txt,Simulations show that mp-MILP achieves superior performance in terms of both power consumption and bit error rate.,
8721.txt,Such a framework is well suitable for networks requiring high reliability.,
8722.txt,Table 4 provides a comparative summary of the characteristics of cooperative routing-based protocols discussed above.,
8723.txt,Biologically inspired principles have led to various technological innovations in different fields of research .,
8724.txt,BIOSARP: A Biologically Inspired self-Organized Secure Autonomous Routing Protocol is proposed.,
8725.txt,It is based on ant colony optimization whose results heavily depend on how efficiently the pheromone is handled.,
8726.txt,It employs two types of ants: forward and backward ones.,
8727.txt,It makes improvement in terms of probability choice formula and pheromone factor renewing ways.,
8728.txt,"It uses endto-end delay, remaining battery power, and link quality as heuristic factors and applies them to the ant pheromone value/probability formula.",
8729.txt,"Therefore, it provides not only minimum delay and high energy efficiency, but also low packet loss.",
8730.txt,"In addition, its data communication is manyto-one.",
8731.txt,It is tested through NS-2 simulator and the results obtained for different mobility scenarios are compared with protocols like secure real-time load distribution routingandimprovedenergyefficientant-basedrouting.,
8732.txt,The results through real testbed experimentation are also obtained.,
8733.txt,It is suitable for event-driven applications.,
8734.txt,"Different from BIOSARP , BeeSensor  is inspired by the honey-bee colony.",
8735.txt,"It is composed of four types of agents: packers, scouts, foragers and swarms.",
8736.txt,"Its main operators include scouting, foraging, swarming and routing loops and path maintenance.",
8737.txt,Its high energy efficiency is achieved by decreasing route-discovery overhead.,
8738.txt,It is more applicable for monitoring applications that require frequent data transfer since a bee's communication skill is better than an ant.,
8739.txt,"Simulations show that BeeSensor achieves superior performanceintermsofbothpowerconsumptionandpacketdelivery ratio than AODV .Besides, compared with BeeSensor, it adds a new agent called HiveHeader whose major role is to claim that it wants to be selected as a cluster head when it detects an event.",
8740.txt,"Furthermore, a freespace energy model is used in Bee-Sensor-C when sending or receiving a one-bit message.",
8741.txt,"Note that, the data communication of both BeeSensor and Bee-Sensor-C is through multipaths.",
8742.txt,"Through simulation, it is shown to not only increase the network lifetime but also enhance other performance metrics like packet delivery rate and scalability as compared with BeeSensor.",
8743.txt,Table 5 provides a comparative summary of the characteristics of biologically inspired optimization routing protocols discussed in this section.,
8744.txt,"As mentioned above, traditional routing protocols assume static and homogeneous WSNs.",
8745.txt,"Opportunistic, cross-layer, cooperative and biologically inspired optimal routings are used to achieve high energy efficiency and network performance.",
8746.txt,Opportunistic routing is proposed to deal with unreliable link problems and reduce unnecessary retransmission.,
8747.txt,The idea of cross-layer routing is straightforward.,
8748.txt,"But its main drawback is its high computation complexity, which may be too heavy for most sensor devices.",
8749.txt,The main advantage of cooperative routing is that it is robust and can achieve high network throughput.,
8750.txt,"It is clear that reducing the size of a forward list of opportunistic routing or the scope of cooperative relay can decrease communication overhead and energy consumption, so as to achieve the purpose of prolonging the network lifetime.",
8751.txt,Biologically inspired optimal routing is more suitable to large scale WSNs.,
8752.txt,"However, it faces the difficulty to achieve global optimal results.",
8753.txt,"Note that, protocols in this class do not assume any special energy models, except JRPRA  and Bee-Sensor-C .",
8754.txt,"JRPRA describes the energy model in sending and receiving states, but does not give more details to explain how to compute the energy consumption, while Bee-Sensor-C only describes the free-space energy model in sending or receiving one bit message.",
8755.txt,Termite-Hill: Termite-hill  is proposed to balance the energy consumption among sensor nodes of WSNs to avoid the emergence of any energy holes.,
8756.txt,Its idea is to adopt one mobile sink that can move without constraints.,
8757.txt,It can avoid energy holes caused by the excessive energy consumption at those nodes near sinks in a static WSN.,
8758.txt,"Termite-hill is an intelligent algorithm, inspired by the behaviors of termites.",
8759.txt,"To evaluate its performance, it is simulated in static and mobile sink scenarios, and implemented on real WSN hardware.",
8760.txt,"The results show that it can achieve higher throughput, success rate and energy efficiency as compared with AODV in mobile sink scenario with varying speed.",
8761.txt,It can improve network lifetime lightly over a static sink approach.,
8762.txt,It represents Trace-Announcing Routing Scheme.,
8763.txt,"Unlike X, Chi and Chang  focus on some applications that need the support of both mobile sinks and targets.",
8764.txt,"Since both can move freely in the network, a virtualgrid-based routing scheme called Trace-Announcing Routing Scheme is designed.",
8765.txt,It is an extension to the tracking-assisted routing scheme for WSNs .,
8766.txt,Its key idea is to capture the mobile objects' moving path by broadcasting a Trace-Announcing packet rather than re-constructing a routing path.,
8767.txt,"To this end, TARS maintains both routing and tracking information tables.",
8768.txt,"Besides, a lightweight shortcutting scheme and time-scheduling radio method are proposed to optimize a routing path in terms of energy consumption.",
8769.txt,"As an energy-efficient distributed clustering protocol with a path predicable mobile sinks, MobiCluster is introduced in X.",
8770.txt,"Its operations have five phases: clustering,  rendezvous node selection, cluster head attachment to rendezvous nodes,  data aggregation and forwarding to the rendezvous nodes, and  communication between rendezvous nodes and mobile sinks.",
8771.txt,A clustering algorithm is introduced to optimally control the cluster size in terms of the distance between a cluster head and mobile sink.,
8772.txt,"The larger distance, the bigger cluster size.",
8773.txt,"By this way, energy consumption among static nodes can be balanced.",
8774.txt,"An algorithm is also given to select rendezvous nodes, such that packet collision and energy consumption are reduced while data throughput is increased.",
8775.txt,"To further prolong WSN lifetime, cluster heads or rendezvous nodes can be replaced on demand when their energy level is low.",
8776.txt,This protocol assumes that the trajectories of mobile sinks are fixed.,
8777.txt,Wang propose an energy-efficient distance-aware routing algorithm with multiple mobile sinks .,
8778.txt,"To reduce energy consumption, it uses the first radio energy model to adjust transmission power according to distance.",
8779.txt,"When transmission power decreases, the risk of interference decreases.",
8780.txt,A relay node with a shorter distance to mobile sinks and with enough energy is selected to use.,
8781.txt,"Unlike other protocols, its mobile sinks can only gather data at certain positions called parking positions by moving along the boundary of a rectangle.",
8782.txt,Mobile sinks cannot collect data when they are moving.,
8783.txt,"In contrast to the selection of the number and positions of rendezvous nodes in MobiCluster, W-L determines the number and parking positions of mobile sinks.",
8784.txt,The simulation results show that WSN lifetime increases with the number of mobile sinks.,
8785.txt,Note that the number of mobile sinks is always proportional to cost.,
8786.txt,Table 6 provides a comparative summary of the characteristics of routing protocols for mobile homogeneous WSNs discussed in this section.,
8787.txt,Routing techniques in this class can deal with not only a hot spot problem but also sparse and disconnected WSNs.,
8788.txt,The mobility makes the signal transmission distance shorter to save energy.,
8789.txt,It makes the energy consumption among nodes easily balanced.,
8790.txt,The major advantage of these protocols is flexibility and scalability.,
8791.txt,"However, a possible side effect brought by this mobility is an increase in packet loss rate due to topology changes and increaseddata latency.Besides, sincethe costof mobilesinks is much higher as compared to static nodes, the adoption of all mobile sensors is unlikely.",
8792.txt,The performance of a WSN using multiple mobile sinks is superior to that using a single one if the cost is not a major issue.,
8793.txt,"Otherwise, choosing an optimal number of mobile sinks becomes an important problem to be answered.",
8794.txt,The trajectory of mobile nodes has a great influence on a sensor network topology and thus on the routing performance.,
8795.txt,"MobiCluster and W-L adopt a fixed trajectory, which is simple and convenient.",
8796.txt,"But in this way, energy consumption of nodes near the sink is relatively large, which cannot fundamentally solve the problem of uneven energy consumption among nodes.",
8797.txt,"Since their sinks move without constraints, Termite-hill and TARS can select a path in real time according to a network condition.",
8798.txt,"They are more flexible, but their implementation is more complicated and may meet more uncertainty.",
8799.txt,"In a large network with a limited moving speed of mobile nodes, the contradiction between the speed of mobile nodes and the requirements for data collection is critical.",
8800.txt,More work is required to design reliable and real-time routing protocols that can be effective in energy conservation while providing delay-guaranteed services.,
8801.txt,"Note that, protocols in this class do not assume any special energy models, except W-L. W-L uses the same energy model as that in X.",
8802.txt,An Energy and Coverage-aware Distributed Clustering protocol for area coverage and point coverage in heterogeneous WSNs and aims at prolonging the lifetime of WSNs.,
8803.txt,"ECDC divides its sensor nodes into three types, cluster head, cluster member and plain node in terms of their energy.",
8804.txt,Its obvious advantage is that it elects a CH based on residual energy and coverage.,
8805.txt,"Due to this, its cluster sizes are even.",
8806.txt,"In addition, its lifetime is defined from the initial time to the time when more than 30% of nodes are not alive.",
8807.txt,"Compared with LEACH and HEED , simulation results show that it can gain less energy consumption and better coverage performance.",
8808.txt,It is applicable to WSNs whether nodes deployed uniformly or not.,
8809.txt,An Energy-Efficient Multilevel Heterogeneous Routing  protocol  aims at saving energy by partitioning all nodes into k level normal nodes and k level advanced nodes where k represents the level of energy.,
8810.txt,"The bigger k, the higher energy level.",
8811.txt,"First, all nodes are divided into two categories as level-1 normal nodes and level-1 advanced nodes.",
8812.txt,Then the latter are further divided into two categories as level-2 normal nodes and level-2 advanced nodes and so on.,
8813.txt,"At end, level k-1 nodes are composed of level k normal nodes and level k advanced nodes.EEMHR uses weighted election probabilities to elect cluster heads to avoid such holes.",
8814.txt,"It is evaluated on experiments that involve five different lifetime definitions with respect to the ratio of alive nodes, three different network sizes and two different initial energy level.",
8815.txt,"Simulation results show that EEMHR is superior to other existing heterogeneous routing protocols, like multi-hop communication routing , in terms of lifetime, stability and the number of cluster heads per round.",
8816.txt,Tyagi present a Lifetime Extended Multi-levels Heterogeneous Routing protocolto enhance EEMHR.,
8817.txt,"First, they indicate the latter's disadvantage by proving that an enhancement of initial energy of a network may not guarantee an enhancement of initial energy for higher level nodes in comparison with the lower level nodes, and the number of higher level nodes depend only on lower level nodes in EEMHR.",
8818.txt,"Then, they select k levels of horizontal energy heterogeneity, where each level has a different amount of initial energy so as to enhance the overall initial energy of a network, rather than use k levels of vertical energy heterogeneity in EEMHR.",
8819.txt,Simulation results show that LE-MHR almost doubles the lifetime of a network with EEMHR.,
8820.txt,"To address three major issues in the design of sensor networks: sensor deployment or sensing area coverage, sink location, and data routing, the work  characterizes the integrated Coverage, Sink Location and Routing Problem in heterogeneous WSNs.",
8821.txt,"All sensors are divided into K types, where K denotes the set of sensor types with different deployment cost.",
8822.txt,Each type also has a different sensing and transmission range.,
8823.txt,Two mixed-integer linear programs are designed.,
8824.txt,One is to consider the total routing energy consumption on the arcs.,
8825.txt,The other aims to minimize the total routing energy that consists of the sensor-to-sink assignment.,
8826.txt,The simulation results show that CSLRP is only applicable to a small-size network with its total node count not exceeding 49.,
8827.txt,"To tackle such complexity issue, it is reduced to the classical p-median problem by giving the sensor location and then tabu search is adopted to solve it.",
8828.txt,Coverage threshold is also considered as additional QoS metric.,
8829.txt,"As discussed above, well-designed routing proposed for heterogeneous WSN can effectively prolong the network lifetime, improve network reliability and meet diverse application requirements.",
8830.txt,"Most existing ones are based on a cluster topology, while they differ in their cluster head selection.",
8831.txt,"Besides energy, the WSN heterogeneity is also manifested in computational capability, network protocols and links, which are related to energy.",
8832.txt,The future work has to deal with more diverse heterogeneity.,
8833.txt,Table 7 provides a comparative summary of the characteristics of routing protocols for static heterogeneous WSN as discussed above with respect to different parameters.,
8834.txt,"Note that, protocols in this class do not assume any special energy models, except EEMHR  and LE-MHR .",
8835.txt,They use the same energy model as that in X.,
8836.txt,"Moreover, clusterbased routing protocols, like those in X, all use single-hop intra-cluster routing methods and multiplehop inter-cluster routing ones to achieve more energy.",
8837.txt,"Hierarchical Adaptive and reliable Routing Protocol  partitions the nodes into two types only, normal nodes and cluster nodes according to their residual energy capacities.",
8838.txt,"Next, cluster head selection is performed based on the residual energy of nodes.",
8839.txt,Its main idea is to build a hierarchical tree in two layers: intra-cluster and inter-cluster.,
8840.txt,The former builds a hierarchical tree among normal nodes with their cluster head as a root while the latter among cluster heads with the sink as a root.,
8841.txt,"Moreover, HARP introduces a local recovery mechanism and mobility management to rebuild trees when link failures occur.",
8842.txt,"Simulation results show that HARP can achieve more efficient, reliable and scalable performances than LEACH.",
8843.txt,"A Routing Algorithm for Heterogeneous Mobile Network divides all sensors into static and mobile ones, while the energy of the former is less than the latter's.",
8844.txt,"The latter can be cluster heads or sink nodes, with different mobility models.",
8845.txt,"Its operations are composed of three phases:  network configuration, detection and election of cluster-heads and  delivery of data to a sink.",
8846.txt,It assumes that all sensors can be elected as a cluster head.,
8847.txt,"The selection of a cluster head depends on mobility level, energy and distance to the sink.",
8848.txt,The results indicate that it is efficient with respect to overhead messages and transmitted data packets.,
8849.txt,A clustered Heterogeneous Sensor Network called HSN is proposed with a mobile sink.,
8850.txt,"The nodes in the network are divided into three categories according to their energy: H-nodes , L-nodes and the sink with unlimited energy.",
8851.txt,H-nodes provide a longer transmission range and higher data rate than L-nodes.,
8852.txt,"Compared with HARP and RAHMoN, its cluster head is fixed and provides a single hop data transmission.",
8853.txt,It uses particle swarm optimization to optimize the sink's moving trajectory among cluster heads.,
8854.txt,It is thus applicable to largescale WSNs.,
8855.txt,The simulation results show that it is more energy-efficient than WSNs with a static sink.,
8856.txt,They also verify that the loss of data occurs when the speed of the mobile sink increases.,
8857.txt,"Similar to routing protocols for homogeneous WSN, introducing mobile nodes to heterogeneous WSN can avoid energy holes, achieve high energy efficiency and balance energy consumption among nodes.",
8858.txt,Table 8 provides a comparative summary of the characteristics of routing protocols for mobile heterogeneous WSN as discussed above with respect to different parameters.,
8859.txt,"Note that, protocols in this class do not assume any special energy models, except HSN.",
8860.txt,"HSN uses the same energy model as that in X.In this paper, we have surveyed the main routing protocols to realize energy-efficient routing for WSNs.",
8861.txt,"We also highlight critical characteristics influencing routing protocol design and applications, and give a comparative summary of the current routing protocols in each class.",
8862.txt,Routing protocols for homogeneous WSNs are more widely investigated than heterogeneous ones.,
8863.txt,More studies of the latter are foreseen in order to meet diverse application requirements.,
8864.txt,"As compared with static WSN's, routing protocols for mobile WSNs promise to bring more benefits to real-time delivery guarantee as well as high coverage, energy efficiency and energy balance but require high implementation and deployment cost.",
8865.txt,"According to the discussion of their characteristics in differentWSNs,weconcludethispaperwiththefollowingopen issues.",
8866.txt,Creating and using a reliable routing metric is important in routing design.,
8867.txt,It should measure routing overhead and routing capability from different aspects due to the diversity of WSNs.,
8868.txt,New routing metrics such as spatial reusability should be taken into consideration in order to increase the network throughput performance with affordable energy overhead.,
8869.txt,"For heterogeneous WSN, besides energy heterogeneity, link heterogeneity is also important and requires further study.",
8870.txt,QoS Routing: Many existing QoS routing protocols are restricted into some particular applications and only take one or two QoS metrics.,
8871.txt,They tend to lose the balance between QoS guarantee and energy efficiency.,
8872.txt,"In this regard, energy efficient routing with QoS guarantee in different applications or diverse WSNs can be viewed as an interesting area for future investigation.",
8873.txt,"In WSNs, each node acts as both perceived role and a router and thus makes itself vulnerable to attack.",
8874.txt,"Hence, secure routing is an important issue that needs further attention.",
8875.txt,Clearly a security mechanism incurs additional energy cost.,
8876.txt,Designers must make a proper tradeoff between security levels and energy consumption for different applications.,
8877.txt,"Application-Specific Routing: Since the application of WSN is wide, the process of routing implementation varies significantly from one WSN to another.",
8878.txt,"Thus, application-specific routing protocols are needed for such situations as vehicles, underwater, space, volcanoes, exploration, epidemic, human body, water and oil pipelines, microgrid, system monitoring and diagnosis, and robots .",
8879.txt,Their applications in Internet of Things and body sensor networks  should be actively sought.,
8880.txt,WSN Hardware Implementation: To evaluate the performance of proposed protocols.,
8881.txt,"More implementations should be realized not only in simulations, but also on real WSN hardware as shown in X.",
8882.txt,Benchmark Studies/Comparisons: Almost every protocol proposed claims to be better than the earlier ones in energy efficiency.,
8883.txt,There is a strong need to create some benchmark problems to facilitate their comparisons by simulation and hardware implementations.,
8884.txt,Many controlled systems suffer from unmodeled nonlinear effects that recur periodically over time.,
8885.txt,"Model-free controllers generally cannot compensate these effects, and good physical models for such periodic dynamics are challenging to construct.",
8886.txt,We investigate nonparametric system identification for periodically recurring nonlinear effects.,
8887.txt,"Within a Gaussian process  regression framework, we use a locally periodic covariance function to shape the hypothesis space, which allows for a structured extrapolation that is not possible with more widely used covariance functions.",
8888.txt,"We show that hyperparameter estimation can be performed online using the maximum a posteriori point estimate, which provides an accuracy comparable with sampling methods as soon as enough data to cover the periodic structure has been collected.",
8889.txt,It is also shown how the periodic structure can be exploited in the hyperparameter optimization.,
8890.txt,The predictions obtained from the GP model are then used in a model predictive control framework to correct the external effect.,
8891.txt,The availability of good continuous predictions allows control at a higher rate than that of the measurements.,
8892.txt,"We show that the proposed approach is particularly beneficial for sampling times that are smaller than, but of the same order of magnitude as, the period length of the external effect.",
8893.txt,"In experiments on a physical system, an electrically actuated telescope mount, this approach achieves a reduction of about 20% in root mean square tracking error.Index Terms?Adaptive control, nonlinear control systems, optimal control
Screws and gears are not the only source of periodically recurring errors in dynamical systems.",
8894.txt,Every system that is tied to the ubiquitous day-and-night cycle or to recurring movements suffers from periodic errors.,
8895.txt,"Since these effects are often small relative to the required control precision, they are in practice usually neglected in the controller design.",
8896.txt,"For high precision control systems, however, such errors can be the dominant source of problems.",
8897.txt,Correcting errors only after they are measured leads to a delay in the error correction.,
8898.txt,"If these errors can be anticipated, the control performance can be significantly improved.",
8899.txt,"While errors arising stochastically cannot be preempted systematically, periodic effects are amenable for prediction: since their future resembles their past, extrapolation  is easier and more structured.",
8900.txt,"Based on this idea, we present a framework for identification and control of periodic effects.",
8901.txt,"Our framework continually performs identification at runtime, and is thus applicable to stochastic time-varying systems.",
8902.txt,The correction of periodic errors has repeatedly been studied.,
8903.txt,"The Very Large Telescope uses an internal parametric model for the known error sources, and a Kalman filter as an estimator for the model parameters .",
8904.txt,"High precision tracking of spacecrafts on periodic trajectories was addressed in X, based on predictive filtering using an extended Kalman filter.",
8905.txt,"To predict the beating motion of a human heart, extended Kalman filtering for state estimation was used in X, allowing the nonlinear model to change over time.",
8906.txt,"Concerning the use of learning-based models for control, there is a wide range of the literature available in the context of adaptive control.",
8907.txt,For methods based on model predictive control .,
8908.txt,"In contrast to previous methods for periodic error correction, the approach presented here does not rely on a prespecified finite-dimensional model class.",
8909.txt,"Instead, we propose a nonparametric framework based on Gaussian process regression that is frequently used for system identification.",
8910.txt,"It is closely related to least-squares regression, which is the most commonly employed technique in system identification, but is based on a probabilistic interpretation, which can be used to guide exploration during identification.",
8911.txt,There is recent work on using GPs for state filtering and on modeling and control of nonlinear systems.,
8912.txt,"The idea of using the learned model in predictive control is conceptually similar to X, with the key difference that we use a GP to predict time-varying effects.",
8913.txt,Reference provides a general introduction to GPs.,
8914.txt,A GP model is parametrized by two objects:  mean and covariance function.,
8915.txt,"When used in system identification, in particular, the choice of covariance function has a strong effect on performance, and requires consideration of the particular dynamics to be identified.",
8916.txt,"Although the literature knows universal covariance functions that can technically approximate any continuous function this notion applies only in the infinite limit, and can be subject to extremely slow  convergence.",
8917.txt,"Hence, the choice of the covariance function is often critical in practice.",
8918.txt,"In this paper, the focus lies on the identification of quasi-periodic systems with GPs using a specific model class involving periodicity .",
8919.txt,"A key element of GP regression is the estimation of the hyperparameters , which is performed by exploiting the structure of the problem at hand.",
8920.txt,We focus on the case where the system up to the periodic effect is linear and use MPC to achieve optimal closed-loop performance .,
8921.txt,"A reformulation in the form of a tracking problem is proposed, which offers simple implementation and facilitates analysis of the control performance .",
8922.txt,"To show the qualitative properties of this framework, we apply it to a toy problem first .",
8923.txt,"As the development of this method was driven by a real problem in astronomy, the method is evaluated on this problem both in simulation and hardware experiments .",
8924.txt,"While GPs and MPC are well-studied techniques, the main contribution of this paper is a combination that is tailored to quasi-periodic functions, allowing for extrapolation and efficient computation, which is crucial for online identification and control.",
8925.txt,A practical technique for hyperparameter optimization is proposed and the effectiveness of the approach for compensation of quasi-periodic errors is demonstrated on the experiment of a telescope mount.,
8926.txt,This paper extends the preliminary conference version on the same topic.,
8927.txt,"We here provide a more extensive treatment of hyperparameter estimation, discuss Markov chain Monte Carlo versus maximum a posteriori  estimation, and propose a custom optimization method for the latter.",
8928.txt,Additional experiments include an analysis of system behavior under sensor failure.,
8929.txt,GP models can also learn nonlinear functions of the state and input.,
8930.txt,We opt for this linear formulation with nonlinear external reference here to keep the resulting control problem conceptually clear and computationally simple.,
8931.txt,"If needed, the definition can also be adapted to a nonlinear system using a nonlinear MPC technique.",
8932.txt,"The function g captures nonlinear time-dependent effects, in particular, we will focus on systems exhibiting some form of periodic behavior.",
8933.txt,"Systems with such time-dependent errors of periodic characteristic appear in different application areas, such as building temperature control, beating-heart surgery, or electrical power grids.",
8934.txt,"However, error sources in real systems are often not perfectly periodic in this sense, they show various forms of phase shift, deformation, and desynchronization.",
8935.txt,"To address this issue, we generalize to consider locally periodic functions.",
8936.txt,We consider the case where a linear model is available and the goal is to infer the disturbance function g(t) online from measurements.,
8937.txt,This is motivated by the fact that often a nominal model is derived either from physical considerations or an offline system identification step.,
8938.txt,"At every measurement time tk, the system goes through the following process.",
8939.txt,"It should be noted that in practice, measurements of  x are generally not available and will be approximated numerically .",
8940.txt,"At this point, it should be intuitively clear that the performance gain one can expect from the use of a periodic model for feed-forward compensation depends on the sampling rate of the control system: if the external error is slow compared with the measurement rate, a locally linear model is sufficient.",
8941.txt,"But if the external error is on the same time scale as the measurement, it helps to use feed-forward control based on GP predictions.",
8942.txt,With the presented approach it is even possible to choose the control interval smaller than the actual measurement interval .,
8943.txt,GP regression is a general framework for nonlinear regression.,
8944.txt,"As mentioned above, in the context of our particular setup, it may in fact also be used to construct probabilistic models for fully nonlinear systems g=g(x,u,t), without major changes.",
8945.txt,This section will propose a covariance function suitable for the identification of quasi-periodic functions and present an efficient technique for hyperparameter optimization.,
8946.txt,"The way to construct a periodic hypothesis class, and the central idea of this paper, is to construct a covariance function that focuses prior probability mass on locally periodic functions.",
8947.txt,Among the most popular kernels for regression purposes is the square-exponential.The different covariance functions are shown in Fig.,
8948.txt,"1, exemplary randomly sampled functions from GPs with those covariance functions are shown in Fig.",
8949.txt,1,
8950.txt,"The posterior mean of GPs with aperiodic and periodic covariance, trained on periodic data, is shown in Fig.",
8951.txt,2,
8952.txt,"In the region far away from data points, the predictions are equal, whereas close predictions show significantly more structure with the  periodic kernel.",
8953.txt,Fig.,
8954.txt,"2 illustrates the key benefit of this approach: with increasing distance from data, the prediction degrades gracefully back to the zero mean.",
8955.txt,"If a periodicity would be predicted with a purely periodic kernel, prediction and reality could run out of phase over time, leading to bad predictive performance.",
8956.txt,The proposed locally periodic covariance function circumvents this problem.,
8957.txt,"However, this approach is intractable and can only be performed approximately at high computational expense.",
8958.txt,"One way to approximate the posterior distribution over  and to marginalize over the unknown parameters  is sampling, using an MCMC method.",
8959.txt,We found shrinking-rank slice sampling  to be particularly well suited for this task and implemented the method accordingly.,
8960.txt,The left column of Fig.,
8961.txt,3 shows the resulting marginals on the function g at two different points in the learning process.,
8962.txt,"Not unexpectedly, the posterior uncertainty is high after only a few observations, in particular after less than one full period, but collapses to a highly confident distribution after several periods of observations have been collected.",
8963.txt,"In the latter case of high certainty, when all samples from the posterior are close to each other, their entirety is represented well by a single point estimate.",
8964.txt,"Such an estimate can be found in a computationally much less demanding process, by optimizing the posterior distribution, or even just the likelihood, to find the MAP or maximum likelihood estimate, respectively.",
8965.txt,"The latter, maximum likelihood approach is also known as evidence maximization, or type-II maximum likelihood, in the literature, to distinguish it from the much more simplistic approach of fitting g itself by a maximum likelihood method.",
8966.txt,Using the MAP estimate is one of the most widely studied and best understood strategies in statistics 5.,
8967.txt,"It is not without weaknesses , some of which are often resolved if enough data is available or by the use of customized optimization algorithms .",
8968.txt,"Other approaches, for example integrating the hyperparameters over MAP estimates or cross validation, have been examined in the past and found to perform worse than the above type-II maximum likelihood approach in practice.",
8969.txt,"The maximization is easier to perform in log domain, in which the effect of the prior is additive.",
8970.txt,"In X, the prior effectively turns into a regularizer, simplifying optimization, and avoiding degeneracy.",
8971.txt,The additional computational cost is negligible compared to the matrix inversion needed for X.,
8972.txt,The right column of Fig.,
8973.txt,3 shows the GP point estimates for g resulting from MAP inference.,
8974.txt,From Fig.,
8975.txt,"3, it is clear that point estimation leads to a more limited, and generally overly confident extrapolation model, especially in early phases of learning, when the dataset does not yet cover several periods.",
8976.txt,"However, MAP offers two advantages that make it attractive from an applied perspective: the first one is computational costMCMC sampling can be orders of magnitude more expensive than optimization for an MAP estimate.",
8977.txt,"The second one is an algebraic one: MCMC estimates are mixtures of GP models.This means the overall dynamical model for the system defined by these models is a very challenging stochastic differential equation which cannot, in general, be interpreted as a differential equation involving a Wiener process.",
8978.txt,"In our implementation and experiments, we thus rely on the computationally much less taxing MAP inference.",
8979.txt,"The log-likelihood surface for  is, in general, not convex.",
8980.txt,Fig.,
8981.txt,4 shows a slice through this surface along the periodicity parameter .,
8982.txt,Standard numerical optimizers will thus usually return suboptimal local extrema of this function.,
8983.txt,An interesting observation in our specific context is that the periodic structure of the covariance function and the data is reflected in this hyperparameter likelihood as well.,
8984.txt,"The reason for this is a harmonic effect: if the data has a true period of , then periodic functions whose periodicity is an integer multiple of  also fit the data well, resulting in low values of X.",
8985.txt,"Intuitively, this can be compared with a function with periodicity , which could also be considered as a function with period length 2.",
8986.txt,"To see this, recall from Fig.",
8987.txt,1 that the periodic functions can have an arbitrary recurring pattern in each repetition.,
8988.txt,"By inspecting X, we can gain intuition and notice that the likelihood X is a nonlinear function of terms of the form X.",
8989.txt,"Since each of these terms is periodic in , the overall function will show periodicity in that term.",
8990.txt,This harmonic structure can be leveraged by means of a heuristic to increase numerical stability of the optimizer.The locations that are iteratively proposed during the loop  are shown as vertical lines in Fig.,
8991.txt,4,
8992.txt,This approach uses the nonconvex structure in the hyperparameter optimization to find better optima.,
8993.txt,"Popular control frameworks supporting the incorporation of feed-forward model predictions include linear quadratic regulator techniques , or MPC .",
8994.txt,"In this paper, we employ an online MPC framework, computing the optimal control input by solving an optimization problem for each measured state.",
8995.txt,"This allows for direct incorporation and updating of the GP model  as well as system constraints, such as input constraints.",
8996.txt,"Since the optimal control input is computed at each sampling time based on the current measured state, the model can be updated online.",
8997.txt,An important aspect and advantage of combining online learning of a continuous time function with MPC is the possibility to decouple the discretization from the sampling time.,
8998.txt,"While in a standard MPC setup, unmodeled effects only become apparent through state measurements and therefore require fast sampling rates, the GP model captures these effects and provides a continuous prediction of their evolution in the future.",
8999.txt,"As a result, the sampling time can be chosen as a multiple of the discretization or prediction interval without sacrificing performance by using the sequence of control inputs in between state measurements.",
9000.txt,It is clear that an upper bound on the sampling time is imposed by the prediction horizon.,
9001.txt,"Since the prediction from the GP model is stochastic and provides a distribution over future function values rather than one particular sequence, stochastic MPC methods offer a natural framework to incorporate the GP model and make use of the posterior model uncertainty.",
9002.txt,"For an overview of recent stochastic MPC methods, see X, and the references therein.",
9003.txt,"This is an important advantage over other nonparametric methods like kernel ridge regression or regularized least squares, which do not provide posterior uncertainty.",
9004.txt,"If the stage cost l is taken to be quadratic and since the inputs are deterministic and the GP posterior is Gaussian, the expected value is equivalent to using the mean of the state evolution, the mean GP prediction of g in dynamics X.",
9005.txt,The most common stochastic MPC problem hence results in a deterministic formulation using the GP posterior and reduces to the certainty equivalent controller.,
9006.txt,We consider the case of a quadratic stage cost in the following.,
9007.txt,A The resulting discrete-time system can directly be used in a standard MPC formulation.,
9008.txt,"Because this is an instance of a basic MPC technique, the standard properties of MPC apply.",
9009.txt,"It also allows for a more principled analysis of the closed-loop properties: extensions in the field of tracking MPC can be applied to ensure stability, such as reference governors, or the periodic MPC approach in X.",
9010.txt,One example is the Kalman filter.,
9011.txt,The nonlinear prediction from the GP can be incorporated into the state prediction without complicating the Kalman filter equations.,
9012.txt,The measurement update of the Kalman filter remains unchanged.,
9013.txt,The GP predictions increase the performance by providing a better state estimate.,
9014.txt,This leads to smaller correction terms and smaller posterior variance.,
9015.txt,"Because the posterior of the GP is a Gaussian distribution, state constraints can be included in the form of soft constraints, penalizing the amount of constraint violation, or chance constraints, ensuring constraint satisfaction with a certain probability .",
9016.txt,"The approach can also be applied to stage cost functions and constraints that do not allow for a deterministic representation using the GP model,a value-at-risk formulation involving the variance of the cost using sample-based methods to approximate the stochastic MPC problem .",
9017.txt,GPs fit well in this framework by being generative models from which sample trajectories can be easily drawn.,
9018.txt,The presented method was implemented and used on different test problems.,
9019.txt,"After providing a toy example that demonstrates how the state evolution is anticipated by the use of the GP prediction, the method is evaluated for a simulated telescope system where the performance under different measurement frequencies and under sensor failure is analyzed.",
9020.txt,"Finally, the proposed method is tested in an experiment on a real telescope system, showing substantial improvements in control performance.",
9021.txt,"Since in practice the state and derivative cannot be measured directly, they have to be approximated from potentially noisy measurements.",
9022.txt,"An observer  can be used to estimate the state, which increases the performance, especially when the measurement noise is high.",
9023.txt,"After an identification phase in the first 5s of the experiment, the GP-based controller shows a drastic performance improvement.",
9024.txt,"Omitting this identification phase, the root-mean-square error, measured with respect to the origin, drops by 90%, from 0.94 for the linear model to 0.097 for the GP-based controller.",
9025.txt,"Speaking more qualitatively, Fig.",
9026.txt,5 also shows less residual structure in the controlled state x1.,
9027.txt,It is visible that control signals are applied earlier when the prediction is used.,
9028.txt,"While the GP-based controller is effective at reducing the periodic structure from the first controlled state, the regression model itself remains able to predict the periodic error correctly into the future, even when trained exclusively on controlled states.",
9029.txt,"This is possible because the regression model is obtained from the controlled dynamics, so it can account for the shift of periodicity from the states to the control input.",
9030.txt,This feature of the framework is crucial for identifying controlled systems .,
9031.txt,The original motivation for the work presented here is the control of periodic errors in astrophotography systems.,
9032.txt,Telescope mounts correct for the earth's rotation relative to the sky by a circular motion at the sidereal velocity.,
9033.txt,"This motion is typically produced by mechanical devices using cogs and worm gears, which gives rise to periodic deviations.",
9034.txt,"Because contemporary telescopes, even those used by amateurs, have high optical resolution, and because images are taken with long exposure times, these mechanical imprecisions are frequently the dominant source of blur on astronomical photographs.",
9035.txt,Existing periodic error correction systems require careful system identification by the user of the telescope.,
9036.txt,"The corresponding measurements need to be realigned after every repositioning of the telescope, and still regularly lead to unsatisfactory performance.",
9037.txt,"A problem specific to this astronomical application is that state measurement is performed by taking photographs of the night sky, which requires relatively long exposure times, so that the measurement frequency can reach the order of magnitude of the periodic error.",
9038.txt,This is precisely the domain in which we expect to see utility from a periodic model.,
9039.txt,Simulated System: The period length of the periodic error in telescopes is relatively slow.,
9040.txt,"To allow rapid prototyping,we designed a simulated system with dynamics similar to a real telescope.",
9041.txt,"Experiments have shown that the model can be reduced by considering only the angular position as state, measured relative to the desired state.",
9042.txt,The state can be influenced by an input velocity.,
9043.txt,Fig.,
9044.txt,6 shows simulation results that empirically confirm the intuition from Section II-A that the benefit of periodic prediction in control depends on the sampling rate.,
9045.txt,"Using the numerical simulation, we compare for various sampling rates of the state.Since we are only interested in the performance in the limit in this experiment, all the controllers were run for an identification phase of 10 period lengths to avoid artifacts from the early identification phase.",
9046.txt,Fig.,
9047.txt,"6 then shows rms error, deviation of the state from the origin, after this phase as a function of the sampling time.",
9048.txt,The rms error is measured over 10 period lengths starting after the identification phase.,
9049.txt,"The discretization time for the MPC is always set to (1/100) of the period length, to 1 s. Between measurements, the MPC controllers are operated in open-loop mode, the control inputs are obtained from the sequence of the last MPC optimization.",
9050.txt,"The results demonstrate the intuition: for sampling times much smaller than , the dynamics are locally linear, and all models achieve an error close to zero.",
9051.txt,Their performance difference is only marginal.,
9052.txt,"For sampling times between 10% and 80% of , the periodic model offers considerable benefits.",
9053.txt,"When the sampling times are close to or larger than the periodicity, the Nyquist rate imposes limits on identifiability of the system, which adversely affects the performance of the periodic nonparametric model.",
9054.txt,This shows that a broad prior can lead to bad performanceif only little data is available.,
9055.txt,"On the other hand, if  is known precisely, very good control is possible even for sampling rates lower than .",
9056.txt,The green line in Fig.,
9057.txt,6 represents the performance of a system almost ignorant of  in the beginning: the prior is very broad.,
9058.txt,One can expect prior information about  of varying vagueness to give performance somewhere in the region between the green and blue curves in Fig.,
9059.txt,6,
9060.txt,"Of course, the case where sampling rate and  are equal is special, since then g appears constant in the measurements, and even the informed periodic model can only ever learn the behavior of g at one unique point during the period.",
9061.txt,A weaker version of this effect is also visible in the plot at a sampling rate of (/2).,
9062.txt,"This selection bias affects all regression models, including the aperiodic ones.",
9063.txt,"Summarizing, the proposed approach offers the main benefit for sampling intervals between 10% and 80% of the disturbance period length.",
9064.txt,"Whereas for short sampling intervals, all techniques result in low errors, systems with sampling frequency below the Nyquist frequency of the periodic disturbance cannot be expected to improve with a system that has to learn the periodicity.",
9065.txt,Evaluation of Fault T olerance: A similar experiment is conducted to investigate the effect of missing measurements on the performance of the controlled system.,
9066.txt,Fig.,
9067.txt,7 shows the empirical results.,
9068.txt,"The setup is the same as in the experiment described before, but now the sampling time is fixed to a value of 5 s, while the period length is 100 s. The length of the horizon is set to 41 time steps, covering more than two full periods of the periodic effect, which is a realistic setting for a real telescope.",
9069.txt,"After giving the system enough time to learn under regular output measurements, no new data is given to the learning procedure to update the GP model of g(t) and no new state estimate is available to the controller.",
9070.txt,This corresponds to a fault in the sensor.,
9071.txt,The sensor does not recover within the simulation time.,
9072.txt,Fig.,
9073.txt,"7 shows the performance of the different controllers, measured in terms of the rms error and calculated from the beginning of the fault, here at time 0.",
9074.txt,"In all controller setups, the MPC controller cannot be recomputed as there is no state estimate available.",
9075.txt,"For the next time steps , the MPC therefore is operated in open-loop mode, i.e., the control inputs are taken from the control sequence computed at the time before the fault.",
9076.txt,"At the beginning of the failure , the performance of all methods is good, since the effect of the periodic function is still small.",
9077.txt,"Over time, we see the simple controller without prediction slowly degrading.",
9078.txt,"Interestingly, the performance of the GP with square exponential kernel with too long a length scale performs even worse than not predicting g(t) at all.",
9079.txt,This illustrates how critical the choice of the hyperparameters is and that a wrong choice can even degrade the performance.,
9080.txt,"The model with sensible length scale performs significantly better initially, but the extrapolation of the SE kernel degrades quickly  resulting in an overall performance that is only slightly better than for the linear model.",
9081.txt,"With periodic predictions, in contrast, the controllers perform significantly better during the fault.",
9082.txt,"The periodic GP is clearly better than the SE with short length scale, even if the period length is inferred and not fixed at a good value.",
9083.txt,The rms error for the GP with optimal parameter  is virtually zero and even a controller knowing the true function g would therefore only show marginal improvement.,
9084.txt,This analysis shows that the proposed combination of a periodic GP model and MPC is able to compensate temporary sensor failures and maintain high control performance for locally periodic dynamic effects.,
9085.txt,"We have tested our implementation on a physical system, a commercially available Vixen Sphinx1telescope mount .",
9086.txt,"Without closed-loop control, this mount shows about 7 asec of rms error after correction for static drift.",
9087.txt,The error arises from the imperfect shape of the cogs in the gear of this mount .,
9088.txt,The imperfect shape is not visible to the naked eye.,
9089.txt,"Because outdoor measurements are subject to random, time-varying effects like weather conditions, we constructed a more reproducible experimental setup using a second, high precision gearless ASA DDM60Pro2telescope mount equipped with a laser star as tracking reference.",
9090.txt,It has a typical tracking rms error of about 0.4 asec.,
9091.txt,"For the hardware interaction, the open source PhD Guiding5 software package is used.",
9092.txt,"In the original implementation, this software uses a deadbeat controller.",
9093.txt,"The telescope is connected to the computer with a Shoestring GPUSB,6 a device that sends pulsewidth modulated signals to telescopes over a commonly used six-wire interface.",
9094.txt,We altered the software to gain access to the measured displacement of the camera image.,
9095.txt,"The value is sent through a network socket to MATLAB, where the controller developed in this paper calculates the optimal control signal, which is in turn sent back to the guiding software.",
9096.txt,The software then sends the control signal to the telescope hardware.,
9097.txt,"For plotting and calculation of the rms error, the measured displacement is converted from pixels into arcseconds  with an empirically determined conversion factor.",
9098.txt,"For real-time implementation, algorithmic complexity is relevant.",
9099.txt,The computational cost of the GP prediction scales cubically in the number of data points.,
9100.txt,"To bound computational cost, we limit the number of used data points to 90 in a moving window fashion.",
9101.txt,"This gives a sufficient coverage of 270 s, or about three periods of the short periodic component.",
9102.txt,"Since inference continuously runs in an extrapolation setting, this is sufficient for precise inference and control.",
9103.txt,"For the prediction of the dynamics in the MPC, an ODE-solver is employed to predict the reference X from the mean of the GP prediction.",
9104.txt,"This has manageable computational cost because the inference cost of a GP is dominated by the initial one-time operation of inverting the Gram matrix K in O(D3) time, while subsequent evaluations of the mean function at M times only has cost O.The optimization of the hyperparameters is also an expensive part of this algorithm.",
9105.txt,"As the kernel Gram matrix has to be built and inverted at every evaluation of the objective function, the number of evaluations has to be kept small at every sampling time.",
9106.txt,"We use a numerical optimizer based on the BFGS update, a quasi-Newton algorithm that updates an estimate of the inverse Hessian in each iteration.",
9107.txt,"In the standard implementation, the estimate of the Hessian obtained at one time step is discarded after each individual call to the optimizer.",
9108.txt,"For the use in the control setting, we altered the algorithm so that the estimate of the inverse Hessian is stored and used to initialize the optimizer's estimate at the next sampling time.",
9109.txt,This makes it possible to do one iteration per sampling interval.,
9110.txt,This significantly reduces computation time.,
9111.txt,"The presented method was tested on two different setups, one with an MPC based on the linear model without g and one with the GP prediction for the periodic error.",
9112.txt,The test was run three times for 25 min each.,
9113.txt,Both the sampling and the discretization time were set to 3 s. The horizon length was N = 10; the state and control weights were set to Q=102and R=103.,
9114.txt,The results of these runs are shown in Table I.,
9115.txt,The rms error drops by 22.64% through the use of GP predictions in this hardware setup.,
9116.txt,Baseline measurements without movement showed about 0.25 asec 0.35 asec of noise.,
9117.txt,The noise introduced by the stepper motor could not be quantified with the current measurement system.,
9118.txt,"Overall, the presented method eliminated at least a third of the controllable error, after subtracting baseline noise but without taking the stepper motor into account.",
9119.txt,"That is a good result in this domain, but could probably be improved, which is also visible through the light residual structure visible in Fig.",
9120.txt,10,
9121.txt,"To further investigate this issue and assess the performance of the method, Fig.11 shows the power spectra of the measurements, obtained from the Fourier transform.",
9122.txt,It is noticeable that the strong periodic components near 100 and 500 s are highly damped with the presented method.,
9123.txt,High precision control of dynamical systems requires precise models of even minor external error sources.,
9124.txt,"Where analytic models are not available, they can only be constructed numerically from measurements of the system.",
9125.txt,"Periodic error sources are an especially promising domain in this regard, as they can be extrapolated well into the future.",
9126.txt,"We have studied a nonparametric modeling framework based on a carefully crafted GP prior exhibiting a weak, localized form of periodicity.",
9127.txt,"Because Gaussian regression returns models in the form of stochastic differential equations, they can be combined directly with existing control frameworks.",
9128.txt,"Integration into an MPC scheme was investigated, which can leverage the prediction at a desired resolution, even below the sampling time.",
9129.txt,Numerical and physical experiments confirm the intuitive result that the benefit of periodic models depends on the relative size of state sampling and disturbance frequencies.,
9130.txt,"We showed that, even in cases where the gain of a periodic prediction is only marginal during normal operation, such models are beneficial when sensors fail temporarily.",
9131.txt,"The presented method also shows considerable increases in control performance, confirming the practical utility of this framework.",
9132.txt,"Brain tumor is one of the most dangerous cancers in people of all ages, and its grade recognition is a challenging problem for radiologists in health monitoring and automated diagnosis.",
9133.txt,"Recently, numerous methods based on deep learning have been presented in the literature for brain tumor classification in order to assist radiologists for a better diagnostic analysis.",
9134.txt,"In this overview, we present an in-depth review of the surveys published so far and recent deep learning-based methods for BTC.",
9135.txt,"Our survey covers the main steps of deep learning-based BTC methods, including preprocessing, features extraction, and classification, along with their achievements and limitations.",
9136.txt,We also investigate the stateof-the-art convolutional neural network models for BTC by performing extensive experiments using transfer learning with and without data augmentation.,
9137.txt,"Furthermore, this overview describes available benchmark data sets used for the evaluation of BTC.",
9138.txt,"Finally, this survey does not only look into the past literature on the topic but also steps on it to delve into the future of this area and enumerates some research directions that should be followed in the future, especially for personalized and smart healthcare.",
9139.txt,"Index Terms?Artificial intelligence, biomedical data analysis, brain tumor classification, deep learning, health monitoring, smart healthcare, transfer learning.",
9140.txt,The past decades of image processing and computer vision arena have helped humanity in the identification of various diseases through automated diagnostic processes.,
9141.txt,These processes in the medical domain have hitherto-assisted medical staff and specialists by providing a second option in many diagnostic procedures.,
9142.txt,"Among all hazardous diseases, cancer is considered as a threat to mankind due to its fatal nature.",
9143.txt,"Traditionally, a specialist analyzes medical images and, manually, estimates the probability of developing a tumor.",
9144.txt,Manually identifying a tumor's sign and relying on this decision for the prescription of subsequent medical treatments is an option that most of the medical practitioners would avoid because of the lethal nature of the brain tumor .,
9145.txt,The most sophisticated and safest way of analyzing the medical images is through computer vision techniques .,
9146.txt,It includes fleeting images through various software with built in algorithms for tumor detection and classification.,
9147.txt,"These algorithms can also be adjusted for implementing tumor segmentation, which denotes the process of separating the infected regions from healthy areas of a medical image under observation.",
9148.txt,The early detection and classification of a brain tumor are of utmost necessity for the effective and timely treatment of a patient.,
9149.txt,"The human visual cortex is known to be limited in its capability to decide between different levels of gray, as present in magnetic resonance imaging.",
9150.txt,This gives birth to computer-aided diagnosis or brain tumor classification methods that are suitable for supporting radiologists in visualizing and defining tumor types.,
9151.txt,"These automated processes for brain tumor detection, segmentation, and classification play a vital role in serving humanity by reducing the chances of surgery.",
9152.txt,"Whenever radiologists get confused about the nature of the tumor, or they want to visually inspect it in depth, these methods are always there to help them.",
9153.txt,"Image processing and computer vision scientists are interested in providing precise and efficient methods for automatic detection, classification, and segmentation of tumors.",
9154.txt,Basic workflow of the traditional BTC and analysis methods.,
9155.txt,methods .,
9156.txt,Traditional BTC methods are based on low-level features and on the application of statistical learning approaches for the classification of a brain tumor.,
9157.txt,"Segmentation methods falling within this category focus on the estimation of the tumor's boundaries and its localization, which involves some preprocessing steps, such as contrast enhancement, image sharpening, and edge detection/refining.",
9158.txt,"The basic workflow of traditional BTC methods follows image acquisition, preprocessing, ROI segmentation, feature extraction and selection, dimensionality reduction, classification, and performance evaluation, as visually summarized in Fig.1.",
9159.txt,"In contrast to traditional approaches, deep learning-based methods mainly depend on the training data with significantly fewer preprocessing needs than traditional counterparts.",
9160.txt,"It is evident from the literature related to deep learning that the accuracy of a system is highly dependent on the amount of data, particularly in the domain of BTC.",
9161.txt,Most deep learning methods in BTC rely on convolutional neural networks.,
9162.txt,"Indeed, the increased usage of CNNs for several computer vision problems in various domains motivates adopting them for BTC, particularly for smart health monitoring.",
9163.txt,"Therefore, in what follows, we focus on this branch of deep learning methods.",
9164.txt,"CNNs-based BTC methods follow a three-step process toward predicting the presence of a brain tumor or its grade, as shown in Fig.",
9165.txt,2,
9166.txt,The first preprocessing step includes noise removal and segmentation methods to segment the tumor from the MRI.,
9167.txt,"The second step is training, where labels and learned features of each image from the data set are provided to the classifier for training.",
9168.txt,The classifier learns the patterns of different grades/classes of tumors from the labeled training data.,
9169.txt,"The testing phase applies the same feature extraction strategy applied in the training phase, but it only extracts features from a single query image.",
9170.txt,"This feature vector is passed/fed to the trained classifier for the final prediction of brain tumor class/grade, depending on the trained classifier.",
9171.txt,"The accuracy of CNN classifiers is significantly higher compared with traditional approaches, making them suitable for radiologists in real-world clinical practice.",
9172.txt,This overview capitalizes on the magnificent momentum featured by deep learning for BTC by comprehensivelyreviewing the literature related to CNN and BTC.,
9173.txt,We critically examine advances reported so far at this crossroads and provide a solid knowledge base to support a prospect of future research topics that remain insufficiently explored to date.,
9174.txt,"Furthermore, we complement our survey by providing empirical evidence of the potential of CNN-based BTC by investigating different CNN models to gauge the tradeoff between accuracy and time complexity.",
9175.txt,"The models presented can balance trade among these conflicting objectives, depending on the situation under consideration.",
9176.txt,"Due to the lack of annotated data that often underlies practical experiences with deep learning-based BTC, we conduct several experiments where this issue is addressed through data augmentation.",
9177.txt,"Specifically, we discuss several investigated models over two publicly accessible data sets: multigrade brain tumor data set and brain tumor public data set.",
9178.txt,The original contributions of our survey can be summarized as follows.,
9179.txt,"In this survey, we cover all existing CNNs-based BTC methods, discussing their achievements and limitations.",
9180.txt,"We explore the overall literature of BTC and highlight its major domains, research trends, and niches, as well as benchmark data sets available for experimentation.",
9181.txt,"Inspired by recent achievements of deep learning models in image classification, we investigate and fine-tune several pretrained CNN models for BTC using two different data sets with and without data augmentation.",
9182.txt,"We provide detailed statistics of these models with various parameters, which can be used by different researchers and radiologists for further investigation and diagnostic assistance.",
9183.txt,"With the recent increase in the usage of smart devices and cloud/fog/edge computing in smart cities, it is feasible to use these technologies for healthcare systems.",
9184.txt,"Therefore, in this survey, we highlight the personalized usage of BTC for patients, remote specialists, and medical centers for smart healthcare services.",
9185.txt,This can make its integrationinto the current smart city ecosystem easier and its widespread deployment and adoption more sustainable.,
9186.txt,This survey identifies the current challenges of the BTC domain and summarizes the overall deep learning-based literature in a single perspective overview.,
9187.txt,"Moreover, we provide recommendations and future directions to motivate other scientists for further research in this domain.",
9188.txt,The remainder of this article is divided into seven sections.,
9189.txt,Existing surveys and their critique are discussed in Section II.,
9190.txt,The coverage of our survey with detailed analysis is given in Section III.,
9191.txt,"The available data sets and transfer learning techniques in BTC are addressed in Sections IV and V, respectively.",
9192.txt,A comparative study of different CNN models is given and discussed in Section VI.,
9193.txt,BTC challenges and future research directions are identified in Section VII.,
9194.txt,Conclusions and an outlook on the field are given in Section VIII.,
9195.txt,"In this section, we review five different existing BTC surveys ranging from 2014 to 2019, with their details given in Table I.",
9196.txt,"The major parts reviewed in this survey are publication year, literature coverage, number of reviewed articles, Authorized licensed use limited to: University of Exeter.",
9197.txt,"There are several limitations of existing surveys, which are addressed in our survey.",
9198.txt,"Among them, the most limiting issue is their lack of detailed reviews to highlight the limitations of other studies and motivations for a new survey.",
9199.txt,"Second, the majority of BTC surveys do not provide detailed future research directions, which is a compulsory section for any Authorized licensed use limited to: University of Exeter.",
9200.txt,Restrictions apply.,
9201.txt,This article has been accepted for inclusion in a future issue of this journal.,
9202.txt,"Content is final as presented, with the exception of pagination.",
9203.txt,Overall distribution of deep learning-based BTC methods.,
9204.txt,Our survey focuses exclusively on deep learning-based methods.,
9205.txt,Fig.,
9206.txt,4,
9207.txt,Significance of the surveyed learned representation-based BTC methods in terms of aggregated citations per year.,
9208.txt,"Thus, this area lacks a comprehensive study of learned representations-based methods for BTC.",
9209.txt,"With these motivations in mind, we conduct this survey for CNNs-based multigrade tumor classification methods.",
9210.txt,We first detach our overview from existing surveys by providing a comprehensive comparison and detailed analysis with their pros and cons.,
9211.txt,The second issue stated earlier is solved by introducing a separate section with current challenges of BTC and detailed future directions for further research.,
9212.txt,An overview of BTC methods with an emphasis on CNN-assisted approaches is depicted in Fig.,
9213.txt,3,
9214.txt,The temporal distribution of the CNN-based BTC literature is given in Fig.,
9215.txt,4,
9216.txt,"In this section, we briefly discuss the architectures and overall methodologies of the existing literature, as given in Table II.",
9217.txt,As illustrated in Fig.,
9218.txt,"2, segmentation of the tumor region is the primary step in the general pipeline of BTC, which is mostly targeted by existing segmentation techniques .",
9219.txt,"On the other hand, some methods used end-to-end models for both segmentation and classification.",
9220.txt,"Since the focus of this study is on BTC, we will cover only BTC approaches or those methods using segmentation followed by classification.",
9221.txt,"In the reviewed literature, several tumor segmentation methods are used as the primary step prior to classification.",
9222.txt,"This method is evaluated with MRI data of 159 patients, with proven 1p/19q status.",
9223.txt,Different data augmentation techniques are used to balance the data distribution.,
9224.txt,"Likewise, Paul presented two types of neural networks for the classification of brain tumors with data augmentation to improve the performance of their method.",
9225.txt,Another approach presented by Ahmed utilized pretrained AlexNet model for the detection of Glioblastoma Multiforme and the estimation of the survival time of patients with this disease.,
9226.txt,Balasooriya and Nawarathna  developed their own custom CNN for BTC.,
9227.txt,"They evaluated their method using TCIA data set that is divided into five different classes: Astrocytoma, Gliobastoma Multiforme, Oligodendroglioma, healthy tissue, and unidentified tumor.",
9228.txt,Wong proposed a medical image classifier for 3-D brain images.,
9229.txt,They extracted features from the segmentation network  and fed them into a pretrained VGG-16 model for three-class brain tumor types classification.,
9230.txt,"Mohsen segmented the tumor regions from 2-D brain MRI images using Fuzzy C-mean clustering and then extracted discrete wavelet transform features, followed by principal component analysis for feature compression.",
9231.txt,"They passed the compressed features on to a deep neural network, having seven hidden layers for classification.",
9232.txt,"Compared with the aforementioned studies, certain methods focused only on BTC.",
9233.txt,"For example, Afshar attempted to address the major two problems of CNNs for the BTC problem, i.e., the need for large volumes of training data and the lack of significant capability to handle transformations.",
9234.txt,"They explored Capsule Networks with four main objectives, i.e., achieving maximum accuracy for BTC, investigation of the overfitting problem, the suitability of CapsNets for only segmented tumor regions or whole MRI images, and visualization of MRI learned features for better understanding.",
9235.txt,CapsNets work well for BTC.,
9236.txt,"However, they are highly sensitive to the miscellaneous image background.",
9237.txt,"In follow-up work, Afshar  elaborated on this problem by proposing a modified CapsNets model, which considers the tumor's boundaries during its main pipeline for BTC.",
9238.txt,Ge proposed a 3-D multiscale CNN model for the classification of glioma tumors into high- and low-level grades.,
9239.txt,"They introduced a feature fusion scheme, which further refined Authorized licensed use limited to: University of Exeter.",
9240.txt,"In another work, Ge used 2-D-CNN with feature aggregation to enhance the performance of classification.",
9241.txt,Decuyper  used pretrained VGG model and extracted features from the first fully connected layer for the classification of glioma into high- and low-level grades.,
9242.txt,Banerjee presented a deep CNN-based CAD system for gliomas classification.,
9243.txt,Pereira  first extracted the tumor regions using a 3-D-U-Net model and then fed them into their proposed Glioma grading CNN after resizing the images.,
9244.txt,"In their proposed CNN model, global average pooling is used to summarize each feature map, followed by a cascade of Authorized licensed use limited to: University of Exeter.",
9245.txt,"Still, on the usage of CNNs, Anaraki recently proposed a CNN model, which was evolved using a genetic algorithm for classification of Glioma into three grades.",
9246.txt,"Similarly, Sajjad first segmented the tumor regions using deep features and then fine-tuned a VGG-19 pretrained model to classify the tumor into four grades.",
9247.txt,They used eight different data augmentation techniques with a total of 30 parameters to extend the existing data sets for training.,
9248.txt,"More recently, six new methods have been reported in the area of BTC using MRI.",
9249.txt,"The detailed information about these new studies and all previous methods in terms of segmentation, employed features, classifier, data set, and target classes are shown in Table II.",
9250.txt,"In the literature related to BTC, several data sets have been furnished within the community, targeting both binary and multiclass classification problems.",
9251.txt,"Among all the publicly available data sets, representative data sets are covered in this section.",
9252.txt,The majority of BTC data sets are from local hospitals or laboratories that are not publicly available for the research community.,
9253.txt,"The publicly available data sets are multigrade brain tumor data set , Brain tumor public data set, The Cancer Imaging Archive , BRATS 2015 , Harvard , and the Internet brain segmentation repository , whose details are given in Sections IV-AIV-F, respectively.",
9254.txt,"There are two variants of this data set: the original one that consists of 121 MRI instances and the augmented data set, containing 3630 MRI instances created from the original images.",
9255.txt,The overall data set is divided into four different grades according to the standard classification of WHO tumors of the Central Nervous System .,
9256.txt,"The overall distribution and statistics of this data set are given in Table III, and sample images are visualized in Fig.",
9257.txt,5.The information about data augmentation and other necessary details are given in X.,
9258.txt,Brain Tumor Public Data Set This data set was captured from two different hospitals in China in the duration of 2005?010.,
9259.txt,"It consists of 3064 T1-weighed CE-MRI slices, collected from 233 different patients.",
9260.txt,"The size of each slice in this data set is 512512, with 6 and 1 mm, slice thickness and gap, respectively.",
9261.txt,The tumor region inside each slice is segmented manually by three experienced radiologists.,
9262.txt,"This data set is divided into three classes, i.e., Meningiomas, Gliomas, and Pituitary tumors.",
9263.txt,"The complete statistics of this data set are given in Table IV , while representative slices from each class are shown in Fig.",
9264.txt,5,
9265.txt,"This repository contains several collections of cancer imagery, but only a few of them are related to our problem of BTC.",
9266.txt,"The concerned group with our problem in this repository is BRAIN-DSC-MRI, which contains two types of brain tumors: low- and high-grade gliomas.",
9267.txt,The data is collected from 49 patients of different ages.,
9268.txt,The BRA TS 2015 data set is created for brain tumor segmentation.,
9269.txt,"However, in several contributions , it has been used for tumor classification.",
9270.txt,It consists of two types of tumors: low- and high-grade gliomas.,
9271.txt,"The overall data set consists of 274 MR scans with 220 and 54 for high- and low-grade glioma, respectively.",
9272.txt,"The MRI scanning is performed using four modalities: T1, T1c, T2, and Flair, with an image size of 240  240  155.",
9273.txt,ANNLIB is an online repository for MRI of the Central Nervous System.,
9274.txt,"This database is available online, consisting of more than 13 000 brain MRIs of 30 different cases.",
9275.txt,"These MRIs contain a large variety of normal and tumor images including different types of stroke or brain attacks, several types of gliomas, Alzheimer's, and infectious diseases.",
9276.txt,Authorized licensed use limited to: University of Exeter.,
9277.txt,Restrictions apply.,
9278.txt,This article has been accepted for inclusion in a future issue of this journal.,
9279.txt,"Content is final as presented, with the exception of pagination.",
9280.txt,Sample images from both data sets.Multigrade brain tumor data set.Internet Brain Segmentation Repository  IBSR is an open-source repository for brain tumor segmentation and classification.,
9281.txt,"Each of the MRI scans contains 60?5 slices, with a resolution of 256  256 pixels.",
9282.txt,"The data is collected from 14 male and four female patients aged seven to 71 years, covering a large variability of brain anatomies.",
9283.txt,"Due to the advancement in deep learning, transfer learning techniques have been integral to almost every field of computer vision, multimedia, surveillance , and medical.",
9284.txt,"Among these domains, transfer learning in medical imaging is the most prominent, where the weights of standard models, trained on nonmedical images or natural image classification data sets, particularly ImageNet , are fine-tuned on medical imaging data.",
9285.txt,"This transfer learning process is adopted in almost every modality of medical imaging, including X-rays, CT scans, pathological images, positron emission tomography , and MRI.",
9286.txt,"In this section, our main target is to review transfer learning techniques based on MR images, especially brain tumor segmentation, classification, and retrieval.",
9287.txt,"The detailed descriptions of each method including publication year, pretrained model, and data set with its main target, are given in Table V. The range of these methods is from 2015 to 2019, starting from traditional machine learning techniques to state-of-theart deep learning models.",
9288.txt,"In addition, we also review a few transfer learning methods, focusing on breast cancer recognition and prostate cancer classification, to show the importance of transfer learning in the medical imaging domain,  MR images.",
9289.txt,"As discussed in Section III, several CNNs and their variants, such as VGG-16, VGG-19, and CapsNets, have been already explored in the literature for BTC.",
9290.txt,"However, the baseline and most popular CNN architectures have not been deeply investigated for this problem.",
9291.txt,"Furthermore, some of the existing studies have used a single data set for experiments and validation of BTC results.",
9292.txt,"For instance, X investigated CapsNets for BTC but using only a single data set introduced in X.",
9293.txt,"Due to these reasons, it is important to investigate the baseline and recent CNN models for BTC using multiple data sets.",
9294.txt,The remaining four data sets are either not freely available or contain 3-D images that are different from the first two data sets and cannot be processed by the CNNs under consideration.,
9295.txt,"The CNNs used for the comparison are AlexNet, GoogleNet, VGG, SqueezeNet , MobileNet , and ResNet.Furthermore, we use Caffe deep learning framework with NVidia DIGITS  for the evaluation.",
9296.txt,"During the training process of each model, several options about different parameters are considered due to which the output accuracy varies.",
9297.txt,"These parameters include the number of epochs, which affects the accuracy positively up to a certain limit.",
9298.txt,"As per the current training setup, we selected 30 epochs because the accuracy stops increasing after this limit.",
9299.txt,"Another important parameter for consideration is the learning rate, which is opted as 0.001 as optimal after exhaustive experiments.",
9300.txt,"The next parameter affecting accuracy is the solver type, which was selected to be stochastic gradient descent due to its better performance .",
9301.txt,"The final parameter is Softmax loss function, which computes the multinomial logistic loss of the Softmax classifier .The detailed results of all CNNs over Data set 1 and Data set 2 are given in Table VI.",
9302.txt,"Three evaluation metrics, including accuracy, frames per second, and model size, are used during experiments for comparison.",
9303.txt,"Accuracy shows the correct predictions of each BTC approach, while fps refers to the processing speed of each method under consideration.",
9304.txt,The model size is the amount of memory needed for the deployment of the final prediction architecture.,
9305.txt,The first metric "accuracy" is considered in the majority of the studies for comparison than the latter two metrics "fps" and "model size.",
9306.txt,"We considered all metrics for comparison to show the strength of each architecture under consideration, considering their performance and practicality.",
9307.txt,It can be observed from the obtained results that SqueezeNet achieved the best fps and model size due to its efficiency.,
9308.txt,"However, in most cases, the model is overfit, i.e., completely biased toward a single class on both data sets.",
9309.txt,AlexNet and GoogleNet achieved almost similar results but not higher enough for consideration in the CAD system due to its critical nature.,
9310.txt,"Furthermore, the results of MobileNet and ResNet are also low and are not trustworthy enough for Authorized licensed use limited to: University of Exeter.",
9311.txt,This article has been accepted for inclusion in a future issue of this journal.,
9312.txt,"Content is final as presented, with the exception of pagination.",
9313.txt,"Results show that VGGNet obtained the best accuracy compared with all other CNNs under consideration, with a similar average fps but larger model size than other CNNs.",
9314.txt,"These results are insightful to both industry and hospitals in the sense that they can select a method of their choice, considering their requirements, accuracy, deployment environment, and other constraints.",
9315.txt,Authorized licensed use limited to: University of Exeter.,
9316.txt,Restrictions apply.,
9317.txt,This article has been accepted for inclusion in a future issue of this journal.,
9318.txt,"Content is final as presented, with the exception of pagination.",
9319.txt,Processing and analyzing MRI data of brain tumors are among the most challenging tasks for computer vision scientists.,
9320.txt,MRI is an advanced technique for producing high-quality images of the human body parts.,
9321.txt,It plays a key role in processing and detecting the right stage and in deciding the correct therapy for the tumor-infected person.,
9322.txt,"To accomplish this task, researchers have proposed many automatic techniques by using MRI .",
9323.txt,"The main reason is that these MRIs are not affected by radiations, and their contrast is better compared with other modalities.",
9324.txt,"This point is taken into consideration in medical image analysis, as several parameters, including similarity measures, modality, image contents, transformation, implementation, and optimization of algorithms, affect the performance.",
9325.txt,"Similarly, the selection of a machine learning method for BTC is also a crucial step, requiring a careful assessment.",
9326.txt,"Most machine learning methods resort to features extracted from images via traditional strategies, followed by their classification.",
9327.txt,This process can be overly complex and time-consuming if the extracted features are highly dimensional.,
9328.txt,Other problems associated with machine learning approaches include the diversity of classes and challenges associated with distance measurement between images.,
9329.txt,"It can also be observed that medical images are usually affected by low-light contrast, deteriorating their quality, which consequently affects the classification accuracy.",
9330.txt,"Recently, methods relying on learned representations have gained momentum for BTC problems at the expense of handcrafted feature-based methods.",
9331.txt,"Despite their strength and huge popularity, CNN-based methods encounter many challenges.",
9332.txt,"For instance, they require a huge amount of data for training, which can be either not available for each domain, or it can be very challenging to get the desired accuracy for a target problem .",
9333.txt,"Also, increasing the number of layers in a CNN model cannot guarantee an increase in classification accuracy.",
9334.txt,"Similarly, deep learning models are computationally expensive due to their underlying running hardware devices .",
9335.txt,"Thus, deploying these models in real scenarios, especially in clinical practice, remains an unsolved challenge.",
9336.txt,"Concluding the challenges faced by the current research community, there are several recommendations and future directions for research scientists.",
9337.txt,Achieving higher accuracy is always the priority while dealing with problems related to Fig.,
9338.txt,6,
9339.txt,"Generic diagram for future research recommendations, where the MRI generated data are processed through GAN to create new images and the newly created data set plus the existing data are passed to an end-to-end deep learning model, generating the detailed results.",
9340.txt,"The output data are distributed to various places, where it can be analyzed further for different purposes.",
9341.txt,"Considering the available resources and required users' services, the optimal computing platform can be used for analysis.",
9342.txt,"This provides personalized medical services, leading to smart healthcare.",
9343.txt,healthcare with CAD techniques.,
9344.txt,"The literature of BTC is richer in terms of studies; however, certain areas still need further extensive research.",
9345.txt,The future recommendations of BTC literature are schematically represented in Fig.,
9346.txt,6 with a focus on personalized and smart healthcare that is briefly discussed in Sections VII-AVII-J.,
9347.txt,Public Availability of BTC Data Sets The main issue with the BTC literature is the scarcity of public data sets.,
9348.txt,"Many researchers are passionate to work in this field, but there are still a severely limited number of publicly available data repositories.",
9349.txt,"This restricts the experimentation and testing of new BTC methods and their maturity compared with other domains, where data sets can be accessed freely.",
9350.txt,"As mentioned previously, the major requirement of any deep learning model is the huge amount of annotated data for achieving better accuracy scores.",
9351.txt,"Unfortunately, most of the existing BTC data sets Authorized licensed use limited to: University of Exeter.",
9352.txt,"Furthermore, the majority of already available data sets only provide data for high-level classification, with no focus on further grades of brain tumors that can be very helpful to radiologists for early diagnosis.",
9353.txt,"Therefore, it is highly recommended to create challenging data sets with detailed grading of each image in future research and ensure their availability for the benefit of the entire research community.",
9354.txt,"End-to-End Deep Learning Models Although the majority of the recent techniques are based on deep learning, they use different models for detection, classification, and segmentation, as discussed in Section III.",
9355.txt,"This increases the computational complexity of the implemented methods, making them less suitable for their consideration in clinical practice.",
9356.txt,"Currently, there is no end-to-end deep learning model, which can detect a tumor in the input MRI image, segment it, and classify its nature as a final output.",
9357.txt,"Thus, both industry and academia are highly encouraged to further investigate deep learning models for the problem of BTC in this context.",
9358.txt,"This can greatly reduce the overall running time of the target BTC model, ultimately matching the practical constraints of smart healthcare and clinical practice.",
9359.txt,"Edge Intelligence for MRI Data Analysis Edge intelligence is used on a wide scale in different domains because of its numerous advantages, such as reduced bandwidth and threats, minimal latency, improved consistency, compliance, and lower cost.",
9360.txt,"For instance, Chen presented a deep learning and edge intelligence-assisted system for distributed video surveillance applications.",
9361.txt,"Their system processes data at network edges instead of network centers, reducing communication overhead, thereby providing accurate video analysis results with elastic and scalable computing power.In the field of BTC, the MRI data are normally collected in the Digital Imaging and Communications in Medicine format, which is manually converted into slices for further analysis.",
9362.txt,This process is timeconsuming and tedious with comparatively higher changes of errors.,
9363.txt,"Through edge intelligence, the DICOM images can be automatically processed over the capturing device for efficient analysis with better accuracy.",
9364.txt,"Currently, there is no such a concept of edge intelligence for the specific problem of BTC, which can be a new trend for further research in this domain.",
9365.txt,Merging F og and Cloud Computing With Federated Learning: A New Dawn for BTC Fog computing is an extension of cloud computing performed over the edge through a distributed network.,
9366.txt,Fog computing makes it easy to facilitate the regular processing and generates the output fast enough by using capabilities of edge network.,
9367.txt,"In the medical field, the data collected from a specific MRI capturing device should be quickly formulated and processed over different cloud and fog layers for efficient analysis.",
9368.txt,This can be possible by exploring fog and cloud computing with an extensive investigation of the new emerging framework of AI "Federated Learning" for BTC in future studies.,
9369.txt,"In FA architecture, models use the distributed mobile/edge devices for computation due to their recently improved capabilities for executing a machine learning model.",
9370.txt,"Using this hybrid computing platform, a model can be improved by training it locally via the data collected by the concerned edge device, and the changes in terms of model parameters and weights can be reported to cloud through a secure communication link, e.g., homomorphic encryption as employed by Feng  for outsourcing big data in the federated cloud environment.",
9371.txt,"The most important aspect of FA is the preservation of user's privacy, which is utterly important in the medical domain.",
9372.txt,"In the case of BTC, the output of brain tumors, classified into various grades, will be generated directly over the cloud or fog, making the overall process smarter and more feasible compared with manual lengthy processes.",
9373.txt,"E. Advanced Data-Enrichment T echniques Data augmentation can be used to generate data up to an extent, which can be used for training deep learning BTC systems.",
9374.txt,"However, the quality of generated data stalls or even degrades after a certain level of augmentation is reached.",
9375.txt,"Thus, more advanced data-enrichment techniques need to be investigated for BTC.",
9376.txt,"GAN creates new data instances from the existing data, realistically complying with the distribution of the input data.",
9377.txt,"As mentioned earlier, the main problem in the BTC literature is the lack of data, which is currently handled through various data augmentation techniques.",
9378.txt,"GAN has still not been explored yet for the problem of BTC, which can easily handle the limited data problem by generating new similar data from the input images.",
9379.txt,"Thus, it is recommended for scientists working in BTC domain to utilize GANs for new data generation to effectively solve the limited data problem and possibly improve the performance of state-ofthe-art methods.",
9380.txt,F .,
9381.txt,"Sequential Learning in DICOM Images DICOM images are sequences of slices captured in an order, where some slices have a small size, while others have a large size of tumors.",
9382.txt,The appearance of a brain tumor varies in size and angle in different slices.,
9383.txt,"When these slices are converted into normal image formats, we may not locate the exact position of a brain tumor.",
9384.txt,Singular 2-D image data cannot provide enough information that can be used in further treatment of tumors using laser therapy.,
9385.txt,"This problem is not addressed in the current literature, needing special attention from both industry and academia.",
9386.txt,"In future work, the DICOM image slices in a group should be analyzed sequentially, which can give enough information in the 3-D form to find the exact location of the brain tumor.",
9387.txt,"Thus, it can directly help and Authorized licensed use limited to: University of Exeter.",
9388.txt,Restrictions apply.,
9389.txt,This article has been accepted for inclusion in a future issue of this journal.,
9390.txt,"There is a special need for trustworthy methods in the BTC literature, which can be implemented in clinics and hospitals on a commercial scale and can be extended to smart healthcare.",
9391.txt,The accuracy achieved by deep learning-based BTC methods is better than traditional methods and convincing enough to be considered as a second opinion for medical specialists.,
9392.txt,"However, it still needs improvements in terms of accuracy, execution time, flexibility, cost, and scalability for commercialization and practicability in real-world medical applications.",
9393.txt,H. Confidence and Explainability in Learning-Based BTC Another crucial aspect when undertaking BTC via machine learning methods is to also consider the usability of the developed methods by medical practitioners.,
9394.txt,"Indeed, the performance of the model when detecting and estimating the severity of a tumor is of pivotal importance due to the relevance and consequences of decisions to be made upon the models output.",
9395.txt,"However, for the medical community to embrace the benefits of deep learning methods used for this purpose, there are far more aspects to be considered beyond model performance.",
9396.txt,"Usability aspects, such as the confidence of the output, must be also placed under the spotlight for the developed models to be actionable.",
9397.txt,"The reliability of the produced predictions can, indeed, make the medical specialist feel more confident with decisions supported by black-box deep learning models.",
9398.txt,"Likewise, there is a rising concern with assessing what deep learning models eventually learn to observe from data, particularly in the medical domain.",
9399.txt,Reasons span beyond the usability of the model: recently reported cases confirm that there is little knowledge about what models surpassing human performance in the diagnosis of certain diseases are learning from data .,
9400.txt,Posthoc techniques for eXplainable Artificial Intelligence can give the clue needed not only to disentangle the knowledge learned by these powerful methods but also to open up new medical research directions.,
9401.txt,"Internet of Medical Things Recently, the Internet of Medical Things attracted more attention of the researchers due to the rapid development in intelligent technologies and real-time data sharing using the Internet of Things .",
9402.txt,"Due to the efficient data sharing and communication technologies, the concept of the IoT has been adopted by almost every field of research,smart networking "", energy management , business , healthcare, and medical.",
9403.txt,"Among these areas, the medical domain especially dealing with brain diseases is considered the most severe case due to the life-threatening issues of patients.",
9404.txt,"Considering this aspect, BTC can be implemented in IoMT, which will minimize the life risk of brain tumor patients by providing the necessary precaution online and informing them about their grade of the tumor.",
9405.txt,"The main advantage of BTS integration with the IoMT is to treat the patients in remote areas, i.e., those who have limited access to medical services.",
9406.txt,The reported performance of existing reviewed methods and models is good enough to be considered in real-time scenarios.,
9407.txt,"However, there are still several challenges for researchers to present a complete IoMT environment for taking decisions in realtime.",
9408.txt,"These challenges include privacy preservation, the computational complexity of deep learning models, the latency of deployed networks , and the compatibility of smart devices with existing technologies , all needing effective solutions for smooth integration with existing medical and patients management systems for smart and personalized healthcare.",
9409.txt,"Synergies With Other Areas of Computational Intelligence The interest in deep learning has propelled intense research efforts around this family of machine learning models in the last few years, yielding countless applications such as the one targeted in this overview.",
9410.txt,"However, many issues underneath the use of deep learning methods still remain insufficiently addressed to date.",
9411.txt,"Renowned practical caveats include the difficult architectural design of deep learning models, the slow convergence of backpropagation for highly complex deep architectures, their relative lack of interpretability, or the burdensome hyperparameter tuning phase required for such models to perform optimally for a given task.",
9412.txt,"The wide acknowledgmentof the research community around these problems has ignited a shift of focus toward hybridizing deep learning models with elements from other areas of computational intelligence , with an emphasis lately placed on the use of evolutionary computation and swarm intelligence.",
9413.txt,"Indeed, a growing number of research works have focused on different flavors of bio-inspired optimization heuristics to overcome problems inherently deriving from deep learning as the ones exemplified earlier.",
9414.txt,"For instance, the use of different forms of evolutionary programming has given rise to tools to automate the design and configuration of complex neural architectures, much like a fresh renaissance of old concepts intersecting neural and evolutionary computation .",
9415.txt,"In this same line of reasoning, bio-inspired heuristics specially devoted to undertake large-scale global optimization problems can be thought today to be a serious competitor to the classical gradient backpropagation algorithm that dominates the spectrum of training algorithms for deep architectures.",
9416.txt,"Further intersections between these two areas include a more effective transfer of the learned knowledge between different classification tasks that, for the medical area, can be a catalyst to allow using deep learning models in new scenarios with scarcely available data.",
9417.txt,"We believe that as in any other specific application area, deep learning models empowered with evolutionary computation, edge and swarm intelligence, and FA will expedite and increase the quality of its results when facing new problems in multigrade brain tumor detection and characterization, eventually reaching unprecedented levels of self-configurability, knowledge transferability, and accuracy.",
9418.txt,"For this to occur, newcomers to the field should steer their efforts toward this expectedly profitable research avenue.",
9419.txt,Authorized licensed use limited to: University of Exeter.,
9420.txt,Restrictions apply.,
9421.txt,This article has been accepted for inclusion in a future issue of this journal.,
9422.txt,"Content is final as presented, with the exception of pagination.",
9423.txt,"Considering the recent development in the domain of BTC and the limitations of existing studies, we presented a comprehensive survey of deep learning-based BTC methods.",
9424.txt,Deep learning technologies accurately assist radiologists in predicting the tumor regions and further classifying them into their respective types.,
9425.txt,"Many researchers contributed to the field of BTC, but many challenges remain therein.",
9426.txt,"Therefore, we conducted this study to provide the overall literature of deep learning-basedBTC methods in a single survey and to draw the attention of both academia and industry toward the necessary development in this domain.",
9427.txt,"This article comprehensively discussed all deep learning-based BTC methods, with their achievements and weaknesses, followed by complete information about the existing publicly available data sets with their respective resources.",
9428.txt,"In order to empirically inform the conclusions drawn from our literature study, we experimentally analyze various deep learning models by performing extensive experiments over BTC data sets and highlighted the suitable option for considerationin smart health care.",
9429.txt,"Finally, this study highlighted key challenges, such as lack of public data sets and end-to-end deep learning models, and suggested detailed directions for further research in BTC domain, exploring edge/fog/cloud computing with FA, advanced data-enrichment techniques, model confidence and explainability, IoMT, and deep investigation of sequential and transfer learning strategies.",
9430.txt,This can increase the maturity level of BTC methods with better applicability for commercial clinical applications and their smooth integration with smart healthcare.,
9431.txt,The brain is an intriguing system whose complexity demands sophisticated means to understand and characterize its behavior.,
9432.txt,"The unrivaled learning capability of deep learning models has made them the standard choice to detect and classify brain tumors from MRI images and other monitored data alike, spawning a flurry of research activity overviewed in this survey.",
9433.txt,We hope that the numerous research paths outlined in our overview will serve as supportive material for the research community currently working on this field and a stimulating read for newcomers to this domain.,
9434.txt,"A common shortfall of supervised deep learning for medical imaging is the lack of labeled data, which is often expensive and time consuming to collect.",
9435.txt,"This article presents a new semisupervised method for medical image segmentation, where the network is optimized by a weighted combination of a common supervised loss only for the labeled inputs and a regularization loss for both the labeled and unlabeled data.",
9436.txt,"To utilize the unlabeled data, our method encourages consistent predictions of the network-in-training for the same input under different perturbations.",
9437.txt,"With the semisupervised segmentation tasks, we introduce a transformation-consistent strategy in the self-ensembling model to enhance the regularization effect for pixel-level predictions.",
9438.txt,"To further improve the regularization effects, we extend the transformation in a more generalized form including scaling and optimize the consistency loss with a teacher model, which is an averaging of the student model weights.",
9439.txt,We extensively validated the proposed semisupervised method on three typical yet challenging medical image segmentation tasks:  skin lesion segmentation from dermoscopy images in the International Skin Imaging Collaboration 2017 data set;  optic disk segmentation from fundus images in the Retinal Fundus Glaucoma Challenge data set; and liver segmentation from volumetric CT scans in the Liver Tumor Segmentation Challenge data set.,
9440.txt,"Compared with state-of-the-art, our method shows superior performance on the challenging 2-D/3-D medical images, demonstrating the effectiveness of our semisupervised method for medical image segmentation.Index Terms?Liver segmentation, optic disk  segmentation, self-ensembling, semisupervised learning, skin lesion segmentation.",
9441.txt,"Recently, deep learning techniques have made impressive progress on semantic image segmentation tasks and become a popular choice in both computer vision and medical imaging community .",
9442.txt,The success of deep neural networks usually relies on the massive labeled data set.,
9443.txt,"However, it is hard and expensive to obtain labeled data, notably in the medical imaging domain where only experts can provide reliable annotations .",
9444.txt,"For example, there are thousands of dermoscopy image records in the clinical center, but melanoma delineation by experienced dermatologists is very scarce, see Fig.",
9445.txt,1,
9446.txt,"Such cases can also be observed in the optic disk segmentation from the retinal fundus images, and especially in liver segmentation from CT scans, where delineating organs from volumetric images in a slice-by-slice manner is very time consuming and expensive.",
9447.txt,"The lack of the labeled data motivates the study of methods that can be trained with limited supervision, such as semisupervised learning , weakly supervised learning , and unsupervised domain adaptation .",
9448.txt,"In this article, we focus on the semisupervised segmentation approaches, considering that it is relatively easy to acquire a large amount of unlabeled medical image data.",
9449.txt,"Semisupervised learning aims to learn from a limited amount of labeled data and an arbitrary amount of unlabeled data, which is a fundamental, challenging problem, and has a high impact on real-world clinical applications.",
9450.txt,The semisupervised problem has been widely studied in medical image research community.,
9451.txt,Recent progress in semisupervised learning for medical image segmentation has featured deep learning.,
9452.txt,"The first, second, and third rows show the skin lesion in the dermoscopy image, the OD in retinal fundus images, and liver segmentations from CT scans, respectively.",
9453.txt,Blue color denotes the structure boundary and red color represents the liver.,
9454.txt,"learning methods are based on the recent techniques, such as variational autoencoder and generative adversarial network.",
9455.txt,We tackle the semisupervised segmentation problem from a different point of view.,
9456.txt,"With the success of the self-ensembling model in the semisupervised classification problem, we further advance the method to medical image segmentation tasks, including 2-D cases and 3-D cases.",
9457.txt,"In this article, we present a new semisupervised learning method based on the self-ensembling strategy for medical image segmentation.",
9458.txt,The whole framework is trained with a weighted combination of supervised and unsupervised losses.,
9459.txt,The supervised loss is designed to utilize the labeled data for accurate predictions.,
9460.txt,"To leverage the unlabeled data, our self-ensembling method encourages a consistent prediction of the network for the same input under different regularizations, e.g., randomized Gaussian noise, network dropout, and randomized data transformation.",
9461.txt,"In particular, our method accounts for the challenging segmentation task, in which a pixel-level classification is required to be predicted.",
9462.txt,"We observe that in the segmentation problem if one transforms the input image, the expected prediction should be transformed in the same manner.",
9463.txt,"When the inputs of convolutional neural networks are rotated, the corresponding network predictions will not rotate in the same way.",
9464.txt,"In this regard, we take advantage of this property by introducing a transformationconsistent scheme at the input and output space of our network.",
9465.txt,"Specifically, we design the unsupervised loss by minimizing the differences between the network predictions under different transformations of the same input.",
9466.txt,"To further improve the regularization, we extend the transformation consistency regularization with the scaling operation and optimize the network under a consistent scaling scheme.",
9467.txt,"In addition, we adopt a teacher model to evaluate images under perturbations to construct better targets.",
9468.txt,"We extensively evaluate our methods for semisupervised medical image segmentation on three representative segmentation tasks, skin lesion segmentation from dermoscopy images, OD segmentation from retinal images, and liver segmentation from CT scans.",
9469.txt,"In summary, our semisupervised method achieves significant improvements compared with the supervised baseline and also outperforms other semisupervised segmentation methods.",
9470.txt,The main contributions of this article are as follows.,
9471.txt,"We present a novel and effective semisupervised method, namely, transformation-consistent self-ensembling model for medical image segmentation.",
9472.txt,Our method is flexible and can be easily applied to both 2-D and 3-D CNNs.,
9473.txt,We regularize unlabeled data with the transformation-consistent strategy and demonstrate effective semisupervised medical image segmentation.,
9474.txt,"Extensive experiments on three representative yet challenging medical image segmentation tasks, including 2-D and 3-D data sets, demonstrate the effectiveness of our semisupervised method over other methods.",
9475.txt,Our method excels with the other state-of-the-art methods and establishes a new record in the International Skin Imaging Collaboration 2017 skin lesion segmentation data set with the semisupervised method.,
9476.txt,This article extends our previous work TCSM in three aspects.,
9477.txt,"First, multiscale inference is an effective technique utilized in many image recognition tasks.",
9478.txt,"To enhance the regularization, we extend TCSM with more generalized transformation, such as random scaling.",
9479.txt,"Through this, we utilize the unlabeled data to improve the regularization of the network.",
9480.txt,"Second, our preliminary TCSM evaluates the inputs with perturbations on the same network.",
9481.txt,"To avoid the misrecognition, we incorporate a teacher model to construct better targets, where the teacher model is an exponential moving average of the student model.",
9482.txt,"Third, we evaluate our method on three data sets, including the skin lesion data set, retinal fundus data set, and liver CT data set.",
9483.txt,Experiments on all three data sets show the effectiveness of our method over existing methods for semisupervised medical image segmentation.Semisupervised Segmentation for Medical Images Early semisupervised works segment medical images mainly using hand-crafted features.,
9484.txt,You combined radial projection and self-training learning to improve the segmentation of retinal vessel from fundus image.,
9485.txt,Portela presented a clustering-based Gaussian mixture model to automatically segment brain MR images.,
9486.txt,"Later on, Gu constructed forest oriented superpixels for vessel segmentation.",
9487.txt,"For skin lesion segmentation, Jaisakthi  explored the K-means clustering and flood fill algorithm.",
9488.txt,"These semisupervised methods are, however, based on hand-crafted features, which suffer from limited representation capacity.",
9489.txt,Recent works for semisupervised segmentation are mainly based on deep learning.,
9490.txt,"An iterative method is proposed by Bai for cardiac segmentation from MR images, Authorized licensed use limited to: University of Exeter.",
9491.txt,"The teacher and student models share the same architecture, and the weight of the teacher model is the EMA of the student model.",
9492.txt,"The student model is trained by the total loss, which is a weighted combination of the cross-entropy loss on labeled data, and mean square error loss on both labeled and unlabeled data.",
9493.txt,The model encourages the teacher and student models to be transformed consistently by utilizing the unlabeled data.,
9494.txt,"irefers to the transformation-consistent regularization, including rotation, flipping, and scaling operations.",
9495.txt,where network parameters and segmentation masks for unlabeled data are alternatively updated.,
9496.txt,Generative model based semisupervised approaches are also popular in the medical image analysis community.,
9497.txt,Sedai introduced a V AE for optic cup  segmentation from retinal fundus images.,
9498.txt,They learned the feature embedding from unlabeled images using V AE and then combined the feature embedding with the segmentation autoencoder trained on the labeled images for pixelwise segmentation of the cup region.,
9499.txt,"To involve unlabeled data in training, Nie presented an attention-based GAN approach to select trustworthy regions of the unlabeled data to train the segmentation network.",
9500.txt,Another GAN-based work employed the cycle-consistency principle and performed experiments on cardiac MR image segmentation.,
9501.txt,"More recently, Ganaye proposed a semisupervised method for brain structures segmentation by taking advantage of the invariant nature and semantic constraint of anatomical structures.",
9502.txt,Multiview co-training-based methods  have also been explored on 3-D medical data.,
9503.txt,"Differently, our method takes advantage of transformation consistency and self-ensembling model, which is simple yet effective for medical image segmentation tasks.",
9504.txt,"Transformation Equivariant Representation Next, we review equivariance representations, to which the transformation equivariance is encoded in the network to explore the network equivariance property.",
9505.txt,"Concurrently, Dieleman  designed four different equivariance to preserve feature map transformations by rotating the feature maps instead of the filters.However, these works aim to encode equivariance into the network to improve its generalization capability, while our method aims to better utilize the unlabeled data in semisupervised learning.",
9506.txt,"C. Medical Image Segmentation Early methods for medical image segmentation mainly focused on using thresholding, statistical shape models  and machine learning , while recent ones are mainly deep learning-based.",
9507.txt,"Deep learning methods showed promising results on skin lesion segmentation, OD segmentation, and liver segmentation.",
9508.txt,Yu explored the network depth property and developed a deep residual network for automatic skin lesion segmentation by stacking residual blocks to increase the network's representative capability.,
9509.txt,Yuan  trained a 19-layer deep CNN in an end-to-end manner for skin lesion segmentation.,
9510.txt,"As for OD segmentation, Fu presented an M-Net for joint OC and OD segmentation.",
9511.txt,"In addition, a disk-aware network  was designed for glaucoma screening by an ensemble of different feature streams of the network.",
9512.txt,"For liver segmentation, Chlebus  presented a cascaded FCN combined with hand-crafted features.",
9513.txt,Li presented a 2-D?-D hybrid architecture for liver and tumor segmentation from CT images.,
9514.txt,"Although these methods achieved good results, they are based on fully supervised learning, requiring massive pixelwise annotations from experienced dermatologists or radiologists.",
9515.txt,Fig.,
9516.txt,2 overviews our TCSM for semisupervised medical image segmentation.,
9517.txt,"First, we randomly sample xiraw data, including both the labeled and unlabeled cases from the training data set, followed by performing random transformations on these images.",
9518.txt,"Teacher and student models are formulated in our framework, where the student model is trained by the loss function, and the teacher model is an average of consecutive student models.",
9519.txt,"To train the student model, the transformed inputs are fed into the student model, and the softmax output Authorized licensed use limited to: University of Exeter.",
9520.txt,"After the weights of the student model have been updated with gradient descent, the teacher model weights are updated as an EMA of the student weights.",
9521.txt,"Hence, the label information is passed to the unlabeled data by constraining the model outputs to be consistent with the unlabeled data.",
9522.txt,A.,
9523.txt,"Mean T eacher-Based Semisupervised Framework To ease the description of our method, we first formulate the semisupervised segmentation task.",
9524.txt,"In the semisupervised segmentation problem, the training set consists of N inputs in total, including M labeled inputs and N ?M unlabeled inputs.",
9525.txt,"The first term in the loss function is trained by the cross-entropy loss, aiming at evaluating the correctness of network output on labeled inputs only.",
9526.txt,"The second term is optimized with the regularization loss, which utilizes both the labeled and unlabeled inputs.",
9527.txt,"The key point of this semisupervised learning is based on the smoothness assumption, i.e., data points close to each other in the image space are likely to be close in the label space .",
9528.txt,"Specifically, these methods focus on improving the target quality using self-ensembling and exploring different perturbations, which include the input noise and the network dropout.",
9529.txt,The network with the regularization loss encourages the predictions to be consistent and is expected to give better predictions.,
9530.txt,"In this article, we share the same spirit as these methods by designing different perturbations for the input data.",
9531.txt,"Specifically, we design the regularization term as a consistency loss to encourage smooth predictions for the same data under different regularization and perturbations.",
9532.txt,"In the earlier, we evaluate the model twice to get two predictions under different perturbations.",
9533.txt,"In this case, the Fig.",
9534.txt,3,
9535.txt,Segmentation is desired to be rotation equivariant.,
9536.txt,"If the input image is rotated, the ground-truth mask should be rotated in the same manner.",
9537.txt,Convolutions are not rotation equivariant in general.,
9538.txt,"If the input image is rotated, the generated output is not the same with the original output that rotated in the same manner.",
9539.txt,model assumes a dual role as a teacher and as a student.,
9540.txt,"As a student, it learns as before, while, as a teacher, it generates targets, which are then used by itself as a student for learning.",
9541.txt,"The model generates the targets by itself, and thus, it may be incorrect, especially when excessive weight is given to the generated targets.",
9542.txt,"If  is large, the teacher model relies more on the previous teacher model in the last step; otherwise, the teacher model relies more on the current student model parameters.",
9543.txt,"According to the empirical evidence in X, setting  = 0 makes the model as a variation of the  model, and the performance is the best when setting  = 0.999.",
9544.txt,"Transformation Consistent Self-Ensembling Model Next, we introduce how we design the randomized data transformation regularization for segmentation.",
9545.txt,"In general self-ensembling semisupervised learning, most regularization and perturbations can be easily designed for the classification problem.",
9546.txt,"However, in the medical image domain, accurate segmentation of important structures or lesions is a very challenging problem, and the perturbations for segmentation tasks are more worthy of exploring.",
9547.txt,One prominent difference between these two common tasks is that the classification problem is transformation invariant while the segmentation task is expected to be transformation equivariant.,
9548.txt,"Specifically, for image classification, the CNN only recognizes the presence or absence of an object in the whole image.",
9549.txt,"In other words, the classification result should remain the same, no matter what the data transformation are applied to Authorized licensed use limited to: University of Exeter.",
9550.txt,"While in the image segmentation task, if the input image is rotated, the segmentation mask is expected to have the same rotation with the original mask, although the corresponding pixelwise predictions are the same.",
9551.txt,"However, in general, convolutions are not transformation equivariant,1 meaning that if one rotates or flips the CNN input, then the feature maps do not necessarily rotate in a meaningful manner, as shown in Fig.",
9552.txt,3.This phenomenon limits the unsupervised regularization effect of randomized data transformation for segmentation .,
9553.txt,"To enhance the regularization and more effectively utilize unlabeled data in our segmentation task, we introduce a transformation-consistent scheme in the unsupervised regularization term.",
9554.txt,"Specifically, this transformation-consistent scheme is embedded in the framework by approximating  to  at the input and output space.",
9555.txt,Fig.,
9556.txt,"2 shows the detailed illustration of the framework, and Algorithm 1 shows the pseudocode.",
9557.txt,"Under the transformation-consistent scheme and other different perturbations, each input xi is fed into the network for twice evaluation to acquire two outputs ziand  zi.",
9558.txt,"More specifically, the transformation-consistent scheme consists of triple ioperations; see Fig.",
9559.txt,2,
9560.txt,"For one training input xi, in the first evaluation, the operation iis applied to the input image, while in the second evaluation, the operation iis applied to the prediction map.",
9561.txt,Random perturbations are applied in the network during the twice evaluations.,
9562.txt,"By minimizing the difference between ziand  ziwith a mean square error loss, the network is regularized to be transformation-consistent and thus increase the network generalization capacity.",
9563.txt,"Finally, the network is trained by minimizing a weighted combination of unsupervised regularization loss and supervised cross-entropy loss.",
9564.txt,"In this way, the network is able to learn accurate information from the labeled data.",
9565.txt,"As the training progresses, the network gets a reliable model and can generate output for the unlabeled data.To enlarge the regularization effect for semisupervised learning, we extend the TCSM to a more generalized form, including random scaling.",
9566.txt,The main goal is to keep the consistency of the teacher and student model after multiscale inference.,
9567.txt,"Specifically, ioperation includes not only rotation but also random scaling operation.",
9568.txt,"For the student model, we give the input and generate the prediction zi.",
9569.txt,"For the teacher model, we randomly scale the input image and generate the prediction result, which is then rescaled to the original size of the input Authorized licensed use limited to: University of Exeter.",
9570.txt,"During each training pass, one rotation operation and one scaling operation within the scaling ratio of 0.8?.2 is randomly chosen and applied to the input image.",
9571.txt,"To keep two terms in the loss function, we evenly and randomly select the labeled and the unlabeled samples in each minibatch.",
9572.txt,Note that we employed the same data augmentation in the training procedure of all the experiments for a fair comparison.,
9573.txt,"However, our method is different from traditional data augmentation.",
9574.txt,"Specifically, our method utilized the unlabeled data by minimizing the network output difference under the transformed inputs, while complying with the smoothness assumption.",
9575.txt,"Technical Details of TCSM_v2 For dermoscopy images and retinal fundus images, we employ the 2-D DenseUNet architecture as both our teacher and student models.",
9576.txt,"Compared with the standard DenseNet , we add the decoder part for the segmentation tasks.",
9577.txt,"The decoder has four blocks, and each block consists of ""upsampling, convolutional, batch normalization, and ReLU activation"" layers.",
9578.txt,The UNet-like skip connection is added between the final convolution layer of each dense block in the encoder part and the convolution layer in the decoder part.,
9579.txt,The final prediction layer is a convolutional layer with a channel number of two.,
9580.txt,"Before the final convolution layer, we add a dropout layer with a drop rate of 0.3.",
9581.txt,The network was trained with Adam algorithm  with a learning rate of 0.0001.,
9582.txt,All the experiments are trained for a total of 8000 iterations.,
9583.txt,We also visualize the network structure diagram to show the implementation of TCSM in Fig.,
9584.txt,"4.For training with 3-D U-Net, we follow the original setting with the following modifications.",
9585.txt,We modify the base filter parameters to 32 to accommodate this input size.,
9586.txt,The optimizer is stochastic gradient descent with a learning rate of 0.01.,
9587.txt,"The batch normalization layer is employed to facilitate the training process, and the loss function is modified to the standard weighted cross-entropy loss.",
9588.txt,All the experiments are trained for a total of 9000 iterations.,
9589.txt,We implemented the model using PyTorch .,
9590.txt,The experiments differ slightly from that in X due to the different implementation platforms.,
9591.txt,"We used the standard data augmentation techniques on-the-fly to avoid overfitting, including randomly flipping, rotating, and scaling with a random scale factor from 0.9 to 1.1.",
9592.txt,Note that all the experiments employed data augmentation for a fair comparison.,
9593.txt,"In the inference phase, we remove the transformation operations in the network and do one single test with the original input for a fair comparison.",
9594.txt,"After getting the probability map from the network, we first apply thresholding with 0.5 to generate the binary segmentation result, and then use morphology operation, filling holes, to obtain the final segmentation result.",
9595.txt,IV .,
9596.txt,EXPERIMENTS A.,
9597.txt,"Data Sets To evaluate our method, we conduct experiments on various modalities of medical images, including dermoscopy images, retinal fundus images, and liver CT scans.",
9598.txt,Dermoscopy Image Data Set: The dermoscopy image data set in our experiments is the 2017 ISIC skin lesion segmentation challenge data set .,
9599.txt,"It includes a training set with 2000 annotated dermoscopic images, a validation set with 150 images, and a testing set with 600 images.",
9600.txt,The image size ranges from 540  722 to 4499  6748.,
9601.txt,"To balance the segmentation performance and computational cost, we first resize all the images to 248248 using bicubic interpolation.Experiments were conducted on the released training data set, which contains 400 retinal images.",
9602.txt,"The training data set is randomly split to training and test sets, and we resize all the images to 248 248 using bicubic interpolation.",
9603.txt,Liver Segmentation Data Set: The liver segmentation data set are from the 2017 Liver Tumor Segmentation Challenge .,
9604.txt,"The LiTS data set contains 131 and 70 contrast-enhanced 3-D abdominal CT scans for training and testing, respectively.",
9605.txt,The data set was acquired by different scanners and protocols at six different clinical sites.,
9606.txt,"The blue and red contours denote the ground truth and our segmentation result, respectively.",
9607.txt,"where TP , TN, FP , and FN refer to the number of true positives, true negatives, false positives, and false negatives, respectively.",
9608.txt,"For the retinal fundus image data set, we use JA to measure the OD segmentation accuracy.",
9609.txt,Experiments on Dermoscopy Image Data Set  Quantitative and Visual Results With 50 Labeled Data: We report the performance of our method trained with only 50 labeled images and 1950 unlabeled images.,
9610.txt,Note that the labeled image is randomly selected from the whole data set.,
9611.txt,"Table I shows the experiments with the supervised method, supervised with regularization, and our semisupervised method on the validation data set.",
9612.txt,We use the same network architecture  in all these experiments for a fair comparison.,
9613.txt,The supervised experiment is optimized by the standard cross-entropy loss on the 50 labeled images.,
9614.txt,"The supervised with regularization experiment is also trained with 50 labeled images, but differently, the total loss function is a weighted combination of the cross-entropy loss and the regularization loss, which is the same with our loss function.",
9615.txt,"From Table I, it is observed that our semisupervised method achieves higher performance than a supervised counterpart on all the evaluation metrics, with prominent improvements of 4.07% on JA and 3.47% on DI, respectively.",
9616.txt,It is worth mentioning that supervised with regularization experiment improves the supervised training due to the regularization loss on the labeled images; see "Supervised+regu" in Table I.,
9617.txt,The consistent improvements of "Supervised+regu" on all evaluation metrics demonstrate the regularization loss is also effective for the labeled images.,
9618.txt,Fig.,
9619.txt,5 presents some segmentation results  of supervised method and our method .,
9620.txt,"Comparing with the segmentation contour achieved by the supervised method , the semisupervised method fits more consistently with the ground-truth boundary.",
9621.txt,"The observation shows the effectiveness of our semisupervised learning method, compared with the supervised method.",
9622.txt,"To show the effectiveness of our proposed transformation-consistent method, we conducted an ablation analysis of our method on the dermoscopy image data set, as the results are shown in Table II.",
9623.txt,"The experiments were performed with randomly selected 50 labeled data and 1950 unlabeled data, and tested on the validation set.",
9624.txt,"In the ""Supervised"" setting, we trained the network with only 50 labeled data.",
9625.txt,"""TCSM-ND"" refers to semisupervised learning with Gaussian noise and dropout regularization.",
9626.txt,"""TCSM-R"" refers to semisupervised learning with transformation-consistent regularization, and ""TCSM"" refers to the experiment with all of these regularizations.",
9627.txt,"As shown in Table II, both kinds of regularizations independently contribute to the performance gains of semisupervised learning.",
9628.txt,"The resulting improvement with transformation-consistent regularization is very competitive, compared with the performance increment with Gaussian noise and dropout regularizations.",
9629.txt,"These two regularizations are complementary, and therefore, when they are employed together, the performance can be further enhanced.",
9630.txt,Authorized licensed use limited to: University of Exeter.,
9631.txt,"From the experiments in Table II, we can see that random scaling with ratio 0.1 could improve the semisupervised learning results, while other transformation settings have limited improvements.",
9632.txt,"""TCSM_v2-NDR"" denotes the mean teacher-based semisupervised learning with transformation-consistent strategy.",
9633.txt,"""TCSM_v2NDRScale"" refers to the mean teacher based semisupervised learning with our transformation-consistent strategy, including both rotation and scaling.",
9634.txt,"From these two comparisons, we can see that the generalized form of transformation-consistent strategy improves the semisupervised learning.",
9635.txt,"""TCSM"" and ""TCSM_v2-NDR"" utilizes the same regularization.",
9636.txt,"From these two comparisons, we can find that the weight-averaged consistency targets improve the semisupervised deep learning results.",
9637.txt,"Our final model achieves 75.24% JA and 83.44% DI, surpassing the supervised baseline by 5.7% JA and 4.4% DI.",
9638.txt,Results Under Different Number of Labeled Data: Table III shows the lesion segmentation results of our TCSM and TCSM_v2 and supervised method under a different number of labeled/unlabeled images.,
9639.txt,We draw the JA score of the results in Fig.,
9640.txt,6,
9641.txt,"It is observed that the semisupervised methods consistently performs better than the supervised method in different labeled/unlabeled data settings, demonstrating that our method effectively utilizes the unlabeled data and brings performance gains.",
9642.txt,"Note that in all semisupervised learning experiments, we train the network with 2000 images in total, including labeled images and unlabeled images.",
9643.txt,"As expected, the performance of supervised Fig.",
9644.txt,6,
9645.txt,Results on the validation set of the dermoscopy image data set with different number of labeled/unlabeled data.,
9646.txt,training increases when more labeled training images are available; see the blue line in Fig.,
9647.txt,6,
9648.txt,"At the same time, the segmentation performance of semisupervised learning can also increase with more labeled training images; see the orange line in Fig.",
9649.txt,6,
9650.txt,"The performance gap between supervised training and semisupervised learning narrows as more labeled samples are available, which conforms to our expectations.",
9651.txt,"When the amount of labeled data set is small, our method can gain a large improvement, since the regularization loss can effectively leverage more information from the unlabeled data.",
9652.txt,"Comparatively, as the number of labeled data increases, the improvement becomes limited.",
9653.txt,"This is because the labeled and unlabeled data are randomly selected from the same data set, and a large amount of labeled data may reach the upper bound performance of the data set.",
9654.txt,"From the comparison between TCSM and TCSM_v2, we can see that TCSM_v2 consistently improve TCSM under different label and unlabeled settings.",
9655.txt,From the comparison between the semisupervised method and supervised method trained with 2000 labeled images in Fig.,
9656.txt,"6, it can be observed that our method increases the JA performance when all labels are used.",
9657.txt,The improvement indicates that the unsupervised loss can also provide regularization to the labeled data.,
9658.txt,"In other words, the consistency requirement in the regularization term can encourage the network to learn more robust features to improve the segmentation performance.",
9659.txt,Comparison With Other Semisupervised Segmentation Methods: We compare our method with two latest semisupervised segmentation methods in the medical imaging community and an adversarial learning-based semisupervised method .,
9660.txt,"In addition, we extend the semisupervised classification model to segmentation for comparison.",
9661.txt,Note that the method for medical image segmentation adopts a similar idea with the adversarial learning-based method .,
9662.txt,"For a fair comparison, we re-implemented their methods with the same network backbone on this data set.",
9663.txt,All the experiments utilized the same data augmentation and training strategies.,
9664.txt,We conducted experiments with the setting of 50 labeled images and 1950 unlabeled images.,
9665.txt,Table IV shows the JA performance of different methods on the validation set.,
9666.txt,"As shown in Table IV, our method achieves 4.07% JA improvement by utilizing unlabeled data.",
9667.txt,"Compared with other methods, we achieve the greatest improvement over the supervised baseline.",
9668.txt,"The comparison shows the effectiveness of our semisupervised segmentation method, compared with other semisupervised methods.",
9669.txt,Authorized licensed use limited to: University of Exeter.,
9670.txt,Comparison With Methods on the Challenge Leaderboard: We also compare our method with state-of-the-art methods submitted to the ISIC 2017 skin lesion segmentation challenge .,
9671.txt,"There are a total of 21 submissions, and the top results are listed in Table V. Note that the final rank is determined according to JA on the testing set.",
9672.txt,We trained two models: TCSM_v2 and baseline.,
9673.txt,"TCSM_v2 was trained with 300 labeled images, and the left are utilized as the unlabeled images.",
9674.txt,The baseline model is trained with only 300 labeled data.,
9675.txt,Other methods use all labeled data as the training data.,
9676.txt,The supervised model is denoted as our baseline model.,
9677.txt,"As shown in Table V, our semisupervised method achieved the best performance on the benchmark, outperforming the state-of-the-art method  with 1.6% improvement on JA .",
9678.txt,"The performance gains on DI and SE are consistent with that on JA, with 1.1% and 3.7% improvement, respectively.",
9679.txt,Our baseline model with 300 labeled data also outperforms other methods due to state-of-the-art network architecture.,
9680.txt,"Based on this strong baseline, our semisupervised learning method further makes significant improvements, which demonstrates the effectiveness of the overall semisupervised learning method.",
9681.txt,D. Experiments on Retinal Fundus Image Data Set We report the performance of our method for OD segmentation from retinal fundus images.,
9682.txt,The 400 training images from the REFUGE challenge  were randomly separated into training and test data set with the ratio of 9:1.,
9683.txt,"For a semisupervised training model, only a portion of labels in the training set were used.",
9684.txt,Examples of our semisupervised segmentation results for the fundus image and liver CT scans.,
9685.txt,Blue color denotes the segmented boundary of OD and red color represents the segmented liver.,
9686.txt,"model, the loss function was the traditional cross-entropy loss, and we used the SGD algorithm with learning rate 0.01 and momentum 0.9.",
9687.txt,"To train the semisupervised model, we added the extra unsupervised regularization loss, and the learning rate was changed to 0.001.",
9688.txt,"We report JA of the supervised and semisupervised results under the setting of 10% labeled training images, and 20% labeled training images, respectively.",
9689.txt,"As shown in Table VI, we also compare with the other semisupervised methods.",
9690.txt,"It can be observed that our method achieves 1.82% improvement under the 10% labeled training set, which ranked top among all these methods.",
9691.txt,"In addition, the improvement achieved by our method under the 20% training setting is also the highest.",
9692.txt,Fig.,
9693.txt,7 shows some visual segmentation results of our semisupervised method.,
9694.txt,We can see that our method can better capture the boundary of the OD structure.,
9695.txt,"E. Experiments on LiTS Data Set For this data set, we evaluate the performance of liver segmentation from CT volumes.",
9696.txt,"According to the evaluation of the 2017 LiTS challenge, we employed Dice per case score to evaluate the liver segmentation result, which refers to an average Dice score per volume.",
9697.txt,"We report the performance of our method and the other three semisupervised methods under the settings of 10% labeled training images and 20% labeled training images, respectively, in Table VII.",
9698.txt,"We can see that our approach achieves the highest performance improvement in both the 10% and 20% labeled training settings, with 5.33% and 5.72% improvements, respectively.",
9699.txt,"In semisupervised learning, it is obvious that our method gains higher performance consistently than other methods in both 10% and 20% settings, respectively.",
9700.txt,We also visualize some liver segmentation results from CT scans in the second row of Fig.,
9701.txt,7,
9702.txt,Supervised deep learning has been proven extremely effective for many problems in the medical image community.,
9703.txt,"However, promising performance heavily relies on the number of annotations.",
9704.txt,Developing new methods with limited annotation will largely advance real-world clinical applications.,
9705.txt,"I n this article, we focus on developing semisupervised learning methods for medical image segmentation, which have great potential to reduce the annotation effort by taking advantage of numerous unlabeled data.",
9706.txt,The key insight of our semisupervised learning method is the transformation-consistent selfensembling strategy.,
9707.txt,Extensive experiments on three representative and challenging data sets demonstrated the effectiveness of our method.,
9708.txt,Medical image data have different formats and 3-D volumetric data .,
9709.txt,"In this article, we use both 2-D and 3-D networks for segmentation.",
9710.txt,Our method is flexible and can be easily applied to both 2-D and 3-D networks.,
9711.txt,"It is worth noting that recent works  are specifically designed for 3-D volume data by considering three-view co-training, i.e., the coronal, sagittal, and axial views of the volume data.",
9712.txt,"However, we aim for a more general approachthat is applicable to 2-D and 3-D medical images.",
9713.txt,"For 3-D semisupervised learning, it could be a promising direction to design specific methods by considering the 3-D natural property of the volumetric data.",
9714.txt,Recent works on network equivariance improve the generalization capacity of trained networks by exploring the equivariance property.,
9715.txt,Cohen and Welling  presented a group equivariant neural network.,
9716.txt,"Our method also leverages the transformation consistency principle, but differently, we aim for semisupervised segmentation.",
9717.txt,"Moreover, if we trained these works, harmonic network, in a semisupervised way to leverage unlabeled data, the transformation regularization will have no effect ideally, since the network outputs are the same when applying the transformation to the input images.",
9718.txt,"Hence, the limited regularization would restrict the performance improvement from unlabeled data.",
9719.txt,One limitation of our method is that we assume both labeled and unlabeled data come from the same distribution.,
9720.txt,"However, in clinical applications, labeled and unlabeled data may have different distributions with a domain shift.",
9721.txt,Oliver  demonstrated that the performance of semisupervised learning methods could degrade substantially when the unlabeled data set contains out-of-distribution samples.,
9722.txt,"However, most of the current semisupervised approaches for medical image segmentation do not consider this issue.",
9723.txt,"Therefore, in the future, we would explore domain adaptation  and investigate how to adapt it with a self-ensembling strategy.",
9724.txt,"In this article, the selection of transformation is based on the property of neural networks.",
9725.txt,The convolution layer is not rotation equivariant.,
9726.txt,"To tackle the segmentation task, we need to train the network to be rotation equivariant.",
9727.txt,"Moreover, the neural network is not scale equivariant due to padding, upsampling, and so on.",
9728.txt,The rotation and scaling transformations are the general transformations used in medical images.,
9729.txt,"Thus, learning to minimize the output differences caused by these transformations will regularize the network to be transformation-consistent.",
9730.txt,"Our method is flexible to extend to more general transformation cases, such as affine transformations.",
9731.txt,"The transformation-consistent module consists of a transformation on the input image that will be fed to the teacher model, and the same transformation on the output space generated by the student model.",
9732.txt,It is flexible without additional training costs to be applied to the neural network.,
9733.txt,"Moreover, recent automatic augmentation search works explored the best transformations for a specific data set.",
9734.txt,It is an interesting future work to explore more useful transformations for our semisupervised segmentation framework through automatic data augmentation.,
9735.txt,"In addition, the experiments reported are the averaged result over three trials, which also indicate the robustness of our method.",
9736.txt,This article presents a novel and effective transformationconsistent self-ensembling semisupervised method for medical image segmentation.,
9737.txt,The whole framework is trained with a teacher-student scheme and optimized by a weighted combination of supervised and unsupervised losses.,
9738.txt,"To achieve this, we introduce a TCSM for the segmentation task, enhancing the regularization and can be easily applied on 2-D and 3-D networks.",
9739.txt,"Comprehensive experimental analysis on three medical imaging data sets, skin lesion, retinal image, and liver CT data sets, demonstrated the effectiveness of our method.",
9740.txt,Our method is general and can be widely used in other semisupervised medical imaging problems.,
9741.txt,Anomalies usually refer to targets with a spot of pixels  that stand out from their neighboring background clutter pixels in hyperspectral imagery.,
9742.txt,"Compared to backgrounds, anomalies have two main characteristics.",
9743.txt,"One is the spectral anomaly, their spectral signatures are different from those associated to their surrounding backgrounds; another is the spatial anomaly, anomalies occur as few pixels embedded in the local homogeneous backgrounds.",
9744.txt,"However, most of the existing anomaly detection algorithms for HSI only employed the spectral anomaly.",
9745.txt,"If the two characteristics are exploited in a detection method simultaneously, better performance may be achieved.",
9746.txt,"The third-order tensor representation of HSI has been proved to be an effective tool to describe the spatial and spectral information equivalently; therefore, tensor representation is convenient for exhibiting the two characteristics of anomalies simultaneously.",
9747.txt,"In this paper , a new anomaly detection method based on tensor decomposition is proposed and divided into three steps.",
9748.txt,"Three factor matrices and a core tensor are first estimated from the third-order tensor that is constructed from the HSI data cube by using the Tucker decomposition, and their major and minor principal components are more likely to correspond to the spectral signatures of the backgrounds and the anomalies, respectively.",
9749.txt,"In the second step, a reconstruction-error-based method is presented to find the first largest PCs along each mode to eliminate the spectral signatures of the backgrounds as much as possible, and thus, the remaining data may be modeled as the spectral signaturesof theanomalies witha Gaussian noise.",
9750.txt,"Finally, a CFAR test is implemented to detect the anomalies from the remaining data.",
9751.txt,"Experiments with simulated, synthetic, and real HSI data sets reveal that the proposed method outperforms those spectral-anomaly-based methods with better detection probability and less false alarm rate.",
9752.txt,"Index TermsAnomaly detection, hyperspectral imagery , tensor representation, Tucker decomposition.",
9753.txt,"Combining imaging technology and high spectral resolution spectroscopy in a unique system, the hyperspectral sensor provides a powerful means to discriminate the targets of interest in a scene.",
9754.txt,"In most practical situations, it is difficult to specify the prior spectrum of the interested target in advance.",
9755.txt,"Anomalies usually refer to targets with a spot of pixels that stand out from the cluttered backgrounds in hyperspectral imagery, and they have two main characteristics.",
9756.txt,"The first one is the spectral anomaly, the spectra of anomalies are distinct from those of their surrounding backgrounds.",
9757.txt,"The second one is the spatial anomaly, i.e., anomalies occur as few pixels  embedded in the local homogeneous backgrounds.",
9758.txt,Various anomaly detection algorithms have been developed by exploiting the two aforementioned characteristics.,
9759.txt,"According to our comprehension, most of the current anomaly detection algorithms place emphasis on the spectral-anomaly characteristic, and they can be classified into two broad categories, i.e., statistical modeling and geometrical modeling techniques.",
9760.txt,Statistical modeling techniques commonly assume that the backgrounds follow a specified statistical distribution while anomalies are far away from such distribution.,
9761.txt,"Among the works that belong to this category, the ReedXiaoli detector is probably the most popular.",
9762.txt,"In this method, the multivariate Gaussian model is assumed to characterize the background information.",
9763.txt,"After estimating the mean vector and covariancematrixbythesamplesselectedfromthewholescene , the Mahalanobis distance between each test pixel and the statistical model is calculated and compared with a threshold for the final discrimination.",
9764.txt,RXD is mathematically tractable and of high computation efficiency.,
9765.txt,"Despite the popularity, there are two main problems with RXD.",
9766.txt,"The first problem is that the unimodal Gaussian model cannot always providean adequatecharacterizationfor the backgrounds, particularly when there are multiple materials.",
9767.txt,This problem may lead to many false alarms in practice.,
9768.txt,Various efforts have been made to address such problem.,
9769.txt,"Some approachesare still based on the Gaussian model, but they are designed for making the model more effective.",
9770.txt,"An example is the clusterbased anomaly detection method, which segments the scene into different spectrally homogeneous clusters and then detects anomalies in individualclusters .",
9771.txt,"Anotherexampleis the method based on the Gaussian-mixture model, combining a set of unimodalGaussian distributions to characterizethe backgrounds.",
9772.txt,It providesmore accurate descriptions of complex backgrounds by accounting for the presence of multiple materials.,
9773.txt,"Some other methods are based on the non-Gaussian model for a better characterization of the backgrounds in real HSI data, such as the anomaly detection algorithm based on elliptically contoured distribution.",
9774.txt,Example for illustrating the different results of spectral-based and spectralspatial-based anomaly detection methods.,
9775.txt,"of authors have observed that the data can be more Gaussian in some directions than in others, so a hybrid Gaussian/ non-Gaussian algorithm was proposed in X.",
9776.txt,This method can explicitly produce a probability density that is a product of the multivariate Gaussian density in the Gaussian directions and a more tailored distribution in the non-Gaussian directions.,
9777.txt,"The second problem is that the background samples often contain also anomalous pixels and noise, which causes that the parameters of the statistical model cannot be estimated accurately, resulting in a poor detection performance.",
9778.txt,"Geometrical modeling techniques are based on the key assumption that backgroundpixels can be approximatelyrepresented by a group of the major spectra/bases, while anomalies cannot.",
9779.txt,Those spectra/bases are collected/extracted from the whole image.,
9780.txt,This type of method avoids assuming any specific statistical model for the backgrounds.,
9781.txt,"As for this category, the subspace-based anomaly detection method is the most typical .",
9782.txt,"This method assumes that the background is well modeled as lying in a low-dimensional subspace that is constructed by a set of bases, which are commonly derived from background endmembers  extracted from the data or eigenvectors acquired by a linear transformation .",
9783.txt,"Then, every pixel is projected to the background orthogonal subspace, and the residual is calculated for discriminating whether the current pixel is an anomaly.",
9784.txt,"The larger the residual is, the more anomalous the pixel may be.",
9785.txt,Some other methods use the original spectra of the whole scene and a local window to represent each pixel.,
9786.txt,The pixel with a large reconstruction residual is more probable to be an anomaly.,
9787.txt,The sparse-representation-based detector and collaborative-representation-baseddetector belong to this category.,
9788.txt,"However, both of the two aforementioned techniques only deal with vector features as inputs, known as the vector-based anomaly detection method.",
9789.txt,"In other words, they just process each pixel as a spectral vector independently, without considering the spatial relationship between different pixels.",
9790.txt,"In those techniques,only the spectral-anomalycharacteristic of an anomaly is exploited.",
9791.txt,"Some researchers suggest that considering the neighboring pixels can employ the spatial information, such as the local RX, dual-window-basedeigen separation transform , and multiple-window anomaly detection.",
9792.txt,"Nevertheless, these methods just analyze the spectral difference in a relatively smaller region; neither the spatial constraints between each pixel in the current local window nor the spatial relationship between different local windows is taken into consideration.",
9793.txt,"As a result, the spectral information is much superior to the spatial information in those methods.",
9794.txt,"The spatial anomaly is equivalently important as the spectral anomaly, which means that an anomaly is not only spectrally distinct from the spectral-homogeneous backgrounds but also spatiallyisolatedinanagglomerationofbackgrounds.Itis clear that, if the two characteristics are exploited in an anomaly detection methodsimultaneously,then better performancemay be achieved.",
9795.txt,"To the best of our knowledge, there is still no method that describes spectral anomaly equivalently with regard to the spatial anomaly in an anomaly detection algorithm.",
9796.txt,Anexampleofthedifferentresultsofspectral-basedanomaly detectorandspectralspatial-basedanomalydetectoris givenin Fig.,
9797.txt,"1, in which an HSI data cube collected over an urban area  is modified by randomly permuting the spatial coordinates (i, j) of the pixel vectors, thus removing the spatial correlation.",
9798.txt,"In this paper, we propose a method for spectralspatial anomaly detection in a novel point of view, which is based on tensor decomposition.",
9799.txt,The proposed algorithm contains three main steps.,
9800.txt,"First, we employ a three-order tensor to represent the observed HSI data cube and introduce the Tucker decomposition technology to decompose such tensor into a core tensor and three factor matrices.",
9801.txt,"Thus, the major and minor principal components of the three factor matrices are likely to correspondto the backgroundandtheanomalyinformation,respectively.Second, a reconstruction-error-based method is present to find the first largest PCs along each mode to eliminate the background information as much as possible, and thus, the remaining data may be modeled as the anomaly with a Gaussian noise.",
9802.txt,"Finally, a CFAR test is implemented to detect the anomalies from the remaining data.",
9803.txt,The remainder of this paper is arranged as follows.,
9804.txt,"In Section II, we give a brief description of the relevant tensor algebra and then present the proposed anomaly detection algorithm based on the Tucker decomposition in detail.",
9805.txt,"After that, the experimentalresults are reported in Section III, followed by the conclusion.In this section, we first give a brief review of the relevant concepts for tensor algebra that will be used in the proposed algorithm.",
9806.txt,"By employing the tensor representation and decomposition technologies, the proposed algorithm is divided into three main steps, as shown in Fig.",
9807.txt,2,
9808.txt,"If the HSI data cube is considered independent along each mode, we can get the fiber analogs of such data .",
9809.txt,"It is noteworthy that, for a routine spectral-based anomaly detection technique, the HSI data are processed as the spectral vector form.",
9810.txt,"In other words, each spectrum is treated independently, without considering the spatial constraints.",
9811.txt,"Then, the Tucker decomposition is applied onto the tensor X; The basic idea of this solution comes from the fact that any one of the factor matrices could be simply acquired by an eigenvalue decomposition problem when the remaining two matrices are fixed.",
9812.txt,"However, in this paper, our aim is to extract the anomaly signals from the data, and the anomaly signals may quite possibly exist in the insignificant part.",
9813.txt,"Therewith, all the three factor matrices A, B, and C are square, and the size of the core tensor is the same with the input tensor.",
9814.txt,"In fact, the Tucker decomposition is a form of higher order PCA; as a result, the column eigenvectors of each factor matrix are ordered by decreasing magnitude of the respective eigenvalues.",
9815.txt,"If each eigenvector is interpreted as a piece of information, the larger the eigenvalue is, the more significant theinformation that it represents.",
9816.txt,"Generally, in an HSI, backgrounds turn up with high probabilities as the major information, while anomalies occur with low probabilities as minor information.",
9817.txt,"Under this circumstance, the first largest eigenvectors of each factor matrix represent the components that address the background informationalongeachmode,while theanomalies areprobably to lie in the remaining eigenvectors.",
9818.txt,"Here, we give an example for illustrating the spatial-anomaly characteristic captured by the tensor representationtechnique.In Fig.",
9819.txt,"5, there is an HSI data cube with a spatial size of 1111.",
9820.txt,The main background pixels are colored red.,
9821.txt,"Another 3  3 sized background colored blue is in the center, and an anomaly pixel locating at pixel(10, 10) is colored yellow.",
9822.txt,"According to the one-mode fiber analog of the tensor, the more image height vectors an object contains, the more column information it owns.",
9823.txt,"Consequently, the corresponding eigenvector of such object is likely to be more former in A, while on the opposite side, the eigenvectorof the object that contains less image height vectors maybe rankedlatter.",
9824.txt,"Analogically,it is the same with theimage width mode.",
9825.txt,An anomalous target may be neither wider nor longer than the backgrounds.,
9826.txt,"Therefore, the eigenvectors of anomalous targets are ranked latter in the factor matrices.",
9827.txt,"Example for illustrating the spatial-anomaly characteristic captured by the tensor representation technique.In fact, the same vectors may be represented by one eigenvector.",
9828.txt,"Therefore, three eigenvectors are needed to represent the data in Fig.",
9829.txt,5,
9830.txt,It can be seen that the eigenvectors corresponding to the background are ranked more former than the anomalies.,
9831.txt,B.,
9832.txt,"Using the Major PCs to Eliminate Background Information To detect anomalies effectively, one of the key challenges is to eliminate the background that presents as interfering signatures.",
9833.txt,"Consequently, this branch of approaches only eliminates the backgrounds in the spectral domain.",
9834.txt,"Among those kinds of anomaly detectors, SSRX is the most popular one, which is a modification to the RXD.",
9835.txt,"In SSRX, several high-variance PCs are deleted before applying the RXD, as these PCs are assumed to capture nonnormal background clutter variance.",
9836.txt,"Unfortunately, there is no reliable method to select an optimal value for the parameter automatically so far.",
9837.txt,The energy-cumulative method is used most commonly.,
9838.txt,"It computes the sum of the eigenvalues from the first to the last one, until the cumulative energy achieves a specified ratio to the total energy.",
9839.txt,"In this method, the ratio is difficult to determine for differentHSI data sets, and it holds no physical meaning.",
9840.txt,"Under certain conditions, SSRX can provide better backgroundsuppression relative to the RXD if the anomaly content falls outside the leading PCs.",
9841.txt,"In contrast, the proposed TenB algorithm eliminates backgroundinformationalong the three modes simultaneously.That is to say, background information is assumed to be represented by both the major PCs in the spectral and spatial domains.",
9842.txt,"In a real-world situation, the background pixels belonging to the same kind may be likely to huddle together.",
9843.txt,"As a result, background information not only dominates in the spectral domain but also in the spatial domain.",
9844.txt,"Therefore, it can make sure that background information could be eliminated more exhaustively by this way.",
9845.txt,"Similar to SSRX, the PC numbersalso need to be determined in TenB.",
9846.txt,"In this paper, we employ a reconstruction-error-based method to deal with this problem, described as follows.It is assumed that each major PC may represent one or more kinds of background.",
9847.txt,"Therefore, whenleaps down, it indicates that a new major material appears in XBg; in the other side, when  decreases slowly, it indicates that some minor material is added to XBg.",
9848.txt,"Under these assumptions, the first point of slow change is used to determine K. This method owns better applicability than the traditional energy-cumulative method, and it can be interpreted in a physical way.",
9849.txt,There are three PC numbers needed to be determined in TenB.,
9850.txt,"Here, we give the process of determiningK1for example.",
9851.txt,"Third, the first eigenvector to the last eigenvector is selected one by one to reconstruct the background of X, denoted as X.",
9852.txt,It is worth noting that the size of every reconstructed tensor is equivalent to that of the input HSI data.,
9853.txt,"As a linear transformation, the Tucker decomposition satisfies the additional rule.",
9854.txt,"Hence, the sum of the eight subtensors is equal to the original tensor.",
9855.txt,We assume that the background information is composed of the significant part along every mode and the anomalies are contained in the remaining part.,
9856.txt,"Notably, the SSRX is a special version of TenB, when the TenB method just processes the data along the spectral mode, known as TenB3.",
9857.txt,"In other words, when the background information is estimated only by the major PCs of X(3), SSRX is equivalent to TenB3.",
9858.txt,This conclusion will be verified in the experimental reports.,
9859.txt,"CF AR Detector Is Implemented on the Data Reconstructed by the Remaining PCs When the number of major PCs is set properly, the background information can be well eliminated; then, the anomaly may possibly lie in the remaining data XAn.",
9860.txt,"Under this condition, a CFAR detection algorithm is expected to detect the anomalies because the CFAR detection algorithm considered in X is suitable for detecting a target pattern in one main image scene and a number of other noise-only reference image scenes that contain negligible signal energy.",
9861.txt,"In order to illustrate the superiority of TenB in background estimation and anomaly detection, a detailed analysis for a simulated HSI data set was given at first.Then,theexperimental analysis was done on both synthetic and real HSI data sets.",
9862.txt,The synthetic data were generated using a Hyperion data set covering an agricultural area.,
9863.txt,It was downloaded from the EO-1 satellite image website.,
9864.txt,"The original data set contains 242 bands covering the visible, near-infrared, and short-wave infrared bands with a spectral resolution of 10 nm.",
9865.txt,"After the removal of the low-SNR bands and the uncalibrated bands, 193 bands are used.",
9866.txt,The selected portion has pixels of 120  180 in size.,
9867.txt,"In this paper, we have decided to use a target implantation method to simulate a set of anomalous targets in the considered Hyperion data set.",
9868.txt,The advantage of using a target implantation method is that we can evaluate the performance of the detectors in a totally controlled environment .,
9869.txt,"The image portion where the targets have been implanted is denoted as ROI-1, which is an open vegetation region with dimensions 120  180  193 and contains a few anomalous pixels.",
9870.txt,Some backgroundbackground mixed pixels are present on the background boundary.,
9871.txt,The characteristic of the target is selected from the original image that is the most different from the main background endmembers.,
9872.txt,Fig.,
9873.txt,"7shows the locations of the implanted targets in ROI-1, and the details of the targets' shape are listed on the top.",
9874.txt,The percentage of target pixels in the entire image is approximately 0.3%.,
9875.txt,A Hyperspectral Digital Imagery Collection Experiment  hyperspectral data set is obtained from an aircraft platform.,
9876.txt,This data set covers an urban area and has a spectral resolution of 10 nm and a spatial resolution of 1 m. False color of the scene.,
9877.txt,True distribution of all the anomalous targets in ROI-3.,
9878.txt,"whole spectral range of 400?500 nm, but only 162 spectral bands are used after discarding the water absorption and lowSNR bands.",
9879.txt,"The false color image of the whole data set has a size of 307  307, as shown in Fig.",
9880.txt,8,
9881.txt,"However, the only definite ground truth is that, in the upper right of the scene, the anomalous targets are the vehicles embedded in the different backgrounds.",
9882.txt,"Therefore, we only use the subimage covering this area in our experiments.",
9883.txt,A scene of 79  100 pixels called ROI-2 and the anomalous targets' positions are shown in Fig.,
9884.txt,8,
9885.txt,"There are nine vehicles with 20 pixels in total, which are regarded as the anomalous targets in the scene.",
9886.txt,Real Data 2: This data set is also cut from the HYDICE data set.,
9887.txt,"The scene consists of 80  60 pixels  with 162 bands, denoted as ROI-3.",
9888.txt,"There are nine vehicles with 10 pixels in total, which are regarded as the anomalous targets in the scene .",
9889.txt,"Compared to ROI-2, ROI-3 is more complex with grass, tree, road, park, and buildings .",
9890.txt,"Furthermore, some of the anomalous targets are difficult to be detected, including the targets in the backgroundbackground mixing area, near the buildings, and even in the shadow of the buildings.",
9891.txt,B.,
9892.txt,Experimental Results and Analysis The RXD  and SSRX detectors are known to be the standard anomaly detectors that form the basis for comparing the performance of a new anomaly detector.,
9893.txt,"In our experiments, the SSRX algorithm is used for comparing with the TenB algorithm in background elimination.",
9894.txt,"Furthermore, we choose several other conventional anomaly detection methods for evaluation and comparison in the performance of anomaly detection, including CBAD , RNAD , CRD, and DWEST.",
9895.txt,"Since the images produced by the detection algorithms are generally grayscale, the target detection and discrimination are usually carried out by visual inspection.",
9896.txt,"In order to avoid such human interpretation and illustrate a more intuitionistic comparison, an adaptive thresholding method is designed to automatically select an appropriate threshold to segment targets from the image background.",
9897.txt,"This method is adaptive and only depends on the grayscale image resulting from anomaly detection, but not on the original image.",
9898.txt,"Generally,G is with the same spatial size of the processed data.",
9899.txt,Each pixel's value  in G indicates the detection energy of the corresponding pixel in the input data.,
9900.txt,"Every anomaly detector can gain a G. Then, we compute u and M from the individual G and construct the corresponding threshold .",
9901.txt,Detection performance is commonly measured in terms of receiver operating characteristic curves .,
9902.txt,"By taking a threshold, the detection result can be transformed to a binary image, where value 1 represents that targets are present in the pixel and value 0 represents that targets are absent.",
9903.txt,A superior detector would lie nearer the top left or a larger area under the curve.,
9904.txt,"Moreover, the AUC is computed to evaluate the detection performance for further validation.",
9905.txt,"As mentioned earlier in Section II-B, the relative reconstruction error  is considered as an important criterion for evaluating the performance of background estimation.",
9906.txt,Fig.,
9907.txt,"10 shows the different  with the number of the major PCs increasing, where TenB1, TenB2, and TenB3 denote the reconstruction background data XBg acquired along the three different modes, respectively.From Fig.",
9908.txt,"10, we can see that, as the number of the PCs increases,  decreases.",
9909.txt,This phenomenon illuminates that the information is preserved more completely in XBgwhen the PC number is larger.TenB method along the second mode.,
9910.txt,TenB method along the third mode and SSRX method.,
9911.txt,the image height mode is contained in the first two PCs.,
9912.txt,The same conclusioncould be drawn fromFig.,
9913.txt,10.Fig.,
9914.txt,10has verified the conclusion that SSRX is equivalent to TenB3 and the PC number can be determined as one.,
9915.txt,"Aside from the relative reconstruction error, the reconstructed spectral curves are also considered to evaluate the background estimation.",
9916.txt,The first row of Fig.,
9917.txt,"11 shows the results of the XBgreconstructed by one, two, and three PCs in SSRX.",
9918.txt,The remaining three rows of Fig.,
9919.txt,"11 are the results of the XBgreconstructed by the TenB algorithm, with the spectral PC number changed in each column and with the spatial PC number changed in each row.",
9920.txt,Fig.1 shows that SSRX-1 has only reconstructed one kind of curve that corresponds to the most important background .,
9921.txt,"In Fig.11, two kinds of curves have been reconstructed by SSRX-2, which are the spectral curves of B1 and B2.",
9922.txt,"Moreover, some information of T has also been reconstructed.",
9923.txt,"This is because T's spectrum is highly correlative with B2's spectrum, and the information of these two spectra may be contained in the same spectral PC.",
9924.txt,"This phenomenon reflects that only using spectral PCs cannot separate two kinds of spectra with high correlation, which is one of the main shortcomings of the spectral-based method.",
9925.txt,Fig.,
9926.txt,11 shows the well-reconstructed result of the three spectra by SSRX-3.,
9927.txt,"Fig.11 shows that the reconstructed curves do not change,althoughthe spectral PC number changed.",
9928.txt,This is because the PC numbers of two spatial modes are set to one.,
9929.txt,"In this case, only the most important material of X can be reconstructed in XBg.",
9930.txt,"As a result, the shape of the green curve is almost the same as that of the cyan curve, and the red and blue curves can be regarded as reconstruction error.",
9931.txt,In Fig.,
9932.txt,"11, although the spatial PC numbers are two, the spectral PC number is one.",
9933.txt,"Hence, still only one kind of curve is well reconstructed.",
9934.txt,"Analogously, Fig.",
9935.txt,"11 has also reconstructed one kind of curve  because the spectral PC number is one, too.",
9936.txt,"Due to that fact that the spatial PC numbers are set to two, Fig.",
9937.txt,11 shows that two kinds of curves are well reconstructed.,
9938.txt,Fig.11 shows that all the three kinds of materials are well reconstructed.,
9939.txt,"This is because the three PC numbers are all selected as three, which is accordant with the real material number of X.",
9940.txt,It is worth noting that Fig.11 shows the reconstructed spectra in the background component of the HSI data.,
9941.txt,From all the results recorded in Figs.,
9942.txt,"10 and 11, some conclusions may be drawn as follows: 1) The user-specified parameters are more convenient for determining bythereconstruction-error-basedmethodthanbythetraditional energy-cumulative method; 2) due to the background estimation being restricted by both the spectral and spatial PCs in the TenB algorithm, the TenB algorithm can separate the spectra with high correlation; and 3) the TenB algorithm is superior to the SSRX algorithm in backgroundestimation.",
9943.txt,"b) Anomaly detection: Since the anomalies will be detected in XAn, the characteristic of XAnshould be analyzed primarily.",
9944.txt,The anomaly is more prominent in the background when SINR is larger.,
9945.txt,The SINR results are reported in Table I.,
9946.txt,"Such conclusion could be further confirmed by the comparisons of the reconstructed curves of the three materials in XAn, w h i c h are shown in Fig.",
9947.txt,12,
9948.txt,It illustrates the differences between the three materials.,
9949.txt,"This phenomenon has proved that, when detecting the anomalies, the RXD and SSRX-1 methods only exploit the spectral anomaly but do not consider the spatial anomaly.",
9950.txt,"As mentioned earlier, an anomaly possesses spectral anomaly and spatial anomaly simultaneously.",
9951.txt,"Therefore, in this example, only T is considered as actual anomalous targets, but not B2, notwithstanding that the difference between the spectra of B2 and B1 is larger than that between the spectra of T and B1.",
9952.txt,B2 only owns spectral anomaly.,
9953.txt,"In fact, an anomaly may not contain such large number of pixels.",
9954.txt,"Therefore, B2 is more likely to be a kind of background than to be an anomaly.",
9955.txt,The detection results have shown the distinction between the spectral-based anomaly detection method and the spectralspatial anomaly detection method.,
9956.txt,This phenomenon indicates that those methods perform similarly when fewer anomalous targets are separated from the background.,
9957.txt,"Since the most separable anomalous targets are the ones with high abundance fraction, all of the methods are able to detect these ones easily.",
9958.txt,"With higher detection probability, which suggests that the more difficult anomalous targets are separated, the ROC curves appear different.",
9959.txt,"At this time, the false alarm rate can be used as an indicator for the separation ability of the different detection Fig.",
9960.txt,21,
9961.txt,ROC curves for Hyperion data set.,
9962.txt,methods.,
9963.txt,"TenB lies nearer the upper left in the axis space than the others, and it performs best at most ranges, which indicates that the method detects more difficult anomalous targets, with better separability from the backgrounds.",
9964.txt,"Therefore, the detection performance of TenB is much superior to that of the compared methods for the ROI-1 scene.",
9965.txt,"Such conclusion could be furtherverifiedby the AUC values, where TenB providesthe highest AUC value.",
9966.txt,According to Fig.,
9967.txt,"22, we determine the spectral PC number as two and both of the two spatial PC numbers as four.From Fig.",
9968.txt,"23, we can see clearly that little anomalous information is contained in XBg, while anomalies are salient in a single background in XAn.",
9969.txt,"Due to the complexityof the background, the anomalies may be enshrouded by background information.",
9970.txt,"As a result, detection on the original data may miss some anomalies.",
9971.txt,"On the other hand, after background elimination, this influence may be mitigated.",
9972.txt,"Consequently, the detection probability may be increased.",
9973.txt,This phenomenon proves that background elimination is propitious to anomaly detection.,
9974.txt,SSRX-2 onlyeliminates backgroundinformationin the spectral domain.,
9975.txt,"In this case, if the spectra of anomalous targets correlate with the backgroundspectra, some informationof anomaloustargets may be weakened when eliminating background.",
9976.txt,"As a result, the detection probability may be reduced.Therefore, backgroundandanomalycanbedistinguishedinthespectralspatial domain, and they can be separated effectively.",
9977.txt,"Furthermore, anomalies can be easily detected in the background-free data.",
9978.txt,We first analyze the relative reconstruction error for determining the PC number along different modes.,
9979.txt,As shown in Fig.,
9980.txt,"27, we determine the spectral PC number as two and both of the two spatial PC numbers as five.",
9981.txt,"Then, the detection performances of those methods are analyzed by the ROC curves reported in Fig.",
9982.txt,28 and the AUC values listed in the brackets.,
9983.txt,"This time, TenB is better at detecting the more difficult anomalous targets than its counterparts.",
9984.txt,The superior detection performance could be further confirmed by the AUC values.,
9985.txt,"Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models.",
9986.txt,This article provides a brief introduction to the field and a quick overview of deep learning architectures and methods.,
9987.txt,It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions.,
9988.txt,Analyzed research areas include several core linguistic processing issues in addition to many applications of computational linguistics.,
9989.txt,A discussion of the current state of the art is then provided along with recommendations for future research in the field.,
9990.txt,"Index Terms?Computational linguistics, deep learning, machine learning, natural language processing, neural networks.",
9991.txt,"The field of natural language processing encompasses a variety of topics, which involves the computational processing and understanding of human languages.",
9992.txt,"Since the 1980s, the field has increasingly relied on data-driven computation involving statistics, probability, and machine learning.",
9993.txt,"In addition, the contemporary availability of large data sets, facilitated by sophisticated data collection processes, enables the training of such deep architectures .",
9994.txt,"In recent years, researchers and practitioners in NLP have leveraged the power of modern ANNs with many propitious results, beginning in large part with the pioneering work of Collobert .",
9995.txt,"In the very recent past, the use of deep learning has considerably upsurged.",
9996.txt,This has led to significant advances both in core areas of NLP and in areas in which it is directly applied to achieve practical and useful objectives.,
9997.txt,"This article provides a brief introduction to both NLP and deep neural networks and then presents an extensive discussion on how deep learning is being used to solve current problems in NLP.Furthermore, no other survey has examined not only the applications of deep learning to computational linguistics but also the underlying theory and traditional NLP tasks.",
9998.txt,"In addition to the discussion of recent revolutionary developments in the field, this article will be useful to readers who want to familiarize themselves quickly with the current state of the art before embarking upon further advanced research and practice.",
9999.txt,"The topics of NLP and AI, including deep learning, are introduced in Section II.Applications of deep learning to more practical areas are discussed in Section IV.",
10000.txt,"Conclusions are then drawn in Section V with a brief summary of the state of the art as well as predictions, suggestions, and other thoughts on the future of this dynamically evolving area.",
10001.txt,"In this section, significant issues that draw the attention of researchers and practitioners are introduced, followed by a brisk explanation of the deep learning architectures commonly used in the field.",
10002.txt,A.,
10003.txt,"Natural Language Processing The field of NLP, also known as computational linguistics, involves the engineering of computational models and processes to solve practical problems in understanding human languages.",
10004.txt,These solutions are used to build useful software.,
10005.txt,"Work in NLP can be divided into two broad subareas: core areas and applications, although it is sometimes difficult to distinguish clearly to which areas issues belong.",
10006.txt,"Attention mechanisms, such as that present in X, allow the decoder to determine which portions of the encoding are most relevant at each output step.",
10007.txt,"semantic processing, which attempts to distill meaning of words, phrases, and higher level components in text.",
10008.txt,"The application areas involve topics, such as extraction of useful information , translation of text between and among languages, summarization of written works, automatic answering of questions by inferring answers, and classification and clustering of documents.",
10009.txt,"Often, one needs to handle one or more of the core issues successfully and apply those ideas and procedures to solve practical problems.",
10010.txt,"Currently, NLP is primarily a data-driven field using statistical and probabilistic computations along with machine learning.",
10011.txt,"In the past, machine learning approaches, such as nave Bayes, k-nearest neighbors, hidden Markov models, conditional random fields , decision trees, random forests, and support vector machines, were widely used.",
10012.txt,"However, during the past several years, there has been a wholesale transformation, and these approaches have been entirely replaced, or at least enhanced, by neural models, discussed next.",
10013.txt,"B. Neural Networks and Deep Learning Neural networks are composed of interconnected nodes, or neurons, each receiving some number of inputs and supplying an output.",
10014.txt,Each of the nodes in the output layers performs weighted sum computation on the values they receive from the input nodes and then generate outputs using simple nonlinear transformation functions on these summations.,
10015.txt,Corrections to the weights are made in response to individual errors or losses that the networks exhibit at the output nodes.,
10016.txt,"Such corrections are usually made in modern networks using stochastic gradient descent, considering the derivatives of errors at the nodes, an approach called backpropagation .",
10017.txt,The main factors that distinguish different types of networks from each other are how the nodes are connected and the number of layers.,
10018.txt,"Basic networks in which all nodes can be organized into sequential layers, with every node receiving inputs only from nodes in earlier layers, are known as feedforward neural networks .",
10019.txt,"While there is no clear consensus on exactly what defines a DNN, generally, networks with multiple hidden layers are considered deep and those with many layers are considered very deep .",
10020.txt,"Convolutional Neural Networks: Convolutional neural networks, built upon Fukashima's neocognitron, derive the name from the convolution operation in mathematics and signal processing.",
10021.txt,"CNNs use functions, known as filters, allowing for simultaneous analysis of different features in the data .",
10022.txt,"CNNs are extensively used in image and video processing, as well as speech and NLP.",
10023.txt,"Often, it is not important precisely where certain features occur, but rather whether or not they appear in particular localities.",
10024.txt,"Therefore, pooling operations can be used to minimize the size of feature maps.",
10025.txt,"The sizes of such pools are generally small to prevent the loss of too much precision.Recursive Neural Networks: Much like CNNs, recursive networks  use a form of weight sharing to minimize training.",
10026.txt,"However, whereas CNNs share weights horizontally , recursive nets share weights vertically .",
10027.txt,"This is particularly appealing, as it allows for easy modeling of structures such as parse trees.",
10028.txt,"In recursive networks, a single tensor of weights can be used at a low level in the tree and then used recursively at successively higher levels.",
10029.txt,Recurrent Neural Networks and Long Short-T erm Memory Networks: A type of recursive neural network that has been used heavily is the recurrent neural network .,
10030.txt,"Since much of NLP is dependent on the order of words or other elements such as phonemes or sentences, it is useful to have memory of the previous elements when processing new ones .",
10031.txt,"Sometimes, backward dependencies exist, i.e., correct processing of some words may depend on words that follow.",
10032.txt,"Thus, it is beneficial to look at sentences in both directions, forward and backward, using two RNN layers and combining their outputs.",
10033.txt,This arrangement of RNNs is called a bidirectional RNN.,
10034.txt,It may also lead to a better final representation if there is a sequence of RNN layers.,
10035.txt,"This may allow the effect of an input to linger longer than a single RNN layer, allowing for longer term effects.",
10036.txt,This setup of sequential RNN cells is called an RNN stack .,
10037.txt,One highly engineered RNN is the long short-term memory  network .,
10038.txt,"In LSTMs, the recursive nodes are composed of several individual neurons connected in a manner designed to retain, forget, or expose specific information.",
10039.txt,"Whereas generic RNNs with single neurons feeding back to themselves technically have some memory of long passed results, these results are diluted with each successive iteration.",
10040.txt,"Oftentimes, it is important to remember information from the distant past, while at the same time, other very recent information may not be important.",
10041.txt,"By using LSTM blocks, this important information can be retained much longer, while irrelevant information can be forgotten.",
10042.txt,"A slightly simpler variant of the LSTM, called the gated recurrent unit , has been shown to perform as well as or better than standard LSTMs in many tasks.",
10043.txt,"Attention Mechanisms and Transformer: For tasks such as machine translation, text summarization, or captioning, the output is in textual form.",
10044.txt,"Typically, this is done through the use of encoderdecoder pairs.",
10045.txt,An encoding ANN is used to produce a vector of a particular length and a decoding ANN is used to return variable-length text based on this vector.,
10046.txt,A robust solution to this is that of attention.,
10047.txt,"The first noted use of an attention mechanism  used a dense layer for annotated weighting of an RNN's hidden state, allowing the network to learn what to pay attention to in accordance with the current hidden state and annotation.",
10048.txt,Such a mechanism is present in Fig.,
10049.txt,1,
10050.txt,"Variants of the mechanism have been introduced, popular ones including convolutional , intratemporal , gated , and selfattention.",
10051.txt,Self-attention involves providing attention to words in the same sentence.,
10052.txt,"For example, during encoding a word in an input sentence, it is beneficial to project variable amounts of attention to other words in the sentence.",
10053.txt,"During decoding to produce a resulting sentence, it makes sense to provide appropriate attention to words that have already been produced.",
10054.txt,"Self-attention, in particular, has become widely used in a state-of-the-art encoderdecoder model called transformer.",
10055.txt,"The transformer model, shown in Fig.",
10056.txt,"2, has a number of encoders and decoders stacked on top of each other, self-attention in each of the encoder and decoder units, and cross attention between the encoders and the decoders.",
10057.txt,It uses multiple instances of attention in parallel and eschews the use of recurrences and convolutions.,
10058.txt,The transformer has become a quintessential component in most state-of-the-art neural networks for NLP.,
10059.txt,"In deep networks, trained via backpropagation , the gradients used to correct for error often vanish or explode.",
10060.txt,"Also, in response to this issue, as well as others, residual connections are often used.",
10061.txt,Such connections are simply those that skip layers .,
10062.txt,"If used in every alternating layer, this cuts in half the number of layers through which the gradient must backpropagate.",
10063.txt,Such a network is known as a residual network .,
10064.txt,"A number of variants exist, including highway networks and DenseNets .",
10065.txt,Another important method used in training ANNs is dropout.,
10066.txt,"In dropout, some connections and maybe even nodes are deactivated, usually randomly, for each training batch, varying which nodes are deactivated each batch.",
10067.txt,"This forces the network to distribute its memory across multiple paths, helping with generalization and lessening the likelihood of overfitting to the training data.",
10068.txt,The core issues are those that are inherently present in any computational linguistic system.,
10069.txt,"To perform translation, text summarization, image captioning, or any other linguistic task, there must be some understanding of the underlying language.",
10070.txt,"This understanding can be broken down into at least four main areas: language modeling, morphology, parsing, and semantics.",
10071.txt,The number of scholarly works in each area over the last decade is shown in Fig.,
10072.txt,3,
10073.txt,Language modeling can be viewed in two ways.,
10074.txt,"First, it determines which words follow which.",
10075.txt,"By extension, however, this can be viewed as determining what words mean, as individual words are only weakly meaningful, deriving their full value only from their interactions with other words.",
10076.txt,Morphology is the study of how words themselves are formed.,
10077.txt,"It considers the roots of words and the use of prefixes and suffixes, compounds, and other intraword devices, to display tense, gender, plurality, and a other linguistic constructs.",
10078.txt,"Parsing considers which words modify others, forming constituents, leading to a sentential structure.",
10079.txt,The area of semantics is the study of what words mean.,
10080.txt,"It considers the meanings of the individual words and how they relate to and modify others, as well as the contexts these words appear in and some degree of world knowledge, ""common sense.""",
10081.txt,There is a significant amount of overlap between each of these areas.,
10082.txt,"Therefore, many models analyzed can be classified as belonging in multiple sections.",
10083.txt,"As such, they are discussed in the most relevant sections with logical connections to those other places where they also interact.",
10084.txt,"Language Modeling and W ord Embeddings Arguably, the most important task in NLP is that of language modeling.",
10085.txt,Language modeling is an essential piece of almost any application of NLP .,
10086.txt,Language modeling is the process of creating a model to predict words or simple linguistic components given previous words or components .,
10087.txt,"This is useful for applications in which a user types input, to provide predictive ability for fast text entry.",
10088.txt,"However, its power and versatility emanate from the fact that it can implicitly capture syntactic and semantic relationships among words or components in a linear neighborhood, making it useful for tasks such as machine translation or text summarization.",
10089.txt,"Using prediction, such programs can generate more relevant, human-sounding sentences.",
10090.txt,Neural Language Modeling: A problem with statistical language models was the inability to deal well with synonyms or out-of-vocabulary  words that were not present in the training corpus.,
10091.txt,Progress was made in solving the problems with the introduction of the neural language model.,
10092.txt,"While much of NLP took another decade to begin to use ANNs heavily, the language modeling community Authorized licensed use limited to: University of Canberra.",
10093.txt,"The number of publications, indexed by Google Scholar, relating to each topic over the last decade is shown.",
10094.txt,"While all areas have experienced growth, language modeling has grown the most.",
10095.txt,"immediately took advantage of them and continued to develop sophisticated models, many of which were summarized by De Mulder .",
10096.txt,"Evaluation of Language Models: While neural networks have made breakthroughs in the language modeling field, it is hard to quantify improvements.",
10097.txt,It is desirable to evaluate language models independently of the applications in which they appear.,
10098.txt,"A number of metrics have been proposed, but no perfect solution has yet been found.",
10099.txt,"The most commonly used metric is perplexity, which is the inverse probability of a test set normalized by the number of words.",
10100.txt,"Perplexity is a reasonable measurement for language modelings trained on the same data sets, but when they are trained on different vocabularies, the metric becomes less meaningful.",
10101.txt,"Luckily, there are several benchmark data sets that are used in the field, allowing for comparison.",
10102.txt,Two such data sets are the Penn Treebank and the Billion Word Benchmark .,
10103.txt,3) Memory Networks and Attention Mechanisms in Language Modeling: Daniluk tested several networks using variations of attention mechanisms.,
10104.txt,"The first network had a simple attention mechanism, which was not fully connected, having a window length of five.",
10105.txt,"They hypothesized that using a single value to predict the next token, encode informationfor the attentional unit, and decode the information in the attentional unit hinders a network, as it is difficult to train a single parameter to perform three distinct tasks simultaneously.",
10106.txt,"Therefore, in the second network, they designed each node to have two outputs: one to encode and decode the information in the attentional unit, and another to predict the next tokens explicitly.",
10107.txt,"In the third network, they further separated the outputs, using separate values to encode the information entering the attentional unit and decode the information being retrieved from it.",
10108.txt,Tests on a Wikipedia corpus showed that the attention mechanism improved perplexity compared to the baseline and that successively adding the second and third parameters led to further increases.,
10109.txt,It was also noted that only the previous five or so tokens carried much value.,
10110.txt,"Therefore, they tested a fourth network that simply used residual connections from each of the previous five units.",
10111.txt,"It was found that this network also provided results comparable to many larger RNNs and LSTMs, suggesting that reasonable results can be achieved using simpler networks.",
10112.txt,Another recent study was done on the usage of residual memory networks for language modeling .,
10113.txt,"The authors found that residual connections skipping two layers were most effective, followed closely by those skipping a single layer.",
10114.txt,"In particular, a residual connection was present between the first layer and the fourth layer, as was between the fifth layer and the eighth, and between the ninth and the twelfth.",
10115.txt,"It was found that increasing network depth improved results, but that when using large batch sizes, memory constraints were encountered.",
10116.txt,"Network width was not found to be of particular importance for performance; however, wide networks were found to be harder to train.",
10117.txt,It was found that RMNs are capable of outperforming LSTMs of similar size.,
10118.txt,Convolutional Neural Networks in Language Modeling: A CNN used recently in language modeling replaced the pooling layers with fully connected layers .,
10119.txt,These layers allowed the feature maps to be reduced to lower dimensional spaces just like the pooling layers.,
10120.txt,"However, whereas any references to the location of such features are lost in pooling layers, fully connected layers somewhat retain this information.",
10121.txt,"Three different architectures were implemented: a multilayer perceptron CNN  in which the filters were not simply linear, but instead small MLPs ; a multilayer CNN in which multiple convolutional layers were stacked on top of each other; and a combination of these networks called COM, in which kernel sizes for filters varied.",
10122.txt,"The results showed that stacking convolutional layers was detrimental in language modeling, but both MLPConv and COM reduced perplexity.",
10123.txt,"Finally, this study showed that CNNs can be used to capture long-term dependencies in sentences.",
10124.txt,"Closer words were found to be of greatest importance, but words located farther away were of some significance as well.",
10125.txt,"Character-Aware Neural Language Models: While most CNNs used in NLP receive word embeddings  as input, recent networks have analyzed character-level input instead.",
10126.txt,"For example, the network of Kim , unlike previous networks , accepted only character-level input, rather than combining it with word embeddings.",
10127.txt,A CNN was used to process the character-level input to provide the representations of the words.,
10128.txt,In a manner similar to how word embeddings usually are these representations were then fed into an encoderdecoder pair composed of a highway networkand an LSTM.,
10129.txt,"They trained the network on the English PTB, as well as on data sets for Czech, German, Spanish, French, Russian, and Arabic.",
10130.txt,"For every non-English language except Russian, the network outperformed previously published results  in both the large and small data sets.",
10131.txt,Authorized licensed use limited to: University of Canberra.,
10132.txt,"However, the network had only 19 million trainable parameters, which is considerably lower than others.",
10133.txt,"Since the network focused on morphological similarities produced by character-level analysis, it was more capable than previous models of handling rare words.",
10134.txt,"Analysis showed that without the use of highway layers, many words had nearest neighbors that were orthographically similar but not necessarily semantically similar.",
10135.txt,"In addition, the network was capable of recognizing misspelled words or words not spelled in the standard way and of recognizing out of vocabulary words.",
10136.txt,"The analysis also showed that the network was capable of identifying prefixes, roots, and suffixes, as well as understandinghyphenatedwords, making it a robust model.",
10137.txt,Jozefowicz  tested a number of architectures producing character-level outputs.,
10138.txt,"While many of these models had only been tested on small-scale language modeling, this study tested them on a large scale, testing them with the Billion Word Benchmark.",
10139.txt,"The most effective model, achieving a state-of-the-art  perplexity of 30.0 with 1.04 billion trainable parameters, was a large LSTM using a character-level CNN as an input network.",
10140.txt,"The best performance, however, was achieved using an ensemble of ten LSTMs.",
10141.txt,"This ensemble, with a perplexity of 23.7, far surpassed the previous state-ofthe-art ensemble , which had a perplexity of 41.",
10142.txt,"V ectors with numeric components, representing individual words, obtained by language modeling techniques are called embeddings.",
10143.txt,This is usually done either by the use of principle component analysis or by capturing internal states in a neural language model.,
10144.txt,"Typically, word embeddings have between 50 and 300 dimensions.",
10145.txt,"An overused example is that of the distributed representations of the words king, queen, man, a n d woman.",
10146.txt,"If one takes the embedding vectors for each of these words, computation can be performed to obtain highly sensible results.",
10147.txt,"Recent Advances and Challenges: Language modeling has been evolving on a weekly basis, beginning with the works of Radford and Peters.",
10148.txt,"Radford introduced generative pretraining which pretrained a language model based on the transformer model , learning dependencies of words in sentences and longer segments of text, rather than just the immediately surrounding words.",
10149.txt,"Peters incorporated bidirectionalism to capture backward context in addition to the forward context, in their Embeddings from Language Models .",
10150.txt,"In addition, they captured the vectorizations at multiple levels, rather than just the final layer.",
10151.txt,"This allowed for multiple encodings of the same information to be captured, which was empirically shown to significantly boost the performance.",
10152.txt,"Devlin  added the additional unsupervised training tasks of random masked neighbor word prediction and nextsentence-prediction, in which given a sentence, another sentence was predicted to either be the next sentence or not.",
10153.txt,"These Bidirectional Encoder Representations from Transformers  were further built upon by Liu to create multitask DNN representations, which are the current state of the art in language modeling.",
10154.txt,The model used a stochastic answer network ontop of a BERT-like model.,
10155.txt,"After pretraining, the model was trained on a number of different tasks before being fine-tuned to the task at hand.",
10156.txt,"Using MT-DNN as the language modeling, they achieved state-ofthe-art results on ten out of eleven of the attempted tasks.",
10157.txt,"While these pretrained models have made excellent headway in ""understanding"" language, as is required for some tasks such as entailment inference, it has been hypothesized by some that these models are learning templates or syntactic patterns present within the data sets, unrelated to logic or inference.",
10158.txt,"When new data sets are created by removing such patterns carefully, the models do not perform well .",
10159.txt,"In addition, while there has been recent work on cross-language modeling and universal language modeling, the amount and level of work need to pick up to address low-resource languages.",
10160.txt,"Morphology Morphology is concerned with finding segments within single words, including roots and stems, prefixes, suffixes, andin some languagesinfixes.",
10161.txt,Luong  constructed a morphologically aware language modeling.,
10162.txt,An RvNN was used to model the morphological structure.,
10163.txt,A neural language model was then placed on top of the RvNN.,
10164.txt,"The model was trained on the WordSim353 data set , and segmentation was performed using Morfessor .",
10165.txt,Two models were constructedone using context and one not.,
10166.txt,It was found that the model that was insensitive to context overaccounted for certain morphological structures.,
10167.txt,"In particular, words with the same stem were clustered together even if they were antonyms.",
10168.txt,"As such, one recent study by Belinkov examined the extent to which morphology was learned and used by a variety of neural machine translation models.",
10169.txt,"A number of translation models were constructed, all translating from English to French, German, Czech, Arabic, or Hebrew.",
10170.txt,"Encoders and decoders were LSTM-based models  or character aware CNNs, and the models were trained on the WIT3 corpus.",
10171.txt,"The decoders were then replaced with POS taggers and morphological taggers, fixing the weights of the encoders to preserve the internal representations.",
10172.txt,The effects of the encoders were examined as were the effects of the Authorized licensed use limited to: University of Canberra.,
10173.txt,The study concluded that the use of attention mechanisms decreases the performance of encoders but increases the performance of decoders.,
10174.txt,"Furthermore, it was found that character-aware models are superior to others for learning morphology and that the output language affects the performance of the encoders.",
10175.txt,"Specifically, the more morphologically rich the output language, the worse the representations created by the encoders.",
10176.txt,Morita analyzed a new morphological language model for unsegmented languages such as Japanese.,
10177.txt,They constructed an RNN-based model with a beam search decoder and trained it on an automatically labeled  corpus and a manually labeled corpus.,
10178.txt,"The model performed a number of tasks jointly, including morphological analysis, POS tagging, and lemmatization.",
10179.txt,"The model was then tested on the Kyoto Text Corpus and the Kyoto University Web Document Leads Corpus , outperforming all baselines on all tasks.",
10180.txt,A recent line of work in morphology is universal morphology.,
10181.txt,"This task considers the relationships between the morphologies of different languages and how they relate to each other, aiming toward the ultimate goal of a single morphological analyzer.",
10182.txt,"However, to the authors' knowledge, there has been only a single study applying deep learning to this area.",
10183.txt,"For those wishing to apply deep learning to this task, several data sets are already available, including one from a CoNLL shared task .",
10184.txt,"In addition to universal morphology, the development of morphological embeddings, which considers the structures of words could aid in multilanguage processing.",
10185.txt,"They could possibly be used across cognate languages, which would be valuable when some languages are more resourced than others.",
10186.txt,"In addition, morphological structures may be important in handling specialized language, such as that used in biomedical literature.",
10187.txt,"Since deep learning has become quite entrenched in NLP , better handling of morphological components is likely to improve the performance of overall models.",
10188.txt,Parsing Parsing examines how different words and phrases relate to each other within a sentence.,
10189.txt,There are at least two distinct forms of parsing: constituency parsing and dependency parsing.,
10190.txt,"In constituency parsing, phrasal constituents are extracted from a sentence in a hierarchical fashion.",
10191.txt,Dependency parsing looks at the relationships between the pairs of individual words.,
10192.txt,"Most recent uses of deep learning in parsing have been in dependency parsing, within which there exists another major divide in types of solutions.",
10193.txt,Graph-based parsing constructs a number of parse trees that are then searched to find the correct one.,
10194.txt,"Most graph-based approaches are generative models, in which a formal grammar, based on the natural language, is used to construct the trees.",
10195.txt,More popular in recent years than graph-based approaches have been transition-based approaches that usually construct only one parse tree.,
10196.txt,"While a number of modifications have been proposed, the standard method of transition-based dependency parsing is to create a buffer containing all of the words in the sentence and stack containing only the ROOT label.",
10197.txt,"Words are then pushed onto the stack, where connections,known as arcs, are made between the top two items.",
10198.txt,"Once dependencies have been determined, words are popped off the stack.",
10199.txt,The process continues until the buffer is empty and only the ROOT label remains on the stack.,
10200.txt,Three major approaches are used to regulate the conditions in which each of the previously described actions takes place.,
10201.txt,In the arc-standard approach all dependents are connected to a word before the word is connected to its parent.,
10202.txt,"In the arc-eager approach , words are connected to their parents as soon as possible, regardless of whether or not their children are all connected to them.",
10203.txt,"Finally, in the swap-lazy approach , the arc-standard approach is modified to allow swapping of positions on the stack.",
10204.txt,This makes the graphing of nonprojective edges possible.,
10205.txt,"Early Neural Parsing: One early application of deep learning to NLP , that of Socher , included the use of RNNs with probabilistic context-free grammars.",
10206.txt,"As far as the authors are aware, the first neural model to achieve state-of-the-art performance in parsing was that of Le and Zuidema .",
10207.txt,"Such performance was achieved on the PTB for both labeled attachment score and unlabeled attachment score  by using an inside-out recursive neural network, which used two vector representations  to allow both top-down and bottom-up flows of data.",
10208.txt,"Vinyals created an LSTM with an attention mechanism in a syntactic constituency parser, which they tested on data from domains different from those of the test data, showing that neural models can generalize between domains.",
10209.txt,Embeddings were first used in dependency parsing by Stenetorp .,
10210.txt,This approach used an RNN to create a directed acyclic graph.,
10211.txt,"While this model did produce results within 2% of the state of the art, by the time it reached the end of a sentence, it seemed to have difficulty in remembering phrases from early in the sentence.",
10212.txt,Transition-Based Dependency Parsing: Chen and Manning  pushed the state of the art in both UAS and LAS on both English and Chinese data sets on the English PTB.,
10213.txt,They accomplished this by using a simple FFNN as the decision-maker in a transition-based parser.,
10214.txt,"By doing so, they were able to subvert the problem of sparsity persistent in the statistical models.",
10215.txt,"Chen and Manning used a simple greedy search, which was replaced by Zhou with a beam search, achieving a significant improvement.",
10216.txt,Weiss improved upon Chen and Manning's work by using a deeper neural network with residual connections and a perceptron layer placed after the softmax layer.,
10217.txt,"They were able to train on significantly more examples than typical by using tritraining, a process in which potential data samples are fed to two other parsers, and those samples upon which both of the parsers agree are used for training the primary parser.",
10218.txt,Another model was produced using an LSTM instead of a feedforward network.,
10219.txt,"Unlike previous models, this model was given knowledge of the entire buffer and the entire stack and had knowledge of the entire history of transition decisions.",
10220.txt,"This allowed for better predictions, generating stateof-the-art scores on the Stanford Dependency Treebank, as well as state-of-the-art results on the CTB5 Chinese data set .",
10221.txt,"Finally, Andor  used a feedforward Authorized licensed use limited to: University of Canberra.",
10222.txt,"Notably, their model required significantly less computation than comparable models.",
10223.txt,"Much like Stenentorp , Wang  used an alternative algorithm to produce directed acyclic graphs, for a task called semantic parsing, where deeper relationships between the words are found.",
10224.txt,The task seeks to identify what types of actions are taking place and how words modify each other.,
10225.txt,"In addition to the typical stack and buffer used in transition-based parsing, the algorithm employed a deque.",
10226.txt,"This allowed for the representation of multiparented words, which although rare in English, are common in many natural languages.",
10227.txt,"Furthermore, it allowed for multiple children of the ROOT label.",
10228.txt,"In addition to producing said graphs, this article is novel in its use of two new LSTM-based techniques: Bi-LSTM subtraction and incremental Tree-LSTM.",
10229.txt,"Bi-LSTM subtraction built on previous work ,  to represent the buffer as a subtraction of the vectors from the head and tail of the LSTM, in addition to using an additional LSTM to represent the deque.",
10230.txt,"Incremental Tree-LSTM is an extension of Tree-LSTM, modified for directed acyclic graphs, by connecting children to parents incrementally, rather than connecting all children to a parent simultaneously.",
10231.txt,The model achieved the best published scores at the time for 14 of the 16 evaluation metrics used on SemEval-2015 Task 18  and SemEval-2016 Task 9.,
10232.txt,"While deep learning had been applied to semantic parsing in particular domains, such as QA , to the authors' knowledge, this was the first time it was applied in large scale to semantic parsing as a whole.",
10233.txt,Generative Dependency and Constituent Parsing: Dyer proposed a model that used RNN grammars for parsing and language modeling.,
10234.txt,"While most approaches take a bottomup approach to parsing, this took a topdown approach, taking as input the full sentence in addition to the current parse tree.",
10235.txt,"This allowed the sentence to be viewed as a whole, rather than simply allowing local phrases within it to be considered.",
10236.txt,This model achieved the best results in English generative parsing as well as in single sentence language modeling.,
10237.txt,It also attained results close to the best in Chinese generative parsing.,
10238.txt,"Choe and Charniak  treated parsing as a language modeling problem and used an LSTM to assign probabilities to the parse trees, achieving state of the art.",
10239.txt,Fried  wanted to determine whether the power of the models came from the reranking process or simply from the combined power of two models.,
10240.txt,"They found that while using one parser for producing candidate trees and another for ranking them was superior to a single parser approach, combining two parsers explicitly was preferable.",
10241.txt,"They used two parsers to both select the candidates and rerank them, achieving state-ofthe-art results.",
10242.txt,"They extended this model to use three parsers, achieving even better results.",
10243.txt,"Finally, an ensemble of eight such models was constructed and achieved the best results on PTB at the time.",
10244.txt,A model created by Dozat and Manning  used a graph-based approach with a self-attentive network.,
10245.txt,"Similarly, Tan used a self-attentional model for semantic role labeling and a subtask of semantic parsing, achieving excellent results.",
10246.txt,"They experimented with recurrent and convolutional replacements to the feedforward portions of the self-attention mechanism, finding that the feedforward variant had the best performance.",
10247.txt,"Another novel approach is that of Duong , who used active learning.",
10248.txt,"While not perfect, this is a possible solution to one of the biggest problems in semantic parsingthe availability of data.",
10249.txt,"Universal Parsing: Much like universal morphology, universal dependency parsing, or universal parsing, is the relatively new task of parsing language using a standardized set of tags and relationships across all languages.",
10250.txt,"While current parsing varies drastically from language to language, this attempts to make it uniform between them, in order to allow for easier processing between and among them.",
10251.txt,"Nivre discussed the recent development of universal grammar and presented the challenges that lie ahead, mainly the development of tree banks in more languages and the consistency of labeling between tree banks in different languages.",
10252.txt,This task has gained traction in large part because it has been a CoNLL shared task for the past two years .,
10253.txt,"A number of approaches from the 2018 task included using deep transition parsing , graph-based neural parsing, and a competitive model, which used only a single neural model, rather than an ensemble .",
10254.txt,"The task has begun to be examined outside of CoNLL, with Liu applying universal dependencies to the parsing of tweets, using an ensemble of bidirectional LSTM.",
10255.txt,"Remaining Challenges: Outside of universal parsing, a parsing challenge that needs to be further investigated is the building of syntactic structures without the use of treebanks for training.",
10256.txt,"Attempts have been made using attention scores and Tree-LSTMs, as well as ""outside-inside"" autoencoders.",
10257.txt,"If such approaches are successful, they have the potential use in many environments, including in the context of low-resource languages and out-of-domain scenarios.",
10258.txt,"While a number of other challenges remain, these are the largest and are expected to receive the most focus.",
10259.txt,"D. Semantics Semantic processing involves understanding the meaning of words, phrases, sentences, or documents at some level.",
10260.txt,"Word embeddings, such as Word2Vec and GloVe , claim to capture meanings of words, following the distributional hypothesis of meaning .As a corollary, when vectors corresponding to phrases, sentences, or other components of text are processed using a neural network, a representation that can be loosely thought to be semantically representative is computed compositionally.",
10261.txt,"In this section, neural semantic processing research is separated into two distinct areas: work on comparing the semantic similarity of two portions of text and work on capturing and transferring meaning in high-level constituents, particularly sentences.",
10262.txt,"Semantic Comparison: One way to test the efficacy of an approach to computing semantics is to see if two similar phrases, sentences, or documents, judged by humans to have similar meaning also are judged similarly by a program.",
10263.txt,Hu proposed two CNNs to perform a semantic comparison task.,
10264.txt,"The first model, ARC-I, inspired by Bordes, used a Siamese network, in which two CNNs sharing weights evaluated two sentences in parallel.",
10265.txt,"In the second network, connections were placed between the Authorized licensed use limited to: University of Canberra.",
10266.txt,The approach outperformed a number of existing models in tasks in English and Chinese.,
10267.txt,"Building on prior work Yin and Schtze  proposed a Bi-CNN-MI , consisting of a pretrained CNN sentence model, a CNN interaction model, and a logistic regressor.",
10268.txt,They modified a Siamese network using dynamic CNNs.,
10269.txt,"In addition, the feature maps from each level were used in the comparison, rather than simply the top-level feature maps.",
10270.txt,They achieved state-of-the-art results on the Microsoft Research Paraphrase Corpus .,
10271.txt,"He constructed feature maps, which were then compared using a ""similarity measurement layer"" followed by a fully connected layer and then a log-softmax output layer within a CNN.",
10272.txt,The windows used in the convolutional layers ranged in length from one to four.,
10273.txt,"The network was trained and evaluated on three data sets: MSRP , the Sentences Involving Compositional Knowledge data set , and the Microsoft Video Paraphrase Corpus.",
10274.txt,State-of-the-art results were achieved on the first and the third.,
10275.txt,Tai  concocted a model using an RvNN with LSTM-like nodes called a Tree-LSTM.,
10276.txt,Two variations were examined and tested on both the SICK data set and Stanford Sentiment Treebank.,
10277.txt,The constituency-based model achieved state-of-the-art results on the Stanford Sentiment Treebank and the dependency-based one achieved state-of-the-art results on SICK.,
10278.txt,"He and Lin presented another model, which outperformed that of Tai  on SICK.",
10279.txt,The model formed a matrix of the two sentences before applying a "similarity focus layer" and then a 19-layer CNN followed by dense layers with a softmax output.,
10280.txt,"The similarity focus layer matched semantically similar pairs of words from the input sentences and applied weights to the matrix locations representing the relations between the words in each pair.Extending from neural language modeling, sentence modeling attempts to capture the meaning of sentences in vectors.",
10281.txt,"Taking this a step further are models, such as that of Le and Mikolov , which attempt to model paragraphs or larger bodies of text in this way.",
10282.txt,"Kalchbrenner generated the representations of sentences using a dynamic convolutional neural network , which used a number of filters and dynamic k-max-pooling layers.",
10283.txt,"Due to dynamic pooling, features of different types and lengths could be identified in sentences with varying structures without padding of the input.",
10284.txt,This allowed not only short-range dependencies but also long-range dependenciesto be identified.,
10285.txt,The DCNN was tested in applied tasks that require semantic understanding.,
10286.txt,It outperformed all comparison models in predicting sentiment of movie reviews in the Stanford Sentiment Treebank and in identification of sentiment in tweets .,
10287.txt,It was also one of the top performers in classifying types of questions using the TREC database .,
10288.txt,"Between their requirement for such understanding and their ease of examination due to the typical encoderdecoder structure they use, NMT systems are splendid testbeds for researching internal semantic representations.",
10289.txt,"Poliak trained encoders on four different language pairs: English and Arabic, English and Spanish, English and Chinese, and English and German.",
10290.txt,"The decoding classifiers were trained on four distinct data sets: Multi NLI , which is an expanded version of SNLI, as well as three recast data sets from the JHU Decompositional Semantics Initiative.",
10291.txt,"None of the results were particularly strong, although they were strongest in SPR.",
10292.txt,This led to the conclusion that NMT models do a poor job of capturing paraphrased information and fail to capture inferences that help in anaphora resolution.,
10293.txt,"They did, however, find that the models learn about protoroles.",
10294.txt,A concurrent work analyzed the quality of many data sets used for natural language inference.,
10295.txt,"Herzig and Berant found that training semantic parsers on a single domain, as is often done, is less effective than training across many domains.",
10296.txt,This conclusion was drawn after testing three LSTM-based models.,
10297.txt,"The first model was a one-to-one model, in which a single encoder and a single decoder were used, requiring the network itself to determine the domain of the input.",
10298.txt,"In the second model, a many-to-many model, a decoder was used for each domain, as were two encoders: the domain-specific encoder and a multidomain encoder.",
10299.txt,"The third model was a one-to-many model, using a single encoder but separate decoders for each domain.",
10300.txt,Each model was trained on the "OVERNIGHT" data set .,
10301.txt,"Exceptional results were achieved for all models, with a stateof-the-art performance exhibited by the one-to-one model.",
10302.txt,Similar conclusions were drawn by Brunner.,
10303.txt,who created several LSTM-based encoderdecoder networks and analyzed the embedding vectors produced.,
10304.txt,"A single encoder accepting English sentences as input was used, as were four different decoders.",
10305.txt,"The first such decoder was a replicating decoder, which reproduced the original English input.",
10306.txt,The second and third decoders translated the text into German and French.,
10307.txt,"Finally, the fourth decoder was a POS tagger.",
10308.txt,"Different combinations of decoders were used; one model had only the replicating decoder, while others had two, three, or all four.",
10309.txt,Sentences of 14 different structures from the EuroParl data set  were used to train the networks.,
10310.txt,A set of test sentences were then fed to the encoders and their output analyzed.,
10311.txt,"In all cases, 14 clusters were formed, each corresponding to one of the sentence structures.",
10312.txt,Analysis showed that adding more decoders led to more correct and more definitive clusters.,
10313.txt,"In particular, using all four of the decoders led to zero error.",
10314.txt,"Furthermore, the researchers confirmed a hypothesis that just as logical arithmetic can be performed on word embeddings, so can it be performed on sentence embeddings.",
10315.txt,"3) Semantic Challenges: In addition to the challenges already mentioned, researchers believe that being able to solve tasks well does not indicate actual understanding.",
10316.txt,Integrating deep networks with general word graphs or knowledge graphs may be able to endow a sense of understanding.,
10317.txt,"Graph embedding is an active area of research, and work on integrating language-based models and graph models has only recently begun to take off, giving hope for better machine understanding.",
10318.txt,Authorized licensed use limited to: University of Canberra.,
10319.txt,"All areas of applied NLP discussed have witnessed growth in recent years, with the largest growth occurring in the last two to three years.",
10320.txt,"E. Summary of Core Issues Deep learning has generally performed very well, surpassing existing states of the art in many individual core NLP tasks and has thus created the foundation on which useful natural language applications can and are being built.",
10321.txt,"However, it is clear from examining the research reviewed here that natural language is an enigmatically complex topic, with myriad core or basic tasks, of which deep learning has only grazed the surface.",
10322.txt,"It is also not clear how architectures for ably executing individual core tasks can be synthesized to build a common edifice, possibly a much more complex distributed neural architecture, to show competence in multiple or ""all"" core tasks.",
10323.txt,"More fundamentally, it is also not clear, how mastering of basic tasks, may lead to superior performance in applied tasks, which are the ultimate engineering goals, especially in the context of building effective and efficient deep learning models.",
10324.txt,"Many, if not most, successful deep learning architectures for applied tasks, discussed in Section IV, seem to forgo explicit architectural components for core tasks and learn such tasks implicitly.",
10325.txt,"Thus, some researchers argue that the relevance of the large amount of work on core issues is not fully justified, while others argue that further extensive research in such areas is necessary to better understand and develop systems which more perfectly perform these tasks, whether explicitly or implicitly.While the study of core areas of NLP is important to understanding how neural models work, it is meaningless in and of itself from an engineering perspective, which values the applications that benefit humanity, not pure philosophical and scientific inquiry.",
10326.txt,Current approaches to solving several immediately useful NLP tasks are summarized here.,
10327.txt,"Note that the issues included here are only those involving the processing of text, not the processing of verbal speech.",
10328.txt,"Because speech processing requires expertise on several other topics including acoustic processing, it is generally considered another field of its own, sharing many commonalities with the field of NLP.",
10329.txt,The number of studies in each discussed area over the last decade is shown in Fig.,
10330.txt,4,
10331.txt,A.,
10332.txt,Information Retrieval The purpose of IR systems is to help people find the right  information in the right format at the right time .,
10333.txt,"Among many issues in IR, a primary problem that needs addressing pertains to ranking documents with respect to a query string in terms of relevance scores for ad hoc retrieval tasks, similar to what happens in a search engine.",
10334.txt,Deep learning models for ad hoc retrieval match texts of queries to texts of documents to obtain relevance scores.,
10335.txt,"Thus, such models have to focus on producing representations of the interactions among individual words in the query and the documents.",
10336.txt,"Some representation-focused approaches build deep learning models to produce good representations for the texts and then match the representations straightforwardly ,whereas interactionfocused approaches first build local interactions directly and then use DNNs to learn how the two pieces of text match based on word interactions .When matching a long document to a short query, the relevant portion can potentially occur anywhere in the long document and may also be distributed, thus, finding how each word in the query relates to portions of the document is helpful.",
10337.txt,"Mindful of the specific needs for IR, Guo built a neural architecture called DRMM, enhancing an interaction-focused model that feeds quantized histograms of the local interaction intensities to an MLP for matching.",
10338.txt,"In parallel, the query terms go through a small subnetwork on their own to establish term importance and term dependencies.",
10339.txt,The outputs of the two parallel networks are mixed at the top so that the relevance of the document to the query can be better learned.,
10340.txt,DRMM achieved the state-of-the-art performance for its time.,
10341.txt,"Most current neural IR models are not end-to-end relevance rankers, but are rerankers for documents a first-stage efficient traditional ranker has deemed relevant to a query.",
10342.txt,"The representations that the neural rerankers learn are dense for both documents and queries,most documents in a collection seem to be relevant to a query, making it impossible to use such ANNs for ranking an entire collection of documents.",
10343.txt,"In contrast, Zamani presented a standalone neural ranking model called SNRM_PRF that learned sparse representations for both queries and documents, mimicking what traditional approaches do.",
10344.txt,"Since queries are much shorter than documents and queries contain much less information than documents, it makes sense for query representations to be denser.",
10345.txt,"This was achieved by using, during training, a sparsity objective combined with hinge loss.",
10346.txt,"In particular, an n-gram representation for queries and documents was used.",
10347.txt,It passed the embedding of each word separately through an individual MLP and performed average pooling on top.,
10348.txt,"During training, the approach used pseudorelevant documents obtained by retrieving documents using the existing models Authorized licensed use limited to: University of Canberra.",
10349.txt,"The approach created a 20 000-bit-long inverted index for each document using the trained network, just like a traditional endto-end approach.",
10350.txt,"For retrieval, a dot product was computed between query and document representations to obtain the retrieval relevance score.",
10351.txt,"The SNRM_PRF system obtained the best metrics across the board for two large data sets, Robust and ClueWeb.",
10352.txt,"MacAveney extracted query term representations from two pretrained contextualized language models, ELMo and BERT, and used the representations to augment three existing competitive neural ranking architectures for ad hoc document ranking, one of them being DRMM .",
10353.txt,They also presented a joint model that combined BERT's classification vector with these architectures to get benefits from both approaches.,
10354.txt,MacAveney's system called contextualized embeddings for document ranking  improved the performance of all three prior models and produced state-of-the-art results using BERT's token representations.,
10355.txt,B.,
10356.txt,Information Extraction Information extraction extracts explicit or implicit information from the text.,
10357.txt,"The outputs of systems vary, but often, the extracted data and the relationships within it are saved in relational databases.",
10358.txt,"Commonly extracted information includes named entities and relations, events and their participants, temporal information, and tuples of facts.",
10359.txt,"Named Entity Recognition: Named entity recognition  refers to the identification of proper nouns as well as information such as dates, times, prices, and product IDs.",
10360.txt,The multitask approach of Collobert  included the task although no results were reported.,
10361.txt,"In their approach, a simple feedforward network was used, having a context with a fixed-sized window around each word.",
10362.txt,"Presumably, this made it difficult to capture long-distance relations between the words.",
10363.txt,LSTMs were first used for NER by Hammerton .,
10364.txt,"The model, which was ahead of its time, had a small network due to the lack of available computing power at the time.",
10365.txt,"In addition, sophisticated numeric vector models for words were not yet available.",
10366.txt,Results were slightly better than the baseline for English and much better than the baseline for German.,
10367.txt,"Dos Santos used a DNN architecture, known as CharWNN, which jointly used word-level and character-level inputs to perform sequential classification.",
10368.txt,"In this article, a number of experiments were performed using the HAREM I annotated Portuguese corpus , and the SPA CoNLL2002 annotated Spanish corpus .",
10369.txt,"For the Portuguese corpus, CharWNN outperformedthe previous state-ofthe-art system across ten named entity classes.",
10370.txt,It also achieved state-of-the-art performance in Spanish.,
10371.txt,"The authors noted that when used alone, neither word embeddings nor character level embeddings worked.",
10372.txt,This revalidated a fact long known: joint use of word-level and character-level features is important to effective NER performance.,
10373.txt,Chiu and Nichols used a bidirectional LSTM with a character-level CNN resembling those used by dos Santos .,
10374.txt,"Without using any private lexicons, detailed information about linked entities, or elaborate hand-crafted features they produced state-of-the-art results on the CoNLL-2003  and OntoNotes  data sets.",
10375.txt,Lample developed an architecture based on bidirectional LSTMs and conditional random fields.,
10376.txt,The model used both character-level inputs and word embeddings.,
10377.txt,"The inputs were combined and then fed to a bidirectional LSTM, whose outputs were in turn fed to a layer that performed CRF computations .",
10378.txt,"The model, when trained using dropout, obtained stateof-the-art performance in both German and Spanish.",
10379.txt,The LSTM-CRF model was also very close in both English and Dutch.,
10380.txt,The main claim of this study was that state-ofthe-art results were achieved without the use of any handengineered features or gazetteers.,
10381.txt,Akbik  achieved the state-of-the-art performance in German and English NER using a pretrained bidirectional character language model.,
10382.txt,"They retrieved for each word a contextual embedding that they passed into a BiLSTM-CRF sequence labeler to perform NER.Event extraction is concerned with identifying words or phrases that refer to the occurrence of events, along with participants such as agents, objects, recipients, and times of occurrence.",
10383.txt,"Event extraction usually deals with four subtasks: identifying event mentions, or phrases that describe events; identifying event triggers, which are the main wordsusually verbs or gerundsthat specify the occurrence of the events; identifying arguments of the events; and identifying arguments' roles in the events.",
10384.txt,"Chen argued that CNNs that use max-pooling are likely to capture only the most important information in a sentence, and as a result, might miss valuable facts when considering sentences that refer to several events.",
10385.txt,"To address this drawback, they divided the feature map into three parts, and instead of using one maximum value, kept the maximum value of each part.",
10386.txt,"In the first stage, they classified each word as either being a trigger word or nontrigger word.",
10387.txt,"If triggers were found, the second stage aligned the roles of arguments.",
10388.txt,Results showed that this approach significantly outperformed other state-of-the-art methods of the time.,
10389.txt,"The following year, Nguyen used an RNN-based encoderdecoder pair to identify event triggers and roles, exceeding earlier results.",
10390.txt,"Liu presented a latent variable neural model to induce event schemas and extract open domain events, achieving the best results on a data set they created and released.",
10391.txt,Relationship Extraction: Another important type of information extracted from the text is that of relationships.,
10392.txt,"These may be possessive, antonymous, or synonymous relationships, or more natural, familial, or geographic relationships.",
10393.txt,"The first deep learning approach was that of Zeng , who used a simple CNN to classify a number of relationships between the elements in sentences.",
10394.txt,"Using only two layers, a window size of three and word embeddings with only 50 dimensions, they attained better results than any prior approach.",
10395.txt,"Further work, by Zheng , used a bidirectional LSTM and a CNN for relationship classification as well as entity recognition.",
10396.txt,"More recently, Sun used an attention-based GRU model with a copy mechanism.",
10397.txt,"This network was novel in its use of a data structure known as a coverage mechanism, which helped ensure that all important information was extracted the correct number Authorized licensed use limited to: University of Canberra.",
10398.txt,Lin achieved the state-of-the-art performance in clinical temporal relation extraction using the pretrained BERT model with supervised training on a biomedical data set.,
10399.txt,Text Classification Another classic application for NLP is text classification or the assignment of free-text documents to predefined classes.,
10400.txt,Document classification has numerous applications.,
10401.txt,Kim was the first to use pretrained word vectors in a CNN for sentence-level classification.,
10402.txt,"Kim's work was motivating, and showed that simple CNNs, with one convolutional layer followed by a dense layer with dropout and softmax output, could achieve excellent results on multiple benchmarks using little hyperparameter tuning.",
10403.txt,"The CNN models proposed were able to improve upon the state of the art on four out of seven different tasks cast as sentence classification, including sentiment analysis and question classification.",
10404.txt,Conneau later showed that networks that employ a large number of convolutional layers work well for document classification.,
10405.txt,Jiang used a hybrid architecture combining a deep belief network and softmax regression .This process was independent of the labeled or classification portion of the task and was therefore initially trained without the softmax regression output layer.,
10406.txt,"Once both sections of the architecture were pretrained, they were combined and trained such as a regular deep neural net with backpropagation and quasi-Newton methods.",
10407.txt,Adhikari  used BERT  to obtain state-ofthe-art classification results on four document data sets.,
10408.txt,"While deep learning is promising for many areas of NLP, including text classification, it is not necessarily the endall-be-all, and many hurdles are still present.",
10409.txt,"Worsham and Kalita  found that for the task of classifying long full-length books by genre, gradient boosting trees are superior to neural networks, including both CNNs and LSTMs.",
10410.txt,Text Generation Many NLP tasks require the generation of human-like language.,
10411.txt,Summarization and machine translation convert one text to another in a sequence-to-sequence fashion.,
10412.txt,"Other tasks, such as image and video captioning and automatic weather and sports reporting, convert nontextual data to text.",
10413.txt,"Some tasks, however, produce text without any input data to convert.",
10414.txt,"These tasks include poetry generation, joke generation, and story generation.",
10415.txt,"Poetry Generation: Poetry generation is arguably the hardest of the generation subtasks, as in addition to producing creative content, the content must be delivered in an esthetic manner, usually following a specific structure.",
10416.txt,"As with most tasks requiring textual output, recurrent models are the standard.",
10417.txt,"However, while recurrent networks are great at learning internal language models, they do a poor job of producing structured output or adhering to any single style.",
10418.txt,Wei addressed the style issue by training using particular poets and controlling for style in Chinese poetry.,
10419.txt,"They found that with enough training data, adequate results could be achieved.The structure problem was addressed by Hopkins and Kiela, who generated rhythmic poetry by training the network on only a single type of poem to ensure the produced poems adhered to a single rhythmic structure.",
10420.txt,"Human evaluators judged poems produced to be of lower quality than, but indistinguishable from, human-produced poems.",
10421.txt,"Another approach to poetry generation, beginning this year, has been to use pretrained language models.",
10422.txt,"Specifically, This study provided astonishing results in the fact that GPT-2 was pretrained on a large English corpus, yet with further training on only a few hundred poems in another language, it turns into a believable generator in that language, even for poetry.",
10423.txt,"Joke and Pun Generation: Another area, which has received little attention, is the use of deep learning for joke and pun generation.",
10424.txt,Yu  generated homographic puns using a small LSTM.,
10425.txt,The network produced sentences in which ambiguities were introduced by words with multiple meanings although it did a poor job of making the puns humorous.,
10426.txt,The generated puns were classified by human evaluators as machine generated a majority of the time.,
10427.txt,The authors noted that training on pun data alone is not sufficient for generating good puns.,
10428.txt,"Ren and Yang used an LSTM to generate jokes, training on two data sets, one of which was a collection of short jokes from Conan O'Brien.",
10429.txt,"Since many of these jokes pertain to current events, the network was also trained on a set of news articles.",
10430.txt,This gave context to the example jokes.,
10431.txt,"Chippada and Saha generated jokes, quotes, and tweets using the same neural network, using an additional input to specify which should be produced.",
10432.txt,"It was found that providing more general knowledge of other types of language, and examples of nonjokes, increased the quality of the jokes produced.",
10433.txt,"Story Generation: While poetry and especially humor generation have not gained much traction, story generation has seen a recent rise in interest.",
10434.txt,Jain used RNN variants with attention to produce short stories from Authorized licensed use limited to: University of Canberra.,
10435.txt,"Another recent study of interest is that by Peng, who used LSTMs to generate stories, providing an input to specify whether the story should have a happy or sad ending.",
10436.txt,Their model successfully did so while at the same time providing better coherence than noncontrolled stories.,
10437.txt,This did a great job of capturing only the most important information but still provided only modest end results in human evaluation.,
10438.txt,Drissi followed a similar approach.,
10439.txt,The strongest models to date focus on creating high-level overviews of stories before breaking them down into smaller components to convert to text.,
10440.txt,Huang  generated short stories from images using a two-tiered network.,
10441.txt,"The first constructed a conceptual overview, while the second converted the overview into words.",
10442.txt,"Fan used a hierarchical approach, based on CNNs, which beat out the nonhierarchical approach in blind comparison by human evaluators.",
10443.txt,"In addition, they found that self-attention leads to better perplexity.",
10444.txt,"They also developed a fusion model with a pretrained language model, leading to greater improvements.",
10445.txt,"These results concur with those of an older study by Li  who read documents in a hierarchical fashion and reproduced them in a hierarchical fashion, achieving great results.",
10446.txt,"Text Generation With GANs: In order to make stories seem more human-like, Lin  used generative adversarial networks to measure human likeness of generated text, forcing the network toward more natural reading output.",
10447.txt,"GANs are based on the concept of a minimax two-player game, in which a generative network and a discriminative network are designed to work against each other with the discriminator attempting to determine whether examples are from the generative network or the training set, and the generator trying to maximize the number of mistakes made by the discriminator.",
10448.txt,"RankGAN, the GAN used in the study, measured differences in embedding space, rather than in output tokens.",
10449.txt,"This meant that the story content was evaluated more directly, without respect to the specific words and grammars used to tell it.",
10450.txt,"Rather than simply using standard metrics and minimizing loss, Tambwekar  used reinforcement learning to train a text generation model.",
10451.txt,This taught the model to not only attempt to optimize metrics but also to generate stories that humans evaluated to be meaningful.,
10452.txt,"Zhang  used another modified GAN, referred to as textGAN, for text generation, employing an LSTM generator and a CNN discriminator, achieving a promising bilingual evaluation understudy score and a high tendency to reproduce realistic-looking sentences.",
10453.txt,GANs have seen increasing use in text generation recently .,
10454.txt,Another interesting type of network is the variational autoencoder .,
10455.txt,"While GANs attempt to produce output indistinguishable from actual samples, VAEs attempt to create output similar to samples in the training set .",
10456.txt,"Several recent studies have used VAEs for text generation, including Wang , who adapted it by adding a module for learning a guiding topic for sequence generation, producing good results.",
10457.txt,Summary of T ext Generation: Humor and poetry generation are still understudied topics.,
10458.txt,"As machine-generated texts improve, the desire for more character, personality, and color in the texts will almost certainly emerge.",
10459.txt,"Hence, it can be expected that research in these areas will increase.",
10460.txt,"While story generation is improving, coherence is still a major problem, especially for longer stories.",
10461.txt,"This has been addressed in part, by Haltzman,who have proposed ""nucleus sampling"" to help counteract this problem, performing their experiments using the GPT-2 model.",
10462.txt,"In addition to issues with lack of creativity and coherence, creating metrics to measure any sort of creative task is difficult, and therefore, human evaluations are the norm, often utilizing Amazon's Mechanical Turk.",
10463.txt,"However, recent works have proposed metrics that make a large step toward reliable automatic evaluation of generated text.",
10464.txt,"In addition to the more creative tasks surveyed here, a number of others were previously discussed by Gatt and Krahmer.",
10465.txt,"The use of deep learning for image captioning has been surveyed very recently, and tasks that generate text given textual inputs are discussed in Sections IV-EIV-G.  Summarization Summarization finds elements of interest in documents in order to produce an encapsulation of the most important content.",
10466.txt,There are two primary types of summarization: extractive and abstractive.,
10467.txt,"The first focuses on sentence extraction, simplification, reordering, and concatenation to relay the important information in documents using text taken directly from the documents.",
10468.txt,"Abstractive summaries rely on expressing documents' contents through generation-style abstraction, possibly using words never seen in the documents.",
10469.txt,"Rush introduced deep learning to summarization, using an FFNN.",
10470.txt,The language model used an encoder and a generative beam search decoder.,
10471.txt,"The initial input was given directly to both the language model and the convolutional attention-based encoder, which determined contextual importance surrounding the summary sentences and phrases.",
10472.txt,The performance of the model was comparable to other state-ofthe-art models of the time.,
10473.txt,"As in other areas, attention mechanisms have improved the performance of encoderdecoder models.",
10474.txt,Krantz and Kalita compared various attention models for abstractive summarization.,
10475.txt,A state-of-the-art approach developed by Paulus used a multiple intratemporal attention encoder mechanism that considered not only the input text tokens but also the output tokens used by the decoder for previously generated words.,
10476.txt,"They also used similar hybrid cross-entropy loss functions to those proposed by Ranzato , which led to decreases in training and execution by orders of magnitude.",
10477.txt,"Finally, they recommended using strategies seen in reinforcement learning to modify gradients and reduce exposure bias, which has been noted in models trained exclusively via supervised learning.",
10478.txt,The use of attention also boosted accuracy in the fully convolutional Authorized licensed use limited to: University of Canberra.,
10479.txt,They encoded the input sequence using BERT.,
10480.txt,The decoder had two stages.,
10481.txt,"In the first stage, a transformer-based decoder generated a draft output sequence.",
10482.txt,"In the second stage, they masked each word of the draft sequence and fed it to BERT, and then by combining the input sequence and the draft representation generated by BERT, they used a transformer-based decoder to predict the refined word for each masked position.",
10483.txt,Their model achieved state-of-the-art performance on the CNN/Daily Mail and New York Times data sets.,
10484.txt,"Question Answering Similar to summarization and information extraction, question answering gathers relevant words, phrases, or sentences from a document.",
10485.txt,QA coherently returns this information in response to a request.,
10486.txt,Current methods resemble those of summarization.,
10487.txt,Wang et al.,
10488.txt,used a gated attention-based recurrent network to match the question with an answer-containing passage.,
10489.txt,A self-matching attention mechanism was used to refine the machine representation by mapping the entire passage.,
10490.txt,Pointer networks were used to predict the location and boundary of an answer.,
10491.txt,"These networks used attention-pooling vector representations of passages, as well as the words being analyzed, to model the critical tokens or phrases necessary.",
10492.txt,Multicolumn CNNs were used by Dong  to automatically analyze questions from multiple viewpoints.,
10493.txt,Parallel networks were used to extract pertinent information from input questions.,
10494.txt,Separate networks were used to find context information and relationships and to determine which forms of answers should be returned.,
10495.txt,The output of these networks was combined and used to rank possible answers.,
10496.txt,Santoro used relational networks for summarization.,
10497.txt,"First proposed by Raposo, RNs are built upon an MLP architecture, with a focus on relational reasoning, defining relationships among entities in the data.",
10498.txt,These feedforward networks implement a similar function among all pairs of objects in order to aggregate correlations among them.,
10499.txt,"For input, the RNs took final LSTM representations of document sentences.",
10500.txt,These inputs were further paired with a representation of the information request given .Yang  demonstrated an end-to-end QA system that integrates BERT with the open-source Anserini IR toolkit.,
10501.txt,"This system can identify answers from a large corpus of Wikipedia articles in an end-to-end fashion, obtaining the best results on a standard benchmark test collection.",
10502.txt,G. Machine Translation Machine translation is the quintessential application of NLP .,
10503.txt,It involves the use of mathematical and algorithmic techniques to translate the documents in one language to another.,
10504.txt,"Performing effective translation is intrinsically onerous even for humans, requiring proficiency in areas such as morphology, syntax, and semantics, as well as an adept understanding and discernment of cultural sensitivities, for both of the languages under consideration.",
10505.txt,"The first attempt at NMT was that by Schwenk , although neural models had previously been used for the similar task of transliteration, converting certain parts of text, such as proper nouns, into different languages .",
10506.txt,"Schwenk used a feedforward network with seven-word inputs and outputs, padding and trimming when necessary.",
10507.txt,The ability to translate from a sentence of one length to a sentence of another length came about with the introduction of encoderdecoder models.,
10508.txt,"The first use of such a model, by Kalchbrenner and Blumson, stemmed from the success of continuous recurrent representations in capturing syntax, semantics, and morphology  in addition to the ability of RNNs to build robust language models.",
10509.txt,This original NMT encoderdecoder model used a combination of generative convolutional and recurrent layers to encode and optimize a source language model and cast this into a target language.,
10510.txt,"The model was quickly reworked and further studied by Cho, and numerous novel and effective advances to this model have since been made].",
10511.txt,"Encoderdecoder models have continuously defined the state of the art, being expanded to contain dozens of layers, with residual connections, attention mechanisms, and even residual attention mechanisms allowing the final decoding layer to attend to the first encoding layer.",
10512.txt,"State-of-the-art results have also been achieved by using numerous convolutional layers in both the encoder and decoder, allowing information to be viewed in several hierarchical layers rather than a multitude of recurrent steps .",
10513.txt,"Such derived models are continually improving, finding answers to the shortcomings of their predecessors and overcoming any need for hand engineering .",
10514.txt,"Recent progress includes effective initialization of decoder hidden states, use of conditional gated attentional cells, removal of bias in embedding layers, use of alternative decoding phases, factorization of embeddings, and test time use of the beam search algorithm .",
10515.txt,"The standard initialization for the decoder state is that proposed by Bahdanau , using the last backward encoder state.",
10516.txt,"However, as noted by Britz , using the average of the embedding or annotation layer seems to lead to the best translations.",
10517.txt,"Gated recurrent cells have been the gold standard for sequence-to-sequence tasks, a variation of which is a conditional GRU , most effectively utilized with an attention mechanism.",
10518.txt,A cGRU cell consists of three key components: two GRU transition blocks and an attention mechanism between them.,
10519.txt,"These three blocks combine the previous hidden state, along with the attention context window to generate the next hidden state.",
10520.txt,"Altering the decoding process  from look at input, generate output token, update hidden representation to a process of look, update, a n d generate can simplify the final decoding.",
10521.txt,"Adding further source attributes, such as morphological segmentation labels, POS tags, and syntactic dependency labels, improves models, and concatenating or factorizing these with embeddings increases robustness further.",
10522.txt,"For remembering long-term dependencies, vertically stacked recurrent units have been the standard, with the optimum number of layers having been determined to be roughly between 2 and 16 , depending on the desired input length as well as Authorized licensed use limited to: University of Canberra.",
10523.txt,"At test time, a beam search algorithm can be used beside the final softmax layer for considering multiple target predictions in a greedy fashion, allowing the best predictions to be found without looking through the entire hypothesis space.",
10524.txt,"In a direction diverging from previous work, Vaswani and Ahmed  proposed discarding the large number of recurrent and convolutional layers and instead focusing exclusively on attention mechanisms to encode a language globally from input to output.",
10525.txt,"Preferring such ""self-attention"" mechanisms over traditional layers is motivated by the following three principles: reducing the complexity of computations required per layer, minimizing sequential training steps, and, finally, abating the path length from input to output and its handicap on the learning of the long-range dependencies that are necessary in many sequencing tasks.",
10526.txt,"Apart from increased accuracy across translation tasks, self-attention models allow more parallelization throughout architectures, decreasing the training times and minimizing necessary sequential steps.",
10527.txt,"At time of writing, the state-of-the-art model generating the best results for English to German and English to French on the International Workshop on Spoken Language Translation 2014 test corpus is that of Medina and Kalita , which modified the model proposed by Vaswani to use parallel self-attention mechanisms, rather than stacking them as was done in the original model.",
10528.txt,"In addition to improving BLEU scores , this also reduced training times.",
10529.txt,Ghazvininejad recently applied BERT to the machine translation task using constant-time models.,
10530.txt,They were able to achieve relatively competitive performance in a fraction of the time.,
10531.txt,"Lample and Conneau attained state-of-the-art results, performing unsupervised machine translation using multiple languages in their language model pretraining.",
10532.txt,Several of the recent state-of-the-art models were examined by Chen.,
10533.txt,The models were picked apart to determine which features were truly responsible for their strength and to provide a fair comparison.,
10534.txt,"Hybrid models were then created using this knowledge, and incorporating the best parts of each previous model, outperforming the previous models.",
10535.txt,"In addition to creating two models with both a self-attentive component and a recurrent component , they determined four techniques that they believe should always be employed, as they are crucial to some models, at best, and neutral to all models examined, at worst.",
10536.txt,"These are label smoothing, multihead attention, layer normalization, and synchronous training.",
10537.txt,"Another study, by Denkowski and Neubig, examined a number of other techniques, recommending three: using Adam optimization, restarting multiple times, with learning rate annealing; performing subword translation; and using an ensemble of decoders.",
10538.txt,"Furthermore, they tested a number of common techniques on models that were strong to begin and determined that three of the four provided no additional benefits to, or actually hurt, the model, those three being lexicon bias , pretranslation, and dropout.",
10539.txt,"They did find, however, that data bootstrapping  was advantageous even to models that are already high performing.",
10540.txt,They recommended that future developments be tested on top-performing models in order to determine their realm of effectiveness.,
10541.txt,"In addition to studies presenting recommendations, one study has listed a number of challenges facing the field.",
10542.txt,"While neural machine translation models are superior to other forms of statistical machine translation models, they require significantly more data, perform poorly outside of the domain in which they are trained, fail to handle rare words adequately, and do not do well with long sentences .",
10543.txt,"Furthermore, attention mechanisms do not perform as well as their statistical counterparts for aligning words, and beam searches used for decoding only work when the search space is small.",
10544.txt,"Surely, these six drawbacks will be, or in some cases, will continue to be, the focus of much research in the coming years.",
10545.txt,"In addition, as mentioned in Section III-D2, NMT models still struggle with some semantic concepts, which will also be a likely area of focus in the upcoming years.",
10546.txt,"While examining some of these failings of NMT can help, predicting the future of research and development in the field is nearly impossible.",
10547.txt,"New models and methods are being reported daily with far too many advancements to survey, and state-of-the-art practices are becoming outdated in a matter of months.",
10548.txt,"Notable recent advancements include using caching to provide networks with greater context than simply the individual sentences being translated, the ability to better handle rare words, and the ability to translate to and from understudied languages, such as those that are polysynthetic.",
10549.txt,"In addition, work has been conducted on the selection, sensitivity, and tuning of hyperparameters, denoising of data , and a number of other important topics surrounding NMT.",
10550.txt,"Finally, a new branch of machine translation has been opened up by groundbreaking research: multilingual translation.",
10551.txt,"A fairly recent study showed that a single, simple neural network could be trained to convert a number of different languages to each other, automatically recognizing the source language and simply needing an input token to identify the output language.",
10552.txt,"Furthermore, the model was found to be capable of understanding, at least somewhat, multilingual input, and of producing mixed outputs when multiple language tokens are given, sometimes even in languages related to, but not actually, those selected.",
10553.txt,"This suggests that DNNs may be capable of learning universal representations for information, independent of language, and even more, that they might possibly be capable of learning some etymology and relationships between and among families of different languages.",
10554.txt,"Summary of Deep Learning NLP Applications Numerous other applications of NLP exist including grammar correction, as seen in word processors, and author mimicking, which, given sufficient data, generates text replicating the style of a particular writer.",
10555.txt,"Many of these applications are infrequently used, understudied, or not yet exposed to deep learning.",
10556.txt,"However, the area of sentiment analysis should be noted, as it is becoming increasingly popular and utilizing deep learning.",
10557.txt,"In large part a semantic task, it is the extraction of a writer's sentimenttheir positive, negative, or neutral Authorized licensed use limited to: University of Canberra.",
10558.txt,"Applications are varied, including product research, futures prediction, social media analysis, and classification of spam.",
10559.txt,"The current state of the art uses an ensemble, including both LSTMs and CNNs.",
10560.txt,This section has provided a number of select examples of the applied usages of deep learning in NLP.,
10561.txt,"Countless studies have been conducted in these and similar areas, chronicling the ways in which deep learning has facilitated the successful use of natural language in a wide variety of applications.",
10562.txt,Only a minuscule fraction of such work has been referred to in this survey.,
10563.txt,"While more specific recommendations for practitioners have been discussed in some individual sections, the current trend in state-of-the-art models in all application areas is to use pretrained stacks of transformer units in some configuration, whether in encoderdecoderconfigurations or just as encoders.",
10564.txt,"Thus, self-attention, which is the mainstay of transformer, has become the norm, along with cross attention between the encoder and decoder units, if decoders are present.",
10565.txt,"In fact, in many recent articles, if not most, transformers have begun to replace LSTM units that were preponderant just a few months ago.",
10566.txt,Pretraining of these large transformer models has also become the accepted way to endow a model with generalized knowledge of language.,
10567.txt,"Models such as BERT, which have been trained on corpora of billions of words, are available for download, thus providing a practitioner with a model that possesses a great amount of general knowledge of language already.",
10568.txt,"A practitioner can further train it with one's own general corpora, if desired, but such training is not always necessary, considering the enormous sizes of the pretraining that downloaded models have received.",
10569.txt,"To train a model to perform a certain task well, the last step that a practitioner must go through is to use available downloadable task-specific corpora or build one's own task-specific corpus.",
10570.txt,This last training step is usually supervised.,
10571.txt,"It is also recommended that if several tasks are to be performed, multitask training is used wherever possible.",
10572.txt,"Early applications of NLP included a well-acclaimed but simpleminded algebra word problem solver program called student, as well as interesting but severely constrained conversational systems such as Eliza, which acted as a ""psychotherapist"" , and another that conversed about manipulating blocks in a microworld.",
10573.txt,"Nowadays, highly advanced applications of NLP are ubiquitous.",
10574.txt,"These include Google's and Microsoft's machine translators, which translate more or less competently from a language to scores of other languages, as well as a number of devices which process voice commands and respond in like.",
10575.txt,"The emergence of these sophisticated applications, particularly in deployed settings, acts as a testament to the impressive accomplishments that have been made in this domain over the last sixty or so years.",
10576.txt,"Without a doubt, incredible progress has taken place, particularly in the last several years.",
10577.txt,"As has been shown, this recent progress has a clear causal relationship with the remarkable advances in ANNs.",
10578.txt,"Considered an ""old"" technology just a decade ago, these machine learning constructs have ushered in progress at an unprecedented rate, breaking performance records in myriad tasks in miscellaneous fields.",
10579.txt,"In particular, deep neural architectures have instilled models with higher performance in natural language tasks, in terms of ""imperfect"" metrics.",
10580.txt,"Consolidating the analysis of all the models surveyed, a few general trends can be surmized.",
10581.txt,"Both convolutional and recurrent specimens had contributed to the state of the art in the recent past; however, of very late, stacks of attention-powered transformer units as encoders and often decoders have consistently produced superior results across the rich and varying terrain of the NLP field.",
10582.txt,These models are generally heavily pretrained on general language knowledge in an unsupervised or supervised manner and somewhat lightly trained on specific tasks in a supervised fashion.,
10583.txt,"Second, attention mechanisms alone, without recurrences or convolutions, seem to provide the best connections between encoders and decoders.",
10584.txt,"Third, forcing networks to examine different features usually improves results.",
10585.txt,"Finally, while highly engineering networks usually optimizes results, there is no substitute for cultivating networks with large quantities of high-quality data, although pretraining on large generic corpora seems to help immensely.",
10586.txt,"Following from this final observation, it may be useful to direct more research effort toward pretraining methodologies, rather than developing highly specialized components to squeeze the last drops of performance from complex models.",
10587.txt,"While the numerous stellar architectures being proposed each month are highly competitive, muddling the process of identifying a winning architecture, the methods of evaluation used add just as much complexity to the problem.",
10588.txt,"Data sets used to evaluate new models are often generated specifically for those models and are then used only several more times, if at all, although consolidated data sets encompassing several tasks such as GLUE have started to emerge.",
10589.txt,"As the features and sizes of these data sets are highly variable, this makes comparison difficult.",
10590.txt,"Most subfields of NLP, as well as the field as a whole, would benefit from extensive, large-scale discussions regarding the necessary contents of such data sets, followed by the compilation of such sets.",
10591.txt,"In addition to high variability in evaluation data, there are numerous metrics used to evaluate performance on each task.",
10592.txt,"Oftentimes, comparing similar models is difficult because different metrics are reported for each.",
10593.txt,Agreement on particular sets of metrics would go a long way toward ensuring clear comparisons in the field.,
10594.txt,"Furthermore, metrics are usually only reported for the best case, with few mentions of average cases and variability, or of worst cases.",
10595.txt,"While it is important to understand the possible performance of new models, it is just as important to understand the standard performance.",
10596.txt,"If models produce highly variable results, they may take many attempts to train to the cutting-edge levels reported.",
10597.txt,"In most cases, this is undesirable, and models that can be consistently trained to relatively high levels of performance are preferable.",
10598.txt,"While increasingly large numbers of randomized parameters do reduce variation in performance, some variance will always exist, necessitating the reporting of more than just best case metrics.",
10599.txt,One final recommendation for future work is that it is directed toward a wider variety of languages than it is at present.,
10600.txt,"Currently, the vast majority of research in NLP is conducted on the English language, with another sizeable portion using Mandarin Chinese.",
10601.txt,"In translation tasks, English Authorized licensed use limited to: University of Canberra.",
10602.txt,"This neglects entire families of languages, as well as the people who speak them.",
10603.txt,"Many linguistic intricacies may not be expressed in any of the languages used and, therefore, are not captured in current NLP software.",
10604.txt,"Furthermore, there are thousands of languages spoken throughout the world, with at least 80 spoken by more than 10 million people, meaning that current research excludes an immense segment of humankind.",
10605.txt,"Collection and validation of data in underanalyzed languages, as well as testing NLP models using such data, will be a tremendous contribution to not only the field of NLP but also to human society as a whole.",
10606.txt,"Due to the small amounts of data available in many languages, the authors do not foresee the complete usurpation of traditional NLP models by deep learning any time in the near future.",
10607.txt,Deep learning models are extremely data hungry.,
10608.txt,"Contrastingly, many traditional models require only relatively small amounts of training data.",
10609.txt,"However, looking further forward, it can be anticipated that deep learning models will become the norm in computational linguistics, with pretraining and transfer learning playing highly impactful roles.",
10610.txt,"Collobert sparked the deep learning revolution in NLP , although one of the key contributions of their workthat of a single unified modelwas not realized widely.",
10611.txt,"Instead, neural networks were introduced into traditional NLP tasks and are only now reconnecting.",
10612.txt,"In the field of parsing, for example, most models continue to implement nonneural structures, simply using ANNs on the side to make the decisions that were previously done using rules and probability models.",
10613.txt,"While more versatile and general architectures are obviously becoming more and more of a reality, understanding the abstract concepts handled by such networks is important to understanding how to build and train better networks.",
10614.txt,"Furthermore, as abstraction is a hallmark of human intelligence, understanding of the abstractions that take place inside an ANN may aid in the understanding of human intelligence and the processes that underlie it.",
10615.txt,"Just as human linguistic ability is only a piece of our sentience, so is linguistic processing just a small piece of artificial intelligence.",
10616.txt,"Understanding how such components are interrelated is important in constructing more complete AI systems, and creating a unified NLP architecture is another step toward making such a system a reality.",
10617.txt,This goal will also be aided by further advances in computational equipment.,
10618.txt,"While GPUs have significantly improved the ability to train deep networks, they are only a step in the right direction.",
10619.txt,"The next step is the wider availability of chips designed specifically for this purpose, such as Google's Tensor Processing Unit, Microsoft's Catapult, and Intel's Lake Crest.",
10620.txt,"Ultimately, ANNs implemented in traditional von Neumann style computers may not be able to reach their full potential.",
10621.txt,"Luckily, another old line of work in computer science and engineering has seen a resurgance in recent years: neuromorphic computing.",
10622.txt,"With neuromorphic chips, which implement neural structures at the hardware level, expected much more widely in the coming years , the continuation of deep learning and the longevity of its success can be highly anticipated, ensuring the opportunity for sustained progress in NLP.",
10623.txt,We announce a new video quality model that accounts for the perceptual impact of variable frame delays in videos with demonstrated top performance on the laboratory for image and video engineering  mobile video quality assessment  database.,
10624.txt,"This model, called VQM_VFD, uses perceptual features extracted from spatialtemporal blocks spanning fixed angular extents and a long edge detection filter.",
10625.txt,VQM_VFD predicts video quality by measuring multiple frame delays using perception based parameters to track subjective quality over time.,
10626.txt,"In the performance analysis of VQM_VFD, we evaluated its efficacy at predicting human opinions of visual quality.",
10627.txt,A detailed correlation analysis and statistical hypothesis testing show that VQM_VFD accurately predicts human subjective judgments and substantially outperforms top-performing image quality assessment and VQA models previously tested on the LIVE mobile VQA database.,
10628.txt,"VQM_VFD achieved the best performance on the mobile and tablet studies of the LIVE mobile VQA database for simulated compression, wireless packet-loss, and rate adaptation, but not for temporal dynamics.",
10629.txt,"It contains a variety of video impairments that are typical of heavily loaded wireless networks, including dynamically varying distortions such as frame freeze and time varying compression rates, as well as static distortions such as compression and wireless packet loss.",
10630.txt,"In August of 2012, LIVE made these video sequences and subjective scores available upon request to researchers.",
10631.txt,One goal is to encourage development of improved video quality models that are appropriate for mobile video applications.,
10632.txt,Objective video quality models are struggling to catch up with the impact of multiple system delays on users' perception of video quality.,
10633.txt,Most models were designed under the one system delay paradigm.,
10634.txt,"Two examples are Peak Signal to Noise Ratio and the NTIA General Model, released in 2001 under the name Video Quality Metric.",
10635.txt,This model was designed to accommodate the reality of multiple system delays.,
10636.txt,"Code implementing VQM_VFD is freely available for any purpose, commercial or non-commercial .",
10637.txt,"VQM_VFD was soft released with a small announcement, while independent analyses were being sought.",
10638.txt,Another goal of the LIVE Mobile VQA database was to analyze the performance of existing objective video quality models for mobile applications.,
10639.txt,Moorthy  analyzed the performance of eleven objective video quality models.,
10640.txt,Their conclusion was that existing VQA algorithms are not well-equipped to handle distortions that vary over time.,
10641.txt,"This analysis did not include VQM_VFD, as the authors were not aware of each other's work.",
10642.txt,We have recently employed the LIVE Mobile VQA database to independently analyze the performance of the VQM_VFD model.,
10643.txt,"The VQA database was not made available to NTIA until after the analyses listed in this report were completed .VQM was trained on 11 datasets, containing a total of 1536 subjectively rated video sequences .",
10644.txt,"For practical reasons, such as the difficulty of getting in-service access to original videos, the software implementations of VQM are full reference .",
10645.txt,This means that the entire original video and processed video are available at one location.,
10646.txt,An overview of these and other model types is provided by Wang and Jiang .,
10647.txt,"By 2010, NTIA had access to 83 datasets, containing a total of 11,255 subjectively rated video sequences.",
10648.txt,"Five combined datasets were created, each with one image size..",
10649.txt,This enabled the combined datasets to be used for developing and testing the output mapping.,
10650.txt,NTIA decided to develop a new FR model to replace VQM.,
10651.txt,"The first are FR calibration routines 1As of the date this article was submitted for publication, Google Scholar finds 655 citations associated with .",
10652.txt,"This does not capture papers that cite VQM with , ITU-T Rec.",
10653.txt,"J.144, or ITU-R Rec.",
10654.txt,BT.1683.,
10655.txt,defined in X.,
10656.txt,The second are reduced reference calibration routines defined in X.,
10657.txt,"Measurement of Multiple Frame Delays Digital video transmission systems can produce pauses in the video presentation, after which the video may continue with or without skipping video frames.",
10658.txt,Sometimes sections of the original video stream may be missing entirely.,
10659.txt,Time varying delays of the output video frames with respect to the input video frames present significant challenges for FR video quality measurement systems.,
10660.txt,Time alignment errors between the output video sequence and the input video sequence can produce measurement errors that greatly exceed the perceptual impact of these time varying video delays.,
10661.txt,Wolf  describes an algorithm that finds the best matching original frame for each received frame.,
10662.txt,This variable frame delay algorithm does pixel-by-pixel comparisons between each received frame and a range of original video frames.,
10663.txt,A heuristic algorithm chooses the set of most likely matching frames.The original video sequence is then modified so it matches the processed video sequence.,
10664.txt,"For instance, if the received video sequence repeats every other frame, then the original sequence would match this behavior.",
10665.txt,"The VFD information generated from this step, together with the calibrated processed video, and the VFD-matched original video are sent to the objective model.",
10666.txt,"In thisway,theobjective model predicts qualitybased oncorrectly aligned original and distorted frames, and on the estimated annoyance of frame delay variations and frame repetition.",
10667.txt,"In our experiments, PSNR_VFD is run twice: once with the FR calibration routines  and once with the RR calibration routines .",
10668.txt,"Next, SInis separated into HVnand HVn, such that HVn contains the horizontal-vertical edges, and HVncontains the diagonal edges.",
10669.txt,Low energy edges are omitted.,
10670.txt,Filter SInassumes that subjects focus on long edges and tend to ignore short edges.,
10671.txt,"As the filter size increases , individual pixels and small details have a decreasing impact on the edge strength and angle calculation.",
10672.txt,"By contrast, Sobel (3  3) responds identically to short and long edges.",
10673.txt,"The optimal SInfilter size depends upon the resolution of the target video and, consequently, the length of interesting edges.",
10674.txt,The filter adapts in size to the video resolution.,
10675.txt,The differences between original and processed features are computed by estimating the change in HV edge energy.,
10676.txt,"This produces one parameter value per ST block, where decreasing values of pHVL indicate the processed video has lost horizontal & vertical edge energy.",
10677.txt,The visual masking function in X implies that impairment perception is inversely proportionate to the amount of local activity.,
10678.txt,The HV_Loss parameter in VQM was oversensitive to impairments for scenes with low and high luma levels and low and high motion levels.,
10679.txt,"Thus, VQM_VFD's HV_Loss parameter includes a quadratic weighting function that de-weights ST blocks containing low and high luma levels and/or low and high motion levels.",
10680.txt,These weighting functions reduce the magnitude of impairments detected in individual ST-blocks.,
10681.txt,A minimum threshold eliminates erratic behavior from imperceptible impairments.,
10682.txt,The SInfilter adapts in size to the video resolution as per HV_Loss.,
10683.txt,The difference between original and processed video is computed by estimating the loss in SI edge energy.,
10684.txt,"VFD ignores pure frame freezes, for example from a constant reduction to the frame rate, and errs on the side of detecting no impairment when the VFD alignments are ambiguous.",
10685.txt,This parameter is triggered by video clips that contain both temporal distortions impacting the pattern of frames  and spatial distortions impacting individual frames.,
10686.txt,This training emphasized manual inspection of individual received sequences and VFD delay traces.,
10687.txt,"The remaining parameters were chosen for consistent performance across all five combined datasets, either in isolation or as a complement to the other parameters.",
10688.txt,The final form for each parameter was determined by calculating numerous variations.,
10689.txt,The parameter variant and parameter combinations were experimentally determined via searches of the five combined databases using Pearson's correlation coefficient.,
10690.txt,A neural network is used to combine these eight objective video quality parameters.,
10691.txt,Schematic diagram of the three different rateswitches in a video stream simulated in this paper.,
10692.txt,and 30% NN testing.,
10693.txt,"The outputs of these eight tansig neurons are then weighted, summed together with a bias, and sent to a purelinear output neuron.",
10694.txt,"There are thus 72 weights and nine biases in the NN, for a total of 81 free parameters, which are determined in the training phase.",
10695.txt,A tansig/purelin NN was chosen because of its ability to act as a generalized function approximator.,
10696.txt,One possible reason for the difficulty in obtaining a robust color distortion measure that brings added information to the VQM_VFD model might be the lack of independent color distortions in the subject datasets.,
10697.txt,Distortions that appear in the chroma channels nearly always also appear in the luma channel.,
10698.txt,"Another reason might be that some of the color distortions are actually pleasing to the eye.Thus, a color distortion metric probably needs to be bipolar, where some distortions produce increases in subjective quality while others produce decreases in subjective quality.",
10699.txt,These databases are available to the research community free of charge.,
10700.txt,The recently-released LIVE Mobile VQA database focuses on video quality distortions typical of a heavily-trafficked wireless network.,
10701.txt,"The goal was to make a dataset available 3Certain commercial equipment, materials, and/or programs are identified in this report to specify adequately the experimental procedure.",
10702.txt,"In no case does such identification imply recommendation or endorsement by the authors or their employers, nor does it imply that the program or equipment identified is necessarily the best available for this application.",
10703.txt,to researchers that aids the development of perceptually optimized VQA algorithms for wireless video transmission on mobile devices and that helps the design of video streaming strategies for video network resource allocation and rate adaptation as a function of time.,
10704.txt,It is useful for our purposes since it includes systematic simulations of realistic distortion including changes in delay.,
10705.txt,TThe final scene pool contains 12 videos that depict a variety of content types.,
10706.txt,"Two of these videos were used for training the human subjects, while the rest were used in the actual study.",
10707.txt,"For each scene, four encoding levels were chosen that show unmistakably different quality levels.",
10708.txt,The JM reference implementation of H.264 scalable video codec  was used with fixed Quantization Parameter  encoding.This perceptual separation makes it possible for people to produce consistent judgments of visual quality.,
10709.txt,"Because the source video content is quite varied, the resulting bitrates vary between 0.7 Mbps and 6 Mbps.",
10710.txt,The LIVE Mobile VQA database consists of 10 reference videos and 200 distorted videos.,
10711.txt,"The distortions simulate most common mobile video impairments as follows:  Compression: This subset contains coding-only impairments R1, R2, R3and R4for each sequence.",
10712.txt,Rate Adaptation: This subset explores the quality impact of rate changes of different magnitudes.,
10713.txt,"The video sequence began with an encoding rate of either R1, R2or R3then after 5 seconds switched to the highest rate, then again after 5 seconds switched back down to the original rate.",
10714.txt,Three rate adaptations are illustrated in Fig.2.,
10715.txt,Overall score rating bar.,
10716.txt,These patterns were designed to evaluate two types of switch patterns: abrupt and smooth .,
10717.txt,Each new rate was presented for between 3 and 5 seconds.,
10718.txt,"Wireless Packet Loss: The H.264 bitstream  was impaired using a Rayleigh fading channel, which was modeled by an IEEE 802.11 based wireless channel simulator.",
10719.txt,"Bit errors due to attenuation, shadowing, fading and multiuser interference in wireless channels cause spatiotemporal transient distortions which appear as glitches in videos.",
10720.txt,5The experimenters were unable to detect any differences between the visual quality of the uncompressed video files and quality of the compressed video streams.,
10721.txt,"The video files used by objective models do not include this compression, nor do they include the resolution due to the monitor or playback software.",
10722.txt,"Testing took place at the LIVE subjective testing lab, using software that was specially created for the Android platform to display videos.",
10723.txt,"The subjects rated the videos as a function of time during the playback, yielding continuous temporal quality scores using an uncalibrated bar that spanned the bottom of the screen.",
10724.txt,"Subjects also rated the overall quality at the end of each video, using a similar bar .",
10725.txt,"A total of 36 subjects attended the mobile study, and 17 subjects participated in the tablet study.",
10726.txt,Most of the subjects were undergraduate students between 22 and 28 years old.,
10727.txt,"Although no vision test was executed, a verbal confirmation of soundness of vision was obtained from each subject.",
10728.txt,Each subject attended two separate sessions.,
10729.txt,"Each session lasted less than 30 minutes, and consisted of the subject viewing 55 videos in randomized order .",
10730.txt,A short training set  preceded the study.,
10731.txt,Differential Mean Opinion Scores were calculated as the difference between the score that the subject gave the reference video and the score for the distorted video.,
10732.txt,The overall scores were used to evaluate the Image Quality Assessment and Video Quality Assessment models.,
10733.txt,D. Evaluation of Subjective Opinion This section summarizes trends indicated by the subjective scores.,
10734.txt,This analysis uses the overall scores.,
10735.txt,The design goal of the compression subset was achieved.,
10736.txt,Subjective opinion of each compression rate was statistically better than of the next lower rate for all contents.,
10737.txt,"Subjects also preferred not to lose content after a frame-freeze, however that preference was less pronounced.",
10738.txt,"For example, subjects preferred two 4 sec framefreezes with loss of content over eight 1 sec frame freezes with no loss of content.",
10739.txt,A Student's t-test on the DMOS results for the rate adaptation and temporal dynamics subsets showed that the timevarying quality of a video had a definite and quantifiable impact.,
10740.txt,"When variations in quality occurred, the opinion scores were influenced by the magnitude, order, and duration of those quality level changes.",
10741.txt,The rate adaptation subset analysis indicated that it is preferable to switch from a low rate to a higher rate when the higher rate segment lasts at least half as long as the lower rate.,
10742.txt,"This study only included rate increases that lasted at least 5 seconds, so further study is needed.",
10743.txt,"Nonetheless, this conclusion parallels a speech quality subjective test that analyzed time varying quality in talk-spurts.",
10744.txt,A change in the lowest rate has a clear impact on visual quality.,
10745.txt,The temporal dynamics subset analysis indicated that it is preferable to switch to an intermediate rate before switching to a higher or lower rate.,
10746.txt,An abrupt change of bitrate received a statistically significantly lower score .,
10747.txt,A comparison between the coding subset and the temporal dynamics subset showed a preference for constant bitrates.,
10748.txt,"For example, R3is favored over R2?R4?R2.",
10749.txt,This preference is not explained by a weighted sum of the compressiononly DMOS scores for rates R2and R4.,
10750.txt,"This behavior could indicate a quality penalty for changing video bitrates, as V oran and Catellier demonstrated can occur when the audio coding bitrate of a talk-spurt is increased.",
10751.txt,We interpret this to mean that humans perceive multiple changes in quality level as attempts to provide better quality and appear to reward those endeavors.,
10752.txt,The overall quality scores were impacted by the quality at the end of the clip.,
10753.txt,This supports the forgiveness effect theory proposed by Hands .,
10754.txt,"Regarding the comparison of subjective opinions between the mobile and the tablet study, subjects seemed to be more sensitive to dynamically varying distortions displayed on the tablet device.",
10755.txt,The higher resolution or larger screen size of the display probably caused those distortions to be more perceptible.,
10756.txt,Another valuable reflection is that the variable frame delay approach is beneficial for the prediction of video quality.,
10757.txt,Comments on LIVE Mobile VQA Database The new LIVE Mobile VQA database opens fertile ground for researchers to test and develop perceptually improved VQA algorithms as well as providing analysis of human behavior to support successful video streaming strategies.,
10759.txt,"Due to limitations of the study session durations, the dataset could not include several other interesting scenarios, such as multiple rate changes between different quality levels, a large number of rate changes, a single change with a high quality segment at the end and so on.",
10760.txt,Longer video sequences with rate switch simulations to analyze time varying quality would also be beneficial for better understanding human perception of visual quality.,
10761.txt,We looked at short term effects in this current study.,
10762.txt,FR calibration is more accurate but does not check for spatial scaling.,
10763.txt,RR calibration version 2 checked whether or not the codec spatially scales the video.,
10764.txt,"Estimation of spatial scaling can be achieved with RR calibration, but the problem is ill-suited for FR calibration.",
10765.txt,"Correlations Against Subjective Opinion The wide variety of FR IQA/VQA algorithms listed in Table I were compared using the Spearman Rank Order Correlation Coefficient , the Pearson's  Correlation Coefficient, and the root mean-squarederror .",
10766.txt,"The SROCC measures the monotonicity of the objective algorithm prediction with human scores, while the LCC assesses the prediction accuracy.",
10767.txt,The LCC and the RMSE were computed after performing a non-linear regression on the objective algorithm scores using a logistic function prescribed in X.Table II shows the SROCC and LCC for 4There were two exceptions.,
10768.txt,The fitting failed for MOVIE; instead the logistic in X was used.,
10769.txt,There was a discrepancy in the logistic function used for the computation of the LCC for VQM.,
10770.txt,"Here, we use the logistic function defined in X.",
10771.txt,Table III tabulates the RMSE between the algorithm scores and DMOS for each distortion subset.,
10772.txt,"For each column of Table III, the bold font highlights the top performing model and all statistically equivalent models.",
10773.txt,"RMSE is used to compare model performance on different subsets, because these RMSE values can be directly compared to each other.",
10774.txt,Pinson demonstrate how LCC drops as the range of quality narrows.,
10775.txt,VQM_VFD showed the best performance for the entire LIVE Mobile VQA database in both the mobile and tablet studies.,
10776.txt,"Since FR and RR calibration options showed almost no determinant differences on high correlation coefficients, we analyzed the performance across calibrations.",
10777.txt,"The tables indicate that the new VQM_VFD model takes into account time varying video delays, and thus is a notable improvement on the previous VQM model.",
10778.txt,"VQM_VFD also outperforms the two top performing models from X, VSNR and VIF, which are true wavelet decomposition based IQA algorithms.",
10779.txt,These results imply that VQM_VFD is quite well correlated with human opinion and properly accounts for the importance of modeling variable frame delays in perceptual VQA.,
10780.txt,VQM_VFD was either the top performing model or statistically equivalent to the top performing model for each data subset.,
10781.txt,"Looking horizontally across Table III, notice that the RMSE values for the temporal dynamics subset are similar to those received by the other subsets.",
10782.txt,"Nonetheless, the temporal dynamics subset identifies a limitation of VQM_VFD.",
10783.txt,Fig.,
10784.txt,4 shows a scatter plot between the VQM_VFD model with FR calibration and DMOS for the mobile and tablet studies.,
10785.txt,Notice that the VQM_VFD scores for the temporal dynamics subset are nearly identical .The VQM_VFD time collapsing functions do not take the order of events into account.,
10786.txt,Almost all other algorithms exhibit a similar behavior.,
10787.txt,This demonstrates that there remains much work to be done on VQA algorithms to enable them to better handle temporal distortions.,
10788.txt,The implication is that these models should take into consideration the order of events.,
10789.txt,"This might have a systematic impact on IQA/VQA models, because a scene's coding complexity can change over time.",
10790.txt,"Among the tested objective IQA/VQA models, PSNR_VFD showed the worst result.",
10791.txt,PSNR_VFD focuses on one aspect of video quality: how well individual frames replicate the original picture.,
10792.txt,PSNR_VFD failed to predict subjective human opinion partly because it does not impose any penalties for dropped or repeated frames and variable video delays.,
10793.txt,Note PSRN_VFD's extraordinarily large RMSE values for the Compression subset.,
10794.txt,This suggests that H.264 SVC makes significant changes to individual frames that people either do not notice or do not find objectionable.Inter-Algorithm Comparison: We executed a statistical analysis of the algorithm scores using the F-statistics as in X and to evaluate whether the correlations of PSNR_VFD and VQM_VFD were significantly different from other algorithms.,
10795.txt,"Specifically, the F-statistic was used to evaluate the variance of the residuals produced after a nonlinear mapping between the two algorithms being compared.Tables IV and V indicate that VQM_VFD significantly outperforms other models.",
10796.txt,Only VIF is competitive with VQM_VFD for the entire database in the hypothesis test.,
10797.txt,This tells us that true multiscale and variable frame delay algorithms like VQM_VFD can improve the performance of objective VQA models for mobile video applications.,
10798.txt,Comparison With the Theoretical Optimal Model: Seshadrinathan and Sheikh propose an alternate method for evaluating the accuracy of an objective video quality model.,
10799.txt,This technique is built on the premise that DMOS is an estimate of the underlying true mean of the entire population; and that an objective model should track this underlying true mean.,
10800.txt,The optimal objective model displays this behavior.,
10801.txt,Objective models estimate mean opinion score.,
10802.txt,This is compared to the variance between the DOS and the algorithm scores .,
10803.txt,"The ratio of the two variables, 2algorithm/ 2null is evaluated with the F-statistic.",
10804.txt,A threshold F-ratio can be determined based on the degrees of freedom exhibited by the numerator and denominator at the 95% confidence level.,
10805.txt,"If the F-statistic is larger than the threshold, the algorithm performance is statistically equivalent to the theoretical optimal model.",
10806.txt,"Table VI indicates that VQM_VFD is equivalent to the theoretical optimal model, when compared to the compression and the wireless subsets.",
10807.txt,"However, none of the algorithms are equivalent to the optimal model when the entire database is considered.",
10808.txt,"Obviously, despite the significant progress of VQM_VFD, there remains considerable opportunity to improve the performance of VQA algorithms with respect to subjective human opinions.",
10809.txt,"We introduced a new video quality model that is able to handle variable frame delays, and successfully captures multiple system delays of the processed video frames with respect to the reference video frames to track subjective quality.",
10810.txt,"The performance of the VQM_VFD was evaluated on the recently-released LIVE Mobile VQA database, which encompasses a wide variety of distortions, including dynamically-varying distortions as well as uniform compression and wireless packet loss.",
10811.txt,This confirms that variable frame delays have a definite impact on human subjective judgments of visual quality and that VQM_VFD significantly contributes to the progress of VQA algorithms.,
10812.txt,"Based on non-optimized code, VQM_VFD takes five times as long to compute as PSNR.",
10813.txt,"Although VQM_VFD performed better than existing topperforming IQA/VQA models tested on the LIVE Mobile VQA database, there remains significant room for improvement.",
10814.txt,The temporal dynamics subset indicates that human subjective opinion is influenced by the time ordering of quality events within short video clips.,
10815.txt,Understanding the reactions of humans to time varying behavior and temporal dynamics may prove helpful in the design of future improved objective VQA algorithms that are appropriate for mobile video applications.,
10816.txt,VSNR and VIF were the best performing IQA models.,
10817.txt,The accuracy of these models implies that there is merit to the idea of an IQA model as the basis of a VQA model.,
10818.txt,The performance differential between VQM and VFD_VQM on the LIVE Mobile VQA database indicates that such IQA based VQA models could benefit by integrating the VFD algorithm.,
10819.txt,"Such integration would require separate training, which is beyond the scope of this paper.",
10820.txt,"Note that the VFD algorithm and SInlong edge detection filter can be used for any purpose, commercial or non-commercial.",
10821.txt,"In this article, we only summarized the portion of the LIVE Mobile database relevant to evaluating PSNR_VFD and VQM_VFD using a performance analysis mirroring the one that Moorthy  did in X.",
10822.txt,The reader is referred to X for a detailed description of the study including the evaluation of temporal quality scores.,
10823.txt,The low noise performance is achieved exclusively through circuit optimization without any process refinements.,
10824.txt,The presented imager relies on a 4T pixel of 6.5m pitch with a properly sized and biased thin oxide PMOS source follower.,
10825.txt,"A full characterization of the proposed image sensor, at room temperature, is presented.",
10826.txt,"Over the last decade, mobile handset and digital cameras occupied the biggest part of the market and fuelled the development of CMOS image sensors for low cost and performance applications.",
10827.txt,For decades charge-coupled devices have been the technology of choice in terms of noise and dynamic range performance.,
10828.txt,"Compared to CMOS active pixel sensors, CCDs are expensive, present higher power consumption, lower speed and preclude on-chip integration.",
10829.txt,"Regarding the sensitivity, the considerable gap between CCDs and CMOS image sensors based on conventional PN junction photodiodes was mainly due to the reset kTC noise.",
10830.txt,The development of pinned photodiodes also known as buried photodiodes in CMOS technology reduced dramatically that gap.,
10831.txt,"Indeed, CMOS image sensors  with PPDs present a lower dark current and a lower noise achieved thanks to the double sampling readout scheme.To this purpose, the noise of the whole readout chain has to be minimized, starting with the thermal noise using conventional circuit techniques, e.g.",
10832.txt,"bandwidth control, in-pixel or column-level amplification and correlated multiple sampling .",
10833.txt,"After thermal noise reduction, the 1/f noise originating from the pixels becomes the dominant noise source.",
10834.txt,"At the circuit level, the correlated double sampling  and CMS reduce dramatically that 1/f noise, but not enough to reach sub-electron noise performance.",
10835.txt,Pixel-level optimization is required in order to further reduce the 1/f noise.,
10836.txt,"It showed that sub-electron performance can be reached, using only circuit techniques, at the cost of a lower dynamic range and higher photo-response nonuniformity.This imager crosses the bridge between highly sensitive lowlight CIS and conventional imagers.",
10837.txt,It demonstrates the efficiency of the proposed design level noise reduction technique that can be easily combined with the process optimizations mentioned above for even more noise reduction.,
10838.txt,This paper is organized as follows.,
10839.txt,Section II reviews the low noise CIS readout chain architecture and noise sources.,
10840.txt,"In Section III, the noise reduction mechanism is recalled.",
10841.txt,Section IV presents the overall architecture of the imager as well as the most important blocks.,
10842.txt,"Section V details the test and characterization of the proposed imager, presents the experimental setup, the measurement method and results.",
10843.txt,Section VI discusses the measurement results.,
10844.txt,The latter can also be performed after analog-to-digital conversion.,
10845.txt,1 shows a schematic of a conventional low-light CIS readout chain together with the pixel timing diagram.,
10847.txt,"Conventional pixels encompass a PPD, a transfer gate , a reset switch, a row selection switch and an SF transistor.",
10848.txt,The PPD accumulates the photo-generated electrons in its buried potential well.,
10849.txt,The transfer gate controls the potential barrier between the PPD and the floating diffusion.,
10850.txt,The SF gate is connected to the floating diffusion in order to sense its voltage level.,
10851.txt,"During the readout, the reset gate is switched-on in order to empty the FD from electrons.",
10852.txt,"The column-level amplifier auto-zero is performed in order to reset the feadback capacitance, cancel the offset and reduce its low frequency noise .",
10853.txt,The floating diffusion voltage reset level is sampled at the output of the column-level amplifier.,
10854.txt,The transfer gate is then switched-on in order to transfer the accumulated photoelectrons to the floating diffusion.,
10855.txt,The voltage level after this operation is again sampled at the output of the columnlevel amplifier and differentiated with the reset level voltage.,
10856.txt,In some low noise CIS the SF transistor is replaced by a gain stage like a common-source  or transimpedance amplifiers.,
10857.txt,It has been shown in a previous work  that a readout chain based on in-pixel gain does not necessarily introduce a lower noise compared to a readout chain with an in-pixel source follower scheme and column-level amplification.,
10858.txt,The CIS readout chain noise mechanisms are depicted in the timing diagram of Fig.,
10859.txt,It shows two types of noise.,
10861.txt,The first is the sampled noise constant in time during one readout of the pixel and randomly changing at the next readout and from pixel to pixel.,
10862.txt,It includes the noise sampled at the sense node after its reset and the noise sampled at the integration capacitor and transferred to the output after the colum-level amplifier AZ .,
10863.txt,This sampled noise originates from the thermal and low frequency noise of the SF stage and the column-level amplifier before opening the AZ switch.,
10864.txt,The second type of noise is the random fluctuation of the signal during the readout originating from the SF stage and the column-level amplifier after opening the AZ switch.,
10865.txt,All these noise sources are uncorrelated and add to each other at the output of the readout chain.,
10866.txt,The double sampling and differentiation performed at the output of the CIS readout chain has two main advantages regarding its noise performance.,
10867.txt,The first one consists in the cancellation of the sampled noise.,
10868.txt,The second one consists in the reduction of the 1/f noise of the SF stage and column-level amplifier.,
10869.txt,"After the double sampling, the dominant noise source is the random fluctuation originating from the thermal, 1/f and random telegraph signal  noise of the readout chain transistors.",
10870.txt,RTS noise is a severe problem that especially appears in small sized transistors like the in-pixel SF.,
10871.txt,"But for current CIS processes, it only appears in a minority of pixels.",
10872.txt,"The noise reduction starts by implementing enough columnlevel gain in order to minimize the noise contribution of the next stages and limit the noise analysis and optimization to the in-pixel SF stage, the current source of the SF and the column-level amplifier.",
10873.txt,The thermal noise originating from the SF stage and column-level amplifier is reduced using a proper design of the SF current source and bandwidth control obtained with high column-level amplification .Simulated input-referred thermal noise as a function of the readout chain bandwidth set by the column level amplifier with the estimated framerates achievable for the presented VGA imager.,
10874.txt,readout chain but at the cost of a larger readout time.,
10875.txt,It has been shown in X that the input-referred thermal noise can also be reduced by increasing the conversion gain of the pixel.,
10876.txt,In this work we chose to perform a simple CDS for a faster readout.,
10877.txt,The bandwidth of the readout chain is roughly inversely proportional to the product of the column level gain and the load capacitance of the column level amplifier.,
10878.txt,It has been set to 265 kHz with a gain of 64 in order to make the thermal noise lower than the 1/f noise.,
10879.txt,Fig.,
10880.txt,2 shows the simulated input-referred thermal noise of the conventional readout chain of Fig.,
10881.txt,1 as a function of the readout chain bandwidth which is tuned using different combinations of the column-level gain and the load capacitance.,
10882.txt,It also indicates the estimated framerates achievable for each bandwidth.,
10883.txt,"For large readout chain bandwidths, the framerate becomes limited by the time required by the ADC to convert and shift the data to the output which is about 10s.",
10884.txt,"At about 80 fps, the low frequency noise of the readout chain becomes the dominant noise source.",
10885.txt,The 1/f noise is dramatically reduced by the AZ and CDS or CMS.,
10886.txt,"However, it remains the dominant noise in the readout chain X.",
10887.txt,The critical transistors of the column-level circuitry can be designed to have gate sizes large enough to make their contribution to the total 1/f noise of the readout chain negligible compared to the in-pixel SF's.,
10888.txt,"Thus, in a conventional low noise CIS readout chain, with column amplification, bandwidth control and careful design, the 1/f noise originating from the in-pixel SF remains the dominant noise source.",
10889.txt,The gate-referred power spectral density of the 1/f noise generated by the in-pixel SF is inversely proportional to its gate size and the squared oxide capacitance per unit-area.,
10890.txt,But the conversion gain of the pixel is linearly dependent on the product of the in-pixel SF gate size and oxide capacitance per unit area.,
10891.txt,"W and L are the SF gate width and length, respectively, Coxis the SF gate oxide capacitance per unit area, CPis the total capacitance at the SN made of the SN junction capacitance, the transfer gate and reset transistor overlap capacitances and the metal wires parasitic capacitance.",
10892.txt,Ceis the extrinsic capacitance per unit width of the SF transistor that includes the fringing-field and overlap capacitances and which can be considered as bias-independent in this first order analysis.,
10893.txt,CMSis a unitless circuit design dependent parameter reflecting here the impact of the correlated sampling .,
10894.txt,"For a simple CDS, assuming enough time for the signal settling between the samples, CMSranges between 4 and 5 .",
10895.txt,"Based on X, the 1/f noise originating from the in-pixel SF can be reduced through process level optimizations, columnlevel design and pixel-level design.",
10896.txt,The process level optimizations include the reduction of K and CP.,
10897.txt,"For instance, the parameter K has been reduced, in X, by using a buried channel SF.",
10898.txt,"In X, the parameter CPhas been minimised by applying process refinements reducing the overlap and junction capacitances connected to the SN.",
10899.txt,"In this work, we use a standard CIS technology and cannot drastically change these parameters.",
10900.txt,"Nevertheless, they can be addressed by making a good device choice among the standard transistors and careful layout, with respect to the standard design rules, in order to keep the term CPas low as possible.",
10901.txt,"At the column-level circuit design, the 1/f noise reduction consists in the correlated multiple or double sampling with a careful design of the column-level circuitry.",
10902.txt,"In this work, a simple CDS is performed.",
10903.txt,The design optimization at the pixel level is the focus of this work.,
10904.txt,The idea is to exploit all the few degrees of freedom left to the designer in order to achieve a 1/f noise as low as possible.,
10905.txt,This choice allows to take advantage of the lower minimum gate width and higher Cox.,
10906.txt,Thick oxide transistors are used in order to support the high voltages used in pixels based on PPDs.,
10907.txt,Thin oxide transistors are used for digital design.,
10908.txt,"For this 180 nm CIS process, thick oxide transistors feature an oxide thickness of 7 nm compared to 3 nm for the standard digital thin oxide transistors.",
10909.txt,Thick oxide transistors feature a lower leakage current and are more suited to be used as switches than thin oxide transistors.,
10910.txt,"Thus, in this work, we propose a pixel design where only the SF transistor features a thin oxide.",
10911.txt,This choice is not obvious since practical issues related to the use of a thin oxide SF need to be solved.,
10912.txt,Simulated input-referred 1/f noise for three readout chains sharing the same column-level circuitry and using different in-pixel SF transistor types.,
10913.txt,oxide transistor supports low voltages but must operate in a high voltage environment without a dramatic impact on the dynamic range of the pixel.,
10914.txt,These points will be discussed in the next Section together with the design of the newly proposed pixel.,
10915.txt,"3 presents the simulated inputreferred 1/f noise of readout chains sharing the same columnlevel amplifier and CDS circuits and based, respectively, on in-pixel thick oxide NMOS, thick oxide PMOS and a the newly proposed thin oxide PMOS.",
10917.txt,The difference between the input-referred noise of the thick oxide transistors is due to the lower K factor of the PMOS.,
10918.txt,The thin oxide PMOS combines a lower K factor with a higher Coxand smaller gate size.,
10919.txt,"Hence, its implementation as a SF results in the best 1/f noise performance as expected theoretically.",
10920.txt,4 shows the overall architecture of the imager.,
10922.txt,The row control block also allows the control of the integration time.,
10923.txt,Each column of the pixels array is connected to a closed loop gain amplifier introducing gain and limiting the bandwidth.,
10924.txt,"A mixed signal analog multiplexing block made of shift registers, voltage level shifters and analog switches is implemented at the output of the column-level amplifiers.",
10925.txt,It allows to choose between an analog or digital output.,
10926.txt,"In the digital readout mode, each column-level output is simply connected to the input of a 10 bits single-slope ADC.",
10927.txt,All the columns are read in parallel.,
10928.txt,"In this configuration, the imager operates at 80fps.",
10929.txt,"In the analog readout mode, the shift registers and analog switches connect the columns to the analog output.",
10930.txt,"In this case, the columns are read one after the other.",
10931.txt,The analog readout mode is important for proper characterizationof the pixels.,
10932.txt,In this mode the frame rate is 640 times slower but the column and pixel readout time remain the same.,
10933.txt,Overall architecture of the proposed image sensor.,
10936.txt,"B. Pixel Design and Layout As discussed in the previous section, the 1/f noise originating from the SF transistor can be reduced using a SF with a thinner oxide and lower gate width.",
10937.txt,"From a designer perspective, this can be achieved by using a thin oxide  transistor instead of a thick oxide in the 180 nm CMOS process used for this work.",
10938.txt,The sense node needs to be reset at a voltage higher than 2 V for a good dynamic range and also to make sure that the sense node attracts efficiently the charges from the PPD when the potential barrier under the transfer gate is removed.,
10939.txt,"Yet, the voltage difference between the gate and the bulk of the thin oxide SF must remain smaller than 1.8 V. Hence, the bulk voltage of the thin oxide SF must be shifted.",
10940.txt,To this purpose a PMOS thin oxide transistor is chosen.,
10941.txt,"Indeed, the bulk voltage of a PMOS transistor can be controlled through the n-well connection.",
10942.txt,"An NMOS transistor with a separated p-well could also be used, but at the cost of a larger area.",
10943.txt,"Also, a PMOS thin oxide SF usually shows a lower 1/f noise parameter K than NMOS in the target technology nodes.",
10944.txt,"Consequently, the K parameter in X is expected to be lower for the PMOS thin oxide SF.",
10945.txt,Hence the slight additional reduction of the 1/f noise obtained by increasing L would be at the cost of a much larger thermal noise.,
10946.txt,The transfer  gate and reset transistor are thick oxide NMOS.,
10947.txt,Introducing an n-well in the pixel of a CIS can be harmful for the fill factor.,
10948.txt,"Indeed, a minimum distance is imposed between the n-well and the neighboring NMOS and PPD.",
10949.txt,"Also, a minimum distance between thin oxide and thick oxide transistors has to be fulfilled.",
10950.txt,"In order to address these issues, an optimized layout still filling all the standard design rules is proposed.",
10951.txt,The optimization relays on putting the maximum number of transistors in the same n-well and keeping this latter Fig.,
10952.txt,Schematic of the proposed pixel  and a layout view of the neighboring pixels.,
10954.txt,"Inside the N well, a common thin oxide area contains the two SFs.",
10955.txt,This compact layout results in a fill factor of 40% with a pixel pitch of 6.5m.,
10956.txt,C. Column-Level Amplifier Fig.,
10957.txt,7 shows the schematic of the column-level adjustable gain amplifier.,
10958.txt,"The feedback capacitors can be switched in order to change the gain between two levels: 1, for high dynamic range in normal light conditions and 64 for low noise at low light conditions.",
10959.txt,The openloop gain is provided by an OTA.,
10960.txt,"For the OTA design and layout, the priority is given to the noise constraint.",
10961.txt,The dynamic range is not critical since the voltage swing at the output of the pixel is not higher than 1.5 V .,
10962.txt,A singleended structure is used because it involves half the number of noisy transistors compared to a differential one.,
10963.txt,Differential amplifiers are certainly better at rejecting any common mode noise but at the cost of more noise and more power.,
10964.txt,"Indeed, in the case of an operational transconductance amplifier such as the one used in this amplifier, the differential structure requires to duplicate the circuit branch resulting in twice the power consumption and twice the thermal noise excess factor for achieving the same transconductance.",
10965.txt,"In order to achieve low noise and to stay within our power budget, we have chosen a single ended implementation.",
10966.txt,The noise originating from the power and bias sources is reduced on-bord by using power filters.,
10967.txt,"Regarding the area, it is manly set by the input and feedback capacitors especially for high gains.",
10968.txt,"Hence, a differential topology would occupy about the same area but, as explained above, with the penalty of double power and noise.",
10969.txt,"The situation would be even worse for a fully differential amplifier since it would generate twice as much noise, power and area compared to the single ended implemented in this work.",
10970.txt,The high closed-loop gain of 64 requires a large open-loop gain hard to achieve with a simple single ended amplifier.,
10971.txt,It is known that cascode structures provide much higher gain with a negligible noise contribution of the cascode transistors.,
10972.txt,"Hence, a fully cascoded single-ended amplifier is used.",
10973.txt,"In order to make the 1/f noise contribution of the column-level amplifier negligible compared to the one originating from the pixel, the transistors of the OTA have gate areas more than 10 times larger than the SF.",
10974.txt,The charge injection of the AZ switch can reduce considerably the output voltage swing of the amplifier in the high column-level gain mode.,
10975.txt,"In order to reduce that charge injection, dummy devices with a proper sizing are used in order to compensate the charge injected by the main NMOS switch.",
10976.txt,D. Column-Level SSADC Fig.,
10977.txt,8 shows the schematic of two neighboring column-level SS-ADCs.,
10978.txt,A double stage comparator is used to reduce the offset.,
10979.txt,Fig.,
10980.txt,9 shows the timing diagram of the whole readout chain.,
10981.txt,"After the reset of the SN, the auto-zeros of the consecutive column-level amplifier and comparators are opened sequentially in order to minimize the impact of charge injection .",
10982.txt,Then the charges are transferred to the SN and the voltage at the input of the comparator is equal to the difference between the transfer and reset levels.,
10983.txt,The ramp is then activated together with the counter.,
10984.txt,Shift registers are used in order to memorise the 10 bit code once the output of the comparators is high.,
10985.txt,The CDS time is defined by the time between the opening of the AZs and the moment when Fig.,
10986.txt,8,
10987.txt,Schematic of the column-level amplifier.,
10988.txt,Fig.,
10989.txt,Block diagram of the SS-ADC of two neighboring columns.,
10991.txt,the output of the comparator is high.,
10992.txt,"During the readout of the next line, the 10 bit codes of all the column-level registers are shifted horizontally to the digital output.",
10993.txt,E. Physical Implementation The chip has been fabricated in a CIS standard 1P4M process.,
10994.txt,The microlenses layer was not used in this work.,
10995.txt,The analog parts of the chip are powered with a 3.3 V source and digital parts with a 1.8V.,
10997.txt,The chip is mounted on the board through a socket over which an optical objective is assembled.,
10998.txt,the board is powered with an external 5 V source and encompass power supply filters for low noise requirements.,
10999.txt,"The board is connected to a PXI rack with two FPGAs that, on the one hand generate the digital control signals, and on the other receive the digital and analog outputs of the board coming out of the chip.",
11000.txt,The analog input of the FPGA has an integrated 14 bit ADC with an LSB of about 200V.,
11001.txt,It was used to characterise the pixels using the analog output mode.,
11002.txt,"For measurements requiring the variation of the input light, a simple led powered with a low noise tunable voltage source was used.",
11003.txt,The LED were fixed at the end of a dark tube put on top of the imager.,
11004.txt,"Conversion Gain Measurement In order to measure the conversion gain of the readout chain, the photon transfer curve measurement technique is used.",
11006.txt,Fig.12 shows the variance versus the signal PTC of the sensor measured from 5000 pixels.,
11007.txt,It is obtained using the analog output of the sensor and the column-level gain set to 64.,
11008.txt,"This time, the saturation originates from the pixel.",
11009.txt,This curve allows the measurement of the pixel full well capacity.This work does not focus on extending the dynamic range for high signal level but rather by pushing down the noise floor.,
11010.txt,Now all the noise reduction techniques presented in this work remain compatible with all the techniques used to reach high full well capacities with pixels based on pinned photodiodes.,
11011.txt,"Temporal Read Noise In order to measure the input-referred noise of the presented imager, the output voltage noise is first measured.",
11012.txt,Then it is referred to the input using the readout chain conversion gain.,
11013.txt,"The column-level amplifier gain is set to 64, limiting the bandwidth to about 300 kHz in order to reduce the thermal noise and the noise originating from the next stages.Measured input-referred noise in the log scale for the two column level gains.",
11014.txt,the noise histogram represents the total noise of the readout chain including the 1/f and thermal noise.,
11015.txt,"Additionally, the estimation of the input-referred 1/f noise is based on the simulated values of the capacitances connected to the sense node.",
11016.txt,"These values depend on the layout and the process, hence it was expected to obtain values slightly different from the calculation and simulation.",
11017.txt,14 shows the inputreferred noise for the two column level gains.,
11019.txt,It shows a large noise increase in the 1 gain configuration as the bandwidth becomes much larger and all the noise sources after the column-level amplifier are no longer negligible.,
11020.txt,Photo-Response Non-Uniformity This measurement is important in order to verify that the input-referred noise reduction does not come at the cost of higher PRNU.,
11021.txt,The PRNU represents the spatial variation of the gain.,
11022.txt,It is given as an RMS percentage.,
11023.txt,"For the presented imager, the PRNU was also measured using the PTC.",
11024.txt,The optical objective of the imager is removed.,
11025.txt,The chip is exposed directly to the LED put far enough to have a uniform illuminance for all the pixels array.,
11026.txt,5000 pixels exposed to the same level of light with the same exposure time are read 100 times.,
11027.txt,The average output signal is calculated for each of the 5000 pixels.,
11028.txt,Then the standard deviation of the spatial variation of the pixels output voltage is plotted in Fig.,
11029.txt,15 as a function of the average over time and space of the pixels output signal for different lighting conditions.,
11030.txt,The curve is linear as expected and the resulting PRNU corresponds to a value of 0.77%.,
11031.txt,"Dark Current To measure the dark current, the imager is covered protecting it from any light.The average output signal of the sensor is measured, at room temperature, for different exposure times.",
11032.txt,16 shows the curve obtained by plotting the measured average output signals of the chip versus the exposure time.,
11034.txt,"For integration times below 300 s, the number of accumulated charges in dark increases linearly with the integration time.",
11035.txt,The slope factor of the curve indicates a dark current of 5.6e?s.,
11036.txt,"Usually, integration times above a few tens of ms are not needed.",
11037.txt,The signal from the second readout of the pixel comes from the electrons left in the PPD after the charge transfer in the first readout.,
11038.txt,The lag is obtained by dividing the signal from second readout over the one from the first readout.,
11039.txt,The lag was measured with different input light levels.,
11040.txt,When the PPD accumulates about 2500 photo-electrons the average measured lag was 0.1%.,
11041.txt,For an average number of Fig.,
11042.txt,Quantum efficiency of the PPD obtained by dividing the QE of the sensor by the fill factor of 40%.,
11044.txt,accumulated electrons around 5000 the obtained lag increases to about 1%.,
11045.txt,G. Quantum Efficiency It is important to verify that the n-well containing the PMOS transistors of the pixel does not act as a photodiode competing with the PPD.,
11046.txt,"To this purpose, a measurement of the quantum efficiency is required.",
11047.txt,Fig.,
11048.txt,17 shows the measured QE of the active area of the imager chip.,
11049.txt,It is obtained by dividing the effective QE by the pixel fill-factor of 40%.,
11050.txt,The resulting QE is as good as state-of-the-art PPDs designed exclusively using NMOS pixels.,
11051.txt,This means that the in-pixel n-well does not compete with the PPD.,
11052.txt,"Furthermore, the micro-lens layer have not been used in this imager.",
11053.txt,This layer focuses the light at the active area of the pixels and increases the effective QE.,
11054.txt,"H. Imaging Demonstration Based on the measured performance, the presented imager is supposed to operate in both low light and normal light conditions.",
11055.txt,"In order to validate this idea, images were taken using the presented image sensor in a dark room with a controlled level of light.",
11056.txt,The imager was set with an exposure time of 12ms and a frame rate of 84 fps.,
11057.txt,Fig.,
11058.txt,"18 shows images taken with the chip under different low light levels using the 64 column gain mode at light levels of 0.005 lux and 0.066 lux corresponding to an average of 3 and 41 photogenerated electrons per pixel, respectively.",
11059.txt,In Fig.,
11060.txt,"18, the SNR of the input light is below 5 dB.",
11061.txt,The dominant noise sources are the photon shot noise and the temporal read noise.,
11062.txt,"One can see that even with such a low input light, the objects in the scene can still be distinguished.",
11063.txt,"18, the SNR of the input light is about 16 dB.",
11065.txt,"Due to the high column gain, one can see that the image is not far from saturation due to voltage swing of the column-level amplifier.",
11066.txt,Images of the same scene taken with the presented chip for different amounts of input light.,
11067.txt,"Indeed the line readout time of 25s is actually 64 and 5.7 times faster than X, respectively.",
11068.txt,A dynamic range of 82.5 dB in the dual gain mode is achieved without using any dynamic range enhancement techniques like lateral overflow capacitance.,
11069.txt,The improvements achieved in this work were obtained only by making design choices and careful layout based on a detailed noise analysis .,
11070.txt,"The thin oxide transistor used as an SF is a standard ""digital"" transistor not optimized for analog applications, thus there is still some room left for process optimization at the SF transistor level.",
11071.txt,"Moreover, X suggests that the input-referred noise can also be mitigated by reducing the contribution of all the parasitic, overlaps and junction capacitances to the sense node.",
11072.txt,But this approach requires process refinements.,
11073.txt,"Indeed, in X, the overlap capacitances were reduced by using reset, transfer and gates without low doped drains.Note that these process level techniques are compatible with the circuit techniques presented in this work.",
11074.txt,"A combination between the reduction of CPand using thin oxide SF with optimized gate size is expected to come with even more noise reduction.This work demonstrates that deep sub-electron noise, in a full VGA APS, can be achieved using a standard CIS process by a proper circuit noise optimization exploiting all the degrees of freedom left to the designer for minimizing the total inputreferred noise.",
11075.txt,"The proposed techniques include the following steps: introduce enough column level gain to, on one hand, reduce the pixel and column-level amplifier thermal noise and on the other the noise contribution of the next stages, design the column-level amplifier with a minimum number of devices large enough to make the residual noise after autozero small enough compared to the SF noise,  replace the conventional thick oxide NMOS SF with a minimum width and optimum length thin oxide PMOS, draw a compact layout with common n-well and minimum sense node parasitic capacitance.",
11076.txt,"This work also provides a full characterization of the VGA imager showing that neither of the dynamic range, the imager lag and the PRNU are compromised with the proposed noise reduction technique.",
11077.txt,The characterization also shows that the QE of the PPD is not affected by the neighboring PMOS n-wells.,
11078.txt,"Note that the proposed approach can be combined with any known additional noise reduction techniques at system , device  and process level  to further reduce the TRN.",
11079.txt,"Utilities often investigate the cause of elevated voltage in the urban environment, and determine whether the condition is the result of stray or contact voltage.",
11080.txt,Stray voltage results from the normal delivery and/or use of electricity and generally does not require mitigation.,
11081.txt,"Therefore, it is not the focus of this paper.",
11082.txt,Contact voltage results from abnormal power system conditions that may be present between two conductive surfaces.,
11083.txt,Contact voltage is never related to the normal system operation and is often from damaged insulation on phase conductors.,
11084.txt,Improperly connected customer or utility equipment can also cause contact voltage.,
11085.txt,"Since contact voltage often involves phase conductors, it should be treated carefully because a low-voltage level can rise to full-line voltage as the impedance of the conductive pathways changes.",
11086.txt,"These investigations are often straightforward, but at other times, the cause of the elevated voltage is difficult to identify.",
11087.txt,The process described herein is intended to help utility engineers quickly eliminate unlikely causes of elevated voltage and direct their troubleshooting to determine the source.,
11088.txt,It is important to remember that investigations of elevated voltageoftendonotdirectlyinvolvestreet-levelutilityobjects such as manholes or poles.,
11089.txt,"In underground systems, the vast majority of the events involve failures along the length of the cable, energizing street-level assets such as sidewalks and fences.",
11090.txt,Investigators should understand that these events may energize multiple objects.,
11091.txt,"Some investigations may last several days, or be passed from one repair crew to another, or even between companies.",
11092.txt,That means utilities need a process that is repeatable between crews and organizations to maximize efficiency in troubleshooting.,
11093.txt,"To streamline their investigative processes, organizationsmaydeveloptheirowninvestigativeflowcharts or modify those in the appendixes and use them as the basis for their investigations.",
11094.txt,The authors recognize that every investigation is different and that not every step of the processes outlined will apply to every investigation.,
11095.txt,"The objective of the investigation is to identify the source of the contact voltage, allowing the crew to repair the defective component as quickly as possible.",
11096.txt,"Elevated voltage can be from a defect on either the line or neutral side of the circuit, so defects on both sides of the circuit should be considered suspect until measurements are taken to determine the exact cause.",
11097.txt,It is important to use proper measurement techniques to reach accurate conclusions.,
11098.txt,"For example, connecting one lead to an object energized at 3V and the other lead to an object energized at 3.4 V will result in the meter displaying a reading of 0.4 V .",
11099.txt,"Because of this method of operation, it is critical that one of the connections to the meter is made to a ground reference that is at zero potential.",
11100.txt,Connection to an energized reference will result in erroneous readings.,
11101.txt,"A resistor that is connected in parallel to the input of the voltmeter, the shunt resistor, is primarily used for eliminating induced or capacitively coupled voltage.",
11102.txt,This voltage may appear on an object but lack the ability to source current and cause a shock.,
11103.txt,"Common shunt resistor values include 500, 3000, and 10 000 ?.",
11104.txt,Higher impedance shunt resistors help minimize the impact of high-impedance contacts between probe tips and energized objects in the field.,
11105.txt,"If induced voltage is not present, the shunt resistor provides little additional value in the investigation process and at times may make it more difficult to locate the source.",
11106.txt,Investigators use the pen tester to determine whether the equipment is energized above a certain threshold.,
11107.txt,Pen testers have various turn-on voltage levels that should be characterized before introduction into a program.,
11108.txt,Turn-on voltage levels range from 3 V to greater than 100 V .,
11109.txt,Pen-type testers are not usable to confirm that a ground reference is not energized.,
11110.txt,This is because the commonly used and most sensitive devices include the technician's body in the measurement circuit.,
11111.txt,"If the technician performing the test is standing on a surface that has an elevated voltage, the difference in voltage measured by the device may be less than the turn-on voltage of the device.",
11112.txt,A reliable ground lead of sufficient length is required to ensure that a suitable reference can be located and connected to the voltmeter.,
11113.txt,Handheld electric field detectors can measure electric fields that are radiated from energized objects.,
11115.txt,They often have displays that give a relative indication of field strength.,
11116.txt,"During an investigation, a handheld electric field detector helps a crew quickly find energized objects and can ensure that reference grounds are not energized.",
11117.txt,The total harmonic distortion of the voltage waveform of an energized object provides important information about the source of the voltage.,
11118.txt,A device that measures THD as a percentage of the fundamental operating frequency  is an important tool for investigators.,
11119.txt,"Since the shunt resistors are linear loads, they have no impact on the harmonic content.",
11120.txt,Inserting the shunt resistor into the measurement circuit will only attenuate the signal and increase the measurement error.,
11121.txt,"Therefore, crews should take harmonic measurements without a shunt resistor in the circuit.",
11122.txt,"To confirm the finding, the crew must locate a reference ground with zero potential and low impedance to earth.",
11123.txt,"That could be a fire hydrant, stand pipe, metal post, or temporary driven ground or other object.",
11124.txt,The crew must confirm that the candidate ground has zero potential either by using an electric field meter or by measuring with a highimpedance voltmeter against additional candidate grounds.,
11125.txt,"Next, investigators use the high-impedance voltmeter to measure the voltage between the ground and the energized object.",
11126.txt,"If the reading is greater than the predefined threshold, typically 1 Vac, the crew repeats the measurement, using an appropriate value shunt resistor, ideally connected through a push button.",
11127.txt,The push button allows selective engagement of the shunt resistor without disturbing measurement contact points.,
11128.txt,"If the reading is still greater than the predefined threshold, 1 Vacfor example, when the shunt is engaged, the object is recorded as detection.",
11129.txt,"If the voltage drops significantly when the shunt is engaged, the crew should select an alternate ground and repeat the process.",
11130.txt,This step ensures a low-impedance ground reference and preserves measurement accuracy.,
11131.txt,Variations in technique in this process can cause significant errors.,
11132.txt,"This is because selecting a ground that is energized or has high earth impedance could result in the failure to validate detection, since the voltmeter is measuring the difference in potential between the object that is selected as the ground and the energized object .",
11133.txt,The investigative process begins with a report of elevated voltage.,
11134.txt,"That report may have come from a crew conducting a periodic testing program, a crew that made a detection during routine work activities, or from a member of the public who reported a shock.",
11135.txt,"The investigator's job is to determine the exact component on the power system that is causing the elevated voltage, whether it stray or contact voltage, and the right actions to take to eliminate the voltage.",
11136.txt,"Without the aid of advanced diagnostic tools such as an oscilloscope capable of analyzing THD, investigators may rely on the basic information from a voltmeter and a shunt resistor.",
11137.txt,"Prior to the development of techniques that use harmonics, investigators would begin their investigation by disconnecting the most likely source of the voltage and remeasuring the voltage on the object.",
11138.txt,"They would repeat this process until the voltage was eliminated.With the introduction of harmonic analysis, the investigative process begins with a measurement that often helps to differentiate possible sources of the elevated voltage.",
11139.txt,1 provides an overview of how these measurements are used in the troubleshooting process.,
11141.txt,"For objects with greater than 10% THD, investigators should look for defects associated with damaged or defective neutral conductors.",
11142.txt,"For objects with less than 10% THD, investigators should focus on defects associated with phase conductors.",
11143.txt,It should be noted that harmonic measurements alone do not provide adequate information to differentiate between stray voltage and contact voltage.,
11144.txt,The voltage and harmonic measurements together can help investigators categorize the source of elevated voltage.,
11145.txt,The figure below relates the possible sources and their characteristics.Anopenorhigh-impedanceneutralconductor is also labeled a fault.,
11146.txt,Contact voltage is sourced from either the line side or the neutral side of a circuit.,
11147.txt,Investigators often focus on the line-side sources without considering possible sources on the neutral conductors and connections.,
11148.txt,It is important to consider and evaluate both to ensure cost-effective timely repairs.,
11149.txt,"Most line-side sources, which normally have a THD of less than 10%, are easily identified by the isolation of a section of cable.",
11150.txt,"Investigators often report finding abandoned cables with improperly sealed ends, improperly insulated split bolt connectors, defective cable insulation, and reversed phase and neutral conductors as the causes of these contact voltage cases.",
11151.txt,"These conditions can exist in utility-owned infrastructure such as manholes, vaults, and conduits, municipally owned infrastructure such as streetlights, or customer-owned equipment.",
11152.txt,"Line-side sources of contact voltage are the most dangerous because even if voltage is detected at a low level, the voltage has the potential to rise to full-line voltage.",
11153.txt,Open or high-impedance neutrals may be the source of elevated voltage and in some cases capable of sourcing enough current to cause harm.,
11154.txt,The voltage from highimpedance neutrals is a result of current flowing through that impedance.,
11155.txt,"As a result, the voltage that is measured is a function of the load on the cable.",
11156.txt,"In addition to electric shock reports and contact voltage detections, these defects may result in customer voltage complaints and reports by cableTVcrewsofcurrentontheircables.Whentroubleshooting cases where the THD is greater than 10%, investigators should first inspect neutral connections and ensure that they are not loose or corroded and that the neutral is carrying the appropriate amount of current compared with the phase line.",
11157.txt,Investigators should also be aware of the relationship between the current and the voltage.,
11158.txt,"Otherwise, they may accidently address the problem when they disconnect the service line; note that the voltage has been eliminated and order a replacement of the service.",
11159.txt,The replacement would likely fix the problem because it replaces both the phase and neutral conductors.,
11160.txt,"However, it will also result in the installation of new connections on both ends of the neutral line, which may have been the cause of the elevated voltage.",
11161.txt,"For each group, an investigative flow chart has been developed to aid in the identification of defects that could be causing the elevated voltage.The objective of the investigation into an ESR is to locate and categorize the energized object so that further troubleshooting can eliminate the elevated voltage.",
11162.txt,These investigations can be difficult because of incomplete information from the public or first responders and delays in reporting.,
11163.txt,"The general investigative strategy is shown in Appendix A.These reports are not cases of contact voltage; since most utilities have processes for investigating these reports, and since they are not the result of the defective equipment, this type of report is not covered in this document.",
11164.txt,"After the elimination of normally energized sources, the next step is to validate the claim of the electric shock.",
11165.txt,This process often involves testing the object or objects that caused the shock.,
11166.txt,Investigators should use a voltmeter to confirm voltage conditions on that object referenced to a qualified ground.,
11167.txt,"Once the voltage on the object has been confirmed, investigators can continue the troubleshooting process by following the appropriate flow chart.",
11168.txt,"The voltage reading may be below what is normally considered a level for human perception, and yet the object delivered a detectable shock.",
11169.txt,This is because the voltage level from a fault can change as conditions around the fault change.,
11170.txt,"If the report cannot be confirmed, investigators should consider variables such as the time of day, the weather, and the system load and then retest, if appropriate.",
11171.txt,"For energized objects that are directly supplied by the utility, such as illuminated bus stops, kiosks, and so on, the first step in the troubleshooting process is to measure the THD to help determine the possible source.",
11172.txt,The general investigative strategy is shown in Appendix B.,
11173.txt,"If the THD is greater than 10%, the source of the elevated voltage is most likely associated with a neutral, either on the customer side of the meter or on the utility side of the meter.",
11174.txt,"If a neutral issue is suspected, current readings on the neutral and ground connections at the meter and at the service box may provide useful information.",
11175.txt,"If there is more current on the customer side, then a high-impedance neutral or neutral connection is likely.",
11176.txt,Disconnecting the load at the main circuit breaker is a simpleandeffectivewaytodeterminewhetherline-sidefaultsare the responsibility of the utility or the customer.,
11177.txt,"However, it is important to make sure that the elimination of the voltage is not due to the reduction in the load.",
11178.txt,"If disconnecting the loads using a main breaker does not eliminate the voltage, then the elevated voltage is likely being caused by a defective service wire.",
11179.txt,"In that case, continue by disconnecting the service wire and retesting for voltage.",
11180.txt,"If the voltage is eliminated, the service should be replaced.",
11181.txt,"If this does not eliminate the voltage, then the source is not associated with the service and other sources should be considered.",
11182.txt,"They may include other nearby mains and services, current circulating on other utility lines such as cable TV shields, signaling systems for transit systems, and so on.",
11183.txt,"When voltage appears on objects such as sidewalks, roadways, and fences, harmonic measurements can help determine a starting point for the investigation.",
11184.txt,Investigators may also choose to use a voltmeter without a shunt resistor to determine where the highest voltage can be measured.,
11185.txt,They can then center their investigation on this location.,
11186.txt,Investigators should consider facilities that cross under the energized object.,
11187.txt,Isolation of these facilities is helpful in determining their relationship to the source of the voltage.,
11188.txt,"Often, the most difficult cases to resolve are those with harmonic content greater than 10% THD.",
11189.txt,These cases generally involve high-impedance neutrals in service or main conductors.,
11190.txt,"As a result of the high-impedance conductor, return currents flow through a variety of metallic and nonmetallic objects including fences, sidewalks, and cable television shields.",
11191.txt,"In these instances, it helps to search for points on the neutral system that are at the same potential as the energized object, or that have the same harmonic content as the energized object.",
11192.txt,"For example, if voltage on a cable TV shield measures 3 V to a remote ground and 0 V to the service neutral inside of a nearby house, a logical next step would be to measure the current on the neutral at the house and the current flow at the point where the service connects to the system.",
11193.txt,"If they are significantly different, there may be high impedance in the service neutral.",
11194.txt,"If there is not a significant difference, the investigator would repeat this process until determining the cause of the elevated voltage.",
11195.txt,Investigations of elevated voltage on street and traffic lights are similar to investigations involving other objects that are directly fed by the utility.,
11196.txt,The slight difference is that often no circuit breaker is present at the interface between the light and the utility.,
11197.txt,"The general investigative strategy is shown in Appendix D. When investigating cases where the THD is greater than 10%, the investigator should also consider that the voltage may not be a result of a high-impedance streetlight neutral.",
11198.txt,"Instead, it may be the result of a high-impedance neutral somewhere else in the electric distribution system.",
11199.txt,Metallic street lighting standards are frequently connected to service neutrals.,
11200.txt,"Because the standards are also grounded, either via driven grounds or through the mounting hardware, current from the system neutrals can flow to the streetlight ground.",
11201.txt,Investigators are often able to measure voltage as a result of this phenomenon.,
11202.txt,"In this case, the mitigation efforts will revolve around identifying the high-impedance component in the electrical system and making the repairs, which may be some distance from the light.In many instances, a defective cable or other piece of equipment is found inside a utility structure or on a pole and the event is quickly mitigated.",
11203.txt,"The general investigative strategy for these types of objects is in Appendix E. Using the voltage and harmonic measurements, investigators will generally find cable with defective insulation sourcing contact voltage with low harmonic distortion or high-impedance neutral connections sourcing contact voltage with high harmonic distortion.",
11204.txt,"In cases where a detailed inspection does not reveal either of these types of defects, investigators should consider other conductive objects as the possible route of the voltage into the structure.",
11205.txt,Cases have been reported where the actual fault was in a structure more than 50 feet away and the metallic conduit connecting the two structures acted as the conductive pathway.,
11206.txt,"Investigators may also consider electric cables in conduits that are in the ground near the cover, but not routed through the structure.",
11207.txt,"Since the metallic cover is often the only object that is tested, it is possible that the ground surface around the structure has been energized from a nearby secondary cable fault, and measured on the metallic cover.",
11208.txt,Isolation of these cables may eliminate the elevated voltage.,
11209.txt,Sometimes investigators arriving at the location of a previously reported detection are unable to measure voltage at that location.,
11210.txt,"Because of the nature of these events, it is possible that the condition has temporarily eliminated itself.",
11211.txt,"Before recording the event as unsubstantiated, investigators should evaluate the effect of factors such as system load, reference grounds, time of day, weather, and other conditions that may be impacting the area.",
11212.txt,"As discussed previously, using different references as a ground can cause significant differences in voltage measurement, since voltmeters measure the difference between the two inputs.",
11213.txt,"When possible, investigators should use the same reference for the initial and subsequent voltage measurements.",
11214.txt,"If investigators cannot use the same reference that was used for the initial reading and cannot measure the previously reported voltage, they should ensure that the new reference is not energized and consider repeating the measurement from other acceptable grounds before leaving the location.",
11215.txt,"When investigators cannot measure the previously reported voltage, they should consider the time of day when the initial reading was taken.",
11216.txt,"For example, if the initial reading was taken when it was dark, investigators should inspect the area for lights or other equipment operated by photocells or timers.",
11217.txt,"Investigators should also consider the current load at the time of the initial and subsequent readings, as discussed below.",
11218.txt,The voltage associated with high-impedance neutrals is a function of the current traveling through the high-impedance portion of the circuit.,
11219.txt,"If the initial readings are taken when the load on the neutral is high and subsequent readings are taken when the load is low, the voltage will be proportionally lower or even zero.",
11220.txt,"If the investigators suspect a high-impedance neutral and are unable to measure a previously recorded voltage, they should consider changes in load between the time of the initial reading and the subsequent investigation.",
11221.txt,"Weather, particularly precipitation, can play a significant role in the voltage level.",
11222.txt,"Precipitation can reduce the impedance of the conductive pathway to the surface, causing the voltage to increase.",
11223.txt,"When that water evaporates or drains away, the impedance increases and the voltage may disappear.",
11224.txt,"For this reason, investigators should consider the weather conditions that existed during the initial detection.",
11225.txt,"If they cannot detect the voltage, they should consider revisiting the location when the weather conditions are similar to those of the initial measurement.",
11226.txt,"Each detection and subsequent mitigation offers insights into system performance, risk, and repair practices.",
11227.txt,"Collecting this data in database can help utilities spot trends, improve processes, and identify underperforming components.",
11228.txt,A standard collection of data across a number of organizations would enable a broader and more detailed analysis of the topic of contact voltage.,
11229.txt,"Some of the data fields that have proven useful in the development of the attached flow charts and other analysis that have been previously published include date, location, voltage and harmonic levels, ground connection point, shunt resistor value, and so on.",
11230.txt,Mitigating contact voltage is challenging.,
11231.txt,"Since many surfaces in the public landscape are conductive, isolating the exact source requires methodical troubleshooting.",
11232.txt,Proper steps to perform accurate voltage and harmonic measurements against qualified ground references simplify the process.,
11233.txt,Cross-lingual sentiment classification aims to leverage rich-labeled resources in the source language to improve prediction models of a resource-scarce domain in the target language.,
11234.txt,"Existing feature representation learning-based approaches try to minimize the difference of latent features between different domains by exact alignment, which is achieved by either one-to-one topic alignment or matrix projection.",
11235.txt,"Exact alignment, however, restricts the representation flexibility and further degrades the model performances on CLSC tasks if the distribution difference between two language domains is large.",
11236.txt,"On the other hand, most previous studies proposed documentlevel models or ignored sentiment polarities of topics that might lead to insufficient learning of latent features.",
11237.txt,"To solve the abovementioned problems, we propose a coarse alignment mechanism to enhance the model's representation by a groupto-group topic alignment into an aspect-level fine-grained model.",
11238.txt,"First, we propose an unsupervised aspect, opinion, and sentiment unification model , which trimodels aspects, opinions, and sentiments of reviews from different domains and helps capture more accurate latent feature representation by a coarse alignment mechanism.",
11239.txt,"To further boost AOS, we propose ps-AOS, a partial supervised AOS model, in which labeled source language data help minimize the difference of feature representations between two language domains with the help of logistics regression.",
11240.txt,"Finally, an expectationmaximization framework with Gibbs sampling is then proposed to optimize our model.",
11241.txt,"Consumers from different countries often write online reviews in different languages to express their opinions after buying products from Amazon or Alibaba, which are deemed valuable to producers, service providers, and consumers themselves.",
11242.txt,"Generally, high-quality and annotated English review corpora are often available, whereas nonEnglish corpora are more difficult to obtain.",
11243.txt,Cross-lingual sentiment classification thus emerges as an important learning task and has attracted much attention from both academia and industries.,
11244.txt,The key idea behind CLSC is to bridge the gap of vocabularies and/or semantics between the source and target language domains such that the resources in the source language domain can be adapted for target language domain.,
11245.txt,"Along this line, machinetranslation-based methods , transfer learning, and feature representation learning-based methods have been proposed to solve cross-lingual problems.",
11246.txt,Feature representation learning-based methods aim to induce a reasonable feature representation between the source and target language domains so as to reduce distributional differences.,
11247.txt,Many variants of topic models have been proposed to solve cross-lingual classification problems.,
11248.txt,"For example, Lin, Paul and Girju, Bao, and Zhuang proposed to encode exact alignment by forcing domains to share the same common topics.",
11249.txt,Li  utilized common topics to learn a projection matrix between different domains.,
11250.txt,"However, the abovementioned methods have an intrinsic drawback,  exact alignment of topics across domains.",
11251.txt,"Specifically, the exact alignment is achieved by either one-to-one topic alignment or matrix projection.",
11252.txt,"The abovementioned exact alignment restricts the representation flexibility and further depresses model performances when the distributional differences between the source and target language domains are large , that is, the assumption of exact alignment is often violated since different language domains usually differ in their underlying distributions.",
11253.txt,This motivates us to reduce the restrictions of exact alignments in modeling cross-lingual classification problems.,
11254.txt,"Generally, coarse-grained models only learn document-level feature representations, which often fail to capture various aspects in one real-life product review.",
11255.txt,"As a matter of fact, fine-grained models outperform coarse-grained ones  for monolingual sentiment classification because the former can capture more accurate latent feature representations.",
11256.txt,"However, for CLSC tasks, even though fine-grained model performs better than coarse-grained one in X, it only achieves comparable performance to support vector machine.",
11257.txt,"Similar to the model in X, the abovementioned methods sample topics from source and target language domains by word-level translation, which might cause semantic drift and result in inaccurate topic-word distributions because of synonym and polysemy.",
11258.txt,"To address the abovementioned problems, we follow the theoretical work of X and try to learn a more accurate and flexible feature representation for CLSC.",
11259.txt,"In this regard, we introduce a coarse alignment mechanism of topic and sentiment and then propose an aspects, opinions, and sentiments unification model named AOS, which not only distinguishes the common and specific topics across different language domains but also identifies sentiment polarity of topics and further coarsely aligns specific topics across different domains.",
11260.txt,AOS model helps learn a fine-grained representation for CLSC tasks.,
11261.txt,"To further boost AOS, we propose an improved model named ps-AOS so that the labeled data in the source domain are used as partial supervision information to help minimize the distribution difference between the source and target domains, as well as the empirical loss in the source language domain.",
11262.txt,"Finally, we present an EM framework with Gibbs sampling to infer the parameters of our model.",
11263.txt,Our main research contributions are summarized as follows.,
11264.txt,"We propose an aspect-level unification model , which trimodels aspects, opinions, and sentiments of reviews from different domains and helps learn more accurate latent feature representation.",
11265.txt,"In unsupervised AOS, we introduce a coarse alignment mechanism to align specific topics with the same sentiment label of different domains, which overcomes the drawbacks of exact alignment in previous models.",
11266.txt,"To make full use of labeled instances in source language training data, we propose an improved model named ps-AOS with partial supervision, in which labeled source language data help minimize the difference of feature representations between the source and target language domains with the help of logistics regression.",
11267.txt,We present an EM framework with Gibbs sampling to infer the parameters of our models and conduct extensive experiments to demonstrate the significant improvement of our models for cross-lingual and/or cross-domain sentiment classification tasks.,
11268.txt,The remainder of this article is organized as follows.,
11269.txt,Section II reviews some related work on CLSC.,
11270.txt,"Then, we formally present our model in Section III and give the experimental setup and results in Sections IV.",
11271.txt,"Finally, Section V summarizes this article.",
11272.txt,Cross-Domain Adaptation Cross-domain adaptation aims to extract the knowledge from the label-rich source domain to enhance the predictive model of the target domain.,
11273.txt,Existing methods often achieve knowledge transfer by detecting a shared low-dimensional feature representation from source domain to target domain.,
11274.txt,"For example, Dai proposed a coclustering-based method, which identified the word clusters across different domains by propagating the class information and knowledge from source domain to target domain.",
11275.txt,Li proposed to share the same word clusters between the source and target domains to transfer label information.,
11276.txt,"However, the word clusters between the source and target domains are only related, rather than the exactly same.",
11277.txt,Zhuang exploited the association between the word features concepts and the example classes as the bridge across domains.,
11278.txt,"Moreover, another recent studies argued that the high-level concepts help to model the difference of data distribution, and they are more appropriate for classification.",
11279.txt,"Specifically, these methods assume that all the data domains have the same set of shared concepts or identical concepts, alike concepts, distinct concepts, which are used as the bridge for knowledge transfer.",
11280.txt,"For instance, Wang first attempted to discover the alike concepts and used them for knowledge transfer.",
11281.txt,"Then, Long  divided shared concepts into identical and alike ones as cross-domain knowledge.",
11282.txt,"Zhuang exploited the identical, alike and distinct concepts for distinguishing knowledge.",
11283.txt,Hu proposed multiknowledge transfer from multisource domains to target domain.,
11284.txt,"To sum up, the abovementioned transfer learning approaches achieved a better performance than nontransferred methods for cross-domain sentiment classification.",
11285.txt,"However, even though some approaches have noted the difference of knowledge or model transferred from source domain to target domain, they are two-stage transfer learning and could not consider transfer learning as a whole framework.",
11286.txt,"B. Cross-Lingual Adaptation Compared with cross-domain adaptation, cross-lingual adaptation needs to address the nonoverlapped feature space problem.",
11287.txt,"Thus, the key idea behind CLSC is to bridge the gap of vocabularies and/or semantics between the source and target language domains.",
11288.txt,"Alone this line, many methods have been studied extensively and deeply.",
11289.txt,"For example, Banea leveraged a machine translation technique to improve the model performance of target language.",
11290.txt,Bilingual parallel corpora and dictionaries are also ideal resources for cross-language sentiment classification tasks .,
11291.txt,"For instance, Wan proposed a cotraining method, which applied bilingual reviews to improve the performance of classifier.",
11292.txt,Authorized licensed use limited to: Auckland University of Technology.,
11293.txt,Topic model is a widely used model for learning latent feature representation across different domains.,
11294.txt,Paul and Girju  proposed a cross-domain Latent Dirichlet Allocation model  and Bao  combined partial supervision into ccLDA; these two models both encoded exact alignment by forcing specific topics between two domains to share the same topic indexes with common topics.,
11295.txt,Li utilized common topics to learn a projection matrix between specific topics of different domains.,
11296.txt,"The disadvantage of the abovementioned methods lies in that exact alignment restricts the representation flexibility and results in a significant decline in accuracy when the distribution difference between the source and target language domains is large , that is, the assumption of exact alignment is often violated since different language domains usually differ in their underlying distributions.",
11297.txt,"Moreover, the abovementioned models are coarse-grained ones because they only learn document-level feature representations, which often fail to capture various aspects in one real-life product review,the screen, battery, and camera of an iPhone.",
11298.txt,"For fine-grained models, Lin sampled topics in word-level translation, but it might cause semantic drift and result in inaccurate topicword distributions because of synonym and polysemy.",
11299.txt,Another challenge in a topic model is that exact inference is often intractable in topic models.,
11300.txt,"Thus, some studies proposed to employ a stochastic EM framework, which incorporated the functional optimization problem with Gibbs sampling.",
11301.txt,"Recently, deep neural networks have been applied to learn shared feature representations for cross-lingual sentiment analysis.",
11302.txt,"For example, Chandar proposed a predicative autoencoder for learning shared representation.",
11303.txt,A compositional distributed semantics was learned in X .,
11304.txt,Jain and Batra developed a cross-lingual sentiment analysis tool based on a bilingually constrained recursive autoencoder.,
11305.txt,Zhou proposed to learn bilingual word embedding for cross-lingual sentiment analysis.,
11306.txt,"Generally, DNNs-based approaches need paired sentences from parallel corpora.",
11307.txt,"Moreover, the learned feature representations are difficult to interpret and the algorithms own higher time complexities.",
11308.txt,"In this article, we first propose an aspect-level unification model , which trimodels aspects, opinions, and sentiments of reviews from different domains and helps learn more accurate latent feature representation by a coarse alignment mechanism.",
11309.txt,"Then, to further boost AOS, we propose an improved model named ps-AOS, in which labeled source language data help minimize the difference of feature representations between the source and target language domains by applying logistics regression.",
11310.txt,Our proposed two methods achieve better performance than various state-of-the-art baselines on CLSC tasks.,
11311.txt,"Thus, predicting the sentiment label of each xt jin Dtbecomes predicting the label of each xttransj by employing Ds.",
11312.txt,"Following the abovementioned models, our models have the following assumptions:  each sentence in reviews only belongs to one topic and has one sentiment polarity and  there are some domain-independent  and some domain-dependent topics across different domains.",
11313.txt,"In this article, we proposed an unsupervised model AOS and its improved model ps-AOS with partial supervision.",
11314.txt,Their graphical representations are shown in Fig.,
11315.txt,1 together.,
11316.txt,"It is worth noting that AOS is the plate without considering the orange shaded region, and its generative process is similar to ps-AOS without Step 3, that is, we do not draw a class label for document d in the source language domain by logistic regression.",
11317.txt,"In order to present the generative process of our two models succinctly, we only show the generative process of ps-AOS as follows.",
11318.txt,The second benefit is that subdividing one topic into different sentiment polarities will strengthen model's representation ability for classification tasks.,
11319.txt,"In our model, and are considered as two different features, whereas they are represented as one feature in previous models.",
11320.txt,We validate the effectiveness of this fine graininess through extensive experiments.,
11321.txt,"Plate notation of the proposed AOS and ps-AOS model, where AOS is the plate without the orange shaded region.",
11324.txt,"The major issue for existing crosslingual topic models is that they try to learn an exact alignment for topics in different domains, either through one-to-one alignment, and PSCCLDA or projection matrix.",
11325.txt,"To address this problem, we introduce a coarse alignment mechanism, which is an alignment between topic groups.",
11326.txt,"For briefness, we define a topic group as a set of topics sharing the same sentiment.",
11327.txt,"The coarse alignment is encoded in the generative process by assuming that a topic zd,sand its common/specific switcher rd,sare generated after sentiment ld,shas been chosen.",
11328.txt,"Under such a generative process, specific topics with the POSITIVE label will forcibly be aligned with common topics with the POSITIVE label.",
11329.txt,"Thus, specific topics with POSITIVE labels in different domains will be aligned via common topics with POSITIVE labels.",
11330.txt,The topics with NEGATIVE labels are similarly aligned.,
11331.txt,"To further improve AOS, we introduce partial supervision into AOS and propose its variant ps-AOS.To reduce the training error, we adopt class labels in the source domain to guide the sampling of topics by partial Authorized licensed use limited to: Auckland University of Technology.",
11332.txt,"Then, the topic zd,sof source domain is sampled according to 1.",
11333.txt,"We can observe that the sampling of zd,sis related to pdand .",
11334.txt,"Actually, our model considers class labels of examples in the source domain into the generative process of topics by parameters pdand .",
11335.txt,"Under the partial supervision, for a sentence s in d from source domain, if the label of d is NEGA TIVE, then the probability of zd,sbelonging to NEGA TIVE sentiment increases.",
11336.txt,"With the supervision for generating topics, feature representations will be enhanced by reducing training error.",
11337.txt,"Therefore, according to the theoretical work in X, a good representation enables achieving a low error rate in the source domain as well as minimizing a distance between the induced marginal distributions of the two domains.",
11338.txt,"In our model, the embedded logistic regression explicitly models class labels of examples in the source domain, which could help minimize the empirical training error in the source domain and 2) new representation learned by aspect-level fine-grained model and coarse alignment can achieve lower proxy A-distance value, which indicates that the new representations of both source and target domains are as indistinguishable as possible .",
11339.txt,We will provide experimental verification of PAD in Section IV.,
11340.txt,"Inference Exact posterior inference is intractable in AOS and ps-AOS models, so we employ a collapsed Gibbs sampling algorithm for approximate inference.",
11342.txt,"To solve the optimization problem of our proposed AOS and ps-AOS models, we propose an EM framework.The other variants based on LDA have the similar computational complexity, such as TSU  and PSCCLDA .",
11343.txt,"Cross-Lingual Sentiment Classification After applying the EM algorithm with Gibbs sampling described in Section III-B, we obtain the topic distribution of each review and use them to represent reviews in high-level latent feature space.",
11344.txt,It also contains the abovementioned three categories.,
11345.txt,"However, there are 2000 positive and 2000 negative reviews.",
11346.txt,"In our experiments, we use English as the source language and each of the other four languages as the target language.",
11347.txt,"Note that the two data sets also provide the corresponding English test reviews of each target language test reviews, which are translated by Google Translate.",
11348.txt,"Therefore, we directly use the translated reviews to predict their categories in AOS and ps-AOS models.",
11349.txt,"Finally, we obtain 12 CLSC tasks and 18 cross-lingual/domain tasks, as shown in Table II.",
11350.txt,"We perform the same data preprocessing for all of the models: remove punctuations, stop words and nonalpha characters.",
11351.txt,Baseline Methods and Setup We compare our proposed method with various kinds of state-of-the-art baseline algorithms.,
11352.txt,They are given in the following.,
11353.txt,We obtained the best values of their parameters by fine-tuning on EFB task.,
11354.txt,"For DTL and TRiTL, we first fine-tuned their parameters on the EFB task and then adopted the fine-tuned values as the default parameters of the rest tasks in order to raise efficiency of our experiments.",
11355.txt,"Finally, the parameters of DTL and TRiTL are as follows.",
11356.txt,"For a word, its sentiment label is initialized by its sentiment polarity.",
11357.txt,"For a sentence, we first find all of sentiment words in it and then use simple majority voting to determine its initial sentiment assignment.",
11358.txt,"For the baselines, LR, SVM, TRiTL, and DTL belong to supervised models because they use the labeled data in the source domain.",
11359.txt,"Compared with the abovementioned unsupervised topic models, PSCCLDA and ps-AOS are partially supervised models because they consider the label information of source language data when learning high-level features.",
11360.txt,Classification Performance It is obvious that ps-AOS is not only suitable for CLSC tasks but also suitable for cross-domain sentiment classifications.,
11361.txt,"In this section, we show both cross-lingual and cross-domain sentiment classification experimental results.",
11362.txt,"CL-SCL utilizes many auxiliary unlabeled target language examples, so its accuracy is higher than machine-translation methods and transfer learning.",
11363.txt,"However, CL-SCL is lower than cotraining and our method in terms of accuracy.",
11364.txt,Our ps-AOS model only takes as input the source language examples and the translated target language ones.,
11365.txt,We can observe that comodeling two domains helps improve classification accuracy significantly from the results shown in Table II.,
11366.txt,"Compared to cotraining, our ps-AOS model improves about 5% in terms of accuracy because it provides an informative high-level latent feature representation for reviews, rather than noisy raw word representation.",
11367.txt,"For unsupervised topic models, TSU performs much better than TCA and PSCCLDA because TSU is a fine-grained model and it can capture more accurate latent features.",
11368.txt,It also shows that fine-grained model performs better for sentiment classification task.,
11369.txt,"Therefore, we also adopt fine-grained model for cross-domain situations, where topics are divided into common and specific topics and each topic is further subdivided by sentiment, aspect, and opinion.",
11370.txt,"For classification, each topic with different sentiment polarities is considered as different latent feature representations of reviews.",
11371.txt,"Due to the representation flexibility introduced by coarse alignment and partial supervision introduced by logistic regression, the accuracy is improved about 11% by ps-AOS, compared with TSU.",
11372.txt,"For cross-domain models, TCA and PSCCLDA achieve the worst performance in general.",
11373.txt,This is because TCA and PSCCLDA belong to a coarse-grained document-level model and thus fail to capture the aspects and sentiment details of each review and the exact alignment restricts the representation ability of the models and results in worse accuracy when the source and target domains have different distributions.,
11374.txt,"To verify the effectiveness of the coarse alignment mechanism and partial supervision, we compare ps-AOS with our proposed baseline models under the same parameter settings.",
11375.txt,The only difference between AOS and AOS is the topic alignment mechanism: coarse alignment versus exact alignment.,
11376.txt,"As shown in Table II, we can observe that coarse alignment improves the averaged accuracy over AOS by 7%.",
11377.txt,"Compared with AOS, the partial supervision further improves the classification accuracy by 1.2% and 2% for cross-lingual and crossdomain tasks, respectively, From the abovementioned experiments, we can observe that our ps-AOS not only constructs a fine-grained model to help capture more accurate feature representations across different domains but also employs coarse alignment and partial supervision to help minimize the differences of latent feature representations across domains for CLSC tasks.",
11378.txt,"D. Mining Aspects, Opinions, and Sentiments Besides classification, ps-AOS can mine aspects, opinions, and sentiment polarities, simultaneously.",
11379.txt,Table III shows the top five words of randomly selected one common topic and two specific topics with different sentiment polarity from the English and Chinese DVD reviews data sets.,
11380.txt,Note that the indexes of two specific topics are the same.,
11381.txt,"For example, we retrieve many sentences, such as ""the dvd is broken"" or ""the price is expensive"" from Chinese reviews.",
11382.txt,"For positive sentiment, English customers praise for ""story"" or ""books"" of DVD, whereas Chinese consumers focus more on ""picture"" or ""disc.""",
11383.txt,"Through the earlier observations, we can find the mined aspects and opinions with different sentiment polarities indeed reflect customers' different focuses on the same products and their opinion expression habits.",
11384.txt,"Authorized licensed use limited to: Auckland University of Technology.The aspects, opinions, and sentiments mined by our model not only reveal the similarity and difference between different language consumers' reviews on the same products but also distinguish aspects with different sentiment as different latent features to strengthen the feature representation ability.",
11385.txt,E. Proxy Distance of Feature Representation Ben-David's theoretical work shows that P AD is a metric estimating the similarity of the source and target representations .,
11386.txt,"Generally, a lower PAD value indicates a better representation between two domains.",
11387.txt,We obtain the P AD value as done in X and verify that feature representations learned by ps-AOS in the source and target domains are difficult to distinguish.,
11388.txt,"Compared with TCA and PSCCLDA, ps-AOS further achieves lower P AD values.",
11389.txt,"These observations also explain that sentiment variable and partial supervision in ps-AOS both help learn a better feature representation between two language domains, which plays a critical role on the improvement of classification accuracy in the target language domain.As shown in Fig.",
11390.txt,"3, we can observe that the model achieves the best performance when the ratio of common topics is set to 0.9 in the same domain task  and 0.1 in cross-domain task .",
11391.txt,"The earlier observation indicates that the proportions of common/specific topics in each review should be uneven, and thus, larger  in the EFB task and smaller  in the EDGM task  could fit the distribution of common/specific topics better.",
11392.txt,"Therefore, for EFB task, the best values of  and  are 1e?and 1, whereas the best values for EDGM task are 0.01 and 1e?.",
11393.txt,"In addition to the four hyperparameters, the ratio of common topics and the total number of topics will also influence the performance of the model.",
11394.txt,Fig.,
11395.txt,3 shows the trend of accuracy when the ratio is changed from 0.1 to 0.9.,
11396.txt,In this Authorized licensed use limited to: Auckland University of Technology.,
11397.txt,"It can be observed that our model performs best when the ratio of common topics falls in [0.6, 0.9] for EFB task.",
11398.txt,"The potential reason behind this might be that the source and target domains are both about BOOK despite the language differences, and thus, it is reasonable that two domains share many common topics.",
11399.txt,"For the EDGM task, the model achieves the best accuracy when the ratio of common topics is 0.1.",
11400.txt,"We believe that this is due to the fact that source and target domains of EDGM task come from DVD and MUSIC, respectively, and thus, it is reasonable for these two domains to share only a small number of common topics.",
11401.txt,Fig.,
11402.txt,3 shows the trend of accuracy when the total number of topics is changed from 4 to 40.,
11403.txt,"Generally, the accuracy increases as the total number of topics increases.",
11404.txt,The potential reason is that the model may capture more semantic details about the reviews as the number of topics increase.,
11405.txt,"In this article, we jointly model aspects, opinions, and sentiments through a coarse alignment in a partially supervised way for CLSC tasks.",
11406.txt,"Through the proposed ps-AOS model, we can mine polarized cross-lingual topics and their corresponding opinions in a coarse alignment manner.",
11407.txt,"Moreover, we adopt logistic regression to make full use of labeled data in the source domain to minimize the difference of latent feature representations between two domains.",
11408.txt,Experimental results demonstrate the effectiveness of our model over various kinds of baselines on CLSC tasks.,
11409.txt,"However, our proposed AOS and ps-AOS models still have some limitations to be improved.",
11410.txt,"For example, the number of common/specific topics across domains is predefined and data-dependent.In the future, we need some algorithms to help determine the number of common/specific from the training data automatically.",
11411.txt,"Another improved direction is how to extend our model to solve multiclass cross-domain text classification problems, in which we need to replace the Bernoulli distribution of class labels with multinomial distribution.",
11412.txt,"In machine learning, it is common to interpret each data sample as a multivariate vector disregarding the correlations among covariates.",
11413.txt,"However , the data may actually be functional, i.e., each data point is a function of some variable, such as time, and the function is discretely sampled.",
11414.txt,The naive treatment of functional data as traditional multivariate data can lead to poor performance due to the correlations.,
11415.txt,"In this article, we focus on subspace clustering for functional data or curves and propose a new method robust to shift and rotation.",
11416.txt,The idea is to define a function or curve and all its versions generated by shift and rotation as an equivalent class and then to find the subspace structure among all equivalent classes as the surrogate for all curves.,
11417.txt,Experimental evaluation on synthetic and real data reveals that this method massively outperforms prior clustering methods in both speed and accuracy when clustering functional data.,
11418.txt,"Index Terms?Clustering, curves, functional data, manifold.",
11419.txt,"Machine learning, it is common to interpret each data point as a vector in the Euclidean space .",
11420.txt,"Such a discretization is chosen because it allows for easy manipulations and fast computation, even with large data sets.",
11421.txt,"However, these methods choose to ignore that the data may not naturally fit into this assumption.",
11422.txt,"In fact, much of the data collected for practical machine learning are actually functions or curves.",
11423.txt,"In contrast to feature vectors, functional data encode gradient information, which is vital to analysis.",
11424.txt,"For example, financial data, such as stock or commodityprices, are functions of monetary values over time .",
11425.txt,"Recently, functional data have become increasingly important in many scientific and engineering research areas, such as electrocardiogram  or electroencephalography in healthcare , subject outlines in both macrobiology and microbiology, weather or climate data , astronomy , and motion trajectories from computer vision.",
11426.txt,"Analyzing functional data has been an emerging topic in statistical research and has attracted great attention from machine learning community in recent years , .",
11427.txt,"Theoretically, functional data are of infinite dimension.",
11428.txt,"Due to discretization, there are only limited samples taken from a functional observation.",
11429.txt,A strong correlation between neighboring samples and the information loss during discretization are major challenges for analysis.,
11430.txt,The desired model for functional data is expected to properly and parsimoniously characterize the nature and variability hidden in the data.,
11431.txt,The classic functional principal component analysis  is one of such examples to discover dominant modes of variation in the data.,
11432.txt,"However, fPCA may fail to capture patterns if the functional data are not well aligned in its domain.",
11433.txt,"For time series, a special type of functional data, i.e., dynamic time warping, has long been proposed to compare time series based on shape and distortions along the temporal axis.",
11434.txt,Another important type of functional data is shape.,
11435.txt,"The shape is an important characterizing feature for objects, and in computer vision, the shape has been widely used for the purpose of object detection, tracking, classification, and recognition.",
11436.txt,"In fact, a natural and popular representation for shape analysis is to parameterize the boundaries of planar objects as 2-D curves.",
11437.txt,"In object recognition, images of the same object should be similar regardless of resolution, lighting, or orientation.",
11438.txt,"Hence, an efficient shape representation or shape analysis scheme must be invariant to scale, translation, and rotation.",
11439.txt,"Our intention in this study is to consider functional data clustering by accounting for the possible invariance in scaling/stretching, translation, and rotation of functional data.",
11440.txt,"The focus of this article is upon functional data, including continuous functions parameterized by a single variable, such as time and shapes in the Euclidean spaces.",
11441.txt,The main characteristic that we are interested in is that the functions are actually clustered in underlying subspaces.,
11442.txt,"In other words, the original functions are sampled from several subspaces, which are embedded in a space with infinitely many dimensions.",
11443.txt,"However, the observed functions are affected by geometric distortions and noise for some reason.",
11444.txt,"The distortions creep in the multivariate representations of the functions and effectively break down the subspace identification methods built on classic multivariate data, even for those with robustness designed in the models to handle fairly large noises.",
11445.txt,"The solution to this problem relies on countering distortions, and the way we approach it is to manipulate the observed functions such that the transformed versions are invariant to distortions, or in other words, we group the distorted versions of one function to be an equivalent class and treat the whole class as a datum in clustering.",
11446.txt,"The equivalent class as a new representation accommodates all possible distortions and, hence, an infinite class.",
11447.txt,"However, the cost is that the new representation of functions has some geometric structure, which has to be dealt with to achieve the final goal.",
11448.txt,"This geometric structure, in particular, is a quotient manifold where each point is an equivalent class of functions that are transformed versions of each other.",
11449.txt,The original subspace then becomes subspaces in this quotient manifold.,
11450.txt,"However, it has no obvious coordinate representation, and hence, no computation can be carried out directly.",
11451.txt,"We get around this problem by projecting points into tangent space, a vector space regarded as a local approximation of the manifold, where we model the relations among the images of the points for clustering purposes.",
11452.txt,A very useful shape representation we consider is the square-root velocity function representation .,
11453.txt,"In general, the resulting SRVF of a continuous shape is squareintegrable, belonging to the well-defined Hilbert space where appropriate measurement can be applied.",
11454.txt,Refer to Section III for more details.,
11455.txt,"By acknowledging the true nature of the data, we develop a more robust clustering method that exploits features that would otherwise be ignored or lead to erroneous results with simple linear models.",
11456.txt,The rest of this article is organized as follows.,
11457.txt,"In Section II, we discuss related work in this field.",
11458.txt,"In Section III, we review the preliminaries about the SRVF and more importantly the manifold of open curves and introduce our robust functional manifold clustering  model.",
11459.txt,"Section IV is dedicated to explaining an efficient algorithm for solving the optimization in the realization of our model based on the linearized alternative direction method with an adaptive penalty , and the algorithm convergence and complexity are also analyzed.",
11460.txt,"In Section V, the proposed model is assessed on both synthetic and real-world databases against several state-of-theart methods.",
11461.txt,"Finally, conclusions are discussed in Section VI.",
11462.txt,The simplest approaches for clustering functional data have relied heavily on DTW .,
11463.txt,DTW is an alignment technique that aims to warp the time axis of the data until the difference between the two sequences is minimized.,
11464.txt,"DTW also provides a distance measurement between the two sequences, once aligned.",
11465.txt,"Historically, DTW has been mainly used for large scale data mining, where queries are performed to quickly find the nearest neighbors to sequences of data .",
11466.txt,"However, the aligned distance produced by DTW has been used for the clustering of functional data.",
11467.txt,"In its simplest form, DTW is used to produce a pairwise distance matrix for the entire data set.",
11468.txt,"Then, the distance matrix is used by a hierarchical or spectral clustering method to produce the final clusters.",
11469.txt,"Although these DTW-based approaches are computationally cheap, their clustering accuracy leaves much to be desired.",
11470.txt,This is due to two flaws in DTW.,
11471.txt,"First, the distance measurement for DTW is based on the Euclidean distance between each point in the sequence.",
11472.txt,This totally ignores any gradient-based information in the sequence.,
11473.txt,"Second, warping accuracy is dependent on the correct choice of window size.",
11474.txt,Poor choices of warping window size can have a dramatic impact on warping and alignment accuracy .,
11475.txt,"Other methods, such as DTW-HMM, have used DTW-based clusters as an initialization point for more advanced methods, such as hidden Markov models.",
11476.txt,A more sophisticated approach for functional data clustering is to use probabilistic methods.,
11477.txt,Early methods used simple Gaussian probability models.,
11478.txt,"However, these models only hold for the Euclidean vector data where the notions of cluster centers and cluster variance can be easily quantified .",
11479.txt,"Zhang  proposed the Bayesian clustering of curves, which is similar in nature to DTW pairwise distance clustering with advances that address most of the drawbacks.",
11480.txt,The distance matrix is based on the analysis of the data points in the curve manifold.,
11481.txt,"Then, the clustering is performed on the distance matrix by using a probabilistic method that simultaneously finds the cluster assignment and the number of clusters automatically.",
11482.txt,"We now draw the readers' attention to subspace clustering methods, as they apply to many situations that traditional clustering methods cannot handle well.",
11483.txt,"Different from finding spatially concentrated clusters measured by the usual Euclidean metric, these methods aim to segment the data into clusters with each cluster corresponding to a unique subspace.The restriction to W as being sparse or low rank has the effect of selecting points from subspaces.",
11484.txt,"Therefore, W can be used as an affinity matrix to form a graph and a spectral clustering method, such as nCUT, to obtain the final subspace labels.",
11485.txt,"Of course, there is always noise in the observed data, which has to be modeled for robustness.",
11486.txt,Authorized licensed use limited to: University of Exeter.,
11487.txt,The subspace assumption can still be valid for the bases being functions as well.,
11488.txt,"This is obvious in spectroscopy where some material spectrum is a mix of several spectra of pure materials , which is one set of bases.",
11489.txt,Segmenting spectra according to their constituents is exactly subspace clustering.,
11490.txt,"Similar applications like this are abundant in many areas, such as computer vision, where the data are essential functions, and therefore, subspace clustering is very useful in a functional setting.",
11491.txt,"As a consequence of the validity of the subspace assumption, the reconstruction in X still holds.",
11492.txt,This justifies the direct application of the subspace clustering to the multivariate representation of functional data when they are clean.,
11493.txt,"However, the observed functionals can be affected by many things except for additive noise.",
11494.txt,The most serious one is distortions in shape.,
11495.txt,"For example, in thermal infrared data of geological substances, a curve may contain a key identifying feature, such as a dip near a particular frequency.",
11496.txt,"This dip may shift or vary position even for the same substance due to impurities, or in other cases, the feature may be elongated, shrunk, or subject to some nonuniform warping or scaling.",
11497.txt,"Unfortunately, these distortions commonly exist in functional data.DTW correction can alleviate the problem to some extent, with the limitation of only dealing with shift effectively.",
11498.txt,"Moreover, when two functions are from different subspaces, the optimal alignment is not clear, and the alignment outcome can be misleading as the shape features of functions can be misaligned during the process.",
11499.txt,"Nonetheless, the DTW idea is interesting.",
11500.txt,"Now, the data in the subspace assumption become equivalent classes instead of individual functions.",
11501.txt,"Although the equivalent class has no explicit vector form, its geometric structure may be used for the computational purpose to recover the subspaces underpinning these equivalent classes.",
11502.txt,"Thus, we need two components at the same time, the map F accounting for distortions which has a suitable geometric structure.",
11503.txt,Section III is dedicated to explaining the details of the development of our method.,
11504.txt,Please note that the differential geometry is involved in this method.,
11505.txt,The work in X is an excellent reference for all the concepts used in this article.,
11506.txt,We start with a few observations.,
11507.txt,"The first is that the distinct features of functions are usually in the rate of changes, such as valleys and peaks, which can be better captured by the first derivative.",
11508.txt,"The third is that the rotation is a simple linear operation whose matrix representation is a rotation matrix.From the line of its development, we see that the functional subspace assumption holds because the gradient and rotation are linear operators and reparameterization works on function bases as well.",
11509.txt,"However, the obstacle now is that Sois an abstract unitary sphere with no obvious vector form.",
11510.txt,Recovering the subspace structure is not straightforward.,
11511.txt,"Nonetheless, the tangent space of any smooth manifold at any point is a well-defined vector space with the same dimensionality as the manifold.",
11512.txt,Observe that the projection to tangent space on unitary sphere Snin Rn+1preserves the subspace structure of the points on the sphere.,
11513.txt,"If the foot of a tangent space is from one subspace, then this subspace will have one less dimension in the tangent space.",
11514.txt,This is illustrated in Fig.,
11515.txt,This prompts us to use tangent space on So.,
11517.txt,"Fortunately, the computation is readily available.",
11518.txt,The advantage of doing this is not only avoiding a vanishing point but also increasing the stability of subspace recovery process.,
11519.txt,The next step is to consolidate the multiple views.,
11520.txt,"Once solved, W can be used as an affinity to build a graph.",
11521.txt,"As W has a consistent pattern within each subspace, the graph should consist of several connected components corresponding to subspaces and graph cut can then be applied to segment them.",
11522.txt,"In particular, we use nCUT for its good performance in both accuracy and efficiency in spectral clustering.",
11523.txt,We call our method rFMC.,null
11524.txt,"Complexity Analysis For ease of analysis, we first define some symbols used in the following.",
11525.txt,"Let K and r denote the total number of iterations and the lowest rank of the matrix W, respectively.",
11526.txt,Convergence Analysis Algorithm 1 is adopted from the algorithm proposed in X.,
11527.txt,"However due to the terms of Bi's in the objective function, the convergence theorem proved in X cannot be directly applied to this case as the linearization is implemented on both the augmented Lagrangian terms and the term involving Bi's.In all the experiments, we have conducted that the algorithm converges very fast at K < 100.In this section, we evaluate the clustering performance of rFMC on synthetic, semisynthetic, and real-world data sets.",
11528.txt,"We compare our algorithm with two baseline algorithms, k-means and spectral clustering of a DTW distance matrix, and the state-of-the-art Bayesian clustering of curves.",
11529.txt,"We also compare against LRR and SSC, two highly cited multivariate subspace clustering methods.",
11530.txt,Note that we used nCUT to find final clustering solution for LRR and SSC as well.,
11531.txt,"To help evaluate consistency, we fixed the parameters to the same values for every experiment.",
11532.txt,Parameters were selected by testing a wide range of values over all data sets so that the best average result for each method was obtained.,
11533.txt,"For our DTW baseline algorithm, we set the warping window to 10% of the data length, which has been shown to be suitable in most cases .",
11534.txt,The SCA metric is taken over all possible pairwise assignments of clusters.,
11535.txt,"Toy Synthetic Data Clustering First, we attempt to verify that rFMC achieves its design purpose for robustness against distortions in subspace recovery, while other methods without the consideration of the special properties of functions, such as LRR and k-means, would be inferior.",
11537.txt,"The curves in each cluster were sine waves, with each cluster corresponding to a unique frequency from 0.1 to 40 Hz.",
11539.txt,"Within each cluster, we applied progressive amounts of warping.",
11540.txt,See Fig.,
11541.txt,2 for an example of data from three synthetically generated clusters.,
11542.txt,"For each number of clusters setting, we repeated the experiment 50 times with new data generated each time to obtain basic statistics of SAC.",
11543.txt,Results are reported using subspace clustering accuracy and can be found in Table I and Fig.,
11544.txt,"Note that in Table I and the following ones, the number besides rFMC indicates the number of clusters tested, andT in the tables is the average run time for the algorithms in the tests.",
11546.txt,This is a challenging data set due to a large number of distortions.,
11547.txt,"However, in this experiment, rFMC achieves very high clustering accuracy in terms of the statistics of accuracy values.",
11548.txt,From Fig.,
11549.txt,"3, it is clearly seen that rFMC outperforms other Authorized licensed use limited to: University of Exeter.",
11550.txt,Each cluster has a base sine curve that is progressively warped with each successive instantiation.,
11551.txt,"When the number of clusters grows, the performance decreases due to increasing difficulty.",
11552.txt,"Note that when the number of clusters reaches 8, the clustering accuracies of all methods drop below 50%, which is not informative.",
11553.txt,"Moreover, some methods, such as the Bayesian become unstable, for some reason.",
11554.txt,"Thus, we set 8 as the maximum number of clusters in all tests.",
11555.txt,"In the following experiments, we test 3, 5, and 8 clusters to observe the behavior of different methods in terms of both clustering accuracy and the trends when the number of clusters varies.",
11556.txt,B. Semisynthetic Thermal Infrared Spectra Clustering We assemble semisynthetic data from a library of pure infrared hyperspectral mineral data.,
11557.txt,"For each cluster, we pick one spectral sample from the library as a basis.",
11558.txt,Each curve basis is then randomly shifted and stretched in a random portion.,
11559.txt,This random warping is performed 20 times to produce the curves for each cluster.,
11560.txt,4 for an example of data used in this experiment.,
11562.txt,"Again, as in the previous experiment, we repeated the test 50 times.",
11563.txt,"Results are reported in Table II.On the other hand, rFMC almost perfectly clustered the data with superb consistency across all cases.",
11564.txt,"The closest competitor was the Bayesian method, which also performed well by clustering accurately most of the time at the cost of extremely high computation load.",
11565.txt,"However, in some cases, the clusters produced were of poor quality, which can be observed in the minimum accuracy and standard deviation statistics.",
11566.txt,"Therefore, rFMC is far more reliable and efficient at clustering this data than other methods.",
11567.txt,Authorized licensed use limited to: University of Exeter.,
11568.txt,"Handwriting Character V elocities In this experiment, a real-world data set consisting of a collection of pen tip trajectories of handwritten English characters was used to evaluate performance.",
11569.txt,"The data set consists of pen position data collected by a digitization tablet at 200 Hz, which is then converted to horizontal and vertical velocities.",
11570.txt,These 2-D trajectory curves are normalized such that the mean of each curve is close to zero.,
11571.txt,6 shows the example plots of curves used in this experiment.,
11575.txt,"For each run of this test, 20 characters were randomly selected from three, five, and eight random character classes.",
11576.txt,"The data as originally released have been carefully produced and processed so that trajectories for each character are extremely similar, far more so than is realistic.",
11577.txt,"For example, the start time for each character has been aligned; furthermore, the writing speed, character size, and variance in velocity over time are extremely consistent.",
11578.txt,"Therefore, to make the data more realistic, we randomly globally shift each character so that their start times vary.",
11579.txt,"Furthermore, we randomly globally stretch and shrink each trajectory to account for different writing speeds, we also scale the trajectories by applying constant factors to account for character size, and finally, we perform local warping  to account for variance in speed over time.",
11580.txt,Example data from the character velocity data set.,
11583.txt,The top row plots the x and y pen tip velocities over time for three sample characters.,
11584.txt,RFMC shows excellent performance with a median accuracy of 86% for the case of three classes on this extremely challenging data set.,
11586.txt,The closest competitors only reach a median clustering accuracy of 50%.,
11587.txt,A similar comparison can be observed in other cases.,
11588.txt,It is clear to see that rFMC outperforms other methods in all metrics in all cases of various numbers of classes.,
11589.txt,Authorized licensed use limited to: University of Exeter.,
11590.txt,"Handwriting Character Trajectories In this experiment, we used the Chars74K data set, which consists of pen tip positions  of handwritten English characters.",
11591.txt,The data set consists of 62 character classes with 55 samples per class.,
11592.txt,"Similar to the previous experiment for each run of this test, 20 characters were randomly selected from three, five, and eight random character classes, and 50 runs were performed.",
11593.txt,"However, different from the previous experiment, we do not apply any further postprocessing to reduce alignment since this data set is relatively unprocessed.",
11594.txt,Results can be found in Table IV.,
11595.txt,"In spite of the aforementioned challenges with this data set, rFMC leads by a significant margin.",
11596.txt,"Notably, the Bayesian clustering suffered many clustering failures leading to very poor accuracy.",
11597.txt,This was due to implementation limitations in the original code provided from X.,
11598.txt,We also have to exclude LRR for the cases where the number of classes is more than 3 because it failed on most random samples.,
11599.txt,"This data was captured at 100 Hz, and no postprocessing was applied.",
11600.txt,"The signs were collected three at a time over a period of nine weeks, so there is noticeable variation within each class.",
11601.txt,"As with the previous experiments, for each run, 20 data points were randomly selected from three, five, and eight random word classes, and 50 runs were performed.",
11602.txt,"Only the position, roll, pitch, and yaw channels were used since the finger bend measurements were far too noisy and unreliable to be of use.",
11603.txt,We also performed a parallel test to determine the effectiveness of smoothing as the first attempt for noise handling.,
11604.txt,A multichannel total variation-based smoothing method was used .,
11605.txt,Results can be found in Tables V and VI.,
11606.txt,"Overall, rFMC performed Authorized licensed use limited to: University of Exeter.",
11607.txt,"In this article, we proposed an algorithm called rFMC to reliably and accurately cluster functional data in terms of their subspaces.",
11608.txt,"This is a highly challenging problem as functional data from the same class can vary greatly due to stretching, shrinking, nonuniformly warping, and scaling.",
11609.txt,We achieved this by representing functional data in curves manifold invariant to these distortions and addressed the challenge of lack of vector forms.,
11610.txt,The analysis is performed in tangent spaces of each point in the manifold via the recovery of null spaces of the log maps of the points to solve the multiple view problems.,
11611.txt,An optimization scheme with a convergence guarantee was also provided to realize the model.,
11612.txt,"Nevertheless, this article still leaves many areas open for further research.",
11613.txt,"First, we only address the data on the manifold of open curves; however, much of the data in recognition and computer vision tasks will lie on the manifold of closed curves.",
11614.txt,"Moreover, our focus was on robustness against geometric distortions.",
11615.txt,Additive noise will be carried through the transformations onto the curve manifold and affect the performance.,
11616.txt,"However, the mechanism is not fully understood although the proposed algorithm can be applied in this case.",
11617.txt,"Nonetheless, it is interesting to study the noise to further improve the results.",
11618.txt,We leave solving these problems for future research.,
11619.txt,Pneumatic devices require tight tolerances to keep them leak-free.,
11620.txt,"Specialized companies offer various off-the-shelf devices, while these work well for many applications, there are also situations where custom design and production of pneumatic parts are desired.",
11621.txt,"Cost efficiency, design flexibility, rapid prototyping, and MRI compatibility requirements are reasons why we investigated a method to design and produce different pneumatic devices using a laser cutter from acrylic, acetal, and rubber-like materials.",
11622.txt,"The properties of the developed valves, pneumatic cylinders, and stepper motors were investigated.",
11623.txt,A MRI-compatible robotic biopsy system driven by the pneumatic stepper motors is also demonstrated.,
11624.txt,We have shown that it is possible to construct pneumatic devices using laser-cutting techniques.,
11625.txt,"This way, plastic MRI-compatible cylinders, stepper motors, and valves can be developed.",
11626.txt,"Provided that a laser-cutting machine is available, the described pneumatic devices can be fabricated within hours at relatively low cost, making it suitable for rapid prototyping applications.",
11627.txt,Pneumatic cylinders are used in many applications.,
11629.txt,These come in different sizes and are being produced by many companies worldwide.,
11630.txt,"The key elements are the bore, piston, and seal, and are normally cylindrically shaped and made of metal.",
11631.txt,"Pressurized air exerts a force on the piston, which causes it to slide within the bore.",
11632.txt,The sliding seal ensures that no air escapes from the chamber.,
11633.txt,"Sometimes, a custom cylinder design is desired, for example, when integrating one or more cylinders in a small mechanical device.",
11634.txt,"Also, MRI compatible systems restrict the usage of metallic materials, because of the strong magnetic fieldinvolved in MRI scanners.",
11635.txt,"Furthermore, the commercial pneumatic devices are often too expensive for low-cost projects by hobbyists.",
11636.txt,"So, there is a desire for a method to design and produce custom pneumatic parts quickly and at relatively low cost.",
11637.txt,A laser cutter can cut out complex 2-D shapes with high precision from plates of various materials.,
11638.txt,"In this paper, we propose a method to assemble functional pneumatic devices from laser-cut parts.",
11639.txt,The properties of these devices are then measured and discussed.,
11640.txt,A functional prototype of an MRI-compatible robotic device is also presented.,
11641.txt,Earlier Research No earlier records involving functional laser-cut pneumatic devices could be found.,
11643.txt,"While laser-cutting techniques are used extensively in different fields of engineering , it is  not yet used for manufacturing pneumatic devices.",
11644.txt,"So, in this section, we focus on existing  A different design of the same kind of motor is given in Fig.",
11645.txt,"2, which was developed by Sajima.",
11646.txt,"Most off-the-shelf pneumatic cylinders involve metallic materials, but there also exist commercial plastic pneumatic cylinders.",
11647.txt,"The miniature LEGO pneumatic cylinder is a fully plastic pneumatic cylinder, which could be used in the MRI-compatible systems.",
11648.txt,Chen et al.,
11649.txt,"combined two of such cylinders to construct a four-phase rotational stepper motor, while it proved to be effective, the motor is also quite large compared to the pneumatic cylinder size.",
11650.txt,"METHODS In this section, it is described how a laser-cut pneumatic piston can be designed and constructed.",
11652.txt,"A. Cylinder Geometry The basic cylinder consists of a housing assembled from multiple laser-cut parts, stacked, and fixedtogetherwithscrews.See Fig.",
11653.txt,"3, for a computer-aided design model.",
11654.txt,The housing basically consists of three layers.,
11655.txt,"Additional, thin sheets can be used to increase the thickness of the middle layer.",
11656.txt,"A piston is then placed in the opening of the middle layer, and a box-shaped rubber seal, adjacent to the piston, seals off the air chamber.",
11657.txt,"When the parts are sufficiently smooth and well tightened together, then no gaskets are needed to avoid air leakages.",
11658.txt,"This way, a single-acting pneumatic cylinder with an approximate rectangular cross section is constructed.",
11659.txt,These can be used for the cylinder housing and the piston.,
11660.txt,Extruded acrylic plates tend to have less variations in thickness than cast acrylic.,
11661.txt,Acetal plates also tend to be more constant in thickness than acrylic plates.,
11662.txt,Sheets of paper or polyester can be used as spacers.,
11663.txt,"Silicone rubber or Trotec laserrubber of thickness 1.5? mm can be used for sliding seals within the bore, and for pneumatic routing between plates.",
11664.txt,Standard off-the-shelf pneumatic tubing is used to supply air to the chambers.,
11665.txt,"Metal  or plastic screws can be used as fastener, in combination with nuts or tapped holes in the bottom part.",
11666.txt,"Metal screws can yield higher compression forces, but only the plastic ones are MRI compatible.",
11667.txt,A sealant such as blue silicone  can also be used to make the housing completely airtight.,
11668.txt,C. Dimensions and T olerances Pneumatic cylinders only work smoothly and leak-free when the dimensions of all parts are accurately designed and fabricated.,
11669.txt,"4, for a cross section of the cylinder, showing the housing , piston, and spacer.",
11671.txt,"The cylinder housing needs to have relatively thick walls, to resist bulging of the parts under pressure.",
11672.txt,This is a limitation that circular cylinders do not have.,
11673.txt,"Another option is to reduce the piston plate's thickness hpusing laser engraving, or by grinding with sand paper.",
11674.txt,"When the seal is laser-cut, the laser kerf's edges are slanted with some angle , which can be exploited to obtain the desired shape.",
11675.txt,"It is also possible to handcut the seals with a knife; while this is less accurate than laser cutting, it allows for a larger angle  and, thus, more tolerance.",
11676.txt,"5, for some laser-cut and hand-cut seals, photographed from different sides.",
11678.txt,"Because of the thickness variation of plates, the dimensioning of certain parts may need to be adapted to the actual thickness of other parts.The manufacturing procedure is as follows: Manufacture cylinder housing and piston.",
11679.txt,"In case of air leakage or excessive seal friction, repeat from step 3.",
11683.txt,"Kerf Geometry When the laser cutter cuts out a piece, material is molten and evaporated along the cutting line.",
11684.txt,"The gap is called the kerf, and knowledge about its geometry is essential to obtain parts with the right dimensions.",
11685.txt,Its cross-sectional shape is approximately trapezoid.,
11686.txt,"The dimensions {kt,kb} depend on the material type, thickness d, laser type, lens' focal distance and focal point, cutting power, speed, frequency, assistant gas, and the local temperature, which in turn depends on the cutting Fig.",
11687.txt,"Various parts laser-cut from acetal , acrylic , and silicone rubber .",
11689.txt,trajectory.,
11690.txt,"The kerf's edges should be as smooth as possible, as grooved edges negatively affect the cylinder performance.",
11691.txt,The optimal settings to obtain a good and clean cut can be determined experimentally.,
11692.txt,"When the working settings are determined for a certain material, its kerf can be measured and can be accounted for in the initial design, and then be further optimized experimentally.",
11693.txt,"The trapezoidal shape of the kerf implies that all the walls of the cut-out parts have slanted edges with angle . T h i s i s not necessarily a problem, as it can be accounted for in the design.",
11694.txt,"For example, the piston can be placed upside-down in the housing, so that the slanted edges of the housing and piston are approximately parallel.",
11695.txt,"The seals also make use of the slanted edges resulting from laser cutting, to control the difference in dimensions wstand wsbin Fig.",
11696.txt,"Otherwise, the seal would lose contact with the piston, and become dislocated rendering it ineffective.",
11698.txt,"A double-acting cylinder is more useful than a single-acting cylinder, as this can perform both outstroke and instroke motions.",
11699.txt,"The simplest way is to connect two single-acting cylinders opposite to each other.The rod does not pass through either chamber, because it would be very difficult to seal it properly.",
11700.txt,"Stepper Motors A double-acting cylinder has two well-definedstates,withthe piston being in either extreme position.",
11701.txt,"Controlling the piston to intermediate positions as well is difficult: it would require position feedback and precise pressure control, and it would result in a compliant actuator due to the compressibility of air, which is generally not desired.",
11702.txt,"So, in this section a different mechanism, a three-phase pneumatic linear stepper motor, is presented which is relatively easy to drive and allows discrete position control of an arbitrary long rack.",
11703.txt,The schematic mechanism of the stepper motor is shown in Fig.,
11704.txt,"The rack slides to left or right, when the threetoothed pistons move up and down in the correct order, working as a wedge on the rack.",
11706.txt,"The step size is one-third of the pitch P. Each piston is driven by a separate double-acting cylinder, so there are six pressure chambers in total.",
11707.txt,Symmetric Stepper Motor: The symmetric stepper motors use rectangular pistons.,
11708.txt,"First, the housing was constructed, consisting of seven layers Fig.",
11709.txt,Stepper motor mechanism showing rack and three pistons .,
11711.txt,"In certain motors, the seals were cut with a knife, in the other ones the seals were laser-cut.",
11712.txt,The seal's dimensions were repeatedly adjusted until the pneumatic cylinders operated smoothly with neither significant air leakage nor excessive friction.,
11713.txt,"Next, the exact distances between the pistons in the housing were measured in order to calculate the piston teeth shape, as these have to be phased 120apart.",
11714.txt,"After laser cutting, the teeth pieces , the acrylic ones were glued to the pistons, while the acetal teeth were snapfit into its locations.",
11715.txt,5 shows some pistons and racks made from both materials.,
11717.txt,Valves are needed to control the pneumatic cylinders and stepper motors described in the previous sections.,
11718.txt,A valve consists of a mechanism that can open and close pneumatic connections.,
11719.txt,"Like the pneumatic cylinders, the valves can also be constructed with the laser-cutting techniques.",
11720.txt,"In this section, several design strategies and motorized pneumatic valves are presented.",
11721.txt,By rotating the wheel over 45? the interconnections between the orifices are changed and different functional states can be reached.,
11722.txt,"The wheel is connected to this servo by means of a gear shaft coupler with an elastomeric spring, to compensate for any angular misalignment.The ball joints are all 3-D printed by the Stratasys Objet Eden250 printer with a FullCure720 material, and the other structural parts are mostly laser-cut from acetal.",
11723.txt,"Except for the needle itself, all parts of the biopsy robot are made of plastic and, thus, MRI-compatible.",
11724.txt,The robot is driven by a pneumatic distributor system as shown in Fig.,
11725.txt,"It consists of an eight motorized 8/6-way valves as described in the Section IV -B, and are manually operated.",
11727.txt,The maximum switching frequency of the pneumatic cylinders and stepper motors should be sufficiently high for the application.,
11728.txt,"This mainly depends on the working pressure, valve switching speed and airflow, tube dimensions, and pneumatic cylinder displacement volume.",
11729.txt,"For pneumatic cylinders and stepper motors, the net force is an important characteristic.",
11730.txt,"To learn about these parameters, various measurements were performed which are described in this section.",
11731.txt,Test setup for force measurements of cylinders and stepper motors.,
11732.txt,"acrylic single-acting cylinder with a cross-sectional bore area of 141 mm2was put under increasing and then decreasing pressure from 0.5 to 6 bar, while the load on the rod was measured with a spring scale.",
11733.txt,Three different seals were included in the test.,
11734.txt,An acrylic stepper motor with a cross-sectional bore area of 78.4 mm2was also tested with the same setup.,
11735.txt,The teeth depth was 6 mm and the pitch was 2 mm.,
11736.txt,"The pressure varied from 1 to 4 bar; for each pressure level the stepper motor was operated very slowly, up to the point that the rack could no longer overcome the spring scale force.",
11737.txt,"The test was then repeated with a different rack and set of pistons, now with a pitch size of 4 mm.",
11738.txt,"The valve airflow was measured by filling a 1.35-L tank, while the transient pressure was being recorded.",
11739.txt,The working pressure varied from 1 to 6 bar.,
11740.txt,"The maximum airflow at each working pressure level was derived from the highest rate of pressure change, and also compared with the airflow resulting from depressurizing the air tank.",
11741.txt,"13 shows the force as a function of applied pressure for the singleacting cylinder, for three different seals.",
11743.txt,"There is some hysteresis caused by the friction of the seal, so the measured force during increasing pressure is lower than during decreasing pressure.",
11744.txt,"Maximum switching frequency of a double-acting cylinder for various pressure levels and tube length/diameter sizes.The airflow is mainly restricted by the diameter of the orifices in the valve, which measure approximately 1 mm in diameter The effective orifice diameter is about 0.8 mm.",
11745.txt,The depressurization airflow was also measured and found to be approximately equal or slightly higher than the pressurization airflow.,
11746.txt,which have become increasingly popular in the field of artificial intelligence .,have become increasingly popular in the field of
,"and if so, which types of communication structures are most helpful in that respect.",are most helpful in
,"most notably, questions concerning the conditions that lead a community of  initially disagreeing agents to reach a consensus and those that lead to polarization.",most notably
,"but it is more interesting  to know whether this dynamics has any effect on accuracy, again measured in terms of SSEs.",it is more interesting  to know whether this dynamics has any effect on accuracy
,there is not much difference between lying a little and lying a lot: neither is very effective in that case.,there is not much difference
,we could only draw limited conclusions on the relation between the understanding on the one hand and task performance  and persuasiveness on the other hand.,
,"it does not necessarily provide insights or constraints into those intermediate levels of computation, or deep structure, that are perceived as ultimately necessary in order to design highly reliable computer vision systems.",
,"at the same time, in a significantly less complex surface mesh for  3D computer graphics applications.",
,"resulting in  a  considerably higher quality  of synthesized views for 3D video applications and,",resulting in
,our adversarial reverse mapping method may  be an effective way to avoid overfitting or "steganography" effect when the domains have different entropy.,may  be an effective way to
,it is essential to have an insight about the accuracy of the search strategy in use.,it is essential to
,without taking the effect of the non-optimum search strategy into account.,taking into account
,"By using the coupled features, we can observe that the prostate-likelihood maps of CF+SCOTO are much better than that of OF+SCOTO.",much better than
,thus they are much more efficient for evaluation.,are much more efficient for
,The proposed two-step method is flexible for incorporating with different kinds of hash  functions  and  loss functions.,is flexible for
,We have shown that various kinds  of  loss  functions and hash functions can be placed in a unified learning framework for supervised hashing.,We have shown that
,"the prostate boundaries are still hard to distinguish since the large prostate motion and appearance change greatly deteriorates the regression results in some cases, especially for the pixels around    the prostate boundaries.",are still hard to
,"it is worth noting that, for prostate segmentation, using structure information based overlapping group strategy to partition blocks   to several overlapped groups is not a trivial task.",it is worth noting that
,it is unclear how to extend them to the more general weakly labeled learning problem.,it is unclear how to
